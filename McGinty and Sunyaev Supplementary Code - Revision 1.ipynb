{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20cae3a5",
   "metadata": {},
   "source": [
    "# McGinty and Sunyaev, Supplementary Code\n",
    "## Table of contents <a name=\"TOC\"></a>\n",
    "1. [Process sample dataset or full dataset?](#sample)\n",
    "2. [Load libraries and define functions which will be used throughout the analysis](#libraries)\n",
    "    1. [Load python libraries](#libraries1)\n",
    "    2. [Define functions](#functions)\n",
    "3. [Process hg38 genome fasta files](#hg38)\n",
    "    1. [Download files](#hg38download)\n",
    "    2. [Read files](#hg38read)\n",
    "    3. [Count trinucleotides](#hg38count)\n",
    "4. [Use Repeatmasker to remove transposable elements from hg38](#RM)\n",
    "    1. [Download files](#RMdownload)  \n",
    "    2. [Read and format files](#RMread)\n",
    "    3. [Count trinucleotides](#RMcount)  \n",
    "    4. [Modify genome fastas to remove Repeatmasker regions](#RMmodify)  \n",
    "5. [Generate a database of repeat motifs in hg38](#DB)\n",
    "    1. [Short Tandem Repeats](#DB_STR)  \n",
    "        1. [Define search features](#DB_STR_define)\n",
    "            1. [All possible N-mers](#DB_STR_define_allNmers)  \n",
    "            2. [Reduce to nonredundant N-mers](#DB_STR_define_nonredundant)  \n",
    "            3. [Find high-N-mers that repeat at least once](#DB_STR_define_reduce)  \n",
    "        1. [Search, including overlaps](#DB_STR_search)\n",
    "        2. [Expand by full repeat unit](#DB_STR_expand_full)\n",
    "        3. [Expand by partial repeat units to get longest perfect STRs](#DB_STR_expand_partial)\n",
    "        4. [Find imperfect STRs](#DB_STR_imperfect)\n",
    "            1. [Overlap coordinates](#DB_STR_imperfect_overlap)\n",
    "            2. [Find location of interruptions within each STR](#DB_STR_imperfect_location)\n",
    "            3. [Separate perfect vs imperfect STRs](#DB_STR_imperfect_separate)\n",
    "            4. [Reversion predictions for in-frame interruptions](#DB_STR_imperfect_predict)\n",
    "            5. [Save/load STR database](#DB_STR_imperfect_save)\n",
    "        5. [Mask reference genome with STRs](#DB_STR_mask)\n",
    "    2. [Inverted Repeats](#DB_IR)  \n",
    "        1. [Find all 5-mer IRs](#DB_IR_5mer)\n",
    "        2. [Expand perfect IRs](#DB_IR_expand)\n",
    "        3. [Expand imperfect IRs](#DB_IR_expand_imperfect)\n",
    "    3. [Mirror Repeats](#DB_MR)  \n",
    "        1. [Find all 5-mer MRs](#DB_MR_5mer)\n",
    "        2. [Expand perfect MRs](#DB_MR_expand)\n",
    "        3. [Expand imperfect MRs](#DB_MR_expand_imperfect)\n",
    "    4. [Direct Repeats](#DB_DR)  \n",
    "        1. [Find perfect DRs](#DB_DR_perfect)\n",
    "        2. [Expand imperfect DRs](#DB_DR_imperfect)   \n",
    "    5. [Z-DNA Motifs](#DB_ZDNA)  \n",
    "        1. [Version 1: RY without AT](#DB_ZDNA_v1)\n",
    "        2. [Version 1: GY](#DB_ZDNA_v2)\n",
    "    6. [G4 Motifs](#DB_G4)  \n",
    "        1. [Leftover from hg19 to hg38](#DB_G4_liftover)\n",
    "        2. [Combine K+ and PDS G4-seq conditions](#DB_G4_combine)\n",
    "        3. [Check for overlap between PDS and K+ G4-seq conditions](#DB_G4_overlaps)\n",
    "        4. [Confirm strand orientation and locate motifs](#DB_G4_motifs)\n",
    "        5. [Save/load G4 database](#DB_G4_save)\n",
    "    7. [Combine all motifs into single database](#DB_all)\n",
    "        1. [Calculate distance to motifs and transposons, then filter database to unique motifs](#DB_all_distance)\n",
    "        2. [Motif type overlaps](#DB_all_overlaps)\n",
    "            1. [Plot for Supplementary Figures S1A and S1B](#DB_nonbdb_plot_S1A)\n",
    "    8. [Random sequences](#DB_random)\n",
    "    9. [Non-B DB](#DB_nonbdb)\n",
    "        1. [Modify and annotate Non-B DB](#DB_nonbdb_modify)\n",
    "            1. [Load and format](#DB_nonbdb_load)\n",
    "            2. [Add in G4 motifs from G4-seq](#DB_nonbdb_G4)\n",
    "            3. [Add in random sequences](#DB_nonbdb_random)\n",
    "            4. [Filter database by proximity (or don't)](#DB_nonbdb_filter)\n",
    "        2. [Plot overlaps between Non-B DB categories](#DB_nonbdb_plot)\n",
    "            1. [Plot for Supplementary Figure S1c](#DB_nonbdb_plot_S1C)\n",
    "            2. [Plot for Supplementary Figure S1d](#DB_nonbdb_plot_S1D)        \n",
    "6. [Prepare gnomAD database](#GNOMAD)\n",
    "    1. [Read gnomAD file in chunks](#GNOMAD_shrink_read)\n",
    "    2. [Combine chunks into .csv file](#GNOMAD_shrink_combine)\n",
    "    3. [Filter to rare SNVs and count GC content](#GNOMAD_rare)\n",
    "    4. [Load gnomAD SNV database and calculate trinucleotide mutation frequency](#GNOMAD_freq)\n",
    "        1. [Generate downsampled gnomAD files based on AC](#GNOMAD_downsample_generate)\n",
    "        2. [Correct allele count to reflect number of independent mutations](#GNOMAD_AC_correction)\n",
    "        3. [Total count and frequency using allele counts](#GNOMAD_freq_AC)\n",
    "        4. [Transition/transversion ratio](#GNOMAD_freq_tstv)\n",
    "    5. [Calculate GC content correction factor](#GNOMAD_GC_correction)\n",
    "    6. [Downsampling gnomAD files](#GNOMAD_downsample)\n",
    "    7. [gnomAD indels](#GNOMAD_indels)\n",
    "        1. [Make database](#GNOMAD_indels_makedb)\n",
    "        2. [Load databse and count genome totals](#GNOMAD_indels_load)\n",
    "7. [Prepare de novo SNV database](#denovo)\n",
    "    1. [Studies aligned to hg19](#denovo_hg19)\n",
    "    2. [Studies aligned to hg38](#denovo_hg38)\n",
    "    3. [Combine all studies](#denovo_combine)\n",
    "    4. [Load de novo SNV database](#denovo_load)\n",
    "8. [Calculate mutation frequency surrounding motifs](#mutation_surrounding)\n",
    "    1. [Define counting functions](#mutation_surrounding_functions)\n",
    "    2. [Count and analyze flanking mutations and trinucleotides](#mutation_surrounding_analysis)\n",
    "        1. [Mutation frequency surrounding random non-motif sequences](#mutation_surrounding_analysis_random)\n",
    "        2. [Mutation frequency surrounding repeat motif sequences](#mutation_surrounding_analysis_repeat)\n",
    "            1. [Load database and define motif categories](#mutation_surrounding_analysis_categories)\n",
    "            2. [Mutation frequency surrounding STRs](#mutation_surrounding_analysis_str)\n",
    "                1. [CG repeats in/outside of CpG islands](#mutation_surrounding_CGI)\n",
    "            3. [Mutation frequency surrounding IRs](#mutation_surrounding_analysis_ir)\n",
    "            4. [Mutation frequency surrounding MRs](#mutation_surrounding_analysis_mr)\n",
    "            5. [Mutation frequency surrounding DRs](#mutation_surrounding_analysis_dr)\n",
    "            6. [Mutation frequency surrounding Z-DNA](#mutation_surrounding_analysis_zdna)\n",
    "            7. [Mutation frequency surrounding G4 motifs](#mutation_surrounding_analysis_g4)\n",
    "            8. [Save/load mutation counts](#mutation_surrounding_analysis_saveload)\n",
    "        3. [Count de novo mutations surrounding motifs](#mutation_surrounding_denovo)\n",
    "    3. [Improper analysis of NonB Database (on purpose)](#mutation_surrounding_nonbdb)\n",
    "        1. [Count and analyze Non-B DB flanking mutations](#mutation_surrounding_nonbdb_count)\n",
    "            1. [Mutation frequency surrounding STRs](#mutation_surrounding_nonbdb_str)\n",
    "            2. [Mutation frequency surrounding IRs](#mutation_surrounding_nonbdb_ir)\n",
    "            3. [Mutation frequency surrounding MRs](#mutation_surrounding_nonbdb_mr)\n",
    "            4. [Mutation frequency surrounding DRs](#mutation_surrounding_nonbdb_dr)\n",
    "            5. [Mutation frequency surrounding Z-DNA](#mutation_surrounding_nonbdb_zdna)\n",
    "            6. [Mutation frequency surrounding G4 motifs](#mutation_surrounding_nonbdb_g4)\n",
    "            7. [Save/load mutation counts](#mutation_surrounding_nonbdb_saveload)\n",
    "    4. [Count flanking mutations using subsampled gnomAD](#mutation_surrounding_subsample)          \n",
    "    5. [Plot flanking mutation frequencies](#mutation_surrounding_plot)\n",
    "        1. [Plot individual motifs/categories](#mutation_surrounding_plot_ind)\n",
    "        2. [Plot for Figure 2](#mutation_surrounding_plot_fig2)\n",
    "        3. [Plot for Supplementary Figure S2a](#mutation_surrounding_plot_figS2A)\n",
    "        4. [Plot for Supplementary Figure S2b](#mutation_surrounding_plot_figS2B)\n",
    "        5. [Plot for Supplementary Figure S2c](#mutation_surrounding_plot_figS2B)\n",
    "    6. [CG repeats in/outside of CpG islands](#mutation_surrounding_CGI)\n",
    "        1. [Download CpG island map](#mutation_surrounding_CGI_download)\n",
    "        2. [Measure distance between CG motifs and CpG islands](#mutation_surrounding_CGI_distance)\n",
    "        3. [Analyze flanking mutations](#mutation_surrounding_CGI_analyze)\n",
    "        4. [Plot for Supplementary Figure S2d](#mutation_surrounding_CGI_plot)\n",
    "    7. [Flanking mutation frequencies after gnomAD subsampling](#mutation_surrounding_subsample)\n",
    "        1. [Plot for Supplementary Figure S3](#mutation_surrounding_subsample_plot)\n",
    "    8. [Flanking mutation frequencies by mutation type](#mutation_surrounding_bymut)\n",
    "        1. [Plot for Supplementary Figure S4](#mutation_surrounding_bymut_plot)\n",
    "9. [Indel analysis for flanking regions](#indel_analysis_flank)\n",
    "    1. [Count indels flanking motifs](#indel_analysis_flank_count)\n",
    "    2. [Save/load counts](#indel_analysis_flank_load)\n",
    "    3. [Plot indels flanking motifs](#indel_analysis_flank_plot)\n",
    "        1. [Plot for Supplementary Figure S2h](#indel_analysis_flank_plot_S2H)\n",
    "10. [Calculate mutation frequencies within motifs](#mutation_internal)\n",
    "    1. [Annotate positions within motifs](#mutation_internal_annotate)\n",
    "        1. [Locate interruptions within motifs](#mutation_internal_annotate_interruptions)\n",
    "        2. [Annotate other positions](#mutation_internal_annotate_other)\n",
    "        3. [Combine all positions into database](#mutation_internal_annotate_combine)\n",
    "    2. [Calculate mutation frequency at specified internal positions](#mutation_internal_count)\n",
    "        1. [Define functions for analysis](#mutation_internal_count_functions)\n",
    "        2. [Count and analyze](#mutation_internal_count_analyze)\n",
    "            1. [Inverted/Mirror/Direct motifs](#mutation_internal_count_analyze_IRDMRDR)\n",
    "            2. [Z-DNA motifs](#mutation_internal_count_analyze_ZDNA)\n",
    "            3. [STR motifs](#mutation_internal_count_analyze_STR)\n",
    "            4. [G4 motifs](#mutation_internal_count_analyze_G4)\n",
    "    3. [Plot mutation frequency within motifs](#mutation_internal_count_plot)\n",
    "        1. [Plot for Figure 3a](#mutation_internal_count_plot_3A)\n",
    "        2. [Plot for Figure S3b](#mutation_internal_count_plot_S3B)\n",
    "        3. [Plot for Supplementary Figure S5a](#mutation_internal_count_plot_S5A)\n",
    "        4. [Plot for Supplementary Figure S5c](#mutation_internal_count_plot_S5C)\n",
    "        5. [Plot for Supplementary Figures S4a, S6a](#mutation_internal_count_plot_S6A)\n",
    "        6. [Plot for Figure 5a](#mutation_internal_count_plot_5A)\n",
    "    4. [Indels within motifs](#mutation_internal_indels)\n",
    "        1. [Define functions for analysis](#mutation_internal_indels_functions)\n",
    "        2. [Counting and analysis of STR/DR/MR/IR/ZDNA](#mutation_internal_indels_analysis)\n",
    "        3. [Counting and analysis of G4](#mutation_internal_indels_analysis_G4)\n",
    "        4. [Save/load counts](#mutation_internal_indels_saveload)\n",
    "        5. [Plots](#mutation_internal_indels_plots)\n",
    "            1. [Plot for Figure 4a](#mutation_internal_indels_plots_fig4A)\n",
    "            2. [Plot for Figure S4b](#mutation_internal_indels_plots_figS4B)\n",
    "            3. [Plot for Figure S5b](#mutation_internal_indels_plots_figS5B)\n",
    "            4. [Plot for Figure S6b](#mutation_internal_indels_plots_figS6B)\n",
    "            5. [Plot for Figure S3a](#mutation_internal_indels_plots_figS3A)\n",
    "            6. [Plots for Figure S5a, S5b](#mutation_internal_indels_plots_figS5)\n",
    "            7. [Plot for Figure 3a](#mutation_internal_combined_plots_fig3A)\n",
    "            8. [Plot for Figure S6c](#mutation_internal_combined_plots_figS6C)\n",
    "        6. [STR insertion fidelity](#mutation_internal_STR_insertion_fidelity)\n",
    "            1. [Calculation of error frequency](#mutation_internal_STR_insertion_fidelity_calculation)\n",
    "            2. [Plot for Figure S3d](#mutation_internal_STR_insertion_fidelity_plots_figS3D)\n",
    "        7. [Ratio of insertions to deletions](#mutation_internal_STR_insertion_deletion_ratio)\n",
    "            1. [Plot for Figure S3c](#mutation_internal_STR_insertion_deletion_ratio_plots_figS3C)\n",
    "        8. [Absolute frequency of indels and SNVs](#mutation_internal_STR_indel_SNV_rate)\n",
    "            1. [Plot for Figure S3e](#mutation_internal_STR_indel_SNV_rate_plots_figS3E)\n",
    "        9. [Direct repeat duplications](#mutation_internal_indel_DR_duplications)\n",
    "            1. [Find and count duplications](#mutation_internal_indel_DR_duplications_count)\n",
    "            2. [Plot for Figure S4d](#mutation_internal_indel_DR_duplications_plot_figS4D)\n",
    "            3. [Duplication error frequency](#mutation_internal_indel_DR_duplications_errors)\n",
    "            4. [Plot for Figure S4e](#mutation_internal_indel_DR_duplications_plot_figS4E)\n",
    "            5. [Double-nucleotide variants, used in Fig. S4f](#mutation_internal_indel_DR_duplications_figS4F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2a4be2",
   "metadata": {},
   "source": [
    "# Process sample dataset (chr22) or full dataset? <a name=\"sample\"></a>\n",
    "    Run one or the other as desired\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625959dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset\n",
    "chr_list = [22]\n",
    "chr_range = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220bb131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full dataset (all autosomes)\n",
    "chr_list = list(range(1,23))\n",
    "chr_range = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd68072f",
   "metadata": {},
   "source": [
    "# Libraries and functions used throughout the analysis\n",
    "<a name=\"libraries\"></a>\n",
    "\n",
    "### Load Python libraries <a name=\"libraries1\"></a>\n",
    "- Links included for instructions on how to install libraries using pip or conda (if libraries not included with conda)\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9417eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO     # https://biopython.org/wiki/SeqIO\n",
    "from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from time import time\n",
    "import pickle\n",
    "import statsmodels.api as statsmodels\n",
    "binconf = statsmodels.stats.proportion_confint\n",
    "from sty import fg, bg, rs, ef, Style, RgbFg      #pip install sty\n",
    "import regex as re     # https://pypi.org/project/regex/\n",
    "from pyliftover import LiftOver     # https://pypi.org/project/pyliftover/\n",
    "\n",
    "import plotly     # https://plotly.com/python/getting-started/\n",
    "plotly.offline.init_notebook_mode()\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2d853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tested with the following versions:\n",
    "\n",
    "#pd.show_versions()\n",
    "\n",
    "#python           : 3.8.12.final.0\n",
    "#pandas           : 1.4.1\n",
    "#numpy            : 1.20.3\n",
    "#scipy            : 1.7.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d531cf0",
   "metadata": {},
   "source": [
    "### Define functions which will be used throughout the analysis <a name=\"functions\"></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879a384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten list\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "# Merge any overlapping genomic windows\n",
    "def interval_overlap_per_chrom(df_in, start_name = 'start', end_name = 'end'):\n",
    "    df_out = dict()\n",
    "    for chrom in range(1,23):\n",
    "        df_current = df_in.loc[df_in['chrom'] == chrom]\n",
    "        if len(df_current) > 0:\n",
    "            range_df = pd.DataFrame()\n",
    "            range_df[start_name] = sorted(list(df_current[start_name]))\n",
    "            range_df[end_name] = sorted(list(df_current[end_name]))\n",
    "\n",
    "            range_df_shift = pd.DataFrame()\n",
    "            range_df_shift[start_name] = range_df[start_name][1:].reset_index(drop = True)\n",
    "            range_df_shift[end_name] = range_df[end_name][:-1].reset_index(drop = True)\n",
    "            range_df_shift['overlap'] = range_df_shift[start_name] > range_df_shift[end_name]\n",
    "            range_df_shift = range_df_shift.loc[range_df_shift['overlap'] == True]\n",
    "\n",
    "            range_df_merged = pd.DataFrame()\n",
    "            range_df_merged[start_name] = [range_df[start_name][0]] +list(range_df_shift[start_name])\n",
    "            range_df_merged[end_name] = list(range_df_shift[end_name]) + [range_df[end_name][len(range_df.index)-1]]\n",
    "\n",
    "            range_df = range_df_merged\n",
    "            range_df['chrom'] = chrom\n",
    "            df_out[chrom] = range_df[['chrom', start_name, end_name]]\n",
    "    df_out = pd.concat(df_out).reset_index(drop = True)\n",
    "    return df_out\n",
    "\n",
    "# Count trinucleotides for a list of genomic coordinates\n",
    "def count_triplets_by_chrom(df_in):\n",
    "    df_in['seq'] = [reference_genome[chrom][start-2:end+1] for chrom, start, end in zip(df_in['chrom'], df_in['start'], df_in['end'])]\n",
    "\n",
    "    triplet_counts = pd.Series(0, index = all_triplets)\n",
    "    for chrom in range(1,23):\n",
    "        current_seq = 'NNN'.join(df_in.loc[df_in['chrom'] == chrom]['seq'])\n",
    "        if len(current_seq) > 0:\n",
    "            triplet_counts = triplet_counts.add(pd.Series(re.findall('...',current_seq)).value_counts()).add(pd.Series(re.findall('...',current_seq[1:])).value_counts()).add(pd.Series(re.findall('...',current_seq[2:])).value_counts()).dropna().astype(int)\n",
    "    return triplet_counts\n",
    "\n",
    "# Count 5mers for a list of genomic coordinates\n",
    "def count_quints_by_chrom(df_in):\n",
    "    df_in['seq'] = [reference_genome[chrom][start-3:end+2] for chrom, start, end in zip(df_in['chrom'], df_in['start'], df_in['end'])]\n",
    "\n",
    "    triplet_counts = pd.Series(0, index = all_triplets)\n",
    "    for chrom in range(chr_range,23):\n",
    "        current_seq = 'NNNNN'.join(df_in.loc[df_in['chrom'] == chrom]['seq'])\n",
    "        if len(current_seq) > 0:\n",
    "            triplet_counts = triplet_counts.add(pd.Series(re.findall('.....',current_seq)).value_counts()).add(pd.Series(re.findall('.....',current_seq[1:])).value_counts()).add(pd.Series(re.findall('.....',current_seq[2:])).value_counts()).add(pd.Series(re.findall('.....',current_seq[3:])).value_counts()).add(pd.Series(re.findall('.....',current_seq[4:])).value_counts()).dropna().astype(int)\n",
    "    return triplet_counts\n",
    "\n",
    "# Generate reverse-complementary sequence or mutation\n",
    "def reverse_complement(dna):\n",
    "    complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A', 'N': 'N'}\n",
    "    return ''.join([complement[base] for base in dna[::-1]]) \n",
    "def reverse_complement_mut(mut):\n",
    "    complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A', 'N': 'N'}\n",
    "    return ''.join([complement[base] for base in mut.split('_')[0][::-1]])+'_'+complement[mut.split('_')[1]]\n",
    "\n",
    "# Make lists of all trinucleotides and trinucleotide mutations\n",
    "all_triplets = [base1+base2+base3 for base1 in ['A', 'T', 'G', 'C'] for base2 in ['A', 'T', 'G', 'C'] for base3 in ['A', 'T', 'G', 'C']]\n",
    "triplet_mutations_und = [base1+base2+base3+'_'+mutbase for base1 in ['A', 'T', 'G', 'C'] for base2 in ['A', 'T', 'G', 'C'] for base3 in ['A', 'T', 'G', 'C'] for mutbase in ['A', 'T', 'G', 'C'] if mutbase != base2]\n",
    "\n",
    "# Reverse-complementary trinucleotides\n",
    "triplets_TC = [base1+base2+base3 for base1 in ['A', 'T', 'G', 'C'] for base2 in ['T', 'C'] for base3 in ['A', 'T', 'G', 'C']]\n",
    "triplets_AG = [reverse_complement(mut) for mut in triplets_TC]\n",
    "triplet_mutations_und_TC = [base1+base2+base3+'_'+mutbase for base1 in ['A', 'T', 'G', 'C'] for base2 in ['T', 'C'] for base3 in ['A', 'T', 'G', 'C'] for mutbase in ['A', 'T', 'G', 'C'] if mutbase != base2]\n",
    "triplet_mutations_und_AG = [reverse_complement(mut[:3]) + '_' + reverse_complement(mut[4]) for mut in triplet_mutations_und_TC]\n",
    "\n",
    "# Make lists of all 5mers and 5mer mutations\n",
    "all_quints = [base1+base2+base3+base4+base5 for base1 in ['A', 'T', 'G', 'C'] for base2 in ['A', 'T', 'G', 'C'] for base3 in ['A', 'T', 'G', 'C'] for base4 in ['A', 'T', 'G', 'C'] for base5 in ['A', 'T', 'G', 'C']]\n",
    "quint_mutations = [base1+base2+base3+base4+base5+'>'+mutbase for base1 in ['A', 'T', 'G', 'C'] for base2 in ['A', 'T', 'G', 'C'] for base3 in ['A', 'T', 'G', 'C'] for base4 in ['A', 'T', 'G', 'C'] for base5 in ['A', 'T', 'G', 'C'] for mutbase in ['A', 'T', 'G', 'C'] if mutbase != base3]\n",
    "quint_mutations_und = [base1+base2+base3+base4+base5+'_'+mutbase for base1 in ['A', 'T', 'G', 'C'] for base2 in ['A', 'T', 'G', 'C'] for base3 in ['A', 'T', 'G', 'C'] for base4 in ['A', 'T', 'G', 'C'] for base5 in ['A', 'T', 'G', 'C'] for mutbase in ['A', 'T', 'G', 'C'] if mutbase != base3]\n",
    "\n",
    "# Reverse-complementary 5mers\n",
    "quints_TC = [base1+base2+base3+base4+base5 for base1 in ['A', 'T', 'G', 'C'] for base2 in ['A', 'T', 'G', 'C'] for base3 in ['T', 'C'] for base4 in ['A', 'T', 'G', 'C'] for base5 in ['A', 'T', 'G', 'C']]\n",
    "quints_AG = [reverse_complement(mut) for mut in quints_TC]\n",
    "quint_mutations_und_TC = [base1+base2+base3+base4+base5+'_'+mutbase for base1 in ['A', 'T', 'G', 'C'] for base2 in ['A', 'T', 'G', 'C'] for base3 in ['T', 'C'] for base4 in ['A', 'T', 'G', 'C']  for base5 in ['A', 'T', 'G', 'C'] for mutbase in ['A', 'T', 'G', 'C'] if mutbase != base3]\n",
    "quint_mutations_und_AG = [reverse_complement(mut[:5]) + '_' + reverse_complement(mut[6]) for mut in quint_mutations_und_TC]\n",
    "\n",
    "# Make lists of all trinucleotide indel mutations\n",
    "triplet_mutations_und_indel = [tri + '_ins' for tri in all_triplets] + [tri + '_del' for tri in all_triplets]\n",
    "triplet_mutations_und_indel_AG = [tri + '_ins' for tri in triplets_AG] + [tri + '_del' for tri in triplets_AG]\n",
    "triplet_mutations_und_indel_TC = [tri + '_ins' for tri in triplets_TC] + [tri + '_del' for tri in triplets_TC]\n",
    "triplet_mutations_und_ins = [tri + '_ins' for tri in all_triplets]\n",
    "triplet_mutations_und_ins_AG = [tri + '_ins' for tri in triplets_AG]\n",
    "triplet_mutations_und_ins_TC = [tri + '_ins' for tri in triplets_TC]\n",
    "triplet_mutations_und_del = [tri + '_del' for tri in all_triplets]\n",
    "triplet_mutations_und_del_AG = [tri + '_del' for tri in triplets_AG]\n",
    "triplet_mutations_und_del_TC = [tri + '_del' for tri in triplets_TC]\n",
    "\n",
    "def tri_function(chrom, pos, base = 1):     # used for base1 coordinates\n",
    "    if base == 1:\n",
    "        return reference_genome[chrom][pos-2: pos+1].upper()\n",
    "    if base == 0:\n",
    "        return reference_genome[chrom][pos-1: pos+2].upper()\n",
    "def quint_function(chrom, pos): \n",
    "    return reference_genome[chrom][pos-3: pos+2].upper()\n",
    "def reference_lookup(chrom, pos, distance):\n",
    "    return reference_genome[chrom][pos-(distance+1): pos+distance].upper()\n",
    "\n",
    "def triplet_combine_RC(input_series, mut_input = False, mut_output = False, decombine = False):\n",
    "    if (mut_input == False) & (decombine == False):\n",
    "        triplet_totals_RC = input_series.reindex(triplets_AG).fillna(0)\n",
    "        triplet_totals_RC.index = triplets_TC\n",
    "        triplet_totals_RC = triplet_totals_RC.add(input_series.reindex(triplets_TC), fill_value = 0)\n",
    "        if mut_output == True:\n",
    "            triplet_totals_RC_mut = triplet_totals_RC.reindex(flatten([[mut]*3 for mut in triplets_TC]))\n",
    "            triplet_totals_RC_mut.index = triplet_mutations_und_TC\n",
    "            return triplet_totals_RC_mut\n",
    "        else:\n",
    "            return triplet_totals_RC\n",
    "    if (mut_input == False) & (decombine == True):\n",
    "        triplet_totals_RC = input_series.reindex(triplets_TC).fillna(0)\n",
    "        triplet_totals_RC.index = triplets_AG\n",
    "        triplet_totals = pd.concat([input_series.reindex(triplets_TC), triplet_totals_RC], axis=0).reindex(all_triplets).fillna(0)\n",
    "        if mut_output == True:\n",
    "            triplet_totals_mut = triplet_totals.reindex(flatten([[mut]*3 for mut in all_triplets])).fillna(0)\n",
    "            triplet_totals_mut.index = triplet_mutations_und\n",
    "            return triplet_totals_mut\n",
    "        else:\n",
    "            return triplet_totals\n",
    "    if (mut_input == True) & (decombine == False):\n",
    "        triplet_totals_RC = input_series.reindex(triplet_mutations_und_AG).fillna(0).fillna(0)\n",
    "        triplet_totals_RC.index = triplet_mutations_und_TC\n",
    "        triplet_totals_RC = triplet_totals_RC.add(input_series.reindex(triplet_mutations_und_TC).fillna(0), fill_value = 0)\n",
    "        return triplet_totals_RC\n",
    "    if (mut_input == True) & (decombine == True):\n",
    "        triplet_totals_RC = input_series.reindex(triplet_mutations_und_TC).fillna(0).fillna(0)\n",
    "        triplet_totals_RC.index = triplet_mutations_und_AG\n",
    "        triplet_totals = pd.concat([input_series.reindex(triplet_mutations_und_TC).fillna(0), triplet_totals_RC], axis=0).fillna(0)\n",
    "        triplet_totals = triplet_totals.reindex(triplet_mutations_und).fillna(0)\n",
    "        return triplet_totals\n",
    "\n",
    "def triplet_combine_RC_indel(input_series, mut_input = False, mut_output = False, decombine = False):\n",
    "    if (mut_input == False) & (decombine == False):\n",
    "        triplet_totals_RC = input_series.reindex(triplets_AG).fillna(0)\n",
    "        triplet_totals_RC.index = triplets_TC\n",
    "        triplet_totals_RC = triplet_totals_RC.add(input_series.reindex(triplets_TC), fill_value = 0)\n",
    "        if mut_output == True:\n",
    "            triplet_totals_RC_mut = pd.concat([triplet_totals_RC,triplet_totals_RC])\n",
    "            triplet_totals_RC_mut.index = triplet_mutations_und_indel_TC\n",
    "            return triplet_totals_RC_mut\n",
    "        else:\n",
    "            return triplet_totals_RC\n",
    "    if (mut_input == False) & (decombine == True):\n",
    "        triplet_totals_RC = input_series.reindex(triplets_TC).fillna(0)\n",
    "        triplet_totals_RC.index = triplets_AG\n",
    "        triplet_totals = pd.concat([input_series.reindex(triplets_TC), triplet_totals_RC], axis=0).reindex(all_triplets).fillna(0)\n",
    "        if mut_output == True:\n",
    "            triplet_totals_mut = pd.concat([triplet_totals,triplet_totals])\n",
    "            triplet_totals_mut.index = triplet_mutations_und_indel\n",
    "            return triplet_totals_mut\n",
    "        else:\n",
    "            return triplet_totals\n",
    "    if (mut_input == True) & (decombine == False):\n",
    "        triplet_totals_RC = input_series.reindex(triplet_mutations_und_indel_AG).fillna(0)\n",
    "        triplet_totals_RC.index = triplet_mutations_und_indel_TC\n",
    "        triplet_totals_RC += triplet_totals_RC.add(input_series.reindex(triplet_mutations_und_indel_TC).fillna(0), fill_value = 0)\n",
    "        return triplet_totals_RC\n",
    "    if (mut_input == True) & (decombine == True):\n",
    "        triplet_totals_RC = input_series.reindex(triplet_mutations_und_indel_TC).fillna(0)\n",
    "        triplet_totals_RC.index = triplet_mutations_und_indel_AG\n",
    "        triplet_totals = pd.concat([input_series.reindex(triplet_mutations_und_indel_TC).fillna(0), triplet_totals_RC], axis=0)\n",
    "        triplet_totals = triplet_totals.reindex(triplet_mutations_und_indel)\n",
    "        return triplet_totals\n",
    "\n",
    "# COSMIC mutation signature colors\n",
    "colors = pd.DataFrame(index = ['C_A', 'C_G', 'C_T', 'T_A', 'T_C', 'T_G'])\n",
    "colors['color'] = ['#2ACAFA', 'black', 'red', '#C0C0C0', '#92FA2A', 'pink']\n",
    "colors['ind'] = [[base1+'C'+base3+'_'+'A' for base1 in ['A', 'C', 'G', 'T'] for base3 in ['A', 'C', 'G', 'T']], [base1+'C'+base3+'_'+'G' for base1 in ['A', 'C', 'G', 'T'] for base3 in ['A', 'C', 'G', 'T']], [base1+'C'+base3+'_'+'T' for base1 in ['A', 'C', 'G', 'T'] for base3 in ['A', 'C', 'G', 'T']], [base1+'T'+base3+'_'+'A' for base1 in ['A', 'C', 'G', 'T'] for base3 in ['A', 'C', 'G', 'T']], [base1+'T'+base3+'_'+'C' for base1 in ['A', 'C', 'G', 'T'] for base3 in ['A', 'C', 'G', 'T']], [base1+'T'+base3+'_'+'G' for base1 in ['A', 'C', 'G', 'T'] for base3 in ['A', 'C', 'G', 'T']]]\n",
    "colors['ind_quint'] = [[base1+base2+'C'+base4+base5+'_'+'A' for base1 in ['A', 'C', 'G', 'T'] for base2 in ['A', 'C', 'G', 'T'] for base4 in ['A', 'C', 'G', 'T'] for base5 in ['A', 'C', 'G', 'T']], [base1+base2+'C'+base4+base5+'_'+'G' for base1 in ['A', 'C', 'G', 'T'] for base2 in ['A', 'C', 'G', 'T'] for base4 in ['A', 'C', 'G', 'T'] for base5 in ['A', 'C', 'G', 'T']], [base1+base2+'C'+base4+base5+'_'+'T' for base1 in ['A', 'C', 'G', 'T'] for base2 in ['A', 'C', 'G', 'T'] for base4 in ['A', 'C', 'G', 'T'] for base5 in ['A', 'C', 'G', 'T']], [base1+base2+'T'+base4+base5+'_'+'A' for base1 in ['A', 'C', 'G', 'T'] for base2 in ['A', 'C', 'G', 'T'] for base4 in ['A', 'C', 'G', 'T'] for base5 in ['A', 'C', 'G', 'T']], [base1+base2+'T'+base4+base5+'_'+'C' for base1 in ['A', 'C', 'G', 'T'] for base2 in ['A', 'C', 'G', 'T'] for base4 in ['A', 'C', 'G', 'T'] for base5 in ['A', 'C', 'G', 'T']], [base1+base2+'T'+base4+base5+'_'+'G' for base1 in ['A', 'C', 'G', 'T'] for base2 in ['A', 'C', 'G', 'T'] for base4 in ['A', 'C', 'G', 'T'] for base5 in ['A', 'C', 'G', 'T']]]\n",
    "colors['ind_F'] = [mut for mut in triplet_mutations_und_TC if (mut[1] == 'C') & (mut[4] == 'A')], [mut for mut in triplet_mutations_und_TC if (mut[1] == 'C') & (mut[4] == 'G')], [mut for mut in triplet_mutations_und_TC if (mut[1] == 'C') & (mut[4] == 'T')], [mut for mut in triplet_mutations_und_TC if (mut[1] == 'T') & (mut[4] == 'A')], [mut for mut in triplet_mutations_und_TC if (mut[1] == 'T') & (mut[4] == 'C')], [mut for mut in triplet_mutations_und_TC if (mut[1] == 'T') & (mut[4] == 'G')]\n",
    "colors['ind_RC'] = [[reverse_complement_mut(mut) for mut in triplets] for triplets in colors['ind_F']]\n",
    "colors['ind_all'] = colors['ind_F'] + colors['ind_RC']\n",
    "#colors['ind'] = [[base1+'CA'+'_'+'A' for base1 in ['A', 'T', 'G', 'C']] + [base1+'CT'+'_'+'A' for base1 in ['A', 'T', 'G', 'C']] + [base1+'CC'+'_'+'A' for base1 in ['A', 'T', 'G', 'C']] + [base1+'CG'+'_'+'A' for base1 in ['A', 'T', 'G', 'C']], [base1+'CA'+'_'+'G' for base1 in ['A', 'T', 'G', 'C']] + [base1+'CT'+'_'+'G' for base1 in ['A', 'T', 'G', 'C']] + [base1+'CC'+'_'+'G' for base1 in ['A', 'T', 'G', 'C']] + [base1+'CG'+'_'+'G' for base1 in ['A', 'T', 'G', 'C']], [base1+'CA'+'_'+'T' for base1 in ['A', 'T', 'G', 'C']] + [base1+'CT'+'_'+'T' for base1 in ['A', 'T', 'G', 'C']] + [base1+'CC'+'_'+'T' for base1 in ['A', 'T', 'G', 'C']] + [base1+'CG'+'_'+'T' for base1 in ['A', 'T', 'G', 'C']], [base1+'TA'+'_'+'A' for base1 in ['A', 'T', 'G', 'C']] + [base1+'TT'+'_'+'A' for base1 in ['A', 'T', 'G', 'C']] + [base1+'TC'+'_'+'A' for base1 in ['A', 'T', 'G', 'C']] + [base1+'TG'+'_'+'A' for base1 in ['A', 'T', 'G', 'C']], [base1+'TA'+'_'+'C' for base1 in ['A', 'T', 'G', 'C']] + [base1+'TT'+'_'+'C' for base1 in ['A', 'T', 'G', 'C']] + [base1+'TC'+'_'+'C' for base1 in ['A', 'T', 'G', 'C']] + [base1+'TG'+'_'+'C' for base1 in ['A', 'T', 'G', 'C']], [base1+'TA'+'_'+'G' for base1 in ['A', 'T', 'G', 'C']] + [base1+'TT'+'_'+'G' for base1 in ['A', 'T', 'G', 'C']] + [base1+'TC'+'_'+'G' for base1 in ['A', 'T', 'G', 'C']] + [base1+'TG'+'_'+'G' for base1 in ['A', 'T', 'G', 'C']]]\n",
    "colors['col_num'] = [1,2,3,4,5,6]\n",
    "\n",
    "triplets_by_mut = colors['ind'].copy()\n",
    "triplets_by_mut['CpG_T'] = [tri for tri in triplets_by_mut['C_T'] if tri[2] == 'G']\n",
    "triplets_by_mut['C_T'] = [tri for tri in triplets_by_mut['C_T'] if tri[2] != 'G']\n",
    "\n",
    "# Use a set of coordinates to mask a fasta sequence and output to new fasta file\n",
    "def coordinates_to_Ns(coordinates, reference, description_str, name):\n",
    "    coordinates = interval_overlap_per_chrom(coordinates)\n",
    "    for chrom in range(chr_range,23):\n",
    "        chr_seq = reference[chrom]\n",
    "        chr_coordinates = coordinates.loc[coordinates['chrom'] == chrom]\n",
    "        \n",
    "        mask_ranges = []\n",
    "        for coord in list(zip(chr_coordinates['start'], chr_coordinates['end'])):\n",
    "            mask_ranges.append(list(range(coord[0], coord[1])))\n",
    "        mask_ranges = flatten(mask_ranges)\n",
    "        mask_ranges = list(set(mask_ranges))\n",
    "\n",
    "        ### replace list of positions with Ns\n",
    "        chr_seq = list(chr_seq)\n",
    "        for pos in mask_ranges:\n",
    "            chr_seq[pos] = 'N'\n",
    "        chr_seq = ''.join(chr_seq)\n",
    "\n",
    "        record = SeqRecord(Seq(chr_seq), id = 'DNA', description = description_str)\n",
    "        with open('./hg38/chromosomes/masked/chr'+str(chrom)+'_mask_'+name+'.fasta', 'w') as output_handle:\n",
    "            SeqIO.write(record, output_handle, \"fasta\")\n",
    "        print('\\r' + str(chrom), end=' ')\n",
    "\n",
    "# Calculate distance between coordinates within the same dataframe\n",
    "def distance_within_df(df, name = '', start_name = 'start', end_name = 'end'):\n",
    "    if name != '':\n",
    "        name = name + '_'\n",
    "    df_distance = dict()\n",
    "    df_internals = dict()\n",
    "    df_duplicated = dict()\n",
    "    for chrom in range(chr_range,23):\n",
    "        current_chrom = df.loc[df['chrom'] == chrom].copy()\n",
    "        current_chrom = current_chrom.sort_values(by = [start_name, end_name])\n",
    "        current_chrom['end_max'] = current_chrom[end_name].cummax()\n",
    "        current_chrom['end_max-end'] = current_chrom['end_max'] - current_chrom[end_name]\n",
    "        # set aside coordinates fully contained inside other coordinates\n",
    "        # internals will have NaN for distance\n",
    "        df_internals[chrom] = current_chrom.loc[current_chrom['end_max-end'] >0].copy()\n",
    "        df_internals[chrom][name+'distance_left'] = np.nan; df_internals[chrom][name+'distance_right'] = np.nan\n",
    "        current_chrom = current_chrom.loc[current_chrom['end_max-end'] == 0]\n",
    "        # remove exact duplicates (keeping one set, setting aside the rest)\n",
    "        df_duplicated[chrom] = current_chrom.loc[current_chrom.duplicated(subset = [start_name, end_name]) == True]\n",
    "        current_chrom = current_chrom.drop_duplicates(subset = [start_name, end_name])\n",
    "        # calculate L and R distance\n",
    "        # all coordinates should be ordered by both start and end, so distance <=0 indicates overlap\n",
    "        # start and end of chromosome will be NaN\n",
    "        current_chrom[name+'distance_left'] = current_chrom[start_name] - current_chrom[end_name].shift(1)\n",
    "        current_chrom[name+'distance_right'] = current_chrom[start_name].shift(-1) - current_chrom[end_name]\n",
    "        df_distance[chrom] = current_chrom\n",
    "        df_distance[chrom].index = [str(chrom)+'_'+str(start)+'_'+str(end) for start, end in zip(df_distance[chrom][start_name], df_distance[chrom][end_name])]\n",
    "        # copy distances to duplicated coordinates (they will show distances to nearest non-identical coordinates)\n",
    "        df_duplicated[chrom]['coordinates'] = [str(chrom)+'_'+str(start)+'_'+str(end) for start, end in zip(df_duplicated[chrom][start_name], df_duplicated[chrom][end_name])]\n",
    "        df_duplicated[chrom][name+'distance_left'] = list(df_distance[chrom].reindex(df_duplicated[chrom]['coordinates'])[name+'distance_left'])\n",
    "        df_duplicated[chrom][name+'distance_right'] = list(df_distance[chrom].reindex(df_duplicated[chrom]['coordinates'])[name+'distance_right'])\n",
    "\n",
    "    df_distance = pd.concat(df_distance)\n",
    "    df_duplicated = pd.concat(df_duplicated)\n",
    "    df_internals = pd.concat(df_internals)\n",
    "    \n",
    "    df_distance[name+'distance_left'] = df_distance[name+'distance_left'].fillna(np.inf)\n",
    "    df_distance[name+'distance_right'] = df_distance[name+'distance_right'].fillna(np.inf)\n",
    "    df_duplicated[name+'distance_left'] = df_duplicated[name+'distance_left'].fillna(np.inf)\n",
    "    df_duplicated[name+'distance_right'] = df_duplicated[name+'distance_right'].fillna(np.inf)\n",
    "\n",
    "    df = pd.concat([df_distance, df_duplicated, df_internals])\n",
    "    df = df.sort_values(by = ['chrom', start_name, end_name]).reset_index(drop = True)\n",
    "    del df['coordinates']; del df['end_max']; del df['end_max-end']\n",
    "    df[name+'distance_min'] = [min([L,R]) for L, R in zip(df[name+'distance_left'], df[name+'distance_right'])]\n",
    "     # if either side is negative, set both values to 0\n",
    "    df[name+'distance_left'] = [dist if dist_min > 0 else 0 for dist, dist_min in zip(df[name+'distance_left'], df[name+'distance_min'])]\n",
    "    df[name+'distance_right'] = [dist if dist_min > 0 else 0 for dist, dist_min in zip(df[name+'distance_right'], df[name+'distance_min'])]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Calculate distance from all coordinates in first dataframe to nearest coordinates in second dataframe\n",
    "def measure_distance(df_measure, df_compare, comp_name, start_name = 'start', end_name = 'end'):\n",
    "    df_measure = df_measure.sort_values(by = ['chrom', start_name, end_name])\n",
    "    df_compare_merged = interval_overlap_per_chrom(df_compare)\n",
    "    df_compare_merged.columns = ['chrom', start_name, end_name]\n",
    "    df_measure_comparedist = dict()\n",
    "    for chrom in range(chr_range,23):\n",
    "        current_measure = df_measure.loc[df_measure['chrom'] == chrom].copy()\n",
    "        current_compare = df_compare_merged.loc[df_compare_merged['chrom'] == chrom].copy()\n",
    "        current_measure[comp_name+'_index'] = np.searchsorted(current_compare[start_name], current_measure[start_name], side = 'left')\n",
    "        current_measure['nearestcompare_left_end'] = list(current_compare.reset_index().reindex(current_measure[comp_name+'_index']-1)[end_name])\n",
    "        current_measure['nearestcompare_right_start'] = list(current_compare.reset_index().reindex(current_measure[comp_name+'_index'])[start_name])\n",
    "        current_measure[comp_name+'_distance_left'] = (current_measure[start_name] - current_measure['nearestcompare_left_end']).fillna(np.inf)\n",
    "        current_measure[comp_name+'_distance_right'] = (current_measure['nearestcompare_right_start'] - current_measure[end_name]).fillna(np.inf)\n",
    "        df_measure_comparedist[chrom] = current_measure\n",
    "    df_measure_comparedist = pd.concat(df_measure_comparedist).sort_values(by = ['chrom', start_name, end_name]).reset_index(drop = True)\n",
    "    del df_measure_comparedist[comp_name+'_index']; del df_measure_comparedist['nearestcompare_left_end']; del df_measure_comparedist['nearestcompare_right_start']\n",
    "    df_measure_comparedist[comp_name+'_distance_min'] = [min([L,R]) for L, R in zip(df_measure_comparedist[comp_name+'_distance_left'], df_measure_comparedist[comp_name+'_distance_right'])]\n",
    "    # if either side is negative, set both values to 0\n",
    "    df_measure_comparedist[comp_name+'_distance_left'] = [dist if dist_min > 0 else 0 for dist, dist_min in zip(df_measure_comparedist[comp_name+'_distance_left'], df_measure_comparedist[comp_name+'_distance_min'])]\n",
    "    df_measure_comparedist[comp_name+'_distance_right'] = [dist if dist_min > 0 else 0 for dist, dist_min in zip(df_measure_comparedist[comp_name+'_distance_right'], df_measure_comparedist[comp_name+'_distance_min'])]\n",
    "    \n",
    "    return df_measure_comparedist\n",
    "\n",
    "# Calculate distance from all point coordinates in first dataframe to nearest start/end coordinates in second dataframe\n",
    "def measure_distance_point(df_measure, df_compare, pos_column_name, comp_name, start_name = 'start', end_name = 'end'):\n",
    "    df_measure = df_measure.sort_values(by = ['chrom', pos_column_name])\n",
    "    df_compare_merged = interval_overlap_per_chrom(df_compare)\n",
    "    df_measure_comparedist = dict()\n",
    "    for chrom in range(chr_range,23):\n",
    "        current_compare = df_compare_merged.loc[df_compare_merged['chrom'] == chrom].copy()\n",
    "        current_compare_combined = pd.DataFrame(pd.concat([current_compare[start_name], current_compare[end_name]]).sort_values(), columns = ['pos']).reset_index(drop = True)\n",
    "        current_compare_combined['se'] = ['s', 'e']*round(len(current_compare_combined)/2)\n",
    "\n",
    "        current_measure = df_measure.loc[df_measure['chrom'] == chrom].reset_index(drop = True).copy()\n",
    "        current_measure[['current_left_pos', 'current_left_se']] = current_compare_combined.reindex(np.searchsorted(current_compare_combined['pos'], current_measure[pos_column_name])-1).reset_index(drop = True)\n",
    "        current_measure[['current_right_pos', 'current_right_se']] = current_compare_combined.reindex(np.searchsorted(current_compare_combined['pos'], current_measure[pos_column_name])).reset_index(drop = True)\n",
    "        current_measure['current_se'] = current_measure['current_left_se'] + current_measure['current_right_se']\n",
    "        current_measure[comp_name + '_distance_left'] = ([pos - left if se == 'es' else 0 for pos, left, se in zip(current_measure[pos_column_name], current_measure['current_left_pos'], current_measure['current_se'])]).fillna(np.inf)\n",
    "        current_measure[comp_name + '_distance_right'] = ([right - pos if se == 'es' else 0 for pos, right, se in zip(current_measure[pos_column_name], current_measure['current_right_pos'], current_measure['current_se'])]).fillna(np.inf)\n",
    "        \n",
    "        df_measure_comparedist[chrom] = current_measure\n",
    "    df_measure_comparedist = pd.concat(df_measure_comparedist).sort_values(by = ['chrom', pos_column_name]).reset_index(drop = True)\n",
    "    del df_measure_comparedist['current_left_pos']; del df_measure_comparedist['current_left_se']; del df_measure_comparedist['current_right_pos']; del df_measure_comparedist['current_right_se']; del df_measure_comparedist['current_se']\n",
    "    df_measure_comparedist[comp_name+'_distance_min'] = [min([L,R]) for L, R in zip(df_measure_comparedist[comp_name+'_distance_left'], df_measure_comparedist[comp_name+'_distance_right'])]\n",
    "    # if either side is negative, set both values to 0\n",
    "    df_measure_comparedist[comp_name+'_distance_left'] = [dist if dist_min > 0 else 0 for dist, dist_min in zip(df_measure_comparedist[comp_name+'_distance_left'], df_measure_comparedist[comp_name+'_distance_min'])]\n",
    "    df_measure_comparedist[comp_name+'_distance_right'] = [dist if dist_min > 0 else 0 for dist, dist_min in zip(df_measure_comparedist[comp_name+'_distance_right'], df_measure_comparedist[comp_name+'_distance_min'])]\n",
    "    return df_measure_comparedist\n",
    "\n",
    "def make_colorscale(list_of_traces, opacity = 0.15):\n",
    "    current_colors = pd.Series(['rgb('+str(current/len(list_of_traces)*255) + ', 180, '+str((len(list_of_traces)-current)/len(list_of_traces)*255)+')' for current in range(len(list_of_traces))], index = list_of_traces)\n",
    "    return pd.Series(current_colors, index = list_of_traces), pd.Series(['rgba' + color[3:-1] + ', '+str(opacity)+')' for color in current_colors], index = list_of_traces)\n",
    "\n",
    "def make_default_colors(list_of_traces, opacity = 0.15, last_black = True):\n",
    "    current_colors = plotly.colors.DEFAULT_PLOTLY_COLORS + plotly.colors.qualitative.Dark2\n",
    "    current_colors = current_colors*max(round(len(list_of_traces)/len(current_colors))+1, 1)\n",
    "    if last_black == True:\n",
    "        current_colors = current_colors[:len(list_of_traces)-1] + ['rgb(0,0,0)']\n",
    "    else:\n",
    "        current_colors = current_colors[:len(list_of_traces)]\n",
    "    return pd.Series(current_colors, index = list_of_traces), pd.Series(['rgba' + color[3:-1] + ', ' + str(opacity) + ')' for color in current_colors], index = list_of_traces)\n",
    "\n",
    "def reverse_complement_dnv(mut):\n",
    "    complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A', 'N': 'N'}\n",
    "    return ''.join([complement[base] for base in mut.split('>')[0][::-1]])+'>'+''.join([complement[base] for base in mut.split('>')[1][::-1]])\n",
    "dinuc = [base1+base2 for base1 in ['A', 'T', 'G', 'C'] for base2 in ['A', 'T', 'G', 'C']]\n",
    "dinuc_F = ['AA', 'AG', 'AC', 'TG', 'TC', 'GG']\n",
    "dinuc_RC = ['TT', 'CT', 'GT', 'CA', 'GA', 'CC']\n",
    "dinuc_sym = ['AT', 'TA', 'GC', 'CG']\n",
    "dinuc_mut_F = [di1 + '>' + di2 for di1 in dinuc_F for di2 in dinuc if (di1[0] != di2[0]) & (di1[1] != di2[1])]\n",
    "dinuc_mut_RC = [reverse_complement_dnv(mut) for mut in dinuc_mut_F]\n",
    "dinuc_mut_sym = [di1 + '>' + di2 for di1 in dinuc_sym for di2 in dinuc if (di1[0] != di2[0]) & (di1[1] != di2[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e80983",
   "metadata": {},
   "source": [
    "# Process hg38 human genome fasta  <a name=\"hg38\"></a>\n",
    "- Measure trinucleotide content\n",
    "- Apply RepeatMasker to remove transposable elements\n",
    "\n",
    "#### Download genome fasta files  <a name=\"hg38download\"></a>\n",
    "- hg38 chromosome fasta files available at: https://hgdownload.soe.ucsc.edu/goldenPath/hg38/chromosomes/\n",
    "- Extract .fa.gz\n",
    "- Place .fa files in subfolder \"./hg38/chromosomes/\"\n",
    "\n",
    "#### Read hg38 fasta files  <a name=\"hg38read\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d43b201",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_genome = dict()\n",
    "for chrom in chr_list:\n",
    "    with open('./hg38/chromosomes/chr'+str(chrom)+'.fa') as fasta_file:\n",
    "        for sequence in SimpleFastaParser(fasta_file):\n",
    "            chr_seq = sequence\n",
    "        reference_genome[chrom] = chr_seq[1]\n",
    "        reference_genome[chrom] = reference_genome[chrom].upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7c6da1",
   "metadata": {},
   "source": [
    "#### Count trinucleotides per chromosome  <a name=\"hg38count\"></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b035ba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count all trinucleotides in hg38\n",
    "triplet_df = pd.Series(0, index = all_triplets)\n",
    "\n",
    "for chrom in range(chr_range,23):\n",
    "    triplet_df = triplet_df.add(pd.Series(re.findall('...',reference_genome[chrom])).value_counts()).add(pd.Series(re.findall('...',reference_genome[chrom][1:])).value_counts()).add(pd.Series(re.findall('...',reference_genome[chrom][2:])).value_counts()).dropna().astype(int)\n",
    "    print('\\r' + str(chrom), end=' ')\n",
    "genome_triplet_totals = pd.DataFrame()\n",
    "genome_triplet_totals['hg38'] = triplet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e995a16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save triplet totals in .csv format\n",
    "genome_triplet_totals.to_csv('./hg38/triplet_totals_hg38_chr'+str(chr_range)+'-22.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d460772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load triplet totals\n",
    "genome_triplet_totals = pd.read_csv('./hg38/triplet_totals_hg38_chr'+str(chr_range)+'-22.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db39d236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count all dinucleotides in hg38\n",
    "di_df = pd.Series(0, index = dinuc)\n",
    "\n",
    "for chrom in range(chr_range,23):\n",
    "    di_df = di_df.add(pd.Series(re.findall('..',reference_genome[chrom])).value_counts()).add(pd.Series(re.findall('..',reference_genome[chrom][1:])).value_counts()).dropna().astype(int)\n",
    "    print('\\r' + str(chrom), end=' ')\n",
    "genome_di_totals = pd.DataFrame()\n",
    "genome_di_totals['hg38'] = di_df\n",
    "\n",
    "# Save dinuc totals in .csv format\n",
    "genome_di_totals.to_csv('./hg38/dinuc_totals_hg38_chr'+str(chr_range)+'-22.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62935f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dinuc totals\n",
    "genome_di_totals = pd.read_csv('./hg38/dinuc_totals_hg38_chr'+str(chr_range)+'-22.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a24d00e",
   "metadata": {},
   "source": [
    "# Use Repeatmasker to remove transposable elements from hg38 <a name=\"RM\"></a>\n",
    "\n",
    "#### Download Repeatmasker <a name=\"RMdownload\"></a>\n",
    "- Download Repeatmasker from UCSC Table Browser: https://genome.ucsc.edu/cgi-bin/hgTables\n",
    "- Select options:\n",
    "    - assembly: Dec 2013 (GRCh38/hg38)\n",
    "    - group: Repeats\n",
    "    - track: RepeatMasker\n",
    "    - region: genome\n",
    "    - output format: all fields from selected table\n",
    "    - output filename: hg38_repeatmasker.bed\n",
    "    - file type returned: gzip compressed\n",
    "- Place .bed.gz file in subfolder './hg38/repeatmasker/'\n",
    "\n",
    "#### Read and format Repeatmasker file <a name=\"RMread\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9591947",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeatmasker = pd.read_csv('./hg38/repeatmasker/hg38_repeatmasker.bed.gz', sep = '\\t', usecols = ['genoName', 'genoStart', 'genoEnd', 'strand', 'repName', 'repClass', 'repFamily'])\n",
    "repeatmasker.columns = ['chrom', 'start', 'end', 'strand', 'repName', 'repClass', 'repFamily']\n",
    "repeatmasker['chrom'] = [chrom[3:] for chrom in repeatmasker['chrom']]\n",
    "repeatmasker = repeatmasker.loc[repeatmasker['chrom'].isin([str(chrom) for chrom in range(chr_range,23)])]\n",
    "repeatmasker['chrom'] = repeatmasker['chrom'].astype(int)\n",
    "repeatmasker = repeatmasker.reset_index(drop = True)\n",
    "\n",
    "# Remove 'Low complexity' and 'Simple Repeat' categories from Repeatmasker\n",
    "repeatmasker = repeatmasker.loc[repeatmasker['repClass'].isin(['Low_complexity', 'Simple_repeat']) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bae0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce Repeatmasker to a set of non-overlapping coordinates\n",
    "RM_LC_SR = interval_overlap_per_chrom(repeatmasker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764e5b8c",
   "metadata": {},
   "source": [
    "#### Modify genome fastas to remove Repeatmasker regions <a name=\"RMmodify\"></a>\n",
    "    make directory './hg38/chromosomes/masked/' for file output\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672690a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate masked reference genome\n",
    "coordinates_to_Ns(RM_LC_SR, reference_genome, 'transposons replaced with Ns', 'RMnosimple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3555e378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load masked reference genome\n",
    "reference_genome_masked = dict()\n",
    "for chrom in chr_list:\n",
    "    with open('./hg38/chromosomes/masked/chr'+str(chrom)+'_mask_RMnosimple.fasta') as fasta_file:\n",
    "        for sequence in SimpleFastaParser(fasta_file):\n",
    "            chr_seq = sequence\n",
    "        reference_genome_masked[chrom] = chr_seq[1]\n",
    "        reference_genome_masked[chrom] = reference_genome_masked[chrom].upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597ade0b",
   "metadata": {},
   "source": [
    "# Generate database of repeats in hg38 <a name=\"DB\"></a>\n",
    "\n",
    "## Short Tandem Repeats <a name=\"DB_STR\"></a>\n",
    "\n",
    "### Define search features <a name=\"DB_STR_define\"></a>\n",
    "\n",
    "#### List of all possible N-mers <a name=\"DB_STR_define_allNmers\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea43e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "bases = ['A', 'T', 'G', 'C']\n",
    "dinucleotides = [base1+base2 for base1 in ['A', 'T', 'G', 'C'] for base2 in ['A', 'T', 'G', 'C'] if base1 != base2]\n",
    "trinucleotides = [base1+base2+base3 for base1 in ['A', 'T', 'G', 'C'] for base2 in ['A', 'T', 'G', 'C'] for base3 in ['A', 'T', 'G', 'C'] if base1+base2+base3 not in ['AAA', 'TTT', 'GGG', 'CCC']]\n",
    "\n",
    "exclude_4 = [base*4 for base in bases] + [di*2 for di in dinucleotides]\n",
    "tetranucleotides = [base1+base2+base3+base4 for base1 in ['A', 'T', 'G', 'C'] for base2 in ['A', 'T', 'G', 'C'] for base3 in ['A', 'T', 'G', 'C'] for base4 in ['A', 'T', 'G', 'C'] if base1+base2+base3+base4 not in exclude_4]\n",
    "\n",
    "exclude_5 = [base*5 for base in bases]\n",
    "exclude_6 = [base*6 for base in bases] + [di*3 for di in dinucleotides] + [tri*2 for tri in trinucleotides]\n",
    "exclude_7 = [base*7 for base in bases]\n",
    "exclude_8 = [base*8 for base in bases] + [di*4 for di in dinucleotides] + [quad*2 for quad in tetranucleotides]\n",
    "exclude_9 = [base*9 for base in bases] + [tri*3 for tri in trinucleotides]\n",
    "\n",
    "nuc_5mer = [base1+base2+base3+base4+base5 for base1 in ['A', 'T', 'G', 'C'] for base2 in ['A', 'T', 'G', 'C'] for base3 in ['A', 'T', 'G', 'C'] for base4 in ['A', 'T', 'G', 'C'] for base5 in ['A', 'T', 'G', 'C'] if base1+base2+base3+base4+base5 not in exclude_5]\n",
    "nuc_6mer = [base1+base2+base3+base4+base5+base6 for base1 in ['A', 'T', 'G', 'C'] for base2 in ['A', 'T', 'G', 'C'] for base3 in ['A', 'T', 'G', 'C'] for base4 in ['A', 'T', 'G', 'C'] for base5 in ['A', 'T', 'G', 'C'] for base6 in ['A', 'T', 'G', 'C'] if base1+base2+base3+base4+base5+base6 not in exclude_6]\n",
    "nuc_7mer = [base1+base2+base3+base4+base5+base6+base7 for base1 in ['A', 'T', 'G', 'C'] for base2 in ['A', 'T', 'G', 'C'] for base3 in ['A', 'T', 'G', 'C'] for base4 in ['A', 'T', 'G', 'C'] for base5 in ['A', 'T', 'G', 'C'] for base6 in ['A', 'T', 'G', 'C'] for base7 in ['A', 'T', 'G', 'C'] if base1+base2+base3+base4+base5+base6+base7 not in exclude_7]\n",
    "nuc_8mer = [base1+base2+base3+base4+base5+base6+base7+base8 for base1 in ['A', 'T', 'G', 'C'] for base2 in ['A', 'T', 'G', 'C'] for base3 in ['A', 'T', 'G', 'C'] for base4 in ['A', 'T', 'G', 'C'] for base5 in ['A', 'T', 'G', 'C'] for base6 in ['A', 'T', 'G', 'C'] for base7 in ['A', 'T', 'G', 'C'] for base8 in ['A', 'T', 'G', 'C'] if base1+base2+base3+base4+base5+base6+base7+base8 not in exclude_8]\n",
    "nuc_9mer = [base1+base2+base3+base4+base5+base6+base7+base8+base9 for base1 in ['A', 'T', 'G', 'C'] for base2 in ['A', 'T', 'G', 'C'] for base3 in ['A', 'T', 'G', 'C'] for base4 in ['A', 'T', 'G', 'C'] for base5 in ['A', 'T', 'G', 'C'] for base6 in ['A', 'T', 'G', 'C'] for base7 in ['A', 'T', 'G', 'C'] for base8 in ['A', 'T', 'G', 'C'] for base9 in ['A', 'T', 'G', 'C'] if base1+base2+base3+base4+base5+base6+base7+base8+base9 not in exclude_9]\n",
    "\n",
    "feature_names = [bases, dinucleotides, trinucleotides, tetranucleotides, nuc_5mer, nuc_6mer, nuc_7mer, nuc_8mer, nuc_9mer]\n",
    "feature_seq = [[part*5 for part in bases], [part*3 for part in dinucleotides], [part*2 for part in trinucleotides], [part*2 for part in tetranucleotides], [part*2 for part in nuc_5mer], [part*2 for part in nuc_6mer], [part*2 for part in nuc_7mer], [part*2 for part in nuc_8mer], [part*2 for part in nuc_9mer]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214a1b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of potential different N-mers per value of N\n",
    "[len(feature) for feature in feature_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a093c9d5",
   "metadata": {},
   "source": [
    "#### Reduce all possible N-mers to nonredundant N-mers <a name=\"DB_STR_define_nonredundant\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcced16",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_pos = dict()\n",
    "exclude_pos[1] = [seq[1]+seq[0] for seq in dinucleotides]\n",
    "dinucleotides_nonredundant = [dinucleotides[pos] for pos in range(len(dinucleotides)) if dinucleotides[pos] not in exclude_pos[1][:pos] ]\n",
    "\n",
    "exclude_pos = dict()\n",
    "exclude_pos[1] = [seq[2]+seq[0]+seq[1] for seq in trinucleotides]\n",
    "exclude_pos[2] = [seq[1]+seq[2]+seq[0] for seq in trinucleotides]\n",
    "trinucleotides_nonredundant = [trinucleotides[pos] for pos in range(len(trinucleotides)) if (trinucleotides[pos] not in exclude_pos[1][:pos]) & (trinucleotides[pos] not in exclude_pos[2][:pos])]\n",
    "\n",
    "exclude_pos = dict()\n",
    "exclude_pos[1] = [seq[3]+seq[0]+seq[1]+seq[2] for seq in tetranucleotides]\n",
    "exclude_pos[2] = [seq[2]+seq[3]+seq[0]+seq[1] for seq in tetranucleotides]\n",
    "exclude_pos[3] = [seq[1]+seq[2]+seq[3]+seq[0] for seq in tetranucleotides]\n",
    "tetranucleotides_nonredundant = [tetranucleotides[pos] for pos in range(len(tetranucleotides)) if (tetranucleotides[pos] not in exclude_pos[1][:pos]) & (tetranucleotides[pos] not in exclude_pos[2][:pos]) & (tetranucleotides[pos] not in exclude_pos[3][:pos])]\n",
    "\n",
    "exclude_pos = dict()\n",
    "exclude_pos[1] = [seq[4]+seq[0]+seq[1]+seq[2]+seq[3] for seq in nuc_5mer]\n",
    "exclude_pos[2] = [seq[3]+seq[4]+seq[0]+seq[1]+seq[2] for seq in nuc_5mer]\n",
    "exclude_pos[3] = [seq[2]+seq[3]+seq[4]+seq[0]+seq[1] for seq in nuc_5mer]\n",
    "exclude_pos[4] = [seq[1]+seq[2]+seq[3]+seq[4]+seq[0] for seq in nuc_5mer]\n",
    "nuc_5mer_nonredundant = [nuc_5mer[pos] for pos in range(len(nuc_5mer)) if (nuc_5mer[pos] not in exclude_pos[1][:pos]) & (nuc_5mer[pos] not in exclude_pos[2][:pos]) & (nuc_5mer[pos] not in exclude_pos[3][:pos]) & (nuc_5mer[pos] not in exclude_pos[4][:pos])]\n",
    "\n",
    "exclude_pos = dict()\n",
    "exclude_pos[1] = [seq[5]+seq[0]+seq[1]+seq[2]+seq[3]+seq[4] for seq in nuc_6mer]\n",
    "exclude_pos[2] = [seq[4]+seq[5]+seq[0]+seq[1]+seq[2]+seq[3] for seq in nuc_6mer]\n",
    "exclude_pos[3] = [seq[3]+seq[4]+seq[5]+seq[0]+seq[1]+seq[2] for seq in nuc_6mer]\n",
    "exclude_pos[4] = [seq[2]+seq[3]+seq[4]+seq[5]+seq[0]+seq[1] for seq in nuc_6mer]\n",
    "exclude_pos[5] = [seq[1]+seq[2]+seq[3]+seq[4]+seq[5]+seq[0] for seq in nuc_6mer]\n",
    "nuc_6mer_nonredundant = [nuc_6mer[pos] for pos in range(len(nuc_6mer)) if (nuc_6mer[pos] not in exclude_pos[1][:pos]) & (nuc_6mer[pos] not in exclude_pos[2][:pos]) & (nuc_6mer[pos] not in exclude_pos[3][:pos]) & (nuc_6mer[pos] not in exclude_pos[4][:pos]) & (nuc_6mer[pos] not in exclude_pos[5][:pos])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27632e97",
   "metadata": {},
   "source": [
    "#### Reduce search space for high-N-mers by first searching for any N-mers that repeat at least once <a name=\"DB_STR_define_reduce\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c1bb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_7mers = dict()\n",
    "for chrom in range(chr_range,23):\n",
    "    rep_7mers[chrom] = dict()\n",
    "    for pos in range(7):\n",
    "        rep_7mers[chrom][pos] = pd.DataFrame(re.findall('.'*7, reference_genome_masked[chrom][pos:]), columns = ['7mer'])\n",
    "        rep_7mers[chrom][pos]['start'] = rep_7mers[chrom][pos].index*7\n",
    "        rep_7mers[chrom][pos]['shift'] = rep_7mers[chrom][pos]['7mer'].shift(-1)\n",
    "        rep_7mers[chrom][pos] = rep_7mers[chrom][pos].loc[(rep_7mers[chrom][pos]['7mer'] == rep_7mers[chrom][pos]['shift']) & (rep_7mers[chrom][pos]['7mer'] != 'N'*7)]\n",
    "    rep_7mers[chrom] = pd.concat(rep_7mers[chrom])\n",
    "    print('\\r' + '7-mer chr' + str(chrom), end='        ')\n",
    "\n",
    "rep_7mer_counts_all = pd.Series(0, index = nuc_7mer)\n",
    "for chrom in range(chr_range,23):\n",
    "    rep_7mer_counts_all += pd.Series(rep_7mers[chrom]['7mer'].value_counts(), index = nuc_7mer)\n",
    "rep_7mer_counts_all = rep_7mer_counts_all.dropna()\n",
    "\n",
    "exclude_pos = dict()\n",
    "exclude_pos[1] = [seq[6]+seq[0]+seq[1]+seq[2]+seq[3]+seq[4]+seq[5] for seq in rep_7mer_counts_all.index]\n",
    "exclude_pos[2] = [seq[5]+seq[6]+seq[0]+seq[1]+seq[2]+seq[3]+seq[4] for seq in rep_7mer_counts_all.index]\n",
    "exclude_pos[3] = [seq[4]+seq[5]+seq[6]+seq[0]+seq[1]+seq[2]+seq[3] for seq in rep_7mer_counts_all.index]\n",
    "exclude_pos[4] = [seq[3]+seq[4]+seq[5]+seq[6]+seq[0]+seq[1]+seq[2] for seq in rep_7mer_counts_all.index]\n",
    "exclude_pos[5] = [seq[2]+seq[3]+seq[4]+seq[5]+seq[6]+seq[0]+seq[1] for seq in rep_7mer_counts_all.index]\n",
    "exclude_pos[6] = [seq[1]+seq[2]+seq[3]+seq[4]+seq[5]+seq[6]+seq[0] for seq in rep_7mer_counts_all.index]\n",
    "nuc_7mer_nonredundant = [rep_7mer_counts_all.index[pos] for pos in range(len(rep_7mer_counts_all.index)) if (rep_7mer_counts_all.index[pos] not in exclude_pos[1][:pos]) & (rep_7mer_counts_all.index[pos] not in exclude_pos[2][:pos]) & (rep_7mer_counts_all.index[pos] not in exclude_pos[3][:pos]) & (rep_7mer_counts_all.index[pos] not in exclude_pos[4][:pos]) & (rep_7mer_counts_all.index[pos] not in exclude_pos[5][:pos]) & (rep_7mer_counts_all.index[pos] not in exclude_pos[6][:pos])]\n",
    "\n",
    "rep_8mers = dict()\n",
    "for chrom in range(chr_range,23):\n",
    "    rep_8mers[chrom] = dict()\n",
    "    for pos in range(8):\n",
    "        rep_8mers[chrom][pos] = pd.DataFrame(re.findall('.'*8, reference_genome_masked[chrom][pos:]), columns = ['8mer'])\n",
    "        rep_8mers[chrom][pos]['start'] = rep_8mers[chrom][pos].index*8\n",
    "        rep_8mers[chrom][pos]['shift'] = rep_8mers[chrom][pos]['8mer'].shift(-1)\n",
    "        rep_8mers[chrom][pos] = rep_8mers[chrom][pos].loc[(rep_8mers[chrom][pos]['8mer'] == rep_8mers[chrom][pos]['shift']) & (rep_8mers[chrom][pos]['8mer'] != 'N'*8)]\n",
    "    rep_8mers[chrom] = pd.concat(rep_8mers[chrom])\n",
    "    print('\\r' + '8-mer chr' + str(chrom), end='        ')\n",
    "\n",
    "rep_8mer_counts_all = pd.Series(0, index = nuc_8mer)\n",
    "for chrom in range(chr_range,23):\n",
    "    rep_8mer_counts_all += pd.Series(rep_8mers[chrom]['8mer'].value_counts(), index = nuc_8mer)\n",
    "rep_8mer_counts_all = rep_8mer_counts_all.dropna()\n",
    "\n",
    "exclude_pos = dict()\n",
    "exclude_pos[1] = [seq[7]+seq[0]+seq[1]+seq[2]+seq[3]+seq[4]+seq[5]+seq[6] for seq in rep_8mer_counts_all.index]\n",
    "exclude_pos[2] = [seq[6]+seq[7]+seq[0]+seq[1]+seq[2]+seq[3]+seq[4]+seq[5] for seq in rep_8mer_counts_all.index]\n",
    "exclude_pos[3] = [seq[5]+seq[6]+seq[7]+seq[0]+seq[1]+seq[2]+seq[3]+seq[4] for seq in rep_8mer_counts_all.index]\n",
    "exclude_pos[4] = [seq[4]+seq[5]+seq[6]+seq[7]+seq[0]+seq[1]+seq[2]+seq[3] for seq in rep_8mer_counts_all.index]\n",
    "exclude_pos[5] = [seq[3]+seq[4]+seq[5]+seq[6]+seq[7]+seq[0]+seq[1]+seq[2] for seq in rep_8mer_counts_all.index]\n",
    "exclude_pos[6] = [seq[2]+seq[3]+seq[4]+seq[5]+seq[6]+seq[7]+seq[0]+seq[1] for seq in rep_8mer_counts_all.index]\n",
    "exclude_pos[7] = [seq[1]+seq[2]+seq[3]+seq[4]+seq[5]+seq[6]+seq[7]+seq[0] for seq in rep_8mer_counts_all.index]\n",
    "nuc_8mer_nonredundant = [rep_8mer_counts_all.index[pos] for pos in range(len(rep_8mer_counts_all.index)) if (rep_8mer_counts_all.index[pos] not in exclude_pos[1][:pos]) & (rep_8mer_counts_all.index[pos] not in exclude_pos[2][:pos]) & (rep_8mer_counts_all.index[pos] not in exclude_pos[3][:pos]) & (rep_8mer_counts_all.index[pos] not in exclude_pos[4][:pos]) & (rep_8mer_counts_all.index[pos] not in exclude_pos[5][:pos]) & (rep_8mer_counts_all.index[pos] not in exclude_pos[6][:pos]) & (rep_8mer_counts_all.index[pos] not in exclude_pos[7][:pos])]\n",
    "\n",
    "rep_9mers = dict()\n",
    "for chrom in range(chr_range,23):\n",
    "    rep_9mers[chrom] = dict()\n",
    "    for pos in range(9):\n",
    "        rep_9mers[chrom][pos] = pd.DataFrame(re.findall('.'*9, reference_genome_masked[chrom][pos:]), columns = ['9mer'])\n",
    "        rep_9mers[chrom][pos]['start'] = rep_9mers[chrom][pos].index*9\n",
    "        rep_9mers[chrom][pos]['shift'] = rep_9mers[chrom][pos]['9mer'].shift(-1)\n",
    "        rep_9mers[chrom][pos] = rep_9mers[chrom][pos].loc[(rep_9mers[chrom][pos]['9mer'] == rep_9mers[chrom][pos]['shift']) & (rep_9mers[chrom][pos]['9mer'] != 'N'*9)]\n",
    "    rep_9mers[chrom] = pd.concat(rep_9mers[chrom])\n",
    "    print('\\r' + '9-mer chr' + str(chrom), end='        ')\n",
    "\n",
    "rep_9mer_counts_all = pd.Series(0, index = nuc_9mer)\n",
    "for chrom in range(chr_range,23):\n",
    "    rep_9mer_counts_all += pd.Series(rep_9mers[chrom]['9mer'].value_counts(), index = nuc_9mer)\n",
    "rep_9mer_counts_all = rep_9mer_counts_all.dropna()\n",
    "\n",
    "exclude_pos = dict()\n",
    "exclude_pos[1] = [seq[8]+seq[0]+seq[1]+seq[2]+seq[3]+seq[4]+seq[5]+seq[6]+seq[7] for seq in rep_9mer_counts_all.index]\n",
    "exclude_pos[2] = [seq[7]+seq[8]+seq[0]+seq[1]+seq[2]+seq[3]+seq[4]+seq[5]+seq[6] for seq in rep_9mer_counts_all.index]\n",
    "exclude_pos[3] = [seq[6]+seq[7]+seq[8]+seq[0]+seq[1]+seq[2]+seq[3]+seq[4]+seq[5] for seq in rep_9mer_counts_all.index]\n",
    "exclude_pos[4] = [seq[5]+seq[6]+seq[7]+seq[8]+seq[0]+seq[1]+seq[2]+seq[3]+seq[4] for seq in rep_9mer_counts_all.index]\n",
    "exclude_pos[5] = [seq[4]+seq[5]+seq[6]+seq[7]+seq[8]+seq[0]+seq[1]+seq[2]+seq[3] for seq in rep_9mer_counts_all.index]\n",
    "exclude_pos[6] = [seq[3]+seq[4]+seq[5]+seq[6]+seq[7]+seq[8]+seq[0]+seq[1]+seq[2] for seq in rep_9mer_counts_all.index]\n",
    "exclude_pos[7] = [seq[2]+seq[3]+seq[4]+seq[5]+seq[6]+seq[7]+seq[8]+seq[0]+seq[1] for seq in rep_9mer_counts_all.index]\n",
    "exclude_pos[8] = [seq[1]+seq[2]+seq[3]+seq[4]+seq[5]+seq[6]+seq[7]+seq[8]+seq[0] for seq in rep_9mer_counts_all.index]\n",
    "nuc_9mer_nonredundant = [rep_9mer_counts_all.index[pos] for pos in range(len(rep_9mer_counts_all.index)) if (rep_9mer_counts_all.index[pos] not in exclude_pos[1][:pos]) & (rep_9mer_counts_all.index[pos] not in exclude_pos[2][:pos]) & (rep_9mer_counts_all.index[pos] not in exclude_pos[3][:pos]) & (rep_9mer_counts_all.index[pos] not in exclude_pos[4][:pos]) & (rep_9mer_counts_all.index[pos] not in exclude_pos[5][:pos]) & (rep_9mer_counts_all.index[pos] not in exclude_pos[6][:pos]) & (rep_9mer_counts_all.index[pos] not in exclude_pos[7][:pos]) & (rep_9mer_counts_all.index[pos] not in exclude_pos[8][:pos])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153a30cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [bases, dinucleotides_nonredundant, trinucleotides_nonredundant, tetranucleotides_nonredundant, nuc_5mer_nonredundant, nuc_6mer_nonredundant, nuc_7mer_nonredundant, nuc_8mer_nonredundant, nuc_9mer_nonredundant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cf5840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save temporary file: list of STR units to search\n",
    "pd.Series(feature_names).to_pickle('./custom_db/temp/STR_units_in_genome_chr'+str(chr_range)+'-22.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f007cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load temporary file: list of STR units to search\n",
    "feature_names = list(pd.read_pickle('./custom_db/temp/STR_units_in_genome_chr'+str(chr_range)+'-22.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6908ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of actual different N-mers per value of N to search\n",
    "[len(feature) for feature in feature_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb78206",
   "metadata": {},
   "source": [
    "### Search, including overlaps <a name=\"DB_STR_search\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe761e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define minimum STR length for each N-mer size:\n",
    "# 5 units for N=1, 3 units for N=2, 2 units for N>=3\n",
    "feature_seq = [[part*5 for part in feature_names[0]], [part*3 for part in feature_names[1]], [part*2 for part in feature_names[2]], [part*2 for part in feature_names[3]], [part*2 for part in feature_names[4]], [part*2 for part in feature_names[5]], [part*2 for part in feature_names[6]], [part*2 for part in feature_names[7]], [part*2 for part in feature_names[8]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cd98f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_STRs = dict()\n",
    "\n",
    "for seq, name in zip(feature_seq[0], feature_names[0]):\n",
    "    found_STRs[name] = dict()\n",
    "    for chrom in range(chr_range,23):\n",
    "        found_STRs[name][chrom] = pd.DataFrame()\n",
    "        current_iter = re.finditer(seq, reference_genome_masked[chrom], overlapped = True)\n",
    "        current_indices = [match.start(0) for match in current_iter]\n",
    "        found_STRs[name][chrom]['start'] = current_indices\n",
    "        found_STRs[name][chrom]['end'] = found_STRs[name][chrom]['start'] +len(seq)\n",
    "        found_STRs[name][chrom]['chrom'] = chrom\n",
    "        print('\\r' + name + ' chr' + str(chrom), end='        ')\n",
    "\n",
    "for seq, name in zip(feature_seq[1], feature_names[1]):\n",
    "    found_STRs[name] = dict()\n",
    "    for chrom in range(chr_range,23):\n",
    "        found_STRs[name][chrom] = pd.DataFrame()\n",
    "        current_iter = re.finditer(seq, reference_genome_masked[chrom], overlapped = True)\n",
    "        current_indices = [match.start(0) for match in current_iter]\n",
    "        found_STRs[name][chrom]['start'] = current_indices\n",
    "        found_STRs[name][chrom]['end'] = found_STRs[name][chrom]['start'] +len(seq)\n",
    "        found_STRs[name][chrom]['chrom'] = chrom\n",
    "        print('\\r' + name + ' chr' + str(chrom), end='        ')\n",
    "\n",
    "counter = 0\n",
    "for seq, name in zip(feature_seq[2], feature_names[2]):\n",
    "    found_STRs[name] = dict()\n",
    "    counter +=1\n",
    "    for chrom in range(chr_range,23):\n",
    "        found_STRs[name][chrom] = pd.DataFrame()\n",
    "        current_iter = re.finditer(seq, reference_genome_masked[chrom], overlapped = True)\n",
    "        current_indices = [match.start(0) for match in current_iter]\n",
    "        found_STRs[name][chrom]['start'] = current_indices\n",
    "        found_STRs[name][chrom]['end'] = found_STRs[name][chrom]['start'] +len(seq)\n",
    "        found_STRs[name][chrom]['chrom'] = chrom\n",
    "        print('\\r' + name + ' chr' + str(chrom) + ' ' + str(counter) + '/' + str(len(feature_names[2])), end='        ')\n",
    "\n",
    "counter = 0\n",
    "for seq, name in zip(feature_seq[3], feature_names[3]):\n",
    "    found_STRs[name] = dict()\n",
    "    counter +=1\n",
    "    for chrom in range(chr_range,23):\n",
    "        found_STRs[name][chrom] = pd.DataFrame()\n",
    "        current_iter = re.finditer(seq, reference_genome_masked[chrom], overlapped = True)\n",
    "        current_indices = [match.start(0) for match in current_iter]\n",
    "        found_STRs[name][chrom]['start'] = current_indices\n",
    "        found_STRs[name][chrom]['end'] = found_STRs[name][chrom]['start'] +len(seq)\n",
    "        found_STRs[name][chrom]['chrom'] = chrom\n",
    "        print('\\r' + name + ' chr' + str(chrom) + ' ' + str(counter) + '/' + str(len(feature_names[3])), end='        ')\n",
    "\n",
    "counter = 0\n",
    "for seq, name in zip(feature_seq[4], feature_names[4]):\n",
    "    found_STRs[name] = dict()\n",
    "    counter +=1\n",
    "    for chrom in range(chr_range,23):\n",
    "        found_STRs[name][chrom] = pd.DataFrame()\n",
    "        current_iter = re.finditer(seq, reference_genome_masked[chrom], overlapped = True)\n",
    "        current_indices = [match.start(0) for match in current_iter]\n",
    "        found_STRs[name][chrom]['start'] = current_indices\n",
    "        found_STRs[name][chrom]['end'] = found_STRs[name][chrom]['start'] +len(seq)\n",
    "        found_STRs[name][chrom]['chrom'] = chrom\n",
    "        print('\\r' + name + ' chr' + str(chrom) + ' ' + str(counter) + '/' + str(len(feature_names[4])), end='        ')\n",
    "\n",
    "counter = 0\n",
    "for seq, name in zip(feature_seq[5], feature_names[5]):\n",
    "    found_STRs[name] = dict()\n",
    "    counter +=1\n",
    "    for chrom in range(chr_range,23):\n",
    "        found_STRs[name][chrom] = pd.DataFrame()\n",
    "        current_iter = re.finditer(seq, reference_genome_masked[chrom], overlapped = True)\n",
    "        current_indices = [match.start(0) for match in current_iter]\n",
    "        found_STRs[name][chrom]['start'] = current_indices\n",
    "        found_STRs[name][chrom]['end'] = found_STRs[name][chrom]['start'] +len(seq)\n",
    "        found_STRs[name][chrom]['chrom'] = chrom\n",
    "        print('\\r' + name + ' chr' + str(chrom) + ' ' + str(counter) + '/' + str(len(feature_names[5])), end='        ')\n",
    "\n",
    "counter = 0\n",
    "for seq, name in zip(feature_seq[6], feature_names[6]):\n",
    "    found_STRs[name] = dict()\n",
    "    counter +=1\n",
    "    for chrom in range(chr_range,23):\n",
    "        found_STRs[name][chrom] = pd.DataFrame()\n",
    "        current_iter = re.finditer(seq, reference_genome_masked[chrom], overlapped = True)\n",
    "        current_indices = [match.start(0) for match in current_iter]\n",
    "        found_STRs[name][chrom]['start'] = current_indices\n",
    "        found_STRs[name][chrom]['end'] = found_STRs[name][chrom]['start'] +len(seq)\n",
    "        found_STRs[name][chrom]['chrom'] = chrom\n",
    "        print('\\r' + name + ' chr' + str(chrom) + ' ' + str(counter) + '/' + str(len(feature_names[6])), end='        ')\n",
    "\n",
    "counter = 0\n",
    "for seq, name in zip(feature_seq[7], feature_names[7]):\n",
    "    found_STRs[name] = dict()\n",
    "    counter +=1\n",
    "    for chrom in range(chr_range,23):\n",
    "        found_STRs[name][chrom] = pd.DataFrame()\n",
    "        current_iter = re.finditer(seq, reference_genome_masked[chrom], overlapped = True)\n",
    "        current_indices = [match.start(0) for match in current_iter]\n",
    "        found_STRs[name][chrom]['start'] = current_indices\n",
    "        found_STRs[name][chrom]['end'] = found_STRs[name][chrom]['start'] +len(seq)\n",
    "        found_STRs[name][chrom]['chrom'] = chrom\n",
    "        print('\\r' + name + ' chr' + str(chrom) + ' ' + str(counter) + '/' + str(len(feature_names[7])), end='        ')\n",
    "\n",
    "counter = 0\n",
    "for seq, name in zip(feature_seq[8], feature_names[8]):\n",
    "    found_STRs[name] = dict()\n",
    "    counter +=1\n",
    "    for chrom in range(chr_range,23):\n",
    "        found_STRs[name][chrom] = pd.DataFrame()\n",
    "        current_iter = re.finditer(seq, reference_genome_masked[chrom], overlapped = True)\n",
    "        current_indices = [match.start(0) for match in current_iter]\n",
    "        found_STRs[name][chrom]['start'] = current_indices\n",
    "        found_STRs[name][chrom]['end'] = found_STRs[name][chrom]['start'] +len(seq)\n",
    "        found_STRs[name][chrom]['chrom'] = chrom\n",
    "        print('\\r' + name + ' chr' + str(chrom) + ' ' + str(counter) + '/' + str(len(feature_names[8])), end='        ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1caf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empties\n",
    "for name in found_STRs:\n",
    "    found_STRs[name] = pd.concat(found_STRs[name])\n",
    "found_STRs_non0 = dict()\n",
    "for name in found_STRs:\n",
    "    if len(found_STRs[name]) != 0:\n",
    "        found_STRs_non0[name] = found_STRs[name]\n",
    "found_STRs = found_STRs_non0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d90584c",
   "metadata": {},
   "source": [
    "### Expand by full repeat unit <a name=\"DB_STR_expand_full\"></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a96114e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search right\n",
    "found_STRs_expand_R = dict()\n",
    "for name in found_STRs:\n",
    "    found_STRs_expand_R[name] = dict()\n",
    "    exp_len = 0\n",
    "    found_STRs_expand_R[name][exp_len] = found_STRs[name].astype(int).copy()\n",
    "    found_STRs_expand_R[name][exp_len]['right+1'] = [reference_genome_masked[chrom][pos:pos+len(name)] for chrom, pos in zip(found_STRs_expand_R[name][exp_len]['chrom'], found_STRs_expand_R[name][exp_len]['end'])]\n",
    "    remaining_len = 1\n",
    "    found_STRs_expand_R[name][exp_len+1] = found_STRs_expand_R[name][exp_len].loc[found_STRs_expand_R[name][exp_len]['right+1'] == name]\n",
    "    found_STRs_expand_R[name][exp_len] = found_STRs_expand_R[name][exp_len].loc[found_STRs_expand_R[name][exp_len]['right+1'] != name]\n",
    "    while remaining_len >0:\n",
    "        exp_len += 1\n",
    "        found_STRs_expand_R[name][exp_len]['end'] += len(name)\n",
    "        found_STRs_expand_R[name][exp_len]['right+1'] = [reference_genome_masked[chrom][pos:pos+len(name)] for chrom, pos in zip(found_STRs_expand_R[name][exp_len]['chrom'], found_STRs_expand_R[name][exp_len]['end'])]\n",
    "        found_STRs_expand_R[name][exp_len+1] = found_STRs_expand_R[name][exp_len].loc[found_STRs_expand_R[name][exp_len]['right+1'] == name]\n",
    "        found_STRs_expand_R[name][exp_len] = found_STRs_expand_R[name][exp_len].loc[found_STRs_expand_R[name][exp_len]['right+1'] != name]\n",
    "        remaining_len = len(found_STRs_expand_R[name][exp_len])\n",
    "        print('\\r' + name + ' ' + str(remaining_len), end='        ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf108689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search left\n",
    "found_STRs_expand_L = dict()\n",
    "for name in found_STRs:\n",
    "    found_STRs_expand_L[name] = dict()\n",
    "    exp_len = 0\n",
    "    found_STRs_expand_L[name][exp_len] = pd.concat(found_STRs_expand_R[name])\n",
    "    found_STRs_expand_L[name][exp_len]['left-1'] = [reference_genome_masked[chrom][pos-len(name):pos] for chrom, pos in zip(found_STRs_expand_L[name][exp_len]['chrom'], found_STRs_expand_L[name][exp_len]['start'])]\n",
    "    remaining_len = 1\n",
    "    found_STRs_expand_L[name][exp_len+1] = found_STRs_expand_L[name][exp_len].loc[found_STRs_expand_L[name][exp_len]['left-1'] == name]\n",
    "    found_STRs_expand_L[name][exp_len] = found_STRs_expand_L[name][exp_len].loc[found_STRs_expand_L[name][exp_len]['left-1'] != name]\n",
    "    while remaining_len >0:\n",
    "        exp_len += 1\n",
    "        found_STRs_expand_L[name][exp_len]['start'] -= len(name)\n",
    "        found_STRs_expand_L[name][exp_len]['left-1'] = [reference_genome_masked[chrom][pos-len(name):pos] for chrom, pos in zip(found_STRs_expand_L[name][exp_len]['chrom'], found_STRs_expand_L[name][exp_len]['start'])]\n",
    "        found_STRs_expand_L[name][exp_len+1] = found_STRs_expand_L[name][exp_len].loc[found_STRs_expand_L[name][exp_len]['left-1'] == name]\n",
    "        found_STRs_expand_L[name][exp_len] = found_STRs_expand_L[name][exp_len].loc[found_STRs_expand_L[name][exp_len]['left-1'] != name]\n",
    "        remaining_len = len(found_STRs_expand_L[name][exp_len])\n",
    "        print('\\r' + name + ' ' + str(remaining_len), end='        ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5427efdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove dupicates\n",
    "for name in found_STRs:\n",
    "    found_STRs_expand_L[name] = pd.concat(found_STRs_expand_L[name])\n",
    "    found_STRs_expand_L[name] = found_STRs_expand_L[name].drop_duplicates(subset = ['chrom', 'start', 'end'])[['chrom', 'start', 'end']].sort_values(by = ['chrom', 'start', 'end']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d4805c",
   "metadata": {},
   "source": [
    "### Expand partial repeat units to get longest perfect STRs <a name=\"DB_STR_expand_partial\"></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e085dd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search right\n",
    "found_STRs_expand_partial_R = dict()\n",
    "for name in found_STRs:\n",
    "    found_STRs_expand_partial_R[name] = dict()\n",
    "    found_STRs_expand_partial_R[name][0] = found_STRs_expand_L[name].copy()\n",
    "    found_STRs_expand_partial_R[name][0]['right+1'] = [reference_genome_masked[chrom][pos:pos+len(name)] for chrom, pos in zip(found_STRs_expand_partial_R[name][0]['chrom'], found_STRs_expand_partial_R[name][0]['end'])]\n",
    "    found_STRs_expand_partial_R[name][0]['partial_len_R'] = 0\n",
    "    for pos in range(1, len(name)):\n",
    "        found_STRs_expand_partial_R[name][pos] = found_STRs_expand_partial_R[name][pos-1].loc[found_STRs_expand_partial_R[name][pos-1]['right+1'].str[:pos] == name[:pos]].copy()\n",
    "        found_STRs_expand_partial_R[name][pos]['partial_len_R'] = pos\n",
    "        found_STRs_expand_partial_R[name][pos-1] = found_STRs_expand_partial_R[name][pos-1].loc[found_STRs_expand_partial_R[name][pos-1]['right+1'].str[:pos] != name[:pos]].copy()\n",
    "        found_STRs_expand_partial_R[name][pos-1]['partial_len_R'] = pos-1\n",
    "    print('\\r' + name, end='        ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af048724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search left\n",
    "found_STRs_expand_partial_L = dict()\n",
    "for name in found_STRs:\n",
    "    found_STRs_expand_partial_L[name] = dict()\n",
    "    found_STRs_expand_partial_L[name][0] = pd.concat(found_STRs_expand_partial_R[name]).copy()\n",
    "    found_STRs_expand_partial_L[name][0]['left-1'] = [reference_genome_masked[chrom][pos-len(name):pos] for chrom, pos in zip(found_STRs_expand_partial_L[name][0]['chrom'], found_STRs_expand_partial_L[name][0]['start'])]\n",
    "    found_STRs_expand_partial_L[name][0]['partial_len_L'] = 0\n",
    "    for pos in range(1, len(name)):\n",
    "        found_STRs_expand_partial_L[name][pos] = found_STRs_expand_partial_L[name][pos-1].loc[found_STRs_expand_partial_L[name][pos-1]['left-1'].str[-pos:] == name[-pos:]].copy()\n",
    "        found_STRs_expand_partial_L[name][pos]['partial_len_L'] = pos\n",
    "        found_STRs_expand_partial_L[name][pos-1] = found_STRs_expand_partial_L[name][pos-1].loc[found_STRs_expand_partial_L[name][pos-1]['left-1'].str[-pos:] != name[-pos:]].copy()\n",
    "        found_STRs_expand_partial_L[name][pos-1]['partial_len_L'] = pos-1\n",
    "    print('\\r' + name, end='        ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642e1ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "for name in found_STRs_expand_partial_L:\n",
    "    found_STRs_expand_partial_L[name] = pd.concat(found_STRs_expand_partial_L[name])\n",
    "    found_STRs_expand_partial_L[name] = found_STRs_expand_partial_L[name].sort_values(by = ['chrom', 'start', 'end']).drop_duplicates(subset = ['chrom', 'start', 'end']).reset_index(drop = True)[['chrom', 'start', 'end', 'partial_len_L', 'partial_len_R']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddb5a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate annotations\n",
    "for name in found_STRs_expand_partial_L:\n",
    "    found_STRs_expand_partial_L[name]['full_start'] = found_STRs_expand_partial_L[name]['start']\n",
    "    found_STRs_expand_partial_L[name]['full_end'] = found_STRs_expand_partial_L[name]['end']\n",
    "    found_STRs_expand_partial_L[name]['start'] = found_STRs_expand_partial_L[name]['start'] - found_STRs_expand_partial_L[name]['partial_len_L']\n",
    "    found_STRs_expand_partial_L[name]['end'] = found_STRs_expand_partial_L[name]['end'] + found_STRs_expand_partial_L[name]['partial_len_R']\n",
    "    found_STRs_expand_partial_L[name]['seq'] = [reference_genome_masked[chrom][start:end] for chrom, start, end in zip(found_STRs_expand_partial_L[name]['chrom'], found_STRs_expand_partial_L[name]['start'], found_STRs_expand_partial_L[name]['end'])]\n",
    "    found_STRs_expand_partial_L[name]['length'] = found_STRs_expand_partial_L[name]['end'] - found_STRs_expand_partial_L[name]['start']\n",
    "    found_STRs_expand_partial_L[name]['n_units'] = found_STRs_expand_partial_L[name]['length'] / len(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4190c1a",
   "metadata": {},
   "source": [
    "### Find imperfect STRs <a name=\"DB_STR_imperfect\"></a>\n",
    "\n",
    "#### Overlap coordinates, allowing for up to one repeat unit of imperfection <a name=\"DB_STR_imperfect_overlap\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da191080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to merge any overlapping windows, merge across interruptions\n",
    "def interval_overlap_per_chrom_interruption(df_in, interruption_len):\n",
    "    df_out = dict()\n",
    "    for chrom in range(chr_range,23):\n",
    "        df_current = df_in.loc[df_in['chrom'] == chrom]\n",
    "        if len(df_current) > 0:\n",
    "            range_df = pd.DataFrame()            \n",
    "            range_df['start'] = sorted(list(df_current['start'] - interruption_len))\n",
    "            range_df['end'] = sorted(list(df_current['end'] + interruption_len))\n",
    "            \n",
    "            range_df_shift = pd.DataFrame()\n",
    "            range_df_shift['start'] = range_df['start'][1:].reset_index(drop = True)\n",
    "            range_df_shift['end'] = range_df['end'][:-1].reset_index(drop = True)\n",
    "            range_df_shift['overlap'] = range_df_shift['start'] > range_df_shift['end']\n",
    "            range_df_shift = range_df_shift.loc[range_df_shift['overlap'] == True]\n",
    "\n",
    "            range_df_merged = pd.DataFrame()\n",
    "            range_df_merged['start'] = [range_df['start'][0]] +list(range_df_shift['start'])\n",
    "            range_df_merged['end'] = list(range_df_shift['end']) + [range_df['end'][len(range_df.index)-1]]\n",
    "\n",
    "            range_df = range_df_merged\n",
    "            range_df['chrom'] = chrom\n",
    "\n",
    "            range_df['start'] = range_df['start'] + interruption_len\n",
    "            range_df['end'] = range_df['end'] - interruption_len\n",
    "\n",
    "            df_out[chrom] = range_df\n",
    "    df_out = pd.concat(df_out).reset_index(drop = True)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea43f279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find interruptions\n",
    "found_STRs_interruptions = dict()\n",
    "for name in found_STRs_expand_partial_L:\n",
    "    found_STRs_interruptions[name] = interval_overlap_per_chrom_interruption(found_STRs_expand_partial_L[name], len(name))\n",
    "    print('\\r' + name, end='        ')\n",
    "\n",
    "# Add annotations\n",
    "for name in found_STRs_interruptions:\n",
    "    found_STRs_interruptions[name]['start'] = found_STRs_interruptions[name]['start'].astype(int)\n",
    "    found_STRs_interruptions[name]['end'] = found_STRs_interruptions[name]['end'].astype(int)\n",
    "    found_STRs_interruptions[name]['length'] = found_STRs_interruptions[name]['end'] - found_STRs_interruptions[name]['start']\n",
    "    found_STRs_interruptions[name]['length'] = found_STRs_interruptions[name]['length'].astype(int)\n",
    "    found_STRs_interruptions[name]['repeat'] = name\n",
    "    found_STRs_interruptions[name]['Sequence'] = [reference_genome_masked[chrom][start:end] for chrom, start, end in zip(found_STRs_interruptions[name]['chrom'], found_STRs_interruptions[name]['start'], found_STRs_interruptions[name]['end'])]\n",
    "    found_STRs_interruptions[name]['n_units'] = found_STRs_interruptions[name]['length'] / len(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5c799a",
   "metadata": {},
   "source": [
    "#### Find location of interruptions within each STR <a name=\"DB_STR_imperfect_location\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b8c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in found_STRs_interruptions:\n",
    "    found_STRs_interruptions[name]['repeat_frame_L'] = [seq[:len(name)] for seq in found_STRs_interruptions[name]['Sequence']]\n",
    "    found_STRs_interruptions[name]['repeat_frame_R'] = [seq[-len(name):] for seq in found_STRs_interruptions[name]['Sequence']]\n",
    "\n",
    "for name in found_STRs_interruptions:\n",
    "    found_STRs_interruptions[name]['rep_pos_L'] = [[match.start(0) for match in re.finditer(frame, seq, overlapped = True)] for frame, seq in zip(found_STRs_interruptions[name]['repeat_frame_L'], found_STRs_interruptions[name]['Sequence'])]\n",
    "    found_STRs_interruptions[name]['rep_pos_R'] = [[match.start(0) for match in re.finditer(frame, seq, overlapped = True)] for frame, seq in zip(found_STRs_interruptions[name]['repeat_frame_R'], found_STRs_interruptions[name]['Sequence'])]\n",
    "    print('\\r' + name, end='        ')\n",
    "\n",
    "for name in found_STRs_interruptions:\n",
    "    found_STRs_interruptions[name]['n_full_units_L'] = [len(matches) for matches in found_STRs_interruptions[name]['rep_pos_L']]\n",
    "    found_STRs_interruptions[name]['n_full_units_R'] = [len(matches) for matches in found_STRs_interruptions[name]['rep_pos_R']]\n",
    "\n",
    "for name in found_STRs_interruptions:\n",
    "    found_STRs_interruptions[name]['rep_pos_inline_L'] = [[pos for pos in matches if pos%len(name) != 0] for matches in found_STRs_interruptions[name]['rep_pos_L']]\n",
    "    found_STRs_interruptions[name]['rep_pos_inline_R'] = [[pos for pos in matches if pos%len(name) != length%len(name)] for matches, length in zip(found_STRs_interruptions[name]['rep_pos_R'], found_STRs_interruptions[name]['length'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b527496",
   "metadata": {},
   "source": [
    "#### Separate perfect vs imperfect STRs <a name=\"DB_STR_imperfect_separate\"></a>\n",
    "\n",
    "- perfect STRs: all unit positions divisible by unit length, and total length is within 1 unit length of repeat length\n",
    "- in-frame mutations: no out of frame positions from L and R ends, and total length is not within 1 unit length of repeat length\n",
    "- short indels: out of frame positions, and total length is within 1 unit length of repeat length\n",
    "- complex: out of frame positions, and total length is not within 1 unit length of repeat length\n",
    "\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874deade",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_STRs_perfect = dict()\n",
    "found_STRs_inframe = dict()\n",
    "found_STRs_shortindel = dict()\n",
    "found_STRs_complex = dict()\n",
    "for name in found_STRs_interruptions:\n",
    "    found_STRs_perfect[name] = found_STRs_interruptions[name].loc[(found_STRs_interruptions[name]['rep_pos_inline_L'].str.len() == 0) & (found_STRs_interruptions[name]['rep_pos_inline_R'].str.len() == 0) & (found_STRs_interruptions[name]['length'] - (found_STRs_interruptions[name]['n_full_units_L'] * len(name)) < len(name)) & (found_STRs_interruptions[name]['n_full_units_L'] >=3)].copy()\n",
    "    found_STRs_inframe[name] = found_STRs_interruptions[name].loc[(found_STRs_interruptions[name]['rep_pos_inline_L'].str.len() == 0) & (found_STRs_interruptions[name]['rep_pos_inline_R'].str.len() == 0) & (found_STRs_interruptions[name]['length'] - (found_STRs_interruptions[name]['n_full_units_L'] * len(name)) >= len(name)) & (found_STRs_interruptions[name]['n_full_units_L'] >=3)].copy()\n",
    "    found_STRs_shortindel[name] = found_STRs_interruptions[name].loc[((found_STRs_interruptions[name]['rep_pos_inline_L'].str.len() != 0) | (found_STRs_interruptions[name]['rep_pos_inline_R'].str.len() != 0)) & ((found_STRs_interruptions[name]['length'] - (found_STRs_interruptions[name]['n_full_units_L'] * len(name)) < len(name)) | (found_STRs_interruptions[name]['length'] - (found_STRs_interruptions[name]['n_full_units_R'] * len(name)) < len(name))) & (found_STRs_interruptions[name]['n_full_units_L'] >=3)].copy()\n",
    "    found_STRs_complex[name] = found_STRs_interruptions[name].loc[((found_STRs_interruptions[name]['rep_pos_inline_L'].str.len() != 0) | (found_STRs_interruptions[name]['rep_pos_inline_R'].str.len() != 0)) & (found_STRs_interruptions[name]['length'] - (found_STRs_interruptions[name]['n_full_units_L'] * len(name)) >= len(name)) & (found_STRs_interruptions[name]['length'] - (found_STRs_interruptions[name]['n_full_units_R'] * len(name)) >= len(name)) & (found_STRs_interruptions[name]['n_full_units_L'] >=3)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee93814",
   "metadata": {},
   "source": [
    "### Save/load  <a name=\"DB_STR_imperfect_save\"></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65be8202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine\n",
    "for name in found_STRs:\n",
    "    found_STRs_perfect[name]['status'] = 'perfect'\n",
    "    found_STRs_inframe[name]['status'] = 'inframe'\n",
    "    found_STRs_shortindel[name]['status'] = 'shortindel'\n",
    "    found_STRs_complex[name]['status'] = 'complex'\n",
    "\n",
    "all_STRs = pd.concat([pd.concat(found_STRs_perfect), pd.concat(found_STRs_inframe), pd.concat(found_STRs_shortindel), pd.concat(found_STRs_complex)])\n",
    "all_STRs = all_STRs.sort_values(by = ['chrom', 'start', 'end', 'repeat']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2fd898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign strand to reverse-complementary motifs\n",
    "\n",
    "# STR motifs with enough power to analyze\n",
    "repeats_highpower = ['T', 'G', 'TG', 'TC', 'TGG', 'ATT', 'TTG', 'TTC', 'TCC', 'ATG', 'TGC', 'ATTT', 'A', 'C',  'AC', 'AG', 'ACC', 'AAT', 'AAC', 'AAG', 'AGG', 'ATC', 'AGC', 'AAAT', 'AT', 'GC']\n",
    "# Symmetric and asymmetric STR motifs\n",
    "repeats_highpower_asym = pd.Series(['T', 'G', 'TG', 'TC', 'TGG', 'ATT', 'TTG', 'TTC', 'TCC', 'ATG', 'TGC', 'ATTT'], index = ['A', 'C',  'AC', 'AG', 'ACC', 'AAT', 'AAC', 'AAG', 'AGG', 'ATC', 'AGC', 'AAAT'])\n",
    "repeats_highpower_sym = ['AT', 'GC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a676df",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_STRs_strand_F = all_STRs.loc[all_STRs['repeat'].isin(repeats_highpower_asym.index)].copy()\n",
    "all_STRs_strand_F['Strand'] = '+'\n",
    "all_STRs_strand_R = all_STRs.loc[all_STRs['repeat'].isin(repeats_highpower_asym)].copy()\n",
    "all_STRs_strand_R['Strand'] = '-'\n",
    "all_STRs_strand_na = all_STRs.loc[~(all_STRs['repeat'].isin(repeats_highpower_asym.index)) & ~(all_STRs['repeat'].isin(repeats_highpower_asym))].copy()\n",
    "\n",
    "all_STRs = pd.concat([all_STRs_strand_F, all_STRs_strand_R, all_STRs_strand_na]).sort_values(by = ['chrom', 'start', 'end', 'repeat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f74d917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save \n",
    "all_STRs.to_csv('./custom_db/temp/STRs_custom_imperfect_1-9_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace0bc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "all_STRs = pd.read_csv('./custom_db/temp/STRs_custom_imperfect_1-9_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de81859",
   "metadata": {},
   "source": [
    "### Mask reference genome with STRs <a name=\"DB_STR_mask\"></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be90192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate masked reference genome\n",
    "coordinates_to_Ns(all_STRs, reference_genome_masked, 'transposons and STRs replaced with Ns', 'RMnosimple_STR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2422b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load masked reference genome\n",
    "reference_genome_masked_STR = dict()\n",
    "for chrom in chr_list:\n",
    "    with open('./hg38/chromosomes/masked/chr'+str(chrom)+'_mask_RMnosimple_STR.fasta') as fasta_file:\n",
    "        for sequence in SimpleFastaParser(fasta_file):\n",
    "            chr_seq = sequence\n",
    "        reference_genome_masked_STR[chrom] = chr_seq[1]\n",
    "        reference_genome_masked_STR[chrom] = reference_genome_masked_STR[chrom].upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f58a835",
   "metadata": {},
   "source": [
    "## Inverted repeats <a name=\"DB_IR\"></a>\n",
    "\n",
    "#### Find all IR 5-mers <a name=\"DB_IR_5mer\"></a>\n",
    "    make directory './custom_db/temp/' for output\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0113b7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5   # N-mer size\n",
    "max_spacer = 100    # Max spacer size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f20376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RC_match = dict()\n",
    "for chrom in range(chr_range,23):\n",
    "    # Find all 5-mers in chromosome\n",
    "    Nmer_sets_overlap = pd.DataFrame(re.findall('.'*N, reference_genome_masked_STR[chrom], overlapped = True), columns = ['seq'])\n",
    "    Nmer_sets_overlap = Nmer_sets_overlap.loc[Nmer_sets_overlap['seq'].str.count('N') ==0]\n",
    "    Nmer_sets_overlap['L_start'] = Nmer_sets_overlap.index\n",
    "    Nmer_sets_overlap.reset_index(drop = True, inplace = True)\n",
    "    # Get reverse_complement of each 5-mer\n",
    "    Nmer_sets_overlap['seq_RC'] = [reverse_complement(seq) for seq in Nmer_sets_overlap['seq']]\n",
    "    Nmer_sets_overlap['R_start'] = Nmer_sets_overlap['L_start']\n",
    "    # For each spacer length, check if FWD 5-mer = REVC 5-mer\n",
    "    Nmer_sets_overlap['spacer'] = -N\n",
    "    RC_match[chrom] = dict()\n",
    "    for n_shifts in range(max_spacer+N+1):\n",
    "        RC_match[chrom][n_shifts] = Nmer_sets_overlap.loc[Nmer_sets_overlap['seq'] == Nmer_sets_overlap['seq_RC']]\n",
    "        Nmer_sets_overlap['seq_RC'] = Nmer_sets_overlap['seq_RC'].shift(-1)\n",
    "        Nmer_sets_overlap['R_start'] = Nmer_sets_overlap['R_start'].shift(-1)\n",
    "        Nmer_sets_overlap['spacer'] = Nmer_sets_overlap['spacer'] + 1\n",
    "        print('\\r' + 'shifting spacer ' +str(n_shifts) + ' chr' + str(chrom), end='        ')\n",
    "    RC_match[chrom] = pd.concat(RC_match[chrom])\n",
    "    RC_match[chrom]['chrom'] = chrom\n",
    "RC_match = pd.concat(RC_match)\n",
    "RC_match.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f8d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "del Nmer_sets_overlap\n",
    "IR_5mers_expand = dict()\n",
    "IR_5mers_expand[N] = RC_match.loc[RC_match['spacer'] >= 0][['chrom', 'L_start', 'R_start']].copy()\n",
    "IR_5mers_expand[N]['R_start'] = IR_5mers_expand[N]['R_start'].astype(int)\n",
    "del RC_match\n",
    "# save temporary file\n",
    "IR_5mers_expand[N].to_csv('./custom_db/temp/IR_SL'+str(N)+'_SP'+str(max_spacer)+'_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f255e226",
   "metadata": {},
   "source": [
    "#### Expand perfect IRs <a name=\"DB_IR_expand\"></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2692a0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load temporary file\n",
    "stem_len = 5    # Initial N-mer size from above section\n",
    "max_spacer = 100  # Max spacer size from above section\n",
    "\n",
    "IR_5mers_expand = dict()\n",
    "IR_5mers_expand[stem_len] = pd.read_csv('./custom_db/temp/IR_SL'+str(stem_len)+'_SP'+str(max_spacer)+'_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533b894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IR_5mers_expand[stem_len]['stem_len'] = stem_len\n",
    "IR_5mers_expand[stem_len]['L_end'] = IR_5mers_expand[stem_len]['L_start'] + stem_len\n",
    "IR_5mers_expand[stem_len]['R_end'] = IR_5mers_expand[stem_len]['R_start'] + stem_len\n",
    "IR_5mers_expand[5]['spacer'] = IR_5mers_expand[5]['R_start'] - IR_5mers_expand[5]['L_end']\n",
    "IR_5mers_expand[5] = IR_5mers_expand[5].loc[IR_5mers_expand[5]['spacer'] <=100]\n",
    "\n",
    "# Continue IR search outwards from initial matches\n",
    "list_len = len(IR_5mers_expand[stem_len])\n",
    "while list_len > 0:\n",
    "    IR_5mers_expand[stem_len]['seq_L'] = [reference_genome_masked_STR[chrom][start-1:end] for chrom, start, end in zip(IR_5mers_expand[stem_len]['chrom'], IR_5mers_expand[stem_len]['L_start'], IR_5mers_expand[stem_len]['L_end'])]\n",
    "    IR_5mers_expand[stem_len]['seq_R'] = [reference_genome_masked_STR[chrom][start:end+1] for chrom, start, end in zip(IR_5mers_expand[stem_len]['chrom'], IR_5mers_expand[stem_len]['R_start'], IR_5mers_expand[stem_len]['R_end'])]\n",
    "    IR_5mers_expand[stem_len]['seq_R'] = [reverse_complement(seq) for seq in IR_5mers_expand[stem_len]['seq_R']]\n",
    "    IR_5mers_expand[stem_len+1] = IR_5mers_expand[stem_len].loc[(IR_5mers_expand[stem_len]['seq_L'] == IR_5mers_expand[stem_len]['seq_R']) & (IR_5mers_expand[stem_len]['seq_L'].str.count('N') == 0) & (IR_5mers_expand[stem_len]['seq_R'].str.count('N') == 0)]\n",
    "    IR_5mers_expand[stem_len] = IR_5mers_expand[stem_len].loc[(IR_5mers_expand[stem_len]['seq_L'] != IR_5mers_expand[stem_len]['seq_R']) | (IR_5mers_expand[stem_len]['seq_L'].str.count('N') != 0) | (IR_5mers_expand[stem_len]['seq_R'].str.count('N') != 0)]\n",
    "    stem_len +=1\n",
    "    list_len = len(IR_5mers_expand[stem_len])\n",
    "    IR_5mers_expand[stem_len]['L_start'] = IR_5mers_expand[stem_len]['L_start'] - 1\n",
    "    IR_5mers_expand[stem_len]['R_end'] = IR_5mers_expand[stem_len]['R_end'] + 1\n",
    "    IR_5mers_expand[stem_len]['stem_len'] = stem_len\n",
    "    print('\\r' + 'expanding out stem_len ' +str(stem_len), end='        ')\n",
    "IR_5mers_expand = pd.concat(IR_5mers_expand)\n",
    "del IR_5mers_expand['seq_L']; del IR_5mers_expand['seq_R']\n",
    "\n",
    "# Remove duplicates and IRs that expand into masked regions\n",
    "IR_5mers_expand = IR_5mers_expand.drop_duplicates(subset = ['L_start', 'L_end', 'R_start', 'R_end'], keep = 'first')\n",
    "IR_5mers_expand['Sequence'] = [reference_genome_masked_STR[chrom][start:end] for chrom, start, end in zip(IR_5mers_expand['chrom'], IR_5mers_expand['L_start'], IR_5mers_expand['R_end'])]\n",
    "IR_5mers_expand = IR_5mers_expand.loc[IR_5mers_expand['Sequence'].str.count('N') == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b724bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue IR search inward, unless spacer length is already 0\n",
    "IR_5mers_expand_in = dict()\n",
    "in_len = 0\n",
    "IR_5mers_expand_in[in_len] = IR_5mers_expand.copy()\n",
    "\n",
    "list_len = len(IR_5mers_expand_in[in_len])\n",
    "while list_len > 0:\n",
    "    IR_5mers_expand_in[in_len]['seq_L'] = [reference_genome_masked_STR[chrom][start:end+1] for chrom, start, end in zip(IR_5mers_expand_in[in_len]['chrom'], IR_5mers_expand_in[in_len]['L_start'], IR_5mers_expand_in[in_len]['L_end'])]\n",
    "    IR_5mers_expand_in[in_len]['seq_R'] = [reference_genome_masked_STR[chrom][start-1:end] for chrom, start, end in zip(IR_5mers_expand_in[in_len]['chrom'], IR_5mers_expand_in[in_len]['R_start'], IR_5mers_expand_in[in_len]['R_end'])]\n",
    "    IR_5mers_expand_in[in_len]['seq_R'] = [reverse_complement(seq) for seq in IR_5mers_expand_in[in_len]['seq_R']]\n",
    "    IR_5mers_expand_in[in_len+1] = IR_5mers_expand_in[in_len].loc[(IR_5mers_expand_in[in_len]['seq_L'] == IR_5mers_expand_in[in_len]['seq_R']) & (IR_5mers_expand_in[in_len]['seq_L'].str.count('N') == 0) & (IR_5mers_expand_in[in_len]['seq_R'].str.count('N') == 0) & (IR_5mers_expand_in[in_len]['spacer'] > 1)]\n",
    "    IR_5mers_expand_in[in_len] = IR_5mers_expand_in[in_len].loc[(IR_5mers_expand_in[in_len]['seq_L'] != IR_5mers_expand_in[in_len]['seq_R']) | (IR_5mers_expand_in[in_len]['seq_L'].str.count('N') != 0) | (IR_5mers_expand_in[in_len]['seq_R'].str.count('N') != 0) | (IR_5mers_expand_in[in_len]['spacer'] <= 1)]\n",
    "    in_len +=1\n",
    "    list_len = len(IR_5mers_expand_in[in_len])\n",
    "    IR_5mers_expand_in[in_len]['R_start'] = IR_5mers_expand_in[in_len]['R_start'] - 1\n",
    "    IR_5mers_expand_in[in_len]['L_end'] = IR_5mers_expand_in[in_len]['L_end'] + 1\n",
    "    IR_5mers_expand_in[in_len]['spacer'] = IR_5mers_expand_in[in_len]['spacer'] -2\n",
    "    print('\\r' + 'expanding in ' +str(in_len), end='        ')\n",
    "\n",
    "IR_5mers_expand_in = pd.concat(IR_5mers_expand_in).reset_index(drop = True)\n",
    "del IR_5mers_expand_in['seq_L']; del IR_5mers_expand_in['seq_R']\n",
    "\n",
    "# Remove duplicates and IRs that expand into masked regions\n",
    "IR_5mers_expand_in = IR_5mers_expand_in.drop_duplicates(subset = ['L_start', 'L_end', 'R_start', 'R_end'], keep = 'first')\n",
    "IR_5mers_expand_in['Sequence'] = [reference_genome_masked_STR[chrom][start:end] for chrom, start, end in zip(IR_5mers_expand_in['chrom'], IR_5mers_expand_in['L_start'], IR_5mers_expand_in['R_end'])]\n",
    "IR_5mers_expand_in = IR_5mers_expand_in.loc[IR_5mers_expand_in['Sequence'].str.count('N') == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3775807c",
   "metadata": {},
   "source": [
    "#### Expand imperfect IRs <a name=\"DB_IR_expand_imperfect\"></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228e0c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore one mismatch, then search again outwards\n",
    "IR_5mers_expand_imperfect = dict()\n",
    "imp_len = 0\n",
    "IR_5mers_expand_imperfect[imp_len] = IR_5mers_expand_in.copy()\n",
    "\n",
    "IR_5mers_expand_imperfect[imp_len]['imp_seq_L'] = [reference_genome_masked_STR[chrom][start-2:start-1] for chrom, start in zip(IR_5mers_expand_imperfect[imp_len]['chrom'], IR_5mers_expand_imperfect[imp_len]['L_start'])]\n",
    "IR_5mers_expand_imperfect[imp_len]['imp_seq_R'] = [reference_genome_masked_STR[chrom][end+1:end+2] for chrom, end in zip(IR_5mers_expand_imperfect[imp_len]['chrom'], IR_5mers_expand_imperfect[imp_len]['R_end'])]\n",
    "IR_5mers_expand_imperfect[imp_len]['imp_seq_R'] = [reverse_complement(seq) for seq in IR_5mers_expand_imperfect[imp_len]['imp_seq_R']]\n",
    "IR_5mers_expand_imperfect[imp_len+1] = IR_5mers_expand_imperfect[imp_len].loc[(IR_5mers_expand_imperfect[imp_len]['imp_seq_L'] == IR_5mers_expand_imperfect[imp_len]['imp_seq_R']) & (IR_5mers_expand_imperfect[imp_len]['imp_seq_L'].str.count('N') == 0) & (IR_5mers_expand_imperfect[imp_len]['imp_seq_R'].str.count('N') == 0)]\n",
    "IR_5mers_expand_imperfect[imp_len] = IR_5mers_expand_imperfect[imp_len].loc[(IR_5mers_expand_imperfect[imp_len]['imp_seq_L'] != IR_5mers_expand_imperfect[imp_len]['imp_seq_R']) | (IR_5mers_expand_imperfect[imp_len]['imp_seq_L'].str.count('N') != 0) | (IR_5mers_expand_imperfect[imp_len]['imp_seq_R'].str.count('N') != 0)]\n",
    "imp_len +=1\n",
    "IR_5mers_expand_imperfect[imp_len]['L_start'] = IR_5mers_expand_imperfect[imp_len]['L_start'] - 2\n",
    "IR_5mers_expand_imperfect[imp_len]['R_end'] = IR_5mers_expand_imperfect[imp_len]['R_end'] + 2\n",
    "\n",
    "list_len = len(IR_5mers_expand_imperfect[imp_len])\n",
    "while list_len > 0:\n",
    "    IR_5mers_expand_imperfect[imp_len]['imp_seq_L'] = [reference_genome_masked_STR[chrom][start-1:start] for chrom, start in zip(IR_5mers_expand_imperfect[imp_len]['chrom'], IR_5mers_expand_imperfect[imp_len]['L_start'])]\n",
    "    IR_5mers_expand_imperfect[imp_len]['imp_seq_R'] = [reference_genome_masked_STR[chrom][end:end+1] for chrom, end in zip(IR_5mers_expand_imperfect[imp_len]['chrom'], IR_5mers_expand_imperfect[imp_len]['R_end'])]\n",
    "    IR_5mers_expand_imperfect[imp_len]['imp_seq_R'] = [reverse_complement(seq) for seq in IR_5mers_expand_imperfect[imp_len]['imp_seq_R']]\n",
    "    IR_5mers_expand_imperfect[imp_len+1] = IR_5mers_expand_imperfect[imp_len].loc[(IR_5mers_expand_imperfect[imp_len]['imp_seq_L'] == IR_5mers_expand_imperfect[imp_len]['imp_seq_R']) & (IR_5mers_expand_imperfect[imp_len]['imp_seq_L'].str.count('N') == 0) & (IR_5mers_expand_imperfect[imp_len]['imp_seq_R'].str.count('N') == 0)]\n",
    "    IR_5mers_expand_imperfect[imp_len] = IR_5mers_expand_imperfect[imp_len].loc[(IR_5mers_expand_imperfect[imp_len]['imp_seq_L'] != IR_5mers_expand_imperfect[imp_len]['imp_seq_R']) | (IR_5mers_expand_imperfect[imp_len]['imp_seq_L'].str.count('N') != 0) | (IR_5mers_expand_imperfect[imp_len]['imp_seq_R'].str.count('N') != 0)]\n",
    "    imp_len +=1\n",
    "    list_len = len(IR_5mers_expand_imperfect[imp_len])\n",
    "    IR_5mers_expand_imperfect[imp_len]['L_start'] = IR_5mers_expand_imperfect[imp_len]['L_start'] - 1\n",
    "    IR_5mers_expand_imperfect[imp_len]['R_end'] = IR_5mers_expand_imperfect[imp_len]['R_end'] + 1\n",
    "    print('\\r' + 'expanding out imp_len ' +str(imp_len), end='        ')\n",
    "\n",
    "IR_5mers_expand_imperfect_out = pd.concat(IR_5mers_expand_imperfect).reset_index(drop = True)\n",
    "IR_5mers_expand_imperfect_out['spacer'] = IR_5mers_expand_imperfect_out['R_start'] - IR_5mers_expand_imperfect_out['L_end']\n",
    "IR_5mers_expand_imperfect_out = IR_5mers_expand_imperfect_out.loc[IR_5mers_expand_imperfect_out['spacer'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22777682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore one mismatch, then search again inwards, unless spacer is already 0\n",
    "IR_5mers_expand_imperfect = dict()\n",
    "imp_len = 0\n",
    "IR_5mers_expand_imperfect[imp_len] = IR_5mers_expand_imperfect_out.copy()\n",
    "\n",
    "IR_5mers_expand_imperfect[imp_len]['imp_seq_L'] = [reference_genome_masked_STR[chrom][end+1:end+2] for chrom, end in zip(IR_5mers_expand_imperfect[imp_len]['chrom'], IR_5mers_expand_imperfect[imp_len]['L_end'])]\n",
    "IR_5mers_expand_imperfect[imp_len]['imp_seq_R'] = [reference_genome_masked_STR[chrom][start-2:start-1] for chrom, start in zip(IR_5mers_expand_imperfect[imp_len]['chrom'], IR_5mers_expand_imperfect[imp_len]['R_start'])]\n",
    "IR_5mers_expand_imperfect[imp_len]['imp_seq_R'] = [reverse_complement(seq) for seq in IR_5mers_expand_imperfect[imp_len]['imp_seq_R']]\n",
    "IR_5mers_expand_imperfect[imp_len+1] = IR_5mers_expand_imperfect[imp_len].loc[(IR_5mers_expand_imperfect[imp_len]['imp_seq_L'] == IR_5mers_expand_imperfect[imp_len]['imp_seq_R']) & (IR_5mers_expand_imperfect[imp_len]['imp_seq_L'].str.count('N') == 0) & (IR_5mers_expand_imperfect[imp_len]['imp_seq_R'].str.count('N') == 0) & (IR_5mers_expand_imperfect[imp_len]['spacer'] > 3)]\n",
    "IR_5mers_expand_imperfect[imp_len] = IR_5mers_expand_imperfect[imp_len].loc[(IR_5mers_expand_imperfect[imp_len]['imp_seq_L'] != IR_5mers_expand_imperfect[imp_len]['imp_seq_R']) | (IR_5mers_expand_imperfect[imp_len]['imp_seq_L'].str.count('N') != 0) | (IR_5mers_expand_imperfect[imp_len]['imp_seq_R'].str.count('N') != 0) | (IR_5mers_expand_imperfect[imp_len]['spacer'] <= 3)]\n",
    "imp_len +=1\n",
    "IR_5mers_expand_imperfect[imp_len]['L_end'] = IR_5mers_expand_imperfect[imp_len]['L_end'] + 2\n",
    "IR_5mers_expand_imperfect[imp_len]['R_start'] = IR_5mers_expand_imperfect[imp_len]['R_start'] - 2\n",
    "IR_5mers_expand_imperfect[imp_len]['spacer'] = IR_5mers_expand_imperfect[imp_len]['spacer'] - 4\n",
    "\n",
    "list_len = len(IR_5mers_expand_imperfect[imp_len])\n",
    "while list_len > 0:\n",
    "    IR_5mers_expand_imperfect[imp_len]['imp_seq_L'] = [reference_genome_masked_STR[chrom][end:end+1] for chrom, end in zip(IR_5mers_expand_imperfect[imp_len]['chrom'], IR_5mers_expand_imperfect[imp_len]['L_end'])]\n",
    "    IR_5mers_expand_imperfect[imp_len]['imp_seq_R'] = [reference_genome_masked_STR[chrom][start-1:start] for chrom, start in zip(IR_5mers_expand_imperfect[imp_len]['chrom'], IR_5mers_expand_imperfect[imp_len]['R_start'])]\n",
    "    IR_5mers_expand_imperfect[imp_len]['imp_seq_R'] = [reverse_complement(seq) for seq in IR_5mers_expand_imperfect[imp_len]['imp_seq_R']]\n",
    "    IR_5mers_expand_imperfect[imp_len+1] = IR_5mers_expand_imperfect[imp_len].loc[(IR_5mers_expand_imperfect[imp_len]['imp_seq_L'] == IR_5mers_expand_imperfect[imp_len]['imp_seq_R']) & (IR_5mers_expand_imperfect[imp_len]['imp_seq_L'].str.count('N') == 0) & (IR_5mers_expand_imperfect[imp_len]['imp_seq_R'].str.count('N') == 0) & (IR_5mers_expand_imperfect[imp_len]['spacer'] > 1)]\n",
    "    IR_5mers_expand_imperfect[imp_len] = IR_5mers_expand_imperfect[imp_len].loc[(IR_5mers_expand_imperfect[imp_len]['imp_seq_L'] != IR_5mers_expand_imperfect[imp_len]['imp_seq_R']) | (IR_5mers_expand_imperfect[imp_len]['imp_seq_L'].str.count('N') != 0) | (IR_5mers_expand_imperfect[imp_len]['imp_seq_R'].str.count('N') != 0) | (IR_5mers_expand_imperfect[imp_len]['spacer'] <= 1)]\n",
    "    imp_len +=1\n",
    "    list_len = len(IR_5mers_expand_imperfect[imp_len])\n",
    "    IR_5mers_expand_imperfect[imp_len]['L_end'] = IR_5mers_expand_imperfect[imp_len]['L_end'] + 1\n",
    "    IR_5mers_expand_imperfect[imp_len]['R_start'] = IR_5mers_expand_imperfect[imp_len]['R_start'] - 1\n",
    "    IR_5mers_expand_imperfect[imp_len]['spacer'] = IR_5mers_expand_imperfect[imp_len]['spacer'] - 2\n",
    "    print('\\r' + 'expanding in imp_len ' +str(imp_len), end='        ')\n",
    "\n",
    "IR_5mers_expand_imperfect = pd.concat(IR_5mers_expand_imperfect).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925bad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format dataframe and remove duplicates\n",
    "IR_5mers_expand_imperfect = IR_5mers_expand_imperfect.drop_duplicates(subset = ['L_start', 'R_start', 'L_end', 'R_end']).copy()\n",
    "IR_5mers_expand_imperfect['stem_len'] = IR_5mers_expand_imperfect['L_end'] - IR_5mers_expand_imperfect['L_start']\n",
    "IR_expand_imperfect = IR_5mers_expand_imperfect.loc[IR_5mers_expand_imperfect['stem_len'] >9].copy()\n",
    "IR_expand_imperfect['seq_L'] = [reference_genome_masked_STR[chrom][start:end] for chrom, start, end in zip(IR_expand_imperfect['chrom'], IR_expand_imperfect['L_start'], IR_expand_imperfect['L_end'])]\n",
    "IR_expand_imperfect['seq_R'] = [reference_genome_masked_STR[chrom][start:end] for chrom, start, end in zip(IR_expand_imperfect['chrom'], IR_expand_imperfect['R_start'], IR_expand_imperfect['R_end'])]\n",
    "IR_expand_imperfect['RC_seq_R'] = [reverse_complement(seq) for seq in IR_expand_imperfect['seq_R']]\n",
    "IR_expand_imperfect['Sequence'] = [reference_genome_masked_STR[chrom][start:end] for chrom, start, end in zip(IR_expand_imperfect['chrom'], IR_expand_imperfect['L_start'], IR_expand_imperfect['R_end'])]\n",
    "IR_expand_imperfect['freq'] = IR_expand_imperfect.groupby('seq_L')['seq_L'].transform('count')  # frequency of stem sequence in database, ignoring spacer sequence\n",
    "IR_expand_imperfect['spacer'] = IR_expand_imperfect['R_start'] - (IR_expand_imperfect['L_end'])\n",
    "IR_expand_imperfect = IR_expand_imperfect.loc[IR_expand_imperfect['Sequence'].str.count('N') == 0]\n",
    "IR_expand_imperfect = IR_expand_imperfect.sort_values(by = ['chrom', 'L_start', 'R_end']).reset_index(drop = True)\n",
    "del IR_expand_imperfect['imp_seq_L']; del IR_expand_imperfect['imp_seq_R']\n",
    "IR_expand_imperfect['#MM'] = [sum(1 for a, b in zip(seq1, seq2) if a != b) for seq1, seq2 in zip(IR_expand_imperfect['seq_L'], IR_expand_imperfect['RC_seq_R'])]\n",
    "IR_expand_imperfect = IR_expand_imperfect.sort_values(by = ['chrom', 'L_start', 'R_end', 'stem_len']).reset_index(drop = True)\n",
    "IR_expand_imperfect = IR_expand_imperfect.drop_duplicates(subset = ['chrom', 'L_start', 'R_end'], keep = 'last')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ebf7e2",
   "metadata": {},
   "source": [
    "#### Save IR data <a name=\"DB_IR_save\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fc04d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save IR database\n",
    "IR_expand_imperfect.to_csv('./custom_db/inverted_repeats_withoutSTRs_imperfect_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a23bf7",
   "metadata": {},
   "source": [
    "## Mirror repeats <a name=\"DB_MR\"></a>\n",
    "\n",
    "#### Find all MR 5-mers <a name=\"DB_MR_5mer\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2e4898",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5   # N-mer size\n",
    "max_spacer = 100    # Max spacer size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793607d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_match = dict()\n",
    "for chrom in range(chr_range,23):\n",
    "    # Find all 5-mers in chromosome\n",
    "    Nmer_sets_overlap = pd.DataFrame(re.findall('.'*N, reference_genome_masked_STR[chrom], overlapped = True), columns = ['seq'])\n",
    "    Nmer_sets_overlap = Nmer_sets_overlap.loc[Nmer_sets_overlap['seq'].str.count('N') ==0]\n",
    "    Nmer_sets_overlap['L_start'] = Nmer_sets_overlap.index\n",
    "    Nmer_sets_overlap.reset_index(drop = True, inplace = True)\n",
    "    # Get reverse sequence of each 5-mer\n",
    "    Nmer_sets_overlap['seq_rev'] = [seq[::-1] for seq in Nmer_sets_overlap['seq']]\n",
    "    Nmer_sets_overlap['R_start'] = Nmer_sets_overlap['L_start']\n",
    "    Nmer_sets_overlap['spacer'] = -N\n",
    "    rev_match[chrom] = dict()\n",
    "    # For each spacer length, check if FWD 5-mer = REV 5-mer\n",
    "    for n_shifts in range(max_spacer+N+1):\n",
    "        rev_match[chrom][n_shifts] = Nmer_sets_overlap.loc[Nmer_sets_overlap['seq'] == Nmer_sets_overlap['seq_rev']]\n",
    "        Nmer_sets_overlap['seq_rev'] = Nmer_sets_overlap['seq_rev'].shift(-1)\n",
    "        Nmer_sets_overlap['R_start'] = Nmer_sets_overlap['R_start'].shift(-1)\n",
    "        Nmer_sets_overlap['spacer'] = Nmer_sets_overlap['spacer'] + 1\n",
    "        print('\\r' + 'shifting spacer ' +str(n_shifts) + ' chr' + str(chrom), end='        ')\n",
    "    rev_match[chrom] = pd.concat(rev_match[chrom])\n",
    "    rev_match[chrom]['chrom'] = chrom\n",
    "rev_match = pd.concat(rev_match)\n",
    "rev_match.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96edf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "del Nmer_sets_overlap\n",
    "MR_5mers_expand = dict()\n",
    "MR_5mers_expand[N] = rev_match.loc[rev_match['spacer'] >= 0][['chrom', 'L_start', 'R_start']].copy()\n",
    "MR_5mers_expand[N]['R_start'] = MR_5mers_expand[N]['R_start'].astype(int)\n",
    "del rev_match\n",
    "# Save temporary file\n",
    "MR_5mers_expand[N].to_csv('./custom_db/temp/MR_SL'+str(N)+'_SP'+str(max_spacer)+'_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d9c977",
   "metadata": {},
   "source": [
    "#### Expand perfect MRs  <a name=\"DB_MR_expand\"></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bf8e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load temporary file\n",
    "stem_len = 5    # Initial N-mer size from above section\n",
    "max_spacer = 100  # Max spacer size from above section\n",
    "MR_5mers_expand = dict()\n",
    "MR_5mers_expand[stem_len] = pd.read_csv('./custom_db/temp/MR_SL'+str(N)+'_SP'+str(max_spacer)+'_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a085e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MR_5mers_expand[stem_len]['stem_len'] = stem_len\n",
    "MR_5mers_expand[stem_len]['L_end'] = MR_5mers_expand[stem_len]['L_start'] + stem_len\n",
    "MR_5mers_expand[stem_len]['R_end'] = MR_5mers_expand[stem_len]['R_start'] + stem_len\n",
    "MR_5mers_expand[5]['spacer'] = MR_5mers_expand[5]['R_start'] - MR_5mers_expand[5]['L_end']\n",
    "MR_5mers_expand[5] = MR_5mers_expand[5].loc[MR_5mers_expand[5]['spacer'] <=100]\n",
    "\n",
    "# Continue MR search outwards from initial matches\n",
    "list_len = len(MR_5mers_expand[stem_len])\n",
    "while list_len > 0:\n",
    "    MR_5mers_expand[stem_len]['seq_L'] = [reference_genome_masked_STR[chrom][start-1:end] for chrom, start, end in zip(MR_5mers_expand[stem_len]['chrom'], MR_5mers_expand[stem_len]['L_start'], MR_5mers_expand[stem_len]['L_end'])]\n",
    "    MR_5mers_expand[stem_len]['seq_R'] = [reference_genome_masked_STR[chrom][start:end+1] for chrom, start, end in zip(MR_5mers_expand[stem_len]['chrom'], MR_5mers_expand[stem_len]['R_start'], MR_5mers_expand[stem_len]['R_end'])]\n",
    "    MR_5mers_expand[stem_len]['seq_R'] = [seq[::-1] for seq in MR_5mers_expand[stem_len]['seq_R']]\n",
    "    MR_5mers_expand[stem_len+1] = MR_5mers_expand[stem_len].loc[(MR_5mers_expand[stem_len]['seq_L'] == MR_5mers_expand[stem_len]['seq_R']) & (MR_5mers_expand[stem_len]['seq_L'].str.count('N') == 0) & (MR_5mers_expand[stem_len]['seq_R'].str.count('N') == 0)]\n",
    "    MR_5mers_expand[stem_len] = MR_5mers_expand[stem_len].loc[(MR_5mers_expand[stem_len]['seq_L'] != MR_5mers_expand[stem_len]['seq_R']) | (MR_5mers_expand[stem_len]['seq_L'].str.count('N') != 0) | (MR_5mers_expand[stem_len]['seq_R'].str.count('N') != 0)]\n",
    "    stem_len +=1\n",
    "    list_len = len(MR_5mers_expand[stem_len])\n",
    "    MR_5mers_expand[stem_len]['L_start'] = MR_5mers_expand[stem_len]['L_start'] - 1\n",
    "    MR_5mers_expand[stem_len]['R_end'] = MR_5mers_expand[stem_len]['R_end'] + 1\n",
    "    MR_5mers_expand[stem_len]['stem_len'] = stem_len\n",
    "    print('\\r' + 'expanding out stem_len ' +str(stem_len), end='        ')\n",
    "\n",
    "MR_5mers_expand = pd.concat(MR_5mers_expand)\n",
    "del MR_5mers_expand['seq_L']; del MR_5mers_expand['seq_R']\n",
    "# remove duplicates and IRs that expand into masked regions\n",
    "MR_5mers_expand = MR_5mers_expand.drop_duplicates(subset = ['L_start', 'L_end', 'R_start', 'R_end'], keep = 'first')\n",
    "MR_5mers_expand['Sequence'] = [reference_genome_masked_STR[chrom][start:end] for chrom, start, end in zip(MR_5mers_expand['chrom'], MR_5mers_expand['L_start'], MR_5mers_expand['R_end'])]\n",
    "MR_5mers_expand = MR_5mers_expand.loc[MR_5mers_expand['Sequence'].str.count('N') == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48a0516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue MR search inward, unless spacer length is already 0\n",
    "MR_5mers_expand_in = dict()\n",
    "in_len = 0\n",
    "MR_5mers_expand_in[in_len] = MR_5mers_expand.copy()\n",
    "list_len = len(MR_5mers_expand_in[in_len])\n",
    "while list_len > 0:\n",
    "    MR_5mers_expand_in[in_len]['seq_L'] = [reference_genome_masked_STR[chrom][start:end+1] for chrom, start, end in zip(MR_5mers_expand_in[in_len]['chrom'], MR_5mers_expand_in[in_len]['L_start'], MR_5mers_expand_in[in_len]['L_end'])]\n",
    "    MR_5mers_expand_in[in_len]['seq_R'] = [reference_genome_masked_STR[chrom][start-1:end] for chrom, start, end in zip(MR_5mers_expand_in[in_len]['chrom'], MR_5mers_expand_in[in_len]['R_start'], MR_5mers_expand_in[in_len]['R_end'])]\n",
    "    MR_5mers_expand_in[in_len]['seq_R'] = [seq[::-1] for seq in MR_5mers_expand_in[in_len]['seq_R']]\n",
    "    MR_5mers_expand_in[in_len+1] = MR_5mers_expand_in[in_len].loc[(MR_5mers_expand_in[in_len]['seq_L'] == MR_5mers_expand_in[in_len]['seq_R']) & (MR_5mers_expand_in[in_len]['seq_L'].str.count('N') == 0) & (MR_5mers_expand_in[in_len]['seq_R'].str.count('N') == 0) & (MR_5mers_expand_in[in_len]['spacer'] > 1)]\n",
    "    MR_5mers_expand_in[in_len] = MR_5mers_expand_in[in_len].loc[(MR_5mers_expand_in[in_len]['seq_L'] != MR_5mers_expand_in[in_len]['seq_R']) | (MR_5mers_expand_in[in_len]['seq_L'].str.count('N') != 0) | (MR_5mers_expand_in[in_len]['seq_R'].str.count('N') != 0) | (MR_5mers_expand_in[in_len]['spacer'] <= 1)]\n",
    "    in_len +=1\n",
    "    list_len = len(MR_5mers_expand_in[in_len])\n",
    "    MR_5mers_expand_in[in_len]['R_start'] = MR_5mers_expand_in[in_len]['R_start'] - 1\n",
    "    MR_5mers_expand_in[in_len]['L_end'] = MR_5mers_expand_in[in_len]['L_end'] + 1\n",
    "    MR_5mers_expand_in[in_len]['spacer'] = MR_5mers_expand_in[in_len]['spacer'] -2\n",
    "    print('\\r' + 'expanding in ' +str(in_len), end='        ')\n",
    "\n",
    "MR_5mers_expand_in = pd.concat(MR_5mers_expand_in).reset_index(drop = True)\n",
    "del MR_5mers_expand_in['seq_L']; del MR_5mers_expand_in['seq_R']\n",
    "\n",
    "MR_5mers_expand_in = MR_5mers_expand_in.drop_duplicates(subset = ['L_start', 'L_end', 'R_start', 'R_end'], keep = 'first')\n",
    "MR_5mers_expand_in['Sequence'] = [reference_genome_masked_STR[chrom][start:end] for chrom, start, end in zip(MR_5mers_expand_in['chrom'], MR_5mers_expand_in['L_start'], MR_5mers_expand_in['R_end'])]\n",
    "MR_5mers_expand_in = MR_5mers_expand_in.loc[MR_5mers_expand_in['Sequence'].str.count('N') == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fca86e0",
   "metadata": {},
   "source": [
    "#### Expand imperfect MRs <a name=\"DB_MR_expand_imperfect\"></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3220385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore one mismatch, then search again outwards\n",
    "MR_5mers_expand_imperfect = dict()\n",
    "imp_len = 0\n",
    "MR_5mers_expand_imperfect[imp_len] = MR_5mers_expand_in.copy()\n",
    "\n",
    "MR_5mers_expand_imperfect[imp_len]['imp_seq_L'] = [reference_genome_masked_STR[chrom][start-2:start-1] for chrom, start in zip(MR_5mers_expand_imperfect[imp_len]['chrom'], MR_5mers_expand_imperfect[imp_len]['L_start'])]\n",
    "MR_5mers_expand_imperfect[imp_len]['imp_seq_R'] = [reference_genome_masked_STR[chrom][end+1:end+2] for chrom, end in zip(MR_5mers_expand_imperfect[imp_len]['chrom'], MR_5mers_expand_imperfect[imp_len]['R_end'])]\n",
    "MR_5mers_expand_imperfect[imp_len]['imp_seq_R'] = [seq[::-1] for seq in MR_5mers_expand_imperfect[imp_len]['imp_seq_R']]\n",
    "MR_5mers_expand_imperfect[imp_len+1] = MR_5mers_expand_imperfect[imp_len].loc[(MR_5mers_expand_imperfect[imp_len]['imp_seq_L'] == MR_5mers_expand_imperfect[imp_len]['imp_seq_R']) & (MR_5mers_expand_imperfect[imp_len]['imp_seq_L'].str.count('N') == 0) & (MR_5mers_expand_imperfect[imp_len]['imp_seq_R'].str.count('N') == 0)]\n",
    "MR_5mers_expand_imperfect[imp_len] = MR_5mers_expand_imperfect[imp_len].loc[(MR_5mers_expand_imperfect[imp_len]['imp_seq_L'] != MR_5mers_expand_imperfect[imp_len]['imp_seq_R']) | (MR_5mers_expand_imperfect[imp_len]['imp_seq_L'].str.count('N') != 0) | (MR_5mers_expand_imperfect[imp_len]['imp_seq_R'].str.count('N') != 0)]\n",
    "imp_len +=1\n",
    "MR_5mers_expand_imperfect[imp_len]['L_start'] = MR_5mers_expand_imperfect[imp_len]['L_start'] - 2\n",
    "MR_5mers_expand_imperfect[imp_len]['R_end'] = MR_5mers_expand_imperfect[imp_len]['R_end'] + 2\n",
    "\n",
    "list_len = len(MR_5mers_expand_imperfect[imp_len])\n",
    "while list_len > 0:\n",
    "    MR_5mers_expand_imperfect[imp_len]['imp_seq_L'] = [reference_genome_masked_STR[chrom][start-1:start] for chrom, start in zip(MR_5mers_expand_imperfect[imp_len]['chrom'], MR_5mers_expand_imperfect[imp_len]['L_start'])]\n",
    "    MR_5mers_expand_imperfect[imp_len]['imp_seq_R'] = [reference_genome_masked_STR[chrom][end:end+1] for chrom, end in zip(MR_5mers_expand_imperfect[imp_len]['chrom'], MR_5mers_expand_imperfect[imp_len]['R_end'])]\n",
    "    MR_5mers_expand_imperfect[imp_len]['imp_seq_R'] = [seq[::-1] for seq in MR_5mers_expand_imperfect[imp_len]['imp_seq_R']]\n",
    "    MR_5mers_expand_imperfect[imp_len+1] = MR_5mers_expand_imperfect[imp_len].loc[(MR_5mers_expand_imperfect[imp_len]['imp_seq_L'] == MR_5mers_expand_imperfect[imp_len]['imp_seq_R']) & (MR_5mers_expand_imperfect[imp_len]['imp_seq_L'].str.count('N') == 0) & (MR_5mers_expand_imperfect[imp_len]['imp_seq_R'].str.count('N') == 0)]\n",
    "    MR_5mers_expand_imperfect[imp_len] = MR_5mers_expand_imperfect[imp_len].loc[(MR_5mers_expand_imperfect[imp_len]['imp_seq_L'] != MR_5mers_expand_imperfect[imp_len]['imp_seq_R']) | (MR_5mers_expand_imperfect[imp_len]['imp_seq_L'].str.count('N') != 0) | (MR_5mers_expand_imperfect[imp_len]['imp_seq_R'].str.count('N') != 0)]\n",
    "    imp_len +=1\n",
    "    list_len = len(MR_5mers_expand_imperfect[imp_len])\n",
    "    MR_5mers_expand_imperfect[imp_len]['L_start'] = MR_5mers_expand_imperfect[imp_len]['L_start'] - 1\n",
    "    MR_5mers_expand_imperfect[imp_len]['R_end'] = MR_5mers_expand_imperfect[imp_len]['R_end'] + 1\n",
    "    print('\\r' + 'expanding out imp_len ' +str(imp_len), end='        ')\n",
    "\n",
    "MR_5mers_expand_imperfect_out = pd.concat(MR_5mers_expand_imperfect).reset_index(drop = True)\n",
    "MR_5mers_expand_imperfect_out['spacer'] = MR_5mers_expand_imperfect_out['R_start'] - MR_5mers_expand_imperfect_out['L_end']\n",
    "MR_5mers_expand_imperfect_out = MR_5mers_expand_imperfect_out.loc[MR_5mers_expand_imperfect_out['spacer'] >= 0]\n",
    "\n",
    "MR_5mers_expand_imperfect_out['seq_L'] = [reference_genome_masked_STR[chrom][start:end] for chrom, start, end in zip(MR_5mers_expand_imperfect_out['chrom'], MR_5mers_expand_imperfect_out['L_start'], MR_5mers_expand_imperfect_out['L_end'])]\n",
    "MR_5mers_expand_imperfect_out['seq_R'] = [reference_genome_masked_STR[chrom][start:end] for chrom, start, end in zip(MR_5mers_expand_imperfect_out['chrom'], MR_5mers_expand_imperfect_out['R_start'], MR_5mers_expand_imperfect_out['R_end'])]\n",
    "MR_5mers_expand_imperfect_out['rev_seq_R'] = [seq[::-1] for seq in MR_5mers_expand_imperfect_out['seq_R']]\n",
    "MR_5mers_expand_imperfect_out['#MM'] = [sum(1 for a, b in zip(seq1, seq2) if a != b) for seq1, seq2 in zip(MR_5mers_expand_imperfect_out['seq_L'], MR_5mers_expand_imperfect_out['rev_seq_R'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2066ae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore one mismatch, then search again inwards, unless spacer is already 0\n",
    "MR_5mers_expand_imperfect = dict()\n",
    "imp_len = 0\n",
    "MR_5mers_expand_imperfect[imp_len] = MR_5mers_expand_imperfect_out.copy()\n",
    "MR_5mers_expand_imperfect[imp_len]['imp_seq_L'] = [reference_genome_masked_STR[chrom][end+1:end+2] for chrom, end in zip(MR_5mers_expand_imperfect[imp_len]['chrom'], MR_5mers_expand_imperfect[imp_len]['L_end'])]\n",
    "MR_5mers_expand_imperfect[imp_len]['imp_seq_R'] = [reference_genome_masked_STR[chrom][start-2:start-1] for chrom, start in zip(MR_5mers_expand_imperfect[imp_len]['chrom'], MR_5mers_expand_imperfect[imp_len]['R_start'])]\n",
    "MR_5mers_expand_imperfect[imp_len]['imp_seq_R'] = [seq[::-1] for seq in MR_5mers_expand_imperfect[imp_len]['imp_seq_R']]\n",
    "MR_5mers_expand_imperfect[imp_len+1] = MR_5mers_expand_imperfect[imp_len].loc[(MR_5mers_expand_imperfect[imp_len]['imp_seq_L'] == MR_5mers_expand_imperfect[imp_len]['imp_seq_R']) & (MR_5mers_expand_imperfect[imp_len]['imp_seq_L'].str.count('N') == 0) & (MR_5mers_expand_imperfect[imp_len]['imp_seq_R'].str.count('N') == 0) & (MR_5mers_expand_imperfect[imp_len]['spacer'] > 3)]\n",
    "MR_5mers_expand_imperfect[imp_len] = MR_5mers_expand_imperfect[imp_len].loc[(MR_5mers_expand_imperfect[imp_len]['imp_seq_L'] != MR_5mers_expand_imperfect[imp_len]['imp_seq_R']) | (MR_5mers_expand_imperfect[imp_len]['imp_seq_L'].str.count('N') != 0) | (MR_5mers_expand_imperfect[imp_len]['imp_seq_R'].str.count('N') != 0) | (MR_5mers_expand_imperfect[imp_len]['spacer'] <= 3)]\n",
    "imp_len +=1\n",
    "MR_5mers_expand_imperfect[imp_len]['L_end'] = MR_5mers_expand_imperfect[imp_len]['L_end'] + 2\n",
    "MR_5mers_expand_imperfect[imp_len]['R_start'] = MR_5mers_expand_imperfect[imp_len]['R_start'] - 2\n",
    "MR_5mers_expand_imperfect[imp_len]['spacer'] = MR_5mers_expand_imperfect[imp_len]['spacer'] - 4\n",
    "\n",
    "list_len = len(MR_5mers_expand_imperfect[imp_len])\n",
    "while list_len > 0:\n",
    "    MR_5mers_expand_imperfect[imp_len]['imp_seq_L'] = [reference_genome_masked_STR[chrom][end:end+1] for chrom, end in zip(MR_5mers_expand_imperfect[imp_len]['chrom'], MR_5mers_expand_imperfect[imp_len]['L_end'])]\n",
    "    MR_5mers_expand_imperfect[imp_len]['imp_seq_R'] = [reference_genome_masked_STR[chrom][start-1:start] for chrom, start in zip(MR_5mers_expand_imperfect[imp_len]['chrom'], MR_5mers_expand_imperfect[imp_len]['R_start'])]\n",
    "    MR_5mers_expand_imperfect[imp_len]['imp_seq_R'] = [seq[::-1] for seq in MR_5mers_expand_imperfect[imp_len]['imp_seq_R']]\n",
    "    MR_5mers_expand_imperfect[imp_len+1] = MR_5mers_expand_imperfect[imp_len].loc[(MR_5mers_expand_imperfect[imp_len]['imp_seq_L'] == MR_5mers_expand_imperfect[imp_len]['imp_seq_R']) & (MR_5mers_expand_imperfect[imp_len]['imp_seq_L'].str.count('N') == 0) & (MR_5mers_expand_imperfect[imp_len]['imp_seq_R'].str.count('N') == 0) & (MR_5mers_expand_imperfect[imp_len]['spacer'] > 1)]\n",
    "    MR_5mers_expand_imperfect[imp_len] = MR_5mers_expand_imperfect[imp_len].loc[(MR_5mers_expand_imperfect[imp_len]['imp_seq_L'] != MR_5mers_expand_imperfect[imp_len]['imp_seq_R']) | (MR_5mers_expand_imperfect[imp_len]['imp_seq_L'].str.count('N') != 0) | (MR_5mers_expand_imperfect[imp_len]['imp_seq_R'].str.count('N') != 0) | (MR_5mers_expand_imperfect[imp_len]['spacer'] <= 1)]\n",
    "    imp_len +=1\n",
    "    list_len = len(MR_5mers_expand_imperfect[imp_len])\n",
    "    MR_5mers_expand_imperfect[imp_len]['L_end'] = MR_5mers_expand_imperfect[imp_len]['L_end'] + 1\n",
    "    MR_5mers_expand_imperfect[imp_len]['R_start'] = MR_5mers_expand_imperfect[imp_len]['R_start'] - 1\n",
    "    MR_5mers_expand_imperfect[imp_len]['spacer'] = MR_5mers_expand_imperfect[imp_len]['spacer'] - 2\n",
    "    print('\\r' + 'expanding in imp_len ' +str(imp_len), end='        ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77942dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format dataframe and remove duplicates\n",
    "MR_5mers_expand_imperfect = pd.concat(MR_5mers_expand_imperfect).reset_index(drop = True)\n",
    "MR_5mers_expand_imperfect = MR_5mers_expand_imperfect.drop_duplicates(subset = ['L_start', 'R_start', 'L_end', 'R_end'])\n",
    "MR_5mers_expand_imperfect['stem_len'] = MR_5mers_expand_imperfect['L_end'] - MR_5mers_expand_imperfect['L_start']\n",
    "MR_expand_imperfect = MR_5mers_expand_imperfect.loc[MR_5mers_expand_imperfect['stem_len'] >9].copy()\n",
    "MR_expand_imperfect['seq_L'] = [reference_genome_masked_STR[chrom][start:end] for chrom, start, end in zip(MR_expand_imperfect['chrom'], MR_expand_imperfect['L_start'], MR_expand_imperfect['L_end'])]\n",
    "MR_expand_imperfect['seq_R'] = [reference_genome_masked_STR[chrom][start:end] for chrom, start, end in zip(MR_expand_imperfect['chrom'], MR_expand_imperfect['R_start'], MR_expand_imperfect['R_end'])]\n",
    "MR_expand_imperfect['rev_seq_R'] = [seq[::-1] for seq in MR_expand_imperfect['seq_R']]\n",
    "MR_expand_imperfect['Sequence'] = [reference_genome_masked_STR[chrom][start:end] for chrom, start, end in zip(MR_expand_imperfect['chrom'], MR_expand_imperfect['L_start'], MR_expand_imperfect['R_end'])]\n",
    "MR_expand_imperfect['freq'] = MR_expand_imperfect.groupby('seq_L')['seq_L'].transform('count')\n",
    "MR_expand_imperfect['spacer'] = MR_expand_imperfect['R_start'] - (MR_expand_imperfect['L_end'])\n",
    "MR_expand_imperfect = MR_expand_imperfect.loc[MR_expand_imperfect['Sequence'].str.count('N') == 0]\n",
    "MR_expand_imperfect = MR_expand_imperfect.sort_values(by = ['chrom', 'L_start', 'R_end']).reset_index(drop = True)\n",
    "del MR_expand_imperfect['imp_seq_L']; del MR_expand_imperfect['imp_seq_R']\n",
    "MR_expand_imperfect['#MM'] = [sum(1 for a, b in zip(seq1, seq2) if a != b) for seq1, seq2 in zip(MR_expand_imperfect['seq_L'], MR_expand_imperfect['rev_seq_R'])]\n",
    "MR_expand_imperfect = MR_expand_imperfect.sort_values(by = ['chrom', 'L_start', 'R_end', 'stem_len']).reset_index(drop = True)\n",
    "MR_expand_imperfect = MR_expand_imperfect.drop_duplicates(subset = ['chrom', 'L_start', 'R_end'], keep = 'last')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9776c1",
   "metadata": {},
   "source": [
    "#### Save MR data <a name=\"DB_MR_save\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db48b399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save MR database\n",
    "MR_expand_imperfect.to_csv('./custom_db/mirror_repeats_withoutSTRs_imperfect_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2613398",
   "metadata": {},
   "source": [
    "## Direct repeats <a name=\"DB_DR\"></a>\n",
    "\n",
    "#### Find all perfect DRs, starting from 5-mers and expanding left and right <a name=\"DB_DR_perfect\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2479b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5   # N-mer size\n",
    "max_spacer = 1000    # Allow spacer length up to 1000, which will allow excess room for expansion algorithm to find stem_len up to 100 with spacer up to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5685ff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DR_5mers_expand = dict()\n",
    "for chrom in range(chr_range,23):\n",
    "    # Find every possible 5mer in the chromosome\n",
    "    Nmer_sets_overlap = pd.DataFrame(re.findall('.'*N, reference_genome_masked_STR[chrom], overlapped = True), columns = ['seq'])\n",
    "    print('\\r' + 'gathered all chr' + str(chrom), end='           ')\n",
    "    Nmer_sets_overlap['L_start'] = Nmer_sets_overlap.index\n",
    "    Nmer_sets_overlap = Nmer_sets_overlap.loc[Nmer_sets_overlap['seq'].str.count('N') == 0]\n",
    "\n",
    "    # Filter to those that appear twice or more\n",
    "    Nmer_sets_overlap['freq'] = Nmer_sets_overlap.groupby('seq')['seq'].transform('count')\n",
    "    Nmer_repeated = Nmer_sets_overlap.loc[Nmer_sets_overlap['freq'] >1]\n",
    "    \n",
    "    # Sort by 5mer sequence and starting position, then calculate spacer distance between every pair\n",
    "    # Allow for overlapping direct repeats in initial search\n",
    "    Nmer_repeated = Nmer_repeated.sort_values(by = ['seq', 'L_start'])\n",
    "    Nmer_repeated['L_end'] = Nmer_repeated['L_start'] + N\n",
    "    Nmer_filtered = dict()\n",
    "    n_shifts = 0\n",
    "    check_len = len(Nmer_repeated)\n",
    "    while check_len >0:\n",
    "        n_shifts += 1\n",
    "        Nmer_repeated['R_start'] = Nmer_repeated['L_start'].shift(-n_shifts)\n",
    "        Nmer_repeated['R_end'] = Nmer_repeated['L_end'].shift(-n_shifts)\n",
    "        Nmer_repeated['spacer'] = Nmer_repeated['R_start'] - (Nmer_repeated['L_end'])\n",
    "        Nmer_repeated['R_seq'] = Nmer_repeated['seq'].shift(-n_shifts)\n",
    "        Nmer_repeated['n_shifts'] = n_shifts\n",
    "        Nmer_filtered[n_shifts] = Nmer_repeated.loc[(Nmer_repeated['spacer'].abs() <max_spacer) & (Nmer_repeated['seq'] == Nmer_repeated['R_seq'])]\n",
    "        Nmer_repeated = Nmer_repeated.loc[(Nmer_repeated['spacer'].abs() <max_spacer) & (Nmer_repeated['seq'] == Nmer_repeated['R_seq'])]\n",
    "        check_len = len(Nmer_repeated)\n",
    "        print('\\r' + str(n_shifts) + ' shifts ' + str(check_len) + ' found - chr' + str(chrom), end='        ')\n",
    "\n",
    "    Nmer_filtered = pd.concat(Nmer_filtered).sort_values(by = ['L_start', 'R_end']).reset_index(drop = True)\n",
    "    del Nmer_filtered['R_seq']\n",
    "    Nmer_filtered['stem_len'] = N\n",
    "\n",
    "    DR_5mers_expand[chrom] = dict()\n",
    "    stem_len = 5\n",
    "    DR_5mers_expand[chrom][stem_len] = Nmer_filtered.copy()\n",
    "    DR_5mers_expand[chrom][stem_len]['R_start'] = DR_5mers_expand[chrom][stem_len]['R_start'].astype(int)\n",
    "    DR_5mers_expand[chrom][stem_len]['R_end'] = DR_5mers_expand[chrom][stem_len]['R_end'].astype(int)\n",
    "    #Search left\n",
    "    list_len = len(DR_5mers_expand[chrom][stem_len])\n",
    "    while list_len > 0:\n",
    "        DR_5mers_expand[chrom][stem_len]['seq_L'] = [reference_genome_masked_STR[chrom][start-1:end] for start, end in zip(DR_5mers_expand[chrom][stem_len]['L_start'], DR_5mers_expand[chrom][stem_len]['L_end'])]\n",
    "        DR_5mers_expand[chrom][stem_len]['seq_R'] = [reference_genome_masked_STR[chrom][start-1:end] for start, end in zip(DR_5mers_expand[chrom][stem_len]['R_start'], DR_5mers_expand[chrom][stem_len]['R_end'])]\n",
    "\n",
    "        DR_5mers_expand[chrom][stem_len+1] = DR_5mers_expand[chrom][stem_len].loc[(DR_5mers_expand[chrom][stem_len]['seq_L'] == DR_5mers_expand[chrom][stem_len]['seq_R']) & (DR_5mers_expand[chrom][stem_len]['seq_L'].str.count('N') == 0) & (DR_5mers_expand[chrom][stem_len]['seq_R'].str.count('N') == 0)]\n",
    "        DR_5mers_expand[chrom][stem_len] = DR_5mers_expand[chrom][stem_len].loc[(DR_5mers_expand[chrom][stem_len]['seq_L'] != DR_5mers_expand[chrom][stem_len]['seq_R']) | (DR_5mers_expand[chrom][stem_len]['seq_L'].str.count('N') != 0) | (DR_5mers_expand[chrom][stem_len]['seq_R'].str.count('N') != 0)]\n",
    "\n",
    "        stem_len +=1\n",
    "        list_len = len(DR_5mers_expand[chrom][stem_len])\n",
    "        DR_5mers_expand[chrom][stem_len]['L_start'] = DR_5mers_expand[chrom][stem_len]['L_start'] - 1\n",
    "        DR_5mers_expand[chrom][stem_len]['R_start'] = DR_5mers_expand[chrom][stem_len]['R_start'] - 1\n",
    "        DR_5mers_expand[chrom][stem_len]['stem_len'] = stem_len\n",
    "        print('\\r' + 'expanding left stem_len ' +str(stem_len) + ' chr' + str(chrom), end='        ')\n",
    "\n",
    "    #Search right\n",
    "    stem_len = 5\n",
    "    list_len = len(DR_5mers_expand[chrom][stem_len])\n",
    "    while list_len > 0:\n",
    "        DR_5mers_expand[chrom][stem_len]['seq_L'] = [reference_genome_masked_STR[chrom][start:end+1] for start, end in zip(DR_5mers_expand[chrom][stem_len]['L_start'], DR_5mers_expand[chrom][stem_len]['L_end'])]\n",
    "        DR_5mers_expand[chrom][stem_len]['seq_R'] = [reference_genome_masked_STR[chrom][start:end+1] for start, end in zip(DR_5mers_expand[chrom][stem_len]['R_start'], DR_5mers_expand[chrom][stem_len]['R_end'])]\n",
    "\n",
    "        # [stem_len+1] is already populated from left search, must change positions first, then concat\n",
    "        move_pos = DR_5mers_expand[chrom][stem_len].loc[(DR_5mers_expand[chrom][stem_len]['seq_L'] == DR_5mers_expand[chrom][stem_len]['seq_R']) & (DR_5mers_expand[chrom][stem_len]['seq_L'].str.count('N') == 0) & (DR_5mers_expand[chrom][stem_len]['seq_R'].str.count('N') == 0)].copy()\n",
    "        move_pos['L_end'] = move_pos['L_end'] + 1\n",
    "        move_pos['R_end'] = move_pos['R_end'] + 1\n",
    "        move_pos['stem_len'] = stem_len+1\n",
    "        if stem_len+1 in DR_5mers_expand[chrom].keys():\n",
    "            DR_5mers_expand[chrom][stem_len+1] = pd.concat([DR_5mers_expand[chrom][stem_len+1], move_pos])\n",
    "        else:\n",
    "            DR_5mers_expand[chrom][stem_len+1] = move_pos\n",
    "        DR_5mers_expand[chrom][stem_len] = DR_5mers_expand[chrom][stem_len].loc[(DR_5mers_expand[chrom][stem_len]['seq_L'] != DR_5mers_expand[chrom][stem_len]['seq_R']) | (DR_5mers_expand[chrom][stem_len]['seq_L'].str.count('N') != 0) | (DR_5mers_expand[chrom][stem_len]['seq_R'].str.count('N') != 0)]\n",
    "\n",
    "        stem_len +=1\n",
    "        list_len = len(DR_5mers_expand[chrom][stem_len])\n",
    "        print('\\r' + 'expanding right stem_len ' +str(stem_len) + ' chr' + str(chrom), end='        ')\n",
    "\n",
    "    DR_5mers_expand[chrom] = pd.concat(DR_5mers_expand[chrom])\n",
    "    del DR_5mers_expand[chrom]['seq_L']; del DR_5mers_expand[chrom]['seq_R']\n",
    "    \n",
    "    # Sorting by n_shifts keeps longer stem_len first in list, allowing drop_duplicates(keep = 'first')\n",
    "    DR_5mers_expand[chrom] = DR_5mers_expand[chrom].sort_values(by = ['L_start', 'R_end', 'n_shifts']).reset_index(drop = True)\n",
    "    DR_5mers_expand[chrom]['Sequence'] = [reference_genome_masked_STR[chrom][start:end] for start, end in zip(DR_5mers_expand[chrom]['L_start'], DR_5mers_expand[chrom]['R_end'])]\n",
    "    DR_5mers_expand[chrom] = DR_5mers_expand[chrom].loc[DR_5mers_expand[chrom]['Sequence'].str.count('N') == 0]\n",
    "    DR_5mers_expand[chrom] = DR_5mers_expand[chrom].drop_duplicates(subset = ['L_start', 'Sequence'], keep = 'first')\n",
    "    \n",
    "    DR_5mers_expand[chrom][['L_start', 'L_end', 'R_start', 'R_end']].to_csv('./custom_db/temp/DR_SL'+str(N)+'_SP'+str(max_spacer)+'_expanded_chrom'+str(chrom)+'.csv.gz', compression = 'gzip', index = False)\n",
    "    \n",
    "    print('\\r' + 'finished chr' + str(chrom), end='        ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a111d6d8",
   "metadata": {},
   "source": [
    "#### Search for imperfect DRs, expanding left and right <a name=\"DB_DR_imperfect\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db66e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow one imperfection, then expand again left and right\n",
    "def DR_expand_imperfect_L_R(chrom):\n",
    "    DR_expand_combined = pd.read_csv('./custom_db/temp/DR_SL'+str(N)+'_SP'+str(max_spacer)+'_expanded_chrom'+str(chrom)+'.csv.gz', compression = 'gzip')\n",
    "\n",
    "    DR_expand_combined['chrom'] = chrom\n",
    "    DR_expand_combined['spacer'] = DR_expand_combined['R_start'] - (DR_expand_combined['L_end'])\n",
    "\n",
    "    DR_5mers_expand_imperfect = dict()\n",
    "    imp_len = 0\n",
    "    DR_5mers_expand_imperfect[imp_len] = DR_expand_combined.copy()\n",
    "\n",
    "    DR_5mers_expand_imperfect[imp_len]['imp_seq_L'] = [reference_genome_masked_STR[chrom][start-2:start-1] for chrom, start in zip(DR_5mers_expand_imperfect[imp_len]['chrom'], DR_5mers_expand_imperfect[imp_len]['L_start'])]\n",
    "    DR_5mers_expand_imperfect[imp_len]['imp_seq_R'] = [reference_genome_masked_STR[chrom][start-2:start-1] for chrom, start in zip(DR_5mers_expand_imperfect[imp_len]['chrom'], DR_5mers_expand_imperfect[imp_len]['R_start'])]\n",
    "\n",
    "    DR_5mers_expand_imperfect[imp_len+1] = DR_5mers_expand_imperfect[imp_len].loc[(DR_5mers_expand_imperfect[imp_len]['imp_seq_L'] == DR_5mers_expand_imperfect[imp_len]['imp_seq_R']) & (DR_5mers_expand_imperfect[imp_len]['imp_seq_L'].str.count('N') == 0) & (DR_5mers_expand_imperfect[imp_len]['imp_seq_R'].str.count('N') == 0) & (DR_5mers_expand_imperfect[imp_len]['spacer'] > 1)]\n",
    "    DR_5mers_expand_imperfect[imp_len] = DR_5mers_expand_imperfect[imp_len].loc[(DR_5mers_expand_imperfect[imp_len]['imp_seq_L'] != DR_5mers_expand_imperfect[imp_len]['imp_seq_R']) | (DR_5mers_expand_imperfect[imp_len]['imp_seq_L'].str.count('N') != 0) | (DR_5mers_expand_imperfect[imp_len]['imp_seq_R'].str.count('N') != 0) | (DR_5mers_expand_imperfect[imp_len]['spacer'] <= 1)]\n",
    "\n",
    "    imp_len +=1\n",
    "    DR_5mers_expand_imperfect[imp_len]['L_start'] = DR_5mers_expand_imperfect[imp_len]['L_start'] - 2\n",
    "    DR_5mers_expand_imperfect[imp_len]['R_start'] = DR_5mers_expand_imperfect[imp_len]['R_start'] - 2\n",
    "    DR_5mers_expand_imperfect[imp_len]['spacer'] = DR_5mers_expand_imperfect[imp_len]['spacer'] - 2\n",
    "\n",
    "\n",
    "    list_len = len(DR_5mers_expand_imperfect[imp_len])\n",
    "    while list_len > 0:\n",
    "        DR_5mers_expand_imperfect[imp_len]['imp_seq_L'] = [reference_genome_masked_STR[chrom][start-1:start] for chrom, start in zip(DR_5mers_expand_imperfect[imp_len]['chrom'], DR_5mers_expand_imperfect[imp_len]['L_start'])]\n",
    "        DR_5mers_expand_imperfect[imp_len]['imp_seq_R'] = [reference_genome_masked_STR[chrom][start-1:start] for chrom, start in zip(DR_5mers_expand_imperfect[imp_len]['chrom'], DR_5mers_expand_imperfect[imp_len]['R_start'])]\n",
    "\n",
    "        DR_5mers_expand_imperfect[imp_len+1] = DR_5mers_expand_imperfect[imp_len].loc[(DR_5mers_expand_imperfect[imp_len]['imp_seq_L'] == DR_5mers_expand_imperfect[imp_len]['imp_seq_R']) & (DR_5mers_expand_imperfect[imp_len]['imp_seq_L'].str.count('N') == 0) & (DR_5mers_expand_imperfect[imp_len]['imp_seq_R'].str.count('N') == 0) & (DR_5mers_expand_imperfect[imp_len]['spacer'] > 0)]\n",
    "        DR_5mers_expand_imperfect[imp_len] = DR_5mers_expand_imperfect[imp_len].loc[(DR_5mers_expand_imperfect[imp_len]['imp_seq_L'] != DR_5mers_expand_imperfect[imp_len]['imp_seq_R']) | (DR_5mers_expand_imperfect[imp_len]['imp_seq_L'].str.count('N') != 0) | (DR_5mers_expand_imperfect[imp_len]['imp_seq_R'].str.count('N') != 0) | (DR_5mers_expand_imperfect[imp_len]['spacer'] <= 0)]\n",
    "\n",
    "        imp_len +=1\n",
    "        list_len = len(DR_5mers_expand_imperfect[imp_len])\n",
    "        DR_5mers_expand_imperfect[imp_len]['L_start'] = DR_5mers_expand_imperfect[imp_len]['L_start'] - 1\n",
    "        DR_5mers_expand_imperfect[imp_len]['R_start'] = DR_5mers_expand_imperfect[imp_len]['R_start'] - 1\n",
    "        DR_5mers_expand_imperfect[imp_len]['spacer'] = DR_5mers_expand_imperfect[imp_len]['spacer'] - 1\n",
    "\n",
    "        print('\\r' + 'chrom ' + str(chrom) + ' expanding left imp_len ' +str(imp_len), end='        ')\n",
    "\n",
    "    DR_5mers_expand_imperfect_out = pd.concat(DR_5mers_expand_imperfect).reset_index(drop = True)\n",
    "    DR_5mers_expand_imperfect_out = DR_5mers_expand_imperfect_out.loc[DR_5mers_expand_imperfect_out['spacer'] >= 0]\n",
    "\n",
    "    DR_5mers_expand_imperfect = dict()\n",
    "    imp_len = 0\n",
    "    DR_5mers_expand_imperfect[imp_len] = DR_5mers_expand_imperfect_out.copy()\n",
    "\n",
    "    DR_5mers_expand_imperfect[imp_len]['imp_seq_L'] = [reference_genome_masked_STR[chrom][end+1:end+2] for chrom, end in zip(DR_5mers_expand_imperfect[imp_len]['chrom'], DR_5mers_expand_imperfect[imp_len]['L_end'])]\n",
    "    DR_5mers_expand_imperfect[imp_len]['imp_seq_R'] = [reference_genome_masked_STR[chrom][end+1:end+2] for chrom, end in zip(DR_5mers_expand_imperfect[imp_len]['chrom'], DR_5mers_expand_imperfect[imp_len]['R_end'])]\n",
    "\n",
    "    DR_5mers_expand_imperfect[imp_len+1] = DR_5mers_expand_imperfect[imp_len].loc[(DR_5mers_expand_imperfect[imp_len]['imp_seq_L'] == DR_5mers_expand_imperfect[imp_len]['imp_seq_R']) & (DR_5mers_expand_imperfect[imp_len]['imp_seq_L'].str.count('N') == 0) & (DR_5mers_expand_imperfect[imp_len]['imp_seq_R'].str.count('N') == 0) & (DR_5mers_expand_imperfect[imp_len]['spacer'] > 1)]\n",
    "    DR_5mers_expand_imperfect[imp_len] = DR_5mers_expand_imperfect[imp_len].loc[(DR_5mers_expand_imperfect[imp_len]['imp_seq_L'] != DR_5mers_expand_imperfect[imp_len]['imp_seq_R']) | (DR_5mers_expand_imperfect[imp_len]['imp_seq_L'].str.count('N') != 0) | (DR_5mers_expand_imperfect[imp_len]['imp_seq_R'].str.count('N') != 0) | (DR_5mers_expand_imperfect[imp_len]['spacer'] <= 1)]\n",
    "\n",
    "    imp_len +=1\n",
    "    DR_5mers_expand_imperfect[imp_len]['L_end'] = DR_5mers_expand_imperfect[imp_len]['L_end'] + 2\n",
    "    DR_5mers_expand_imperfect[imp_len]['R_end'] = DR_5mers_expand_imperfect[imp_len]['R_end'] + 2\n",
    "    DR_5mers_expand_imperfect[imp_len]['spacer'] = DR_5mers_expand_imperfect[imp_len]['spacer'] - 2\n",
    "\n",
    "\n",
    "    list_len = len(DR_5mers_expand_imperfect[imp_len])\n",
    "    while list_len > 0:\n",
    "        DR_5mers_expand_imperfect[imp_len]['imp_seq_L'] = [reference_genome_masked_STR[chrom][end:end+1] for chrom, end in zip(DR_5mers_expand_imperfect[imp_len]['chrom'], DR_5mers_expand_imperfect[imp_len]['L_end'])]\n",
    "        DR_5mers_expand_imperfect[imp_len]['imp_seq_R'] = [reference_genome_masked_STR[chrom][end:end+1] for chrom, end in zip(DR_5mers_expand_imperfect[imp_len]['chrom'], DR_5mers_expand_imperfect[imp_len]['R_end'])]\n",
    "\n",
    "        DR_5mers_expand_imperfect[imp_len+1] = DR_5mers_expand_imperfect[imp_len].loc[(DR_5mers_expand_imperfect[imp_len]['imp_seq_L'] == DR_5mers_expand_imperfect[imp_len]['imp_seq_R']) & (DR_5mers_expand_imperfect[imp_len]['imp_seq_L'].str.count('N') == 0) & (DR_5mers_expand_imperfect[imp_len]['imp_seq_R'].str.count('N') == 0) & (DR_5mers_expand_imperfect[imp_len]['spacer'] > 0)]\n",
    "        DR_5mers_expand_imperfect[imp_len] = DR_5mers_expand_imperfect[imp_len].loc[(DR_5mers_expand_imperfect[imp_len]['imp_seq_L'] != DR_5mers_expand_imperfect[imp_len]['imp_seq_R']) | (DR_5mers_expand_imperfect[imp_len]['imp_seq_L'].str.count('N') != 0) | (DR_5mers_expand_imperfect[imp_len]['imp_seq_R'].str.count('N') != 0) | (DR_5mers_expand_imperfect[imp_len]['spacer'] <= 0)]\n",
    "\n",
    "        imp_len +=1\n",
    "        list_len = len(DR_5mers_expand_imperfect[imp_len])\n",
    "        DR_5mers_expand_imperfect[imp_len]['L_end'] = DR_5mers_expand_imperfect[imp_len]['L_end'] + 1\n",
    "        DR_5mers_expand_imperfect[imp_len]['R_end'] = DR_5mers_expand_imperfect[imp_len]['R_end'] + 1\n",
    "        DR_5mers_expand_imperfect[imp_len]['spacer'] = DR_5mers_expand_imperfect[imp_len]['spacer'] - 1\n",
    "\n",
    "        print('\\r' + 'chrom ' + str(chrom) + 'expanding right imp_len ' +str(imp_len), end='        ')\n",
    "\n",
    "    DR_5mers_expand_imperfect = pd.concat(DR_5mers_expand_imperfect).reset_index(drop = True)\n",
    "    DR_5mers_expand_imperfect = DR_5mers_expand_imperfect.drop_duplicates(subset = ['L_start', 'R_start', 'L_end', 'R_end'])\n",
    "    DR_5mers_expand_imperfect['stem_len'] = DR_5mers_expand_imperfect['L_end'] - DR_5mers_expand_imperfect['L_start']\n",
    "    DR_expand_imperfect = DR_5mers_expand_imperfect.loc[DR_5mers_expand_imperfect['stem_len'] >9].copy()\n",
    "    DR_expand_imperfect['seq_L'] = [reference_genome_masked_STR[chrom][start:end] for chrom, start, end in zip(DR_expand_imperfect['chrom'], DR_expand_imperfect['L_start'], DR_expand_imperfect['L_end'])]\n",
    "    DR_expand_imperfect['seq_R'] = [reference_genome_masked_STR[chrom][start:end] for chrom, start, end in zip(DR_expand_imperfect['chrom'], DR_expand_imperfect['R_start'], DR_expand_imperfect['R_end'])]\n",
    "    DR_expand_imperfect['Sequence'] = [reference_genome_masked_STR[chrom][start:end] for chrom, start, end in zip(DR_expand_imperfect['chrom'], DR_expand_imperfect['L_start'], DR_expand_imperfect['R_end'])]\n",
    "    DR_expand_imperfect['freq'] = DR_expand_imperfect.groupby('seq_L')['seq_L'].transform('count')\n",
    "    DR_expand_imperfect['spacer'] = DR_expand_imperfect['R_start'] - (DR_expand_imperfect['L_end'])\n",
    "    DR_expand_imperfect = DR_expand_imperfect.loc[DR_expand_imperfect['Sequence'].str.count('N') == 0]\n",
    "    DR_expand_imperfect = DR_expand_imperfect.sort_values(by = ['chrom', 'L_start', 'R_end']).reset_index(drop = True)\n",
    "    del DR_expand_imperfect['imp_seq_L']; del DR_expand_imperfect['imp_seq_R']\n",
    "    DR_expand_imperfect['#MM'] = [sum(1 for a, b in zip(seq1, seq2) if a != b) for seq1, seq2 in zip(DR_expand_imperfect['seq_L'], DR_expand_imperfect['seq_R'])]\n",
    "    \n",
    "    print('\\r' + 'chrom ' + str(chrom) + 'done')\n",
    "          \n",
    "    return DR_expand_imperfect\n",
    "\n",
    "DR_expand_imperfect_all = dict()\n",
    "for chrom in range(chr_range,23):\n",
    "    DR_expand_imperfect_all[chrom] = DR_expand_imperfect_L_R(chrom)\n",
    "\n",
    "DR_expand_imperfect_all = pd.concat(DR_expand_imperfect_all)\n",
    "\n",
    "DR_expand_imperfect_all = DR_expand_imperfect_all.sort_values(by = ['chrom', 'L_start', 'R_end']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d1e22e",
   "metadata": {},
   "source": [
    "#### Save DR data <a name=\"DB_DR_save\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ab3c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DR database\n",
    "DR_expand_imperfect_all.to_csv('./custom_db/direct_repeats_withoutSTRs_imperfect_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac9d3e9",
   "metadata": {},
   "source": [
    "## Z-DNA <a name=\"DB_ZDNA\"></a>\n",
    "\n",
    "### ZDNA version 1: <a name=\"DB_ZDNA_v1\"></a>\n",
    "- alternative purinepyrimidine tracts of at least 10 nucleotides with the exclusion of AT/TA dinucleotides\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42155c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace reference genome with purine/pyrimidine sequence\n",
    "RY_genome = dict()\n",
    "for chrom in range(chr_range,23):\n",
    "    RY_genome[chrom] = reference_genome_masked_STR[chrom].replace('A', 'R').replace('G', 'R').replace('C', 'Y').replace('T', 'Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69539f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all alternating purine/pyrimidine sequences of 8nt length\n",
    "found_Zmers = dict()\n",
    "for chrom in range(chr_range,23):\n",
    "    found_Zmers[chrom] = pd.DataFrame()\n",
    "    current_Z_8mers = [match.start(0) for match in re.finditer('RYRYRYRY', RY_genome[chrom], overlapped = True)]\n",
    "    found_Zmers[chrom]['start'] = current_Z_8mers\n",
    "    found_Zmers[chrom]['end'] = found_Zmers[chrom]['start'] + 8\n",
    "    found_Zmers[chrom]['chrom'] = chrom\n",
    "    print('\\r' + ' chr' + str(chrom), end='        ')\n",
    "\n",
    "found_Zmers = pd.concat(found_Zmers)\n",
    "\n",
    "found_Zmers['Sequence'] = [reference_genome_masked_STR[chrom][start:end] for chrom, start, end in zip(found_Zmers['chrom'], found_Zmers['start'], found_Zmers['end'])]\n",
    "found_Zmers['RY_seq'] = [RY_genome[chrom][start:end] for chrom, start, end in zip(found_Zmers['chrom'], found_Zmers['start'], found_Zmers['end'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b53427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude sequences with AT dinucleotides\n",
    "found_Zmers_noAT = found_Zmers.loc[(found_Zmers['Sequence'].str.count('AT') == 0) & (found_Zmers['Sequence'].str.count('TA') == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38492a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand Z-DNA left\n",
    "Zmers_expand_noAT = dict()\n",
    "expand_left = found_Zmers_noAT.copy()\n",
    "list_len = len(expand_left)\n",
    "pos = 0\n",
    "while len(expand_left) > 0:\n",
    "    expand_left['Y_base'] = [RY_genome[chrom][start-1:start] for chrom, start in zip(expand_left['chrom'], expand_left['start'])]\n",
    "    expand_left['R_base'] = [RY_genome[chrom][start-2:start-1] for chrom, start in zip(expand_left['chrom'], expand_left['start'])]\n",
    "    expand_left['seq-1'] = [reference_genome_masked_STR[chrom][start-1:end] for chrom, start, end in zip(expand_left['chrom'], expand_left['start'], expand_left['end'])]\n",
    "    expand_left['seq-2'] = [reference_genome_masked_STR[chrom][start-2:end] for chrom, start, end in zip(expand_left['chrom'], expand_left['start'], expand_left['end'])]\n",
    "\n",
    "    Zmers_expand_noAT[pos] = expand_left.loc[(expand_left['Y_base'] != 'Y') | (expand_left['seq-1'].str.count('AT') != 0) | (expand_left['seq-1'].str.count('TA') != 0)].copy()\n",
    "    expand_left = expand_left.loc[(expand_left['Y_base'] == 'Y') & (expand_left['seq-1'].str.count('AT') == 0) & (expand_left['seq-1'].str.count('TA') == 0)]\n",
    "    Zmers_expand_noAT[pos-1] = expand_left.loc[(expand_left['R_base'] != 'R') | (expand_left['seq-2'].str.count('AT') != 0) | (expand_left['seq-2'].str.count('TA') != 0)].copy()\n",
    "    Zmers_expand_noAT[pos-1]['start'] = Zmers_expand_noAT[pos-1]['start'] -1\n",
    "    expand_left = expand_left.loc[(expand_left['Y_base'] == 'Y') & (expand_left['R_base'] == 'R') & (expand_left['seq-2'].str.count('AT') == 0) & (expand_left['seq-2'].str.count('TA') == 0)]\n",
    "    expand_left['start'] = expand_left['start'] -2\n",
    "    pos += -2\n",
    "    print('\\r' + 'expanding left ' + str(pos) + ' #' + str(len(expand_left)), end = '         ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa35ab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand Z-DNA right    \n",
    "expand_right = pd.concat(Zmers_expand_noAT)\n",
    "Zmers_expand_noAT = dict()\n",
    "list_len = len(expand_right)\n",
    "pos = 0\n",
    "while len(expand_right) > 0:\n",
    "    expand_right['R_base'] = [RY_genome[chrom][end:end+1] for chrom, end in zip(expand_right['chrom'], expand_right['end'])]\n",
    "    expand_right['Y_base'] = [RY_genome[chrom][end+1:end+2] for chrom, end in zip(expand_right['chrom'], expand_right['end'])]\n",
    "    expand_right['seq+1'] = [reference_genome_masked_STR[chrom][start:end+1] for chrom, start, end in zip(expand_right['chrom'], expand_right['start'], expand_right['end'])]\n",
    "    expand_right['seq+2'] = [reference_genome_masked_STR[chrom][start:end+2] for chrom, start, end in zip(expand_right['chrom'], expand_right['start'], expand_right['end'])]\n",
    "\n",
    "    Zmers_expand_noAT[pos] = expand_right.loc[(expand_right['R_base'] != 'R')  | (expand_right['seq+1'].str.count('AT') != 0) | (expand_right['seq+1'].str.count('TA') != 0)].copy()\n",
    "    expand_right = expand_right.loc[(expand_right['R_base'] == 'R') & (expand_right['seq+1'].str.count('AT') == 0) & (expand_right['seq+1'].str.count('TA') == 0)]\n",
    "    Zmers_expand_noAT[pos-1] = expand_right.loc[(expand_right['Y_base'] != 'Y') | (expand_right['seq+2'].str.count('AT') != 0) | (expand_right['seq+2'].str.count('TA') != 0)].copy()\n",
    "    Zmers_expand_noAT[pos-1]['end'] = Zmers_expand_noAT[pos-1]['end'] +1\n",
    "    expand_right = expand_right.loc[(expand_right['R_base'] == 'R') & (expand_right['Y_base'] == 'Y') & (expand_right['seq+2'].str.count('AT') == 0) & (expand_right['seq+2'].str.count('TA') == 0)]\n",
    "    expand_right['end'] = expand_right['end'] +2\n",
    "    pos += 2\n",
    "    print('\\r' + 'expanding right ' + str(pos) + ' #' + str(len(expand_right)), end = '         ')\n",
    "Zmers_expand_noAT = pd.concat(Zmers_expand_noAT)\n",
    "del Zmers_expand_noAT['Y_base']; del Zmers_expand_noAT['R_base']; del Zmers_expand_noAT['seq-1']; del Zmers_expand_noAT['seq-2']; del Zmers_expand_noAT['seq+1']; del Zmers_expand_noAT['seq+2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b82e7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates and annotate\n",
    "Zmers_expand_noAT = Zmers_expand_noAT.drop_duplicates(subset = ['chrom', 'start', 'end'], keep = 'first')\n",
    "Zmers_expand_noAT['Sequence'] = [reference_genome_masked_STR[chrom][start:end] for chrom, start, end in zip(Zmers_expand_noAT['chrom'], Zmers_expand_noAT['start'], Zmers_expand_noAT['end'])]\n",
    "Zmers_expand_noAT['RY_seq'] = [RY_genome[chrom][start:end] for chrom, start, end in zip(Zmers_expand_noAT['chrom'], Zmers_expand_noAT['start'], Zmers_expand_noAT['end'])]\n",
    "Zmers_expand_noAT = Zmers_expand_noAT.sort_values(by = ['chrom', 'start', 'end']).reset_index(drop = True)\n",
    "Zmers_expand_noAT['length'] = Zmers_expand_noAT['Sequence'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf0fd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum length for Z-DNA\n",
    "Zmers_expand_noAT = Zmers_expand_noAT.loc[Zmers_expand_noAT['length'] >= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3669ea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Z-DNA database\n",
    "Zmers_expand_noAT.to_csv('./custom_db/temp/ZDNA_noSTRs_noAT_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd096645",
   "metadata": {},
   "source": [
    "### ZDNA version 2: <a name=\"DB_ZDNA_v2\"></a>\n",
    "- G followed by Y (C or T) for at least 10 nt\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a78be7f",
   "metadata": {},
   "source": [
    "#### G strand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3150887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace pyrimidines in reference genome with Y\n",
    "AGY_genome = dict()\n",
    "for chrom in range(chr_range,23):\n",
    "    AGY_genome[chrom] = reference_genome_masked_STR[chrom].replace('C', 'Y').replace('T', 'Y')\n",
    "\n",
    "# Find all alternating G/pyrimidine sequences of 8nt length\n",
    "found_Zmers = dict()\n",
    "for chrom in range(chr_range,23):\n",
    "    found_Zmers[chrom] = pd.DataFrame()\n",
    "    current_Z_8mers = [match.start(0) for match in re.finditer('GYGYGYGY', AGY_genome[chrom], overlapped = True)]\n",
    "    found_Zmers[chrom]['start'] = current_Z_8mers\n",
    "    found_Zmers[chrom]['end'] = found_Zmers[chrom]['start'] + 8\n",
    "    found_Zmers[chrom]['chrom'] = chrom\n",
    "    print('\\r' + ' chr' + str(chrom), end='        ')\n",
    "found_Zmers = pd.concat(found_Zmers)\n",
    "\n",
    "found_Zmers['Sequence'] = [reference_genome_masked_STR[chrom][start:end] for chrom, start, end in zip(found_Zmers['chrom'], found_Zmers['start'], found_Zmers['end'])]\n",
    "found_Zmers['AGY_seq'] = [AGY_genome[chrom][start:end] for chrom, start, end in zip(found_Zmers['chrom'], found_Zmers['start'], found_Zmers['end'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cfa20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand Z-DNA left\n",
    "Zmers_expand_Gstrand = dict()\n",
    "expand_left = found_Zmers.copy()\n",
    "list_len = len(expand_left)\n",
    "pos = 0\n",
    "while len(expand_left) > 0:\n",
    "    expand_left['Y_base'] = [AGY_genome[chrom][start-1:start] for chrom, start in zip(expand_left['chrom'], expand_left['start'])]\n",
    "    expand_left['G_base'] = [AGY_genome[chrom][start-2:start-1] for chrom, start in zip(expand_left['chrom'], expand_left['start'])]\n",
    "    Zmers_expand_Gstrand[pos] = expand_left.loc[expand_left['Y_base'] != 'Y'].copy()\n",
    "    Zmers_expand_Gstrand[pos-1] = expand_left.loc[(expand_left['Y_base'] == 'Y') & (expand_left['G_base'] != 'G')].copy()\n",
    "    Zmers_expand_Gstrand[pos-1]['start'] = Zmers_expand_Gstrand[pos-1]['start'] -1\n",
    "    expand_left = expand_left.loc[(expand_left['Y_base'] == 'Y') & (expand_left['G_base'] == 'G')]\n",
    "    expand_left['start'] = expand_left['start'] -2\n",
    "    pos += -2\n",
    "    print('\\r' + 'expanding left ' + str(pos) + ' #' + str(len(expand_left)), end = '         ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e16bd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand Z-DNA right\n",
    "expand_right = pd.concat(Zmers_expand_Gstrand)\n",
    "Zmers_expand_Gstrand = dict()\n",
    "list_len = len(expand_right)\n",
    "pos = 0\n",
    "while len(expand_right) > 0:\n",
    "    expand_right['G_base'] = [AGY_genome[chrom][end:end+1] for chrom, end in zip(expand_right['chrom'], expand_right['end'])]\n",
    "    expand_right['Y_base'] = [AGY_genome[chrom][end+1:end+2] for chrom, end in zip(expand_right['chrom'], expand_right['end'])]\n",
    "    Zmers_expand_Gstrand[pos] = expand_right.loc[expand_right['G_base'] != 'G'].copy()\n",
    "    Zmers_expand_Gstrand[pos-1] = expand_right.loc[(expand_right['G_base'] == 'G') & (expand_right['Y_base'] != 'Y')].copy()\n",
    "    Zmers_expand_Gstrand[pos-1]['end'] = Zmers_expand_Gstrand[pos-1]['end'] +1\n",
    "    expand_right = expand_right.loc[(expand_right['G_base'] == 'G') & (expand_right['Y_base'] == 'Y')]\n",
    "    expand_right['end'] = expand_right['end'] +2\n",
    "    pos += 2\n",
    "    print('\\r' + 'expanding right ' + str(pos) + ' #' + str(len(expand_right)), end = '         ')\n",
    "Zmers_expand_Gstrand = pd.concat(Zmers_expand_Gstrand)\n",
    "del Zmers_expand_Gstrand['Y_base']; del Zmers_expand_Gstrand['G_base']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cbe50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates and annotate\n",
    "Zmers_expand_Gstrand = Zmers_expand_Gstrand.drop_duplicates(keep = 'first')\n",
    "Zmers_expand_Gstrand['Sequence'] = [reference_genome_masked_STR[chrom][start:end] for chrom, start, end in zip(Zmers_expand_Gstrand['chrom'], Zmers_expand_Gstrand['start'], Zmers_expand_Gstrand['end'])]\n",
    "Zmers_expand_Gstrand['AGY_seq'] = [AGY_genome[chrom][start:end] for chrom, start, end in zip(Zmers_expand_Gstrand['chrom'], Zmers_expand_Gstrand['start'], Zmers_expand_Gstrand['end'])]\n",
    "Zmers_expand_Gstrand = Zmers_expand_Gstrand.sort_values(by = ['chrom', 'start', 'end']).reset_index(drop = True)\n",
    "Zmers_expand_Gstrand['length'] = Zmers_expand_Gstrand['Sequence'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47797c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum length for Z-DNA\n",
    "Zmers_expand_Gstrand = Zmers_expand_Gstrand.loc[Zmers_expand_Gstrand['length'] >= 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9984992c",
   "metadata": {},
   "source": [
    "#### C-strand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4826797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace purines in reference genome with R\n",
    "TCR_genome = dict()\n",
    "for chrom in range(chr_range,23):\n",
    "    TCR_genome[chrom] = reference_genome_masked_STR[chrom].replace('A', 'R').replace('G', 'R')\n",
    "\n",
    "# Find all alternating C/purine sequences of 8nt length\n",
    "found_Zmers = dict()\n",
    "for chrom in range(chr_range,23):\n",
    "    found_Zmers[chrom] = pd.DataFrame()\n",
    "    current_Z_8mers = [match.start(0) for match in re.finditer('CRCRCRCR', TCR_genome[chrom], overlapped = True)]\n",
    "    found_Zmers[chrom]['start'] = current_Z_8mers\n",
    "    found_Zmers[chrom]['end'] = found_Zmers[chrom]['start'] + 8\n",
    "    found_Zmers[chrom]['chrom'] = chrom\n",
    "    print('\\r' + ' chr' + str(chrom), end='        ')\n",
    "found_Zmers = pd.concat(found_Zmers)\n",
    "found_Zmers['Sequence'] = [reference_genome_masked_STR[chrom][start:end] for chrom, start, end in zip(found_Zmers['chrom'], found_Zmers['start'], found_Zmers['end'])]\n",
    "found_Zmers['TCR_seq'] = [TCR_genome[chrom][start:end] for chrom, start, end in zip(found_Zmers['chrom'], found_Zmers['start'], found_Zmers['end'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bfd4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand Z-DNA left\n",
    "Zmers_expand_Cstrand = dict()\n",
    "expand_left = found_Zmers.copy()\n",
    "list_len = len(expand_left)\n",
    "pos = 0\n",
    "while len(expand_left) > 0:\n",
    "    expand_left['R_base'] = [TCR_genome[chrom][start-1:start] for chrom, start in zip(expand_left['chrom'], expand_left['start'])]\n",
    "    expand_left['C_base'] = [TCR_genome[chrom][start-2:start-1] for chrom, start in zip(expand_left['chrom'], expand_left['start'])]\n",
    "    Zmers_expand_Cstrand[pos] = expand_left.loc[expand_left['R_base'] != 'R'].copy()\n",
    "    Zmers_expand_Cstrand[pos-1] = expand_left.loc[(expand_left['R_base'] == 'R') & (expand_left['C_base'] != 'C')].copy()\n",
    "    Zmers_expand_Cstrand[pos-1]['start'] = Zmers_expand_Cstrand[pos-1]['start'] -1\n",
    "    expand_left = expand_left.loc[(expand_left['R_base'] == 'R') & (expand_left['C_base'] == 'C')]\n",
    "    expand_left['start'] = expand_left['start'] -2\n",
    "    pos += -2\n",
    "    print('\\r' + 'expanding left ' + str(pos) + ' #' + str(len(expand_left)), end = '         ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d02f758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand Z-DNA right\n",
    "expand_right = pd.concat(Zmers_expand_Cstrand)\n",
    "Zmers_expand_Cstrand = dict()\n",
    "list_len = len(expand_right)\n",
    "pos = 0\n",
    "while len(expand_right) > 0:\n",
    "    expand_right['C_base'] = [TCR_genome[chrom][end:end+1] for chrom, end in zip(expand_right['chrom'], expand_right['end'])]\n",
    "    expand_right['R_base'] = [TCR_genome[chrom][end+1:end+2] for chrom, end in zip(expand_right['chrom'], expand_right['end'])]\n",
    "    Zmers_expand_Cstrand[pos] = expand_right.loc[expand_right['C_base'] != 'C'].copy()\n",
    "    Zmers_expand_Cstrand[pos-1] = expand_right.loc[(expand_right['C_base'] == 'C') & (expand_right['R_base'] != 'R')].copy()\n",
    "    Zmers_expand_Cstrand[pos-1]['end'] = Zmers_expand_Cstrand[pos-1]['end'] +1\n",
    "    expand_right = expand_right.loc[(expand_right['C_base'] == 'C') & (expand_right['R_base'] == 'R')]\n",
    "    expand_right['end'] = expand_right['end'] +2\n",
    "    pos += 2\n",
    "    print('\\r' + 'expanding right ' + str(pos) + ' #' + str(len(expand_right)), end = '         ')\n",
    "Zmers_expand_Cstrand = pd.concat(Zmers_expand_Cstrand)\n",
    "del Zmers_expand_Cstrand['R_base']; del Zmers_expand_Cstrand['C_base']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58f3fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates and annotate\n",
    "Zmers_expand_Cstrand = Zmers_expand_Cstrand.drop_duplicates(keep = 'first')\n",
    "Zmers_expand_Cstrand['Sequence'] = [reference_genome_masked_STR[chrom][start:end] for chrom, start, end in zip(Zmers_expand_Cstrand['chrom'], Zmers_expand_Cstrand['start'], Zmers_expand_Cstrand['end'])]\n",
    "Zmers_expand_Cstrand['TCR_seq'] = [TCR_genome[chrom][start:end] for chrom, start, end in zip(Zmers_expand_Cstrand['chrom'], Zmers_expand_Cstrand['start'], Zmers_expand_Cstrand['end'])]\n",
    "Zmers_expand_Cstrand = Zmers_expand_Cstrand.sort_values(by = ['chrom', 'start', 'end']).reset_index(drop = True)\n",
    "Zmers_expand_Cstrand['length'] = Zmers_expand_Cstrand['Sequence'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3757c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum length for Z-DNA\n",
    "Zmers_expand_Cstrand = Zmers_expand_Cstrand.loc[Zmers_expand_Cstrand['length'] >= 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d800f4",
   "metadata": {},
   "source": [
    "#### Combine G and C strands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e90203",
   "metadata": {},
   "outputs": [],
   "source": [
    "Zmers_expand_Gstrand['Strand'] = 'G'\n",
    "Zmers_expand_Cstrand['Strand'] = 'C'\n",
    "Zmers_expand = pd.concat([Zmers_expand_Gstrand, Zmers_expand_Cstrand])\n",
    "del Zmers_expand['AGY_seq']; del Zmers_expand['TCR_seq']\n",
    "Zmers_expand = Zmers_expand.drop_duplicates(subset = ['chrom', 'start', 'end']).sort_values(by = ['chrom', 'start', 'end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f924b956",
   "metadata": {},
   "outputs": [],
   "source": [
    "Zmers_expand.to_csv('./custom_db/temp/ZDNA_noSTRs_GY_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85099d2d",
   "metadata": {},
   "source": [
    "### Combine RY and GY versions <a name=\"DB_ZDNA_all\"></a>\n",
    "- all motifs in GY version are contained within RY version\n",
    "- GY motifs can extend into longer RY motifs\n",
    "\n",
    "[Return to Table of Contents](#TOC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa6c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Zmers_expand_noAT = pd.read_csv('./custom_db/temp/ZDNA_noSTRs_noAT_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip', usecols = ['start', 'end', 'chrom', 'Sequence', 'length'])\n",
    "Zmers_expand_noAT['repeat'] = 'RY'\n",
    "Zmers_expand = pd.read_csv('./custom_db/temp/ZDNA_noSTRs_GY_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip', usecols = ['start', 'end', 'chrom', 'Sequence', 'length', 'Strand'])\n",
    "Zmers_expand['repeat'] = 'GY'\n",
    "\n",
    "Zmers_expand_noAT = measure_distance(Zmers_expand_noAT, Zmers_expand, 'GY')\n",
    "\n",
    "# RY does not overlap GY\n",
    "Zmers_expand_noAT_noGYoverlap = Zmers_expand_noAT.loc[Zmers_expand_noAT['GY_distance_min'] >0]\n",
    "\n",
    "Zmers_expand_noAT_GYoverlap = Zmers_expand_noAT.loc[Zmers_expand_noAT['GY_distance_min'] <1]\n",
    "# GY and RY are identical\n",
    "Zmers_expand_fulloverlap = pd.concat([Zmers_expand, Zmers_expand_noAT_GYoverlap]).loc[pd.concat([Zmers_expand, Zmers_expand_noAT_GYoverlap]).duplicated(subset = ['chrom', 'start', 'end'], keep = 'last')]\n",
    "# GY is contained within RY\n",
    "Zmers_expand_partialoverlap = pd.concat([Zmers_expand, Zmers_expand, Zmers_expand_noAT_GYoverlap]).drop_duplicates(subset = ['chrom', 'start', 'end'], keep = False)\n",
    "\n",
    "# Check whether partial overlap is with G or C strand\n",
    "Zmers_expand_partialoverlap = measure_distance(Zmers_expand_partialoverlap, Zmers_expand.loc[Zmers_expand['Strand'] == 'G'], 'Gstrand')\n",
    "Zmers_expand_partialoverlap = measure_distance(Zmers_expand_partialoverlap, Zmers_expand.loc[Zmers_expand['Strand'] == 'C'], 'Cstrand')\n",
    "Zmers_expand_partialoverlap_Gstrand = Zmers_expand_partialoverlap.loc[(Zmers_expand_partialoverlap['Gstrand_distance_min'] <1) & (Zmers_expand_partialoverlap['Cstrand_distance_min'] >0)].copy()\n",
    "Zmers_expand_partialoverlap_Gstrand['Strand'] = 'G'\n",
    "Zmers_expand_partialoverlap_Cstrand = Zmers_expand_partialoverlap.loc[(Zmers_expand_partialoverlap['Gstrand_distance_min'] >0) & (Zmers_expand_partialoverlap['Cstrand_distance_min'] <1)].copy()\n",
    "Zmers_expand_partialoverlap_Cstrand['Strand'] = 'C'\n",
    "Zmers_expand_partialoverlap_bothstrands = Zmers_expand_partialoverlap.loc[(Zmers_expand_partialoverlap['Gstrand_distance_min'] <1) & (Zmers_expand_partialoverlap['Cstrand_distance_min'] <1)].copy()\n",
    "\n",
    "# Combine all motifs\n",
    "Zmers_all = pd.concat([Zmers_expand_noAT_noGYoverlap, Zmers_expand_fulloverlap, Zmers_expand_partialoverlap_Gstrand, Zmers_expand_partialoverlap_Cstrand, Zmers_expand_partialoverlap_bothstrands])\n",
    "Zmers_all = Zmers_all[['start', 'end', 'chrom', 'Sequence', 'length', 'Strand']].copy().sort_values(by = ['chrom', 'start']).reset_index(drop = True)\n",
    "\n",
    "# Save\n",
    "Zmers_all.to_csv('./custom_db/ZDNA_noSTRs_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe238643",
   "metadata": {},
   "source": [
    "## G4 motifs <a name=\"DB_G4\"></a>\n",
    "#### Uses G4-seq data, then cleans up based on motifs\n",
    "- download files from https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM3003539\n",
    "    - GSM3003539_Homo_all_w15_th-1_plus.hits.max.K.w50.25.bed.gz\n",
    "    - GSM3003539_Homo_all_w15_th-1_minus.hits.max.K.w50.25.bed.gz\n",
    "- download from https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM3003540\n",
    "    - GSM3003540_Homo_all_w15_th-1_plus.hits.max.PDS.w50.35.bed.gz\n",
    "    - GSM3003540_Homo_all_w15_th-1_minus.hits.max.PDS.w50.35.bed.gz\n",
    "- place files in directory './custom_db/G4seq/'\n",
    "\n",
    "[Return to Table of Contents](#TOC)\n",
    "\n",
    "#### Liftover datasets from hg19 <a name=\"DB_G4_liftover\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0654035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load G4-seq files\n",
    "# Note: '-' strand corresponds to G strand\n",
    "G4seq_PDS_R = pd.read_csv('./custom_db/G4seq/GSM3003540_Homo_all_w15_th-1_plus.hits.max.PDS.w50.35.bed.gz', header = None, sep = '\\t', compression = 'gzip')\n",
    "G4seq_PDS_R.columns = ['chrom', 'start', 'end', 'score']\n",
    "\n",
    "G4seq_PDS_F = pd.read_csv('./custom_db/G4seq/GSM3003540_Homo_all_w15_th-1_minus.hits.max.PDS.w50.35.bed.gz', header = None, sep = '\\t', compression = 'gzip')\n",
    "G4seq_PDS_F.columns = ['chrom', 'start', 'end', 'score']\n",
    "\n",
    "G4seq_K_R = pd.read_csv('./custom_db/G4seq/GSM3003539_Homo_all_w15_th-1_plus.hits.max.K.w50.25.bed.gz', header = None, sep = '\\t', compression = 'gzip')\n",
    "G4seq_K_R.columns = ['chrom', 'start', 'end', 'score']\n",
    "\n",
    "G4seq_K_F = pd.read_csv('./custom_db/G4seq/GSM3003539_Homo_all_w15_th-1_minus.hits.max.K.w50.25.bed.gz', header = None, sep = '\\t', compression = 'gzip')\n",
    "G4seq_K_F.columns = ['chrom', 'start', 'end', 'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9527c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liftover to hg38\n",
    "lo = LiftOver('hg19', 'hg38')\n",
    "for repeats in [G4seq_PDS_F, G4seq_PDS_R, G4seq_K_F, G4seq_K_R]:\n",
    "    repeats['hg38_lo'] = [lo.convert_coordinate(chrom, pos) for chrom,pos in zip(repeats['chrom'], repeats['start'])]\n",
    "    repeats['hg38_chr_s'] = [pos[0][0] if len(pos) >0 else np.nan for pos in repeats['hg38_lo']]\n",
    "    repeats['hg38_start'] = [pos[0][1] if len(pos) >0 else np.nan for pos in repeats['hg38_lo']]\n",
    "    repeats['hg38_lo'] = [lo.convert_coordinate(chrom, pos) for chrom,pos in zip(repeats['chrom'], repeats['end'])]\n",
    "    repeats['hg38_chr_e'] = [pos[0][0] if len(pos) >0 else np.nan for pos in repeats['hg38_lo']]\n",
    "    repeats['hg38_end'] = [pos[0][1] if len(pos) >0 else np.nan for pos in repeats['hg38_lo']]\n",
    "\n",
    "# Filter for split chromosomes and start > end\n",
    "G4seq_PDS_F = G4seq_PDS_F.loc[(G4seq_PDS_F['hg38_chr_s'] == G4seq_PDS_F['hg38_chr_e']) & (G4seq_PDS_F['hg38_chr_s'].isin(['chr'+str(chrom) for chrom in range(1,23)])) & (G4seq_PDS_F['hg38_start'] < G4seq_PDS_F['hg38_end'])]\n",
    "G4seq_PDS_R = G4seq_PDS_R.loc[(G4seq_PDS_R['hg38_chr_s'] == G4seq_PDS_R['hg38_chr_e']) & (G4seq_PDS_R['hg38_chr_s'].isin(['chr'+str(chrom) for chrom in range(1,23)])) & (G4seq_PDS_R['hg38_start'] < G4seq_PDS_R['hg38_end'])]\n",
    "G4seq_K_F = G4seq_K_F.loc[(G4seq_K_F['hg38_chr_s'] == G4seq_K_F['hg38_chr_e']) & (G4seq_K_F['hg38_chr_s'].isin(['chr'+str(chrom) for chrom in range(1,23)])) & (G4seq_K_F['hg38_start'] < G4seq_K_F['hg38_end'])]\n",
    "G4seq_K_R = G4seq_K_R.loc[(G4seq_K_R['hg38_chr_s'] == G4seq_K_R['hg38_chr_e']) & (G4seq_K_R['hg38_chr_s'].isin(['chr'+str(chrom) for chrom in range(1,23)])) & (G4seq_K_R['hg38_start'] < G4seq_K_R['hg38_end'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007aabfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "G4seq_PDS_F = G4seq_PDS_F[['hg38_chr_s', 'hg38_start', 'hg38_end', 'score']]\n",
    "G4seq_PDS_F.columns = ['chrom', 'start', 'end', 'score']\n",
    "G4seq_PDS_R = G4seq_PDS_R[['hg38_chr_s', 'hg38_start', 'hg38_end', 'score']]\n",
    "G4seq_PDS_R.columns = ['chrom', 'start', 'end', 'score']\n",
    "G4seq_K_F = G4seq_K_F[['hg38_chr_s', 'hg38_start', 'hg38_end', 'score']]\n",
    "G4seq_K_F.columns = ['chrom', 'start', 'end', 'score']\n",
    "G4seq_K_R = G4seq_K_R[['hg38_chr_s', 'hg38_start', 'hg38_end', 'score']]\n",
    "G4seq_K_R.columns = ['chrom', 'start', 'end', 'score']\n",
    "\n",
    "G4seq_PDS_F = G4seq_PDS_F.loc[G4seq_PDS_F['chrom'].isin(['chr'+str(chrom) for chrom in range(1,23)])]\n",
    "G4seq_PDS_F['chrom'] = [chrom[3:] for chrom in G4seq_PDS_F['chrom']]\n",
    "G4seq_PDS_F['chrom'] = G4seq_PDS_F['chrom'].astype(int)\n",
    "G4seq_PDS_R = G4seq_PDS_R.loc[G4seq_PDS_R['chrom'].isin(['chr'+str(chrom) for chrom in range(1,23)])]\n",
    "G4seq_PDS_R['chrom'] = [chrom[3:] for chrom in G4seq_PDS_R['chrom']]\n",
    "G4seq_PDS_R['chrom'] = G4seq_PDS_R['chrom'].astype(int)\n",
    "G4seq_K_F = G4seq_K_F.loc[G4seq_K_F['chrom'].isin(['chr'+str(chrom) for chrom in range(1,23)])]\n",
    "G4seq_K_F['chrom'] = [chrom[3:] for chrom in G4seq_K_F['chrom']]\n",
    "G4seq_K_F['chrom'] = G4seq_K_F['chrom'].astype(int)\n",
    "G4seq_K_R = G4seq_K_R.loc[G4seq_K_R['chrom'].isin(['chr'+str(chrom) for chrom in range(1,23)])]\n",
    "G4seq_K_R['chrom'] = [chrom[3:] for chrom in G4seq_K_R['chrom']]\n",
    "G4seq_K_R['chrom'] = G4seq_K_R['chrom'].astype(int)\n",
    "\n",
    "G4seq_PDS_F['start'] = G4seq_PDS_F['start'].astype(int)\n",
    "G4seq_PDS_F['end'] = G4seq_PDS_F['end'].astype(int)\n",
    "G4seq_PDS_R['start'] = G4seq_PDS_R['start'].astype(int)\n",
    "G4seq_PDS_R['end'] = G4seq_PDS_R['end'].astype(int)\n",
    "G4seq_K_F['start'] = G4seq_K_F['start'].astype(int)\n",
    "G4seq_K_F['end'] = G4seq_K_F['end'].astype(int)\n",
    "G4seq_K_R['start'] = G4seq_K_R['start'].astype(int)\n",
    "G4seq_K_R['end'] = G4seq_K_R['end'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582cf9f7",
   "metadata": {},
   "source": [
    "#### Reduce overlaps within each condition <a name=\"DB_G4_combine\"></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520d594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Within each categoriy, combine overlapping entries while retaining G4seq scores\n",
    "G4seq_PDS_F_overlap = interval_overlap_per_chrom(G4seq_PDS_F)\n",
    "G4seq_PDS_F_combined = pd.concat([G4seq_PDS_F, G4seq_PDS_F_overlap])\n",
    "G4seq_PDS_F_changed = G4seq_PDS_F_combined.drop_duplicates(subset = ['chrom', 'start', 'end'], keep = False).dropna(subset = ['score'])\n",
    "G4seq_PDS_F_unchanged = G4seq_PDS_F_combined.sort_values(by = ['chrom', 'start', 'end', 'score']).reset_index(drop = True)\n",
    "G4seq_PDS_F_unchanged = G4seq_PDS_F_unchanged.loc[G4seq_PDS_F_unchanged.duplicated(subset = ['chrom', 'start', 'end'], keep = 'last')]\n",
    "G4seq_PDS_F_changed_overlap = interval_overlap_per_chrom(G4seq_PDS_F_changed)\n",
    "G4seq_PDS_F_changed_overlap['score'] = [G4seq_PDS_F_changed.loc[(G4seq_PDS_F_changed['chrom'] == chrom) & (G4seq_PDS_F_changed['start'] >= start) & (G4seq_PDS_F_changed['end'] <= end)]['score'].max() for chrom, start, end in zip(G4seq_PDS_F_changed_overlap['chrom'], G4seq_PDS_F_changed_overlap['start'], G4seq_PDS_F_changed_overlap['end'])]\n",
    "G4seq_PDS_F = pd.concat([G4seq_PDS_F_unchanged, G4seq_PDS_F_changed_overlap]).sort_values(by = ['chrom', 'start', 'end']).reset_index(drop = True)\n",
    "\n",
    "G4seq_PDS_R_overlap = interval_overlap_per_chrom(G4seq_PDS_R)\n",
    "G4seq_PDS_R_combined = pd.concat([G4seq_PDS_R, G4seq_PDS_R_overlap])\n",
    "G4seq_PDS_R_changed = G4seq_PDS_R_combined.drop_duplicates(subset = ['chrom', 'start', 'end'], keep = False).dropna(subset = ['score'])\n",
    "G4seq_PDS_R_unchanged = G4seq_PDS_R_combined.sort_values(by = ['chrom', 'start', 'end', 'score']).reset_index(drop = True)\n",
    "G4seq_PDS_R_unchanged = G4seq_PDS_R_unchanged.loc[G4seq_PDS_R_unchanged.duplicated(subset = ['chrom', 'start', 'end'], keep = 'last')]\n",
    "G4seq_PDS_R_changed_overlap = interval_overlap_per_chrom(G4seq_PDS_R_changed)\n",
    "G4seq_PDS_R_changed_overlap['score'] = [G4seq_PDS_R_changed.loc[(G4seq_PDS_R_changed['chrom'] == chrom) & (G4seq_PDS_R_changed['start'] >= start) & (G4seq_PDS_R_changed['end'] <= end)]['score'].max() for chrom, start, end in zip(G4seq_PDS_R_changed_overlap['chrom'], G4seq_PDS_R_changed_overlap['start'], G4seq_PDS_R_changed_overlap['end'])]\n",
    "G4seq_PDS_R = pd.concat([G4seq_PDS_R_unchanged, G4seq_PDS_R_changed_overlap]).sort_values(by = ['chrom', 'start', 'end']).reset_index(drop = True)\n",
    "\n",
    "G4seq_K_F_overlap = interval_overlap_per_chrom(G4seq_K_F)\n",
    "G4seq_K_F_combined = pd.concat([G4seq_K_F, G4seq_K_F_overlap])\n",
    "G4seq_K_F_changed = G4seq_K_F_combined.drop_duplicates(subset = ['chrom', 'start', 'end'], keep = False).dropna(subset = ['score'])\n",
    "G4seq_K_F_unchanged = G4seq_K_F_combined.sort_values(by = ['chrom', 'start', 'end', 'score']).reset_index(drop = True)\n",
    "G4seq_K_F_unchanged = G4seq_K_F_unchanged.loc[G4seq_K_F_unchanged.duplicated(subset = ['chrom', 'start', 'end'], keep = 'last')]\n",
    "G4seq_K_F_changed_overlap = interval_overlap_per_chrom(G4seq_K_F_changed)\n",
    "G4seq_K_F_changed_overlap['score'] = [G4seq_K_F_changed.loc[(G4seq_K_F_changed['chrom'] == chrom) & (G4seq_K_F_changed['start'] >= start) & (G4seq_K_F_changed['end'] <= end)]['score'].max() for chrom, start, end in zip(G4seq_K_F_changed_overlap['chrom'], G4seq_K_F_changed_overlap['start'], G4seq_K_F_changed_overlap['end'])]\n",
    "G4seq_K_F = pd.concat([G4seq_K_F_unchanged, G4seq_K_F_changed_overlap]).sort_values(by = ['chrom', 'start', 'end']).reset_index(drop = True)\n",
    "\n",
    "G4seq_K_R_overlap = interval_overlap_per_chrom(G4seq_K_R)\n",
    "G4seq_K_R_combined = pd.concat([G4seq_K_R, G4seq_K_R_overlap])\n",
    "G4seq_K_R_changed = G4seq_K_R_combined.drop_duplicates(subset = ['chrom', 'start', 'end'], keep = False).dropna(subset = ['score'])\n",
    "G4seq_K_R_unchanged = G4seq_K_R_combined.sort_values(by = ['chrom', 'start', 'end', 'score']).reset_index(drop = True)\n",
    "G4seq_K_R_unchanged = G4seq_K_R_unchanged.loc[G4seq_K_R_unchanged.duplicated(subset = ['chrom', 'start', 'end'], keep = 'last')]\n",
    "G4seq_K_R_changed_overlap = interval_overlap_per_chrom(G4seq_K_R_changed)\n",
    "G4seq_K_R_changed_overlap['score'] = [G4seq_K_R_changed.loc[(G4seq_K_R_changed['chrom'] == chrom) & (G4seq_K_R_changed['start'] >= start) & (G4seq_K_R_changed['end'] <= end)]['score'].max() for chrom, start, end in zip(G4seq_K_R_changed_overlap['chrom'], G4seq_K_R_changed_overlap['start'], G4seq_K_R_changed_overlap['end'])]\n",
    "G4seq_K_R = pd.concat([G4seq_K_R_unchanged, G4seq_K_R_changed_overlap]).sort_values(by = ['chrom', 'start', 'end']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2a7733",
   "metadata": {},
   "source": [
    "#### Check for overlaps between PDS and K+ G4-seq conditions <a name=\"DB_G4_overlap\"></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893f8d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label each condition\n",
    "G4seq_PDS_F['status'] = 'PDS'\n",
    "G4seq_PDS_F['Strand'] = '+'\n",
    "G4seq_PDS_R['status'] = 'PDS'\n",
    "G4seq_PDS_R['Strand'] = '-'\n",
    "\n",
    "G4seq_K_F['status'] = 'K+'\n",
    "G4seq_K_F['Strand'] = '+'\n",
    "G4seq_K_R['status'] = 'K+'\n",
    "G4seq_K_R['Strand'] = '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368b58ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for overlaps\n",
    "G4seq_K_F = measure_distance(G4seq_K_F, G4seq_PDS_F, 'PDS')\n",
    "G4seq_PDS_F = measure_distance(G4seq_PDS_F, G4seq_K_F, 'K')\n",
    "\n",
    "G4seq_K_R = measure_distance(G4seq_K_R, G4seq_PDS_R, 'PDS')\n",
    "G4seq_PDS_R = measure_distance(G4seq_PDS_R, G4seq_K_R, 'K')\n",
    "\n",
    "# Use K+ condition entries for any overlaps, since this is the more sensitive test\n",
    "G4seq_both_F = G4seq_K_F.loc[G4seq_K_F['PDS_distance_min'] <1].copy()\n",
    "G4seq_both_F['status'] = 'both'\n",
    "G4seq_both_R = G4seq_K_R.loc[G4seq_K_R['PDS_distance_min'] <1].copy()\n",
    "G4seq_both_R['status'] = 'both'\n",
    "\n",
    "G4seq_F = pd.concat([G4seq_both_F, G4seq_K_F.loc[G4seq_K_F['PDS_distance_min'] >0], G4seq_PDS_F.loc[G4seq_PDS_F['K_distance_min'] >0]])\n",
    "G4seq_R = pd.concat([G4seq_both_R, G4seq_K_R.loc[G4seq_K_R['PDS_distance_min'] >0], G4seq_PDS_R.loc[G4seq_PDS_R['K_distance_min'] >0]])\n",
    "\n",
    "G4seq_F = G4seq_F[['chrom', 'start', 'end', 'score', 'status', 'Strand']]\n",
    "G4seq_R = G4seq_R[['chrom', 'start', 'end', 'score', 'status', 'Strand']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a7c8fc",
   "metadata": {},
   "source": [
    "#### Confirm strand orientation and locate motifs <a name=\"DB_G4_motifs\"></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606e5d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select chromosomes of interest\n",
    "G4seq_F = G4seq_F.loc[G4seq_F['chrom'].isin(range(chr_range,23))].copy()\n",
    "G4seq_R = G4seq_R.loc[G4seq_R['chrom'].isin(range(chr_range,23))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f462cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove very long entries\n",
    "G4seq_F['length'] = G4seq_F['end'] - G4seq_F['start']\n",
    "G4seq_R['length'] = G4seq_R['end'] - G4seq_R['start']\n",
    "\n",
    "G4seq_F = G4seq_F.loc[G4seq_F['length'] <1000]\n",
    "G4seq_R = G4seq_R.loc[G4seq_R['length'] <1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc677339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve sequence and confirm orientation (using base-1 start position)\n",
    "G4seq_F['Sequence'] = [reference_genome[chrom][start-1:end].upper() for chrom, start, end in zip(G4seq_F['chrom'], G4seq_F['start'], G4seq_F['end'])]\n",
    "G4seq_R['Sequence'] = [reference_genome[chrom][start-1:end].upper() for chrom, start, end in zip(G4seq_R['chrom'], G4seq_R['start'], G4seq_R['end'])]\n",
    "\n",
    "G4seq_F['GGG_count'] = [seq.count('GGG') for seq in G4seq_F['Sequence']]\n",
    "G4seq_R['GGG_count'] = [seq.count('GGG') for seq in G4seq_R['Sequence']]\n",
    "\n",
    "G4seq_F['CCC_count'] = [seq.count('CCC') for seq in G4seq_F['Sequence']]\n",
    "G4seq_R['CCC_count'] = [seq.count('CCC') for seq in G4seq_R['Sequence']]\n",
    "\n",
    "for df, name in zip([G4seq_F, G4seq_R], ['G4seq_F', 'G4seq_R']):\n",
    "    print(name + ' ' + 'GGG ' + str(round(len(df.loc[df['GGG_count'] >3]) / len(df),3)) + ' CCC ' + str(round(len(df.loc[df['CCC_count'] >3]) / len(df), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715e1a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to somewhat standard G4 motifs (at least 4 sets of GGG)\n",
    "G4seq_filtered_F = G4seq_F.loc[G4seq_F['GGG_count'] >3].reset_index(drop = True).copy()\n",
    "G4seq_filtered_R = G4seq_R.loc[G4seq_R['CCC_count'] >3].reset_index(drop = True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e608ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim to start and end with 'GGG' (using base-0 start coordinates)\n",
    "G4seq_filtered_F['start'] = [start -1 + len(seq.split('GGG')[0]) for start, seq in zip(G4seq_filtered_F['start'], G4seq_filtered_F['Sequence'])]\n",
    "G4seq_filtered_F['end'] = [end - len(seq[::-1].split('GGG')[0]) for end, seq in zip(G4seq_filtered_F['end'], G4seq_filtered_F['Sequence'])]\n",
    "\n",
    "G4seq_filtered_R['start'] = [start -1 + len(seq.split('CCC')[0]) for start, seq in zip(G4seq_filtered_R['start'], G4seq_filtered_R['Sequence'])]\n",
    "G4seq_filtered_R['end'] = [end - len(seq[::-1].split('CCC')[0]) for end, seq in zip(G4seq_filtered_R['end'], G4seq_filtered_R['Sequence'])]\n",
    "\n",
    "# Annotate with sequence and motif length\n",
    "G4seq_filtered_F['Sequence'] = [reference_genome[chrom][start:end].upper() for chrom, start, end in zip(G4seq_filtered_F['chrom'], G4seq_filtered_F['start'], G4seq_filtered_F['end'])]\n",
    "G4seq_filtered_R['Sequence'] = [reference_genome[chrom][start:end].upper() for chrom, start, end in zip(G4seq_filtered_R['chrom'], G4seq_filtered_R['start'], G4seq_filtered_R['end'])]\n",
    "\n",
    "G4seq_filtered_F['length'] = G4seq_filtered_F['Sequence'].str.len()\n",
    "G4seq_filtered_R['length'] = G4seq_filtered_R['Sequence'].str.len()\n",
    "\n",
    "G4seq_filtered_F = G4seq_filtered_F.sort_values(by = ['chrom', 'start', 'end', 'score'])\n",
    "G4seq_filtered_F = G4seq_filtered_F.drop_duplicates(subset = ['chrom', 'start', 'end', 'status'], keep = 'last')\n",
    "\n",
    "G4seq_filtered_R = G4seq_filtered_R.sort_values(by = ['chrom', 'start', 'end', 'score'])\n",
    "G4seq_filtered_R = G4seq_filtered_R.drop_duplicates(subset = ['chrom', 'start', 'end', 'status'], keep = 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb59843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for repeat, name in zip([G4seq_filtered_F, G4seq_filtered_R], ['G4seq_filtered_F', 'G4seq_filtered_R']):\n",
    "    print(name + ' ' + str(len(repeat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b69a05e",
   "metadata": {},
   "source": [
    "#### Save G4 database <a name=\"DB_G4_save\"></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227795fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine FWD and REV\n",
    "G4seq_filtered = pd.concat([G4seq_filtered_F, G4seq_filtered_R])\n",
    "G4seq_filtered['length'] = G4seq_filtered['length'].astype(int)\n",
    "G4seq_filtered['GGG_count'] = G4seq_filtered['GGG_count'].astype(int)\n",
    "G4seq_filtered['CCC_count'] = G4seq_filtered['CCC_count'].astype(int)\n",
    "G4seq_filtered = G4seq_filtered.sort_values(by = ['chrom', 'start', 'end']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d63fa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "G4seq_filtered.to_csv('./custom_db/G4seq_filtered_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7054596d",
   "metadata": {},
   "source": [
    "## Combine all motifs into single database <a name=\"DB_all\"></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e65970",
   "metadata": {},
   "source": [
    "#### Load individual motif databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec7abbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load STR database\n",
    "all_STRs = pd.read_csv('./custom_db/temp/STRs_custom_imperfect_1-9_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip')\n",
    "all_STRs = all_STRs[['start', 'end', 'chrom', 'length', 'repeat', 'Sequence', 'Strand', 'status', 'repeat_frame_L']]\n",
    "all_STRs['Type'] = 'STR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b009bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IR database\n",
    "IR_expand_imperfect = pd.read_csv('./custom_db/inverted_repeats_withoutSTRs_imperfect_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip')\n",
    "for col in ['L_start', 'R_start', 'chrom', 'stem_len', 'L_end', 'R_end', 'spacer', 'freq', '#MM']:\n",
    "    IR_expand_imperfect[col] = IR_expand_imperfect[col].astype(int)\n",
    "\n",
    "# Filter out direct/inverted/mirror multi-category repeats\n",
    "IR_expand_imperfect['rev_seq_R'] = [seq[::-1] for seq in IR_expand_imperfect['seq_R']]\n",
    "IR_MR = IR_expand_imperfect.loc[IR_expand_imperfect['seq_L'] == IR_expand_imperfect['rev_seq_R']]\n",
    "IR_DR = IR_expand_imperfect.loc[IR_expand_imperfect['seq_L'] == IR_expand_imperfect['seq_R']]\n",
    "IR_expand_imperfect = IR_expand_imperfect.loc[(IR_expand_imperfect['seq_L'] != IR_expand_imperfect['seq_R']) & (IR_expand_imperfect['seq_L'] != IR_expand_imperfect['rev_seq_R'])]\n",
    "\n",
    "IR_expand_imperfect = IR_expand_imperfect[['chrom', 'L_start', 'R_end', 'L_end', 'R_start', 'stem_len', 'spacer', 'Sequence', 'seq_L', 'seq_R', 'RC_seq_R', '#MM']]\n",
    "IR_expand_imperfect.columns = ['chrom', 'start', 'end', 'L_end', 'R_start', 'stem_len', 'spacer', 'Sequence', 'seq_L', 'seq_R', 'RC_seq_R', '#MM']\n",
    "IR_expand_imperfect['Type'] = 'IR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f309f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MR database\n",
    "MR_expand_imperfect = pd.read_csv('./custom_db//mirror_repeats_withoutSTRs_imperfect_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip')\n",
    "for col in ['L_start', 'R_start', 'chrom', 'stem_len', 'L_end', 'R_end', 'spacer', 'freq', '#MM']:\n",
    "    MR_expand_imperfect[col] = MR_expand_imperfect[col].astype(int)\n",
    "\n",
    "# Filter out direct/inverted/mirror multi-category repeats\n",
    "MR_expand_imperfect['RC_seq_R'] = [reverse_complement(seq) for seq in MR_expand_imperfect['seq_R']]\n",
    "MR_IR = MR_expand_imperfect.loc[MR_expand_imperfect['seq_L'] == MR_expand_imperfect['RC_seq_R']]\n",
    "MR_DR = MR_expand_imperfect.loc[MR_expand_imperfect['seq_L'] == MR_expand_imperfect['seq_R']]\n",
    "MR_expand_imperfect = MR_expand_imperfect.loc[(MR_expand_imperfect['seq_L'] != MR_expand_imperfect['seq_R']) & (MR_expand_imperfect['seq_L'] != MR_expand_imperfect['RC_seq_R'])]\n",
    "\n",
    "MR_expand_imperfect = MR_expand_imperfect[['chrom', 'L_start', 'R_end', 'L_end', 'R_start', 'stem_len', 'spacer', 'Sequence', 'seq_L', 'seq_R', 'rev_seq_R', '#MM']]\n",
    "MR_expand_imperfect.columns = ['chrom', 'start', 'end', 'L_end', 'R_start', 'stem_len', 'spacer', 'Sequence', 'seq_L', 'seq_R', 'rev_seq_R', '#MM']\n",
    "MR_expand_imperfect['Type'] = 'MR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ec02ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DR database\n",
    "DR_expand_imperfect = pd.read_csv('./custom_db/direct_repeats_withoutSTRs_imperfect_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip')\n",
    "for col in ['L_start', 'R_start', 'chrom', 'stem_len', 'L_end', 'R_end', 'spacer', 'freq', '#MM']:\n",
    "    DR_expand_imperfect[col] = DR_expand_imperfect[col].astype(int)\n",
    "\n",
    "# Filter out direct/inverted/mirror multi-category repeats and duplicates\n",
    "DR_expand_imperfect['rev_seq_R'] = [seq[::-1] for seq in DR_expand_imperfect['seq_R']]\n",
    "DR_expand_imperfect['RC_seq_R'] = [reverse_complement(seq) for seq in DR_expand_imperfect['seq_R']]\n",
    "DR_MR = DR_expand_imperfect.loc[DR_expand_imperfect['seq_L'] == DR_expand_imperfect['rev_seq_R']]\n",
    "DR_IR = DR_expand_imperfect.loc[DR_expand_imperfect['seq_L'] == DR_expand_imperfect['RC_seq_R']]\n",
    "DR_expand_imperfect = DR_expand_imperfect.loc[(DR_expand_imperfect['seq_L'] != DR_expand_imperfect['RC_seq_R']) & (DR_expand_imperfect['seq_L'] != DR_expand_imperfect['rev_seq_R'])]\n",
    "del DR_expand_imperfect['rev_seq_R']; del DR_expand_imperfect['RC_seq_R']\n",
    "\n",
    "# Exclude very long spacers\n",
    "DR_expand_imperfect = DR_expand_imperfect.loc[DR_expand_imperfect['spacer'] <101]\n",
    "# drop duplicates, keep longest stem\n",
    "DR_expand_imperfect = DR_expand_imperfect.sort_values(by = ['chrom', 'L_start', 'R_end', 'stem_len']).drop_duplicates(subset = ['chrom', 'L_start', 'R_end'], keep = 'last')\n",
    "\n",
    "DR_expand_imperfect = DR_expand_imperfect[['chrom', 'L_start', 'R_end', 'L_end', 'R_start', 'stem_len', 'spacer', 'Sequence', 'seq_L', 'seq_R', '#MM']]\n",
    "DR_expand_imperfect.columns = ['chrom', 'start', 'end', 'L_end', 'R_start', 'stem_len', 'spacer', 'Sequence', 'seq_L', 'seq_R', '#MM']\n",
    "DR_expand_imperfect['Type'] = 'DR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3b8d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Z-DNA database\n",
    "Zmers_all = pd.read_csv('./custom_db/ZDNA_noSTRs_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip')\n",
    "Zmers_all['Type'] = 'ZDNA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af15822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load G4 database\n",
    "G4seq_filtered = pd.read_csv('./custom_db/G4seq_filtered_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip')\n",
    "G4seq_filtered.columns = ['chrom', 'start', 'end', 'G4seq_score', 'status', 'Strand', 'length', 'Sequence', 'GGG_count', 'CCC_count']\n",
    "G4seq_filtered['Type'] = 'G4'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa887a3",
   "metadata": {},
   "source": [
    "### Combine into single database, calculate distance to motifs and transposons, then filter database <a name=\"DB_all_distance\"></a>\n",
    "\n",
    "#### Distance measurement explanation:\n",
    "- Note: Measuring distance between coordinates using two different functions with slightly different behavior:\n",
    "\n",
    "    - \"distance_within_df()\" function:\n",
    "        - Compares each interval in dataframe A with every other interval in the same dataframe A.\n",
    "        - 0 indicates overlap.\n",
    "        - For nested overlaps (one completely inside the other), the smaller interval is labeled NaN and the larger interval ignores the smaller interval. This preserves the larger interval.\n",
    "\n",
    "    - \"measure_distance()\" function:\n",
    "        - Compares each interval in dataframe A with every other interval in different dataframe B.\n",
    "        - Takes non-overlapping intervals from dataframe B, and finds the nearest two intervals in B for each interval in dataframe A, based on start coordinates.\n",
    "        - Behavior is slightly counterintuitive for certain overlap configurations, but overlaps of any type (including both pairs of a nested overlap) will have at least left or right distance < 0, which is then replaced by 0 for both left and right.\n",
    "\n",
    "#### To generate unique database:\n",
    "- Combine all individual motif types into one database prior to distance filtering.\n",
    "- Search each individual motif type for overlaps against the STR database, and against the full database (excluding STRs and the current motif type) using \"measure_distance()\".\n",
    "- Search for overlaps within each individual database, preserving longest nested overlaps, using \"distance_within_df()\".\n",
    "- Combine individual motif types again, this time post-search, into one database.\n",
    "- Filter for distance_min > 0 for both distance categories.\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54fffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_motifs = pd.concat([all_STRs, IR_expand_imperfect, MR_expand_imperfect, DR_expand_imperfect, Zmers_all, G4seq_filtered])\n",
    "all_motifs['length'] = all_motifs['end'] - all_motifs['start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17998f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "IR_expand_imperfect = measure_distance(IR_expand_imperfect, all_motifs.loc[all_motifs['Type'] == 'STR'], 'STR')\n",
    "MR_expand_imperfect = measure_distance(MR_expand_imperfect, all_motifs.loc[all_motifs['Type'] == 'STR'], 'STR')\n",
    "DR_expand_imperfect = measure_distance(DR_expand_imperfect, all_motifs.loc[all_motifs['Type'] == 'STR'], 'STR')\n",
    "Zmers_all = measure_distance(Zmers_all, all_motifs.loc[all_motifs['Type'] == 'STR'], 'STR')\n",
    "\n",
    "# Exclude very short STRs from G4 distance filtering, because physical G4 detection should supercede questionably short STR motif detection\n",
    "G4seq_filtered = measure_distance(G4seq_filtered, all_motifs.loc[(all_motifs['Type'] == 'STR') & (all_motifs['length'] > 7)], 'STR')\n",
    "\n",
    "# Set these values to infinity, so that they don't interfere with filtering based on distance_within_df\n",
    "all_STRs['STR_distance_left'] = np.inf\n",
    "all_STRs['STR_distance_right'] = np.inf\n",
    "all_STRs['STR_distance_min'] = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f155ae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_STRs = measure_distance(all_STRs, all_motifs.loc[(all_motifs['Type'] != 'STR')], 'nonSTR')\n",
    "IR_expand_imperfect = measure_distance(IR_expand_imperfect, all_motifs.loc[(all_motifs['Type'] != 'STR') & (all_motifs['Type'] != 'IR')], 'nonSTR')\n",
    "MR_expand_imperfect = measure_distance(MR_expand_imperfect, all_motifs.loc[(all_motifs['Type'] != 'STR') & (all_motifs['Type'] != 'MR')], 'nonSTR')\n",
    "DR_expand_imperfect = measure_distance(DR_expand_imperfect, all_motifs.loc[(all_motifs['Type'] != 'STR') & (all_motifs['Type'] != 'DR')], 'nonSTR')\n",
    "Zmers_all = measure_distance(Zmers_all, all_motifs.loc[(all_motifs['Type'] != 'STR') & (all_motifs['Type'] != 'ZDNA')], 'nonSTR')\n",
    "G4seq_filtered = measure_distance(G4seq_filtered, all_motifs.loc[(all_motifs['Type'] != 'STR') & (all_motifs['Type'] != 'G4')], 'nonSTR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72d3c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_STRs = distance_within_df(all_STRs, 'within_motif')\n",
    "IR_expand_imperfect = distance_within_df(IR_expand_imperfect, 'within_motif')\n",
    "MR_expand_imperfect = distance_within_df(MR_expand_imperfect, 'within_motif')\n",
    "DR_expand_imperfect = distance_within_df(DR_expand_imperfect, 'within_motif')\n",
    "Zmers_all = distance_within_df(Zmers_all, 'within_motif')\n",
    "G4seq_filtered = distance_within_df(G4seq_filtered, 'within_motif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d327e88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join/sort by priority in order to use drop_duplicates(keep = 'first') below\n",
    "all_STRs = pd.concat([all_STRs.loc[all_STRs['status'] == 'perfect'], all_STRs.loc[all_STRs['status'] == 'inframe'], all_STRs.loc[all_STRs['status'] == 'shortindel'], all_STRs.loc[all_STRs['status'] == 'complex']])\n",
    "all_motifs = pd.concat([all_STRs.sort_values(by = ['chrom', 'start', 'end']), G4seq_filtered.sort_values(by = ['chrom', 'start', 'end']), Zmers_all.sort_values(by = ['chrom', 'start', 'end']), IR_expand_imperfect.sort_values(by = ['chrom', 'start', 'end']), MR_expand_imperfect.sort_values(by = ['chrom', 'start', 'end']), DR_expand_imperfect.sort_values(by = ['chrom', 'start', 'end'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72472a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_motifs['overall_distance_min'] = [min(nonSTR_distance, STR_distance, within_distance) for nonSTR_distance, STR_distance, within_distance in zip(all_motifs['nonSTR_distance_min'], all_motifs['STR_distance_min'], all_motifs['within_motif_distance_min'])]\n",
    "all_motifs['length'] = all_motifs['end'] - all_motifs['start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d45880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distance between motifs and transposable elements\n",
    "all_motifs = measure_distance(all_motifs, repeatmasker.loc[~repeatmasker['repClass'].isin(['Simple_repeat', 'Low_complexity'])], 'RM')\n",
    "# Remove motifs that overlap Repeatmasker non-simple regions\n",
    "# Should only include G4 motifs at this point, since all others were found using masked reference genome\n",
    "all_motifs = all_motifs.loc[all_motifs['RM_distance_min'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108f755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save database (CSV format is human-readable)\n",
    "all_motifs.to_csv('./custom_db/all_motifs_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip', index = False)\n",
    "# Save database (Python-readable pickle file for easier loading)\n",
    "all_motifs.to_pickle('./custom_db/all_motifs_chr'+str(chr_range)+'-22.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1673a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_motifs = pd.read_csv('./custom_db/all_motifs_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422f9266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove motifs that overlap with other motifs in the database\n",
    "all_motifs_unique = all_motifs.loc[(all_motifs['STR_distance_min'] >0) & (all_motifs['nonSTR_distance_min'] >0) & (all_motifs['within_motif_distance_min'] >0)].copy()\n",
    "\n",
    "# Remove any remaining fully-duplicated positions by priority (established above)\n",
    "all_motifs_unique = all_motifs_unique.drop_duplicates(subset = ['chrom', 'start', 'end'], keep = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45478cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save database (CSV format is human-readable)\n",
    "all_motifs_unique.to_csv('./custom_db/all_motifs_unique_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip', index = False)\n",
    "# Save database (Python-readable pickle file for easier loading)\n",
    "all_motifs_unique.to_pickle('./custom_db/all_motifs_unique_chr'+str(chr_range)+'-22.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefeb585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load motif database\n",
    "all_motifs_unique = pd.read_pickle('./custom_db/all_motifs_unique_chr'+str(chr_range)+'-22.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7013cdfe",
   "metadata": {},
   "source": [
    "### Repeat database stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24d59f9",
   "metadata": {},
   "source": [
    "#### Plots for Supplementary Figure S1A and B <a name=\"DB_nonbdb_plot_S1A\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e941a48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_len_count = all_motifs.groupby(['Type', 'stem_len']).count()['chrom'].unstack()\n",
    "len_count = all_motifs.groupby(['Type', 'length']).count()['chrom'].unstack()\n",
    "\n",
    "stem_len_count_unique = all_motifs_unique.groupby(['Type', 'stem_len']).count()['chrom'].unstack()\n",
    "len_count_unique = all_motifs_unique.groupby(['Type', 'length']).count()['chrom'].unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0598bcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_type_colors = make_default_colors(['STR', 'IR', 'DR', 'MR', 'ZDNA', 'G4'], opacity = 0.75, last_black=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7500179",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_fig_unique = go.Figure()\n",
    "for motif in ['STR', 'ZDNA', 'G4']:\n",
    "    len_fig_unique.add_trace(go.Scatter(x = len_count.transpose().index, y = len_count.transpose()[motif], legendgroup = motif, mode = 'lines', line = dict(color = motif_type_colors[1][motif]), name = motif))\n",
    "    len_fig_unique.add_trace(go.Scatter(x = len_count_unique.transpose().index, y = len_count_unique.transpose()[motif], legendgroup = motif, showlegend = False, mode = 'lines', line = dict(color = motif_type_colors[1][motif], dash = 'dot'), name = motif))\n",
    "for motif in ['IR', 'DR', 'MR']:\n",
    "    len_fig_unique.add_trace(go.Scatter(x = stem_len_count.transpose().index, y = stem_len_count.transpose()[motif], legendgroup = motif, mode = 'lines', line = dict(color = motif_type_colors[1][motif]), name = motif))\n",
    "    len_fig_unique.add_trace(go.Scatter(x = stem_len_count_unique.transpose().index, y = stem_len_count_unique.transpose()[motif], legendgroup = motif, showlegend = False, mode = 'lines', line = dict(color = motif_type_colors[1][motif], dash = 'dot'), name = motif))\n",
    "len_fig_unique.update_yaxes(type = 'log', dtick = 1, title = dict(text = '# Motifs', font = dict(size = 18)))\n",
    "len_fig_unique.update_xaxes(type = 'log', title = dict(text = 'Motif length', font = dict(size = 18)))\n",
    "len_fig_unique.update_layout(height = 400, width = 800, margin = dict(l = 55, r = 5, b = 40, t = 30))\n",
    "\n",
    "len_fig_unique.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22759047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S1A\n",
    "len_fig_unique.write_image('./plots/revision_repeatdb_length_count_fig_S1a.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801f09d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeats_highpower = ['T', 'G', 'TG', 'TC', 'TGG', 'ATT', 'TTG', 'TTC', 'TCC', 'ATG', 'TGC', 'ATTT', 'A', 'C',  'AC', 'AG', 'ACC', 'AAT', 'AAC', 'AAG', 'AGG', 'ATC', 'AGC', 'AAAT', 'AT', 'GC']\n",
    "# Symmetric and asymmetric STR motifs\n",
    "repeats_highpower_asym = pd.Series(['T', 'G', 'TG', 'TC', 'TGG', 'ATT', 'TTG', 'TTC', 'TCC', 'ATG', 'TGC', 'ATTT'], index = ['A', 'C',  'AC', 'AG', 'ACC', 'AAT', 'AAC', 'AAG', 'AGG', 'ATC', 'AGC', 'AAAT'])\n",
    "repeats_highpower_sym = ['AT', 'GC']\n",
    "repeats_highpower_all = ['A', 'C',  'AC', 'AG', 'AT', 'GC', 'ACC', 'AAT', 'AAC', 'AAG', 'AGG', 'ATC', 'AGC', 'AAAT']\n",
    "STR_colors = make_default_colors(repeats_highpower_all, 0.75, last_black=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559efffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "STR_motifs_forcount_unique = all_motifs_unique.loc[(all_motifs_unique['Type'] == 'STR') & (all_motifs_unique['repeat'].isin(repeats_highpower))][['length', 'repeat', 'status']].copy()\n",
    "STR_motifs_forcount_unique['repeat_rc'] = [reverse_complement(repeat) if repeat in list(repeats_highpower_asym) else repeat for repeat in STR_motifs_forcount_unique['repeat']]\n",
    "STR_len_count_unique = STR_motifs_forcount_unique.groupby(['repeat_rc', 'status', 'length']).count()['repeat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4911d1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_len_fig_unique = go.Figure()\n",
    "for motif in repeats_highpower_all:\n",
    "    str_len_fig_unique.add_trace(go.Scatter(x = STR_len_count_unique.loc[motif].loc['perfect'].index, y = STR_len_count_unique.loc[motif].loc['perfect'], mode = 'lines', line = dict(color = STR_colors[1][motif]), name = motif))\n",
    "    str_len_fig_unique.add_trace(go.Scatter(x = STR_len_count_unique.loc[motif].loc['inframe'].index, y = STR_len_count_unique.loc[motif].loc['inframe'], showlegend = False, mode = 'lines', line = dict(color = STR_colors[1][motif], dash = 'dot'), name = motif))\n",
    "str_len_fig_unique.update_yaxes(type = 'log', dtick = 1, title = dict(text = '# Motifs', font = dict(size = 18)))\n",
    "str_len_fig_unique.update_xaxes(type = 'log', range = [0.7,2.2], title = dict(text = 'Motif length', font = dict(size = 18)))\n",
    "str_len_fig_unique.update_layout(height = 400, width = 800, margin = dict(l = 55, r = 5, b = 40, t = 30))\n",
    "str_len_fig_unique.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2d9965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. S1B\n",
    "str_len_fig_unique.write_image('./plots/revision_repeatdb_STR_length_count_fig_S1b.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e48748",
   "metadata": {},
   "source": [
    "#### Motif type overlaps  <a name=\"DB_all_overlaps\"></a>\n",
    "- Check whether motifs consistently overlap with motifs in other categories\n",
    "- Plots demonstrate the importance and effectiveness of filtering method described above\n",
    "- Same approach can be used to assess overlaps in \"Non-B DB\" (https://nonb-abcc.ncifcrf.gov/apps/site/default)\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482e4ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_motif_types = dict()\n",
    "motif_types = ['DR', 'G4', 'IR', 'MR', 'STR', 'ZDNA']\n",
    "for motif in motif_types:\n",
    "    current_motif = all_motifs.loc[all_motifs['Type'] == motif].copy()\n",
    "    current_motif['motif_overlaps'] = ''\n",
    "    for other in motif_types:\n",
    "        current_motif = measure_distance(current_motif, all_motifs.loc[all_motifs['Type'] == other], other)\n",
    "        current_motif['motif_overlaps'] = current_motif['motif_overlaps'] + [other + ' ' if pos <1 else '' for pos in current_motif[other + '_distance_min']]\n",
    "        del current_motif[other+'_distance_left']; del current_motif[other+'_distance_right']; del current_motif[other+'_distance_min']\n",
    "        print('\\r' + motif + ' ' + other, end='         ', flush = True)\n",
    "    all_motif_types[motif] = current_motif\n",
    "\n",
    "all_motifs = pd.concat(all_motif_types)\n",
    "all_motifs = all_motifs.sort_values(by = ['chrom', 'start', 'end']).reset_index(drop = True)\n",
    "\n",
    "all_motifs['motif_overlaps'] = [motifs_list[:-1] for motifs_list in all_motifs['motif_overlaps']]\n",
    "\n",
    "# Remove motifs that overlap with other motifs in the database\n",
    "all_motifs_unique = all_motifs.loc[(all_motifs['overall_distance_min'] >0)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267d6a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before filtering - Compare to Figure S1C\n",
    "groups_df = pd.DataFrame(index = set(all_motifs['motif_overlaps']))\n",
    "for group in all_motif_types:\n",
    "    groups_df[group] = all_motifs.loc[all_motifs['Type'] == group]['motif_overlaps'].value_counts() / len(all_motifs.loc[all_motifs['Type'] == group])\n",
    "\n",
    "# group together entries that comprise only a small percentage of the category\n",
    "groups_df_slim = pd.DataFrame(index = set(all_motifs['motif_overlaps']))\n",
    "for group in all_motif_types:\n",
    "    groups_df_slim[group] = groups_df[group].loc[groups_df[group] > 0.1]\n",
    "groups_df_slim = groups_df_slim.dropna(how = 'all').fillna(0)\n",
    "relevant_groups = list(groups_df_slim.index)\n",
    "groups_df_slim = pd.DataFrame(index = relevant_groups)\n",
    "for group in all_motif_types:\n",
    "    groups_df_slim[group] = groups_df[group].loc[relevant_groups]\n",
    "groups_df_slim = groups_df_slim.dropna(how = 'all').fillna(0)\n",
    "groups_df_slim.loc['Other multiple'] = [1- groups_df_slim[col].sum() for col in groups_df_slim.columns]\n",
    "groups_df_slim = groups_df_slim.loc[[group for group in groups_df_slim.index if len(group.split(' ')) > 1]]\n",
    "groups_df_slim.loc['Unique'] = [1- groups_df_slim[col].sum() for col in groups_df_slim.columns]\n",
    "\n",
    "groups_df_slim = groups_df_slim.loc[list(groups_df_slim.index[-1:]) + list(groups_df_slim.index[:-1])]\n",
    "groups_df_slim = groups_df_slim[['IR', 'G4', 'STR', 'DR', 'MR', 'ZDNA']]\n",
    "groups_df_slim_color = pd.Series(plotly.colors.DEFAULT_PLOTLY_COLORS[:len(groups_df_slim.index)-1] + ['rgb(220,220,220)'], index = groups_df_slim.index)\n",
    "\n",
    "group_overlap_fig = go.Figure()\n",
    "for types in groups_df_slim.index:\n",
    "    group_overlap_fig.add_trace(go.Bar(name=types, x = groups_df_slim.columns, y = groups_df_slim.loc[types], text = types, marker = dict(color = groups_df_slim_color[types])))\n",
    "group_overlap_fig.update_layout(barmode='stack')\n",
    "group_overlap_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019f7c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After filtering  - Compare to Figure S1C\n",
    "groups_df = pd.DataFrame(index = set(all_motifs_unique['motif_overlaps']))\n",
    "for group in all_motif_types:\n",
    "    groups_df[group] = all_motifs_unique.loc[all_motifs_unique['Type'] == group]['motif_overlaps'].value_counts() / len(all_motifs_unique.loc[all_motifs_unique['Type'] == group])\n",
    "\n",
    "# group together entries that comprise only a small percentage of the category\n",
    "groups_df_slim = pd.DataFrame(index = set(all_motifs_unique['motif_overlaps']))\n",
    "for group in all_motif_types:\n",
    "    groups_df_slim[group] = groups_df[group].loc[groups_df[group] > 0.15]\n",
    "groups_df_slim = groups_df_slim.dropna(how = 'all').fillna(0)\n",
    "relevant_groups = list(groups_df_slim.index)\n",
    "groups_df_slim = pd.DataFrame(index = relevant_groups)\n",
    "for group in all_motif_types:\n",
    "    groups_df_slim[group] = groups_df[group].loc[relevant_groups]\n",
    "groups_df_slim = groups_df_slim.dropna(how = 'all').fillna(0)\n",
    "groups_df_slim.loc['Other multiple'] = [1- groups_df_slim[col].sum() for col in groups_df_slim.columns]\n",
    "groups_df_slim = groups_df_slim.loc[[group for group in groups_df_slim.index if len(group.split(' ')) > 1]]\n",
    "groups_df_slim.loc['Unique'] = [1- groups_df_slim[col].sum() for col in groups_df_slim.columns]\n",
    "\n",
    "groups_df_slim = groups_df_slim.loc[list(groups_df_slim.index[-1:]) + list(groups_df_slim.index[:-1])]\n",
    "groups_df_slim = groups_df_slim[['IR', 'G4', 'STR', 'DR', 'MR', 'ZDNA']]\n",
    "groups_df_slim_color = pd.Series(plotly.colors.DEFAULT_PLOTLY_COLORS[:len(groups_df_slim.index)-1] + ['rgb(220,220,220)'], index = groups_df_slim.index)\n",
    "\n",
    "group_overlap_fig = go.Figure()\n",
    "for types in groups_df_slim.index:\n",
    "    group_overlap_fig.add_trace(go.Bar(name=types, x = groups_df_slim.columns, y = groups_df_slim.loc[types], text = types, marker = dict(color = groups_df_slim_color[types])))\n",
    "group_overlap_fig.update_layout(barmode='stack')\n",
    "group_overlap_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7f1011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall minimum distance to next motif, represented by percentile  - Compare to Figure S1D\n",
    "plot_values = all_motifs.drop_duplicates(subset = ['chrom', 'start', 'end'])['overall_distance_min'].fillna(0).quantile([i/100 for i in range(1,99)])\n",
    "# Count all overlaps as 0\n",
    "plot_values[plot_values < 0] = 0\n",
    "\n",
    "distance_all_motifs_fig = go.Figure()\n",
    "distance_all_motifs_fig.add_trace(go.Bar(x = list(range(1,99)), y = plot_values))\n",
    "distance_all_motifs_fig.update_yaxes(title = 'distance to nearest motif (nt =0 indicates overlap)')\n",
    "distance_all_motifs_fig.update_xaxes(title = 'quantile')\n",
    "distance_all_motifs_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e635a082",
   "metadata": {},
   "source": [
    "## Random sequences <a name=\"DB_random\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b46bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_coordinates(prefilter_number):\n",
    "    # Select random regions proportionally across all chromosomes\n",
    "    # Use reference_genome_masked_STR to find random sequences that don't overlap with STRs or transposons\n",
    "    # Pre-filter number is the initial number of random sequences across chromsomes 1-22, though many will be filtered out.\n",
    "    count_prefilter = prefilter_number/chr_range\n",
    "    reference_portion = pd.Series([len(reference_genome_masked_STR[chrom]) for chrom in range(chr_range,23)], index = range(chr_range,23)) / sum([len(reference_genome_masked_STR[chrom]) for chrom in range(chr_range,23)])\n",
    "    num_to_sample = (reference_portion * count_prefilter).astype(int)\n",
    "\n",
    "    import random\n",
    "    random_coordinates = dict()\n",
    "    for chrom in range(chr_range,23):\n",
    "        random_coordinates[chrom] = pd.DataFrame()\n",
    "        random_coordinates[chrom]['start'] = pd.Series(random.sample(range(chr_range,len(reference_genome_masked_STR[chrom])), num_to_sample[chrom]))\n",
    "        random_coordinates[chrom]['end'] = random_coordinates[chrom]['start'] + 30\n",
    "        random_coordinates[chrom]['chrom'] = chrom\n",
    "    random_coordinates = pd.concat([random_coordinates[chrom] for chrom in random_coordinates])\n",
    "\n",
    "    # Remove any sequences with Ns\n",
    "    random_coordinates['Sequence'] = [reference_genome_masked_STR[chrom][start:end].upper() for chrom, start, end in zip(random_coordinates['chrom'], random_coordinates['start'], random_coordinates['end'])]\n",
    "    random_coordinates['count_N'] = [seq.count('N') for seq in random_coordinates['Sequence']]\n",
    "    random_coordinates = random_coordinates.loc[random_coordinates['count_N'] == 0]\n",
    "    del random_coordinates['count_N']\n",
    "\n",
    "    # Distance to nearest motif\n",
    "    random_coordinates = measure_distance(random_coordinates, all_motifs.loc[all_motifs['Type'] == 'STR'], 'STR')\n",
    "    random_coordinates = measure_distance(random_coordinates, all_motifs.loc[(all_motifs['Type'] != 'STR') & (all_motifs['Type'] != 'IR')], 'nonSTR')\n",
    "    random_coordinates = distance_within_df(random_coordinates, 'within_motif')\n",
    "\n",
    "    # Distance to nearest Repeatmasker entry (excluding simple and low complexity)\n",
    "    random_coordinates = measure_distance(random_coordinates, repeatmasker.loc[~repeatmasker['repClass'].isin(['Simple_repeat', 'Low_complexity'])], 'RM')\n",
    "\n",
    "    # Filter out sequences with nearby motifs/transposons\n",
    "    RM_filter_distance = 5; nonSTR_filter_distance = 5; STR_filter_distance = 20; within_motif_filter_distance = 20\n",
    "\n",
    "    random_filtered = random_coordinates.loc[(random_coordinates['RM_distance_min'] >= RM_filter_distance) & (random_coordinates['STR_distance_min'] >= STR_filter_distance) & (random_coordinates['nonSTR_distance_min'] >= nonSTR_filter_distance)  & (random_coordinates['within_motif_distance_min'] >= within_motif_filter_distance)]\n",
    "    \n",
    "    return random_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7177f5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate two independent sets of random coordinates\n",
    "random_set1 = generate_random_coordinates(500000)\n",
    "random_set2 = generate_random_coordinates(500000)\n",
    "\n",
    "# Save database (for repeatability)\n",
    "random_set1.to_csv('./custom_db/random_sequences_set1_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip', index = False)\n",
    "random_set2.to_csv('./custom_db/random_sequences_set2_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6a1de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate two (larger) independent sets of random coordinates\n",
    "random_set3 = generate_random_coordinates(5000000)\n",
    "random_set4 = generate_random_coordinates(5000000)\n",
    "\n",
    "# Save database (for repeatability)\n",
    "random_set3.to_csv('./custom_db/random_sequences_set3_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip', index = False)\n",
    "random_set4.to_csv('./custom_db/random_sequences_set4_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb241fc",
   "metadata": {},
   "source": [
    "## Non-B DB <a name=\"DB_nonbdb\"></a>\n",
    "- For comparison purposes\n",
    "- Download at https://nonb-abcc.ncifcrf.gov/apps/nBMST/default/\n",
    "- Choose hg38 version: \"human_hg38.tsv.tar.gz\"\n",
    "- Save to directory \"./nonbdb/\"\n",
    "\n",
    "### Modify and annotate Non-B DB <a name=\"DB_nonbdb_modify\"></a>\n",
    "\n",
    "#### Load and format Non-B Database <a name=\"DB_nonbdb_load\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d368fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Non-B DB database file\n",
    "nonbdb = pd.read_csv('./nonbdb/human_hg38.tsv.tar.gz', sep = '\\t', low_memory = False)\n",
    "\n",
    "# Format database\n",
    "nonbdb = nonbdb.dropna(how = 'all', axis=0)\n",
    "del nonbdb['Source']; del nonbdb['Strand']\n",
    "nonbdb.columns = ['chrom', 'Type', 'start', 'end', 'length', 'Score', 'repeat', 'Spacer', 'Tracts', 'Subset', 'Composition', 'Sequence']\n",
    "# Filter to desired motifs\n",
    "nonbdb = nonbdb.loc[nonbdb['Type'].isin(['Direct_Repeat', 'Inverted_Repeat', 'Mirror_Repeat', 'Short_Tandem_Repeat', 'Z_DNA_Motif'])].copy()\n",
    "# Filter to chromosomes 1-22\n",
    "nonbdb['chrom'] = [chrom[3:] for chrom in nonbdb['chrom']]\n",
    "nonbdb = nonbdb.loc[nonbdb['chrom'].str.isnumeric()].copy()\n",
    "nonbdb['chrom'] = nonbdb['chrom'].astype(int)\n",
    "# Filter to chrom range for testing purposes\n",
    "nonbdb = nonbdb.loc[nonbdb['chrom'].isin(list(range(chr_range, 23)))].copy()\n",
    "# Change start coordinates to base-0\n",
    "nonbdb['start'] = nonbdb['start'].astype(int) -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dcee93",
   "metadata": {},
   "source": [
    "#### Add in G4 motifs from G4-seq data <a name=\"DB_nonbdb_G4\"></a>\n",
    "- Replaces G4 motifs in Non-B DB with G4 motifs from G4seq, as annotated by this study\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdfe020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file from above G4 section\n",
    "G4seq_filtered = pd.read_csv('./custom_db/G4seq_filtered_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip', usecols = ['chrom', 'start', 'end', 'score', 'status', 'Strand', 'length', 'Sequence'])\n",
    "# Format\n",
    "G4seq_filtered.columns = ['chrom', 'start', 'end', 'Score', 'status', 'Strand', 'length', 'Sequence']\n",
    "G4seq_filtered['Type'] = 'G4'\n",
    "# Filter to K+ condition\n",
    "G4seq_filtered = G4seq_filtered.loc[G4seq_filtered['status'] != 'PDS'].copy()\n",
    "del G4seq_filtered['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764bbccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine\n",
    "nonbdb = pd.concat([nonbdb, G4seq_filtered])\n",
    "# Format\n",
    "for col in ['start', 'end', 'length']:\n",
    "    nonbdb[col] = nonbdb[col].astype(int)\n",
    "for col in ['Score', 'repeat', 'Spacer']:\n",
    "    nonbdb[col] = nonbdb[col].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87df8585",
   "metadata": {},
   "source": [
    "#### Calculate proximity to other motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ab334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distance to nearest nonBdb motif\n",
    "nonbdb = distance_within_df(nonbdb, 'nonbdb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6555e8",
   "metadata": {},
   "source": [
    "#### Add in random sequences <a name=\"DB_nonbdb_random\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ebb0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random sequences without filtering for proximity to motifs or transposons\n",
    "def generate_random_coordinates_nofilter():\n",
    "    # Select random regions proportionally across all chromosomes\n",
    "    # Use reference_genome_masked_STR to find random sequences that don't overlap with STRs or transposons\n",
    "    # Target number is 500,000 across chromsomes 1-22, though many will be filtered out.\n",
    "    count_prefilter = 500000/chr_range\n",
    "    reference_portion = pd.Series([len(reference_genome[chrom]) for chrom in range(chr_range,23)], index = range(chr_range,23)) / sum([len(reference_genome[chrom]) for chrom in range(chr_range,23)])\n",
    "    num_to_sample = (reference_portion * count_prefilter).astype(int)\n",
    "\n",
    "    import random\n",
    "    random_coordinates = dict()\n",
    "    for chrom in range(chr_range,23):\n",
    "        random_coordinates[chrom] = pd.DataFrame()\n",
    "        random_coordinates[chrom]['start'] = pd.Series(random.sample(range(chr_range,len(reference_genome[chrom])), num_to_sample[chrom]))\n",
    "        random_coordinates[chrom]['end'] = random_coordinates[chrom]['start'] + 30\n",
    "        random_coordinates[chrom]['chrom'] = chrom\n",
    "    random_coordinates = pd.concat([random_coordinates[chrom] for chrom in random_coordinates])\n",
    "\n",
    "    # Remove any sequences with Ns\n",
    "    random_coordinates['Sequence'] = [reference_genome[chrom][start:end].upper() for chrom, start, end in zip(random_coordinates['chrom'], random_coordinates['start'], random_coordinates['end'])]\n",
    "    random_coordinates['count_N'] = [seq.count('N') for seq in random_coordinates['Sequence']]\n",
    "    random_coordinates = random_coordinates.loc[random_coordinates['count_N'] == 0]\n",
    "    del random_coordinates['count_N']\n",
    "    \n",
    "    random_coordinates['length'] = random_coordinates['end'] - random_coordinates['start']\n",
    "\n",
    "    return random_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b41a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sequences\n",
    "random_nofilter = generate_random_coordinates_nofilter()\n",
    "# Measure distance to NonB-DB motifs\n",
    "random_nofilter = measure_distance(random_nofilter, nonbdb, 'nonbdb')\n",
    "random_nofilter['Type'] = 'random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc288ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add random sequences to NonB-DB\n",
    "nonbdb = pd.concat([nonbdb, random_nofilter])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9b4f10",
   "metadata": {},
   "source": [
    "#### Filter database by proximity to motifs and transposons (or don't) <a name=\"DB_nonbdb_filter\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5045308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distance between motifs and transposable elements\n",
    "nonbdb = measure_distance(nonbdb, repeatmasker.loc[~repeatmasker['repClass'].isin(['Simple_repeat', 'Low_complexity'])], 'RM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb456df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save modified NonB-DB\n",
    "nonbdb.to_csv('./nonbdb/nonbdb_modified_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa21a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "nonbdb = pd.read_csv('./nonbdb/nonbdb_modified_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94012a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for transposon distance\n",
    "nonbdb_filtered = nonbdb.loc[(nonbdb['RM_distance_min'] > 500)]\n",
    "# Filter for overlaps with Non-B motifs\n",
    "nonbdb_unique = nonbdb_filtered.loc[(nonbdb_filtered['nonbdb_distance_min'] > 0)]\n",
    "# Basic filter for removing motifs with neighboring motifs\n",
    "nonbdb_distant = nonbdb_filtered.loc[(nonbdb_filtered['nonbdb_distance_min'] > 250)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07a8414",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_counts = pd.DataFrame(); repeat_counts['all'] = nonbdb['Type'].value_counts(); repeat_counts['filtered'] = nonbdb_filtered['Type'].value_counts(); repeat_counts['unique'] = nonbdb_unique['Type'].value_counts(); repeat_counts['distant'] = nonbdb_distant['Type'].value_counts()\n",
    "repeat_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e7d478",
   "metadata": {},
   "source": [
    "### Plot overlaps between Non-B DB categories <a name=\"DB_nonbdb_plot\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28be1caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_motif_types = dict()\n",
    "motif_types = ['Direct_Repeat', 'G4', 'Inverted_Repeat', 'Mirror_Repeat', 'Short_Tandem_Repeat', 'Z_DNA_Motif']\n",
    "for motif in motif_types:\n",
    "    current_motif = nonbdb.loc[nonbdb['Type'] == motif].copy()\n",
    "    current_motif['motif_overlaps'] = ''\n",
    "    for other in motif_types:\n",
    "        current_motif = measure_distance(current_motif, nonbdb.loc[nonbdb['Type'] == other], other)\n",
    "        current_motif['motif_overlaps'] = current_motif['motif_overlaps'] + [other + ' ' if pos <1 else '' for pos in current_motif[other + '_distance_min']]\n",
    "        del current_motif[other+'_distance_left']; del current_motif[other+'_distance_right']; del current_motif[other+'_distance_min']\n",
    "        print('\\r' + motif + ' ' + other, end='         ', flush = True)\n",
    "    all_motif_types[motif] = current_motif\n",
    "\n",
    "nonbdb = pd.concat(all_motif_types)\n",
    "nonbdb = nonbdb.sort_values(by = ['chrom', 'start', 'end']).reset_index(drop = True)\n",
    "\n",
    "nonbdb['motif_overlaps'] = [motifs_list[:-1] for motifs_list in nonbdb['motif_overlaps']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c649cda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before filtering\n",
    "groups_df = pd.DataFrame(index = set(nonbdb['motif_overlaps']))\n",
    "for group in all_motif_types:\n",
    "    groups_df[group] = nonbdb.loc[nonbdb['Type'] == group]['motif_overlaps'].value_counts() / len(nonbdb.loc[nonbdb['Type'] == group])\n",
    "\n",
    "# group together entries that comprise only a small percentage of the category\n",
    "groups_df_slim = pd.DataFrame(index = set(nonbdb['motif_overlaps']))\n",
    "for group in all_motif_types:\n",
    "    groups_df_slim[group] = groups_df[group].loc[groups_df[group] > 0.075]\n",
    "groups_df_slim = groups_df_slim.dropna(how = 'all').fillna(0)\n",
    "relevant_groups = list(groups_df_slim.index)\n",
    "groups_df_slim = pd.DataFrame(index = relevant_groups)\n",
    "for group in all_motif_types:\n",
    "    groups_df_slim[group] = groups_df[group].loc[relevant_groups]\n",
    "groups_df_slim = groups_df_slim.dropna(how = 'all').fillna(0)\n",
    "groups_df_slim.loc['Other multiple'] = [1- groups_df_slim[col].sum() for col in groups_df_slim.columns]\n",
    "groups_df_slim = groups_df_slim.loc[[group for group in groups_df_slim.index if len(group.split(' ')) > 1]]\n",
    "groups_df_slim.loc['Unique'] = [1- groups_df_slim[col].sum() for col in groups_df_slim.columns]\n",
    "\n",
    "groups_df_slim_names = [names.replace('Inverted_Repeat', 'IR').replace('Direct_Repeat', 'DR').replace('Mirror_Repeat', 'MR').replace('Short_Tandem_Repeat', 'STR').replace('Z_DNA_Motif', 'ZDNA') for names in groups_df_slim.index]\n",
    "groups_df_slim.index = groups_df_slim_names\n",
    "groups_df_slim = groups_df_slim.loc[list(groups_df_slim.index[-1:]) + list(groups_df_slim.index[:-1])]\n",
    "\n",
    "groups_df_slim_colnames = [names.replace('Inverted_Repeat', 'IR').replace('Direct_Repeat', 'DR').replace('Mirror_Repeat', 'MR').replace('Short_Tandem_Repeat', 'STR').replace('Z_DNA_Motif', 'ZDNA') for names in groups_df_slim.columns]\n",
    "groups_df_slim.columns = groups_df_slim_colnames\n",
    "groups_df_slim = groups_df_slim[['IR', 'G4', 'STR', 'DR', 'MR', 'ZDNA']]\n",
    "\n",
    "groups_df_slim_color = pd.Series(plotly.colors.DEFAULT_PLOTLY_COLORS[:len(groups_df_slim.index)-1] + ['rgb(220,220,220)'], index = groups_df_slim.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62a328d",
   "metadata": {},
   "source": [
    "#### Plot for Supplementary Figure S1c <a name=\"DB_nonbdb_plot_S1C\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3182c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_overlap_fig_S1c = go.Figure()\n",
    "for types in groups_df_slim.index:\n",
    "    group_overlap_fig_S1c.add_trace(go.Bar(name=types, x = groups_df_slim.columns, y = groups_df_slim.loc[types], marker = dict(color = groups_df_slim_color[types])))\n",
    "group_overlap_fig_S1c.update_layout(barmode='stack')\n",
    "\n",
    "group_overlap_fig_S1c.update_xaxes(tickfont  = dict(size = 14))\n",
    "group_overlap_fig_S1c.update_yaxes(tickfont  = dict(size = 14))\n",
    "group_overlap_fig_S1c.update_yaxes(title = dict(text = 'Portion of category', font = dict(size = 18), standoff = 0))\n",
    "group_overlap_fig_S1c.update_layout(height = 300, width = 600, margin = dict(l = 55, r = 5, b = 20, t = 20))\n",
    "\n",
    "group_overlap_fig_S1c.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4507b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_overlap_fig_S1c.write_image('./plots/revision_nonbdb_category_overlap_fig_S1c.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8f5f59",
   "metadata": {},
   "source": [
    "#### Plot for Supplementary Figure S1d <a name=\"DB_nonbdb_plot_S1D\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d366155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum distance to next Non-B DB motif, represented by percentile\n",
    "plot_values = nonbdb.drop_duplicates(subset = ['chrom', 'start', 'end'])['nonbdb_distance_min'].fillna(0).quantile([i/100 for i in range(1,99)])\n",
    "# Count all overlaps as 0\n",
    "plot_values[plot_values < 0] = 0\n",
    "# Minimum distance to next Non-B DB motif or Repeatmasker transposon, represented by percentile\n",
    "plot_values_rm = nonbdb.drop_duplicates(subset = ['chrom', 'start', 'end'])[['nonbdb_distance_min', 'RM_distance_min']].min(axis=1).fillna(0).quantile([i/100 for i in range(1,99)])\n",
    "# Count all overlaps as 0\n",
    "plot_values_rm[plot_values_rm < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb4bc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_nonbdb_fig_S1d = go.Figure()\n",
    "distance_nonbdb_fig_S1d.add_trace(go.Scatter(x = list(range(1,99)), y = plot_values, name = 'NonB', opacity = 0.75))\n",
    "distance_nonbdb_fig_S1d.add_trace(go.Scatter(x = list(range(1,99)), y = plot_values_rm, name = 'NonB and Repeatmasker', opacity = 0.75))\n",
    "distance_nonbdb_fig_S1d.update_yaxes(range = [-20, 575], tickfont = dict(size = 14), title = dict(text = 'Distance to nearest motif (nt)', font = dict(size = 16), standoff = 0))\n",
    "distance_nonbdb_fig_S1d.update_xaxes(tickfont = dict(size = 14), title = dict(text = 'Percentile', font = dict(size = 18), standoff = 0))\n",
    "distance_nonbdb_fig_S1d.update_layout(height = 300, width = 400, margin = dict(l = 55, r = 5, b = 35, t = 30), legend = dict(x = 0.05, y = 1.1, orientation = 'h', font = dict(size = 14)))\n",
    "\n",
    "distance_nonbdb_fig_S1d.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a9e831",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_nonbdb_fig_S1d.write_image('./plots/revision_nonbdb_overlap_fig_S1d.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd51d4c4",
   "metadata": {},
   "source": [
    "# Prepare gnomAD database  <a name=\"GNOMAD\"></a>\n",
    "Download from https://gnomad.broadinstitute.org/downloads\n",
    "- WARNING: files are extremely large\n",
    "- Select gnomAD V3\n",
    "- Download individual chromosome files\n",
    "- Chr22 example: https://storage.googleapis.com/gcp-public-data--gnomad/release/3.1.1/vcf/genomes/gnomad.genomes.v3.1.1.sites.chr22.vcf.bgz\n",
    "- Place in directory './gnomad/temp/'\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab23c5d",
   "metadata": {},
   "source": [
    "## Shrink gnomAD files by removing unneeded information <a name=\"GNOMAD_shrink\"></a>\n",
    "\n",
    "#### Read gnomAD file in chunks, and output each chunk to a temporary file <a name=\"GNOMAD_shrink_read\"></a>\n",
    "- This is a very slow and inefficient step, but necessary in order to use the freely available gnomAD files.\n",
    "    - ~8 hours for Chr22\n",
    "- Different chromosomes can be run in parallel, depending on CPU and RAM limitations:\n",
    "    - Copy the following notebook cell into another notebook.\n",
    "    - Replace the line \"for chrom in range(chr_range,23):\" with \"chrom = 22\" and change the chromosome number each time.\n",
    "    \n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf49415b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chrom in range(chr_range,23):\n",
    "\n",
    "    # Can lower chunk size to reduce memory usage.\n",
    "    chunk_size = 50000\n",
    "\n",
    "    download_path = ('./gnomad/temp/')\n",
    "    file_list = [file for file in os.listdir(download_path) if file.endswith('.vcf.bgz') == True]\n",
    "    pickle_list = [file for file in os.listdir(download_path) if file.endswith('chr'+str(chrom)+'.pickle') == True]\n",
    "    skip = 943\n",
    "    n = 0\n",
    "    time_start = time()\n",
    "    file = 'gnomad.genomes.v3.1.1.sites.chr'+str(chrom)+'.vcf.bgz'\n",
    "\n",
    "    reader = pd.read_csv(download_path+file, sep = '\\t', skiprows = skip, header = None, usecols = [1,3,4,6,7], compression = 'gzip', chunksize = chunk_size)\n",
    "    for chunk in reader:\n",
    "        if n >= len(pickle_list):\n",
    "            snps = pd.DataFrame(chunk)\n",
    "            snps.columns = ['POS', 'REF', 'ALT', 'FILTER', 'INFO']\n",
    "            for infotype in ['AC', 'AN', 'n_alt_alleles', 'nhomalt', 'variant_type', 'DP', 'VarDP', 'InbreedingCoeff', 'MQ', 'MQRankSum', 'ReadPosRankSum', 'QD', 'AS_VQSLOD', 'AS_FS', 'AS_MQ', 'AS_MQRankSum', 'AS_pab_max', 'AS_QD', 'AS_ReadPosRankSum', 'AS_SOR']:\n",
    "                snps[infotype] = snps['INFO'].str.split(infotype+'=', expand = True)[1].str.split(';', expand = True)[0]\n",
    "            for infotype in ['AC', 'AN', 'n_alt_alleles', 'nhomalt', 'DP', 'VarDP']:\n",
    "                snps[infotype] = snps[infotype].astype(int)\n",
    "            for infotype in ['MQ', 'QD', 'AS_VQSLOD', 'InbreedingCoeff', 'MQRankSum', 'ReadPosRankSum', 'AS_FS', 'AS_MQ', 'AS_MQRankSum', 'AS_pab_max', 'AS_QD', 'AS_ReadPosRankSum', 'AS_SOR']:\n",
    "                snps[infotype] = snps[infotype].replace('.', np.nan).astype(float)\n",
    "            snps = snps.drop(['INFO'], axis=1)\n",
    "            snps = snps.loc[(snps['AC'] > 0)]\n",
    "            n+=1\n",
    "            print('chr' + str(chrom) + '_' + str(n), end=\"\\r\", flush=True)\n",
    "            snps.to_pickle(download_path+'chunk_'+str(n)+'_chr'+str(chrom)+'.pickle')\n",
    "        else:\n",
    "            print('chr' + str(chrom) + '_skip_' + str(n), end=\"\\r\", flush=True)\n",
    "            n+=1\n",
    "\n",
    "    time_end = time()\n",
    "    print(str(chrom) + ' ' + str((time_end - time_start) / 3600) + ' hours')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3789d111",
   "metadata": {},
   "source": [
    "#### Combine chunks into one .csv.gz file per chromosome <a name=\"GNOMAD_shrink_combine\"></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6062501",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chrom in range(chr_range,23):\n",
    "    pickle_list = [file for file in os.listdir(download_path) if file.endswith('chr'+str(chrom)+'.pickle') == True]\n",
    "\n",
    "    all_variants = dict()\n",
    "    n=0\n",
    "    for pick in pickle_list:\n",
    "        n+=1\n",
    "        all_variants[n] = pd.read_pickle(download_path+pick)\n",
    "        print('chr' + str(chrom) + ' ' + str(n) + ' / '+str(len(pickle_list)) + '          ', end=\"\\r\", flush=True)\n",
    "\n",
    "    all_variants_df = pd.concat(all_variants).reset_index(drop = True)\n",
    "    all_variants_df = all_variants_df.drop_duplicates(keep = 'first')\n",
    "\n",
    "    all_variants_df.to_csv('./gnomad/all_variants_chr'+str(chrom)+'.csv.gz', index = False, compression = 'gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867b2d2b",
   "metadata": {},
   "source": [
    "#### Filter to rare SNVs and format files for mutation counting <a name=\"GNOMAD_rare\"></a>\n",
    "- also calculate genome GC correction factors at the same time (for efficiency)\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046c96d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slim_gnomad_files_gc_content(chrom):\n",
    "    gnomad_current = pd.read_csv('./gnomad/all_variants_chr'+str(chrom)+'.csv.gz', compression = 'gzip', usecols = ['POS', 'REF', 'ALT', 'AC', 'AN', 'AS_VQSLOD', 'InbreedingCoeff'])\n",
    "    print('processing chr' + str(chrom) + '      ', end=\"\\r\", flush=True)\n",
    "\n",
    "    # Select only rare variants\n",
    "    gnomad_current = gnomad_current.loc[gnomad_current['AC'] / gnomad_current['AN'] <  10**-4].copy()\n",
    "\n",
    "    # SNVs only\n",
    "    gnomad_current['ref_len'] = [len(ref) for ref in gnomad_current['REF']]\n",
    "    gnomad_current['alt_len'] = [len(alt) for alt in gnomad_current['ALT']]\n",
    "    gnomad_current = gnomad_current.loc[(gnomad_current['ref_len'] == 1) & (gnomad_current['alt_len'] == 1)].copy()\n",
    "    del gnomad_current['ref_len']; del gnomad_current['alt_len']\n",
    "\n",
    "    # One line per position, keeping AC and AS_VQSLOD quality scores per mutation type\n",
    "    gnomad_byalt = dict()\n",
    "    for alt in ['A', 'T', 'G', 'C']:\n",
    "        gnomad_byalt[alt] = gnomad_current.loc[gnomad_current['ALT'] == alt].copy()\n",
    "    gnomad_slim = pd.concat([gnomad_byalt[alt][['POS', 'AC']].set_index('POS') for alt in ['A', 'T', 'G', 'C']], axis=1).fillna(0).astype(int)\n",
    "    gnomad_slim.columns = ['A', 'T', 'G', 'C']\n",
    "    gnomad_slim = gnomad_slim.sort_index()\n",
    "    gnomad_slim['Tri'] = [tri_function(chrom,pos) for pos in gnomad_slim.index]\n",
    "    for alt in ['A', 'T', 'G', 'C']:\n",
    "        gnomad_slim['qual_'+alt] = gnomad_byalt[alt][['POS', 'AS_VQSLOD']].set_index('POS')\n",
    "        gnomad_slim['inbr_'+alt] = gnomad_byalt[alt][['POS', 'InbreedingCoeff']].set_index('POS')\n",
    "        \n",
    "    # Calculate GC content +/- 51nt for each SNV position\n",
    "    nmer = 51\n",
    "    current_gc = pd.DataFrame(list(reference_genome[chrom]), columns = ['seq'])\n",
    "    current_gc['GC'] = current_gc['seq'].isin(['G', 'C'])\n",
    "    current_gc['N'] = current_gc['seq'] == 'N'\n",
    "    current_gc['GC_'+str(nmer)] = current_gc['GC'].rolling(nmer, center = True).mean()\n",
    "    current_gc['N_'+str(nmer)] = current_gc['N'].rolling(nmer, center = True).mean()\n",
    "    chrom_nucleotide_content = pd.DataFrame(current_gc.loc[current_gc['N_'+str(nmer)] == False]['GC_'+str(nmer)]).round(3)\n",
    "    chrom_nucleotide_content.index = chrom_nucleotide_content.index +1\n",
    "    gnomad_slim['GC_'+str(nmer)] = chrom_nucleotide_content['GC_'+str(nmer)].reindex(gnomad_slim.index)\n",
    "    chrom_nucleotide_content['Tri'] = [tri_function(chrom, pos) for pos in chrom_nucleotide_content.index]\n",
    "    chrom_nucleotide_content['count'] = 1\n",
    "    \n",
    "    print('saving chr' + str(chrom) + '        ', end=\"\\r\", flush=True)\n",
    "    gnomad_slim.to_csv('./gnomad/gnomad_chr'+str(chrom)+'_lowN_AC-tri-qual.csv.gz', compression = 'gzip')\n",
    "    print('finished chr' + str(chrom) + '      ', end=\"\\r\", flush=True)\n",
    "\n",
    "    return triplet_combine_RC(chrom_nucleotide_content.groupby(['GC_'+str(nmer), 'Tri']).count()['count'].unstack().transpose(), mut_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d778b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_nucleotide_count = dict()\n",
    "for chrom in range(chr_range, 23):\n",
    "    genome_nucleotide_count[chrom] = slim_gnomad_files_gc_content(chrom)\n",
    "    print('finished chr' + str(chrom) + '      ', end=\"\\r\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589f8647",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_nucleotide_count_all = pd.concat(genome_nucleotide_count).groupby(pd.concat(genome_nucleotide_count).index.get_level_values(1)).sum().astype(int)\n",
    "combined_nucleotide_count = triplet_combine_RC(genome_nucleotide_count_all, mut_input=True).astype(int)\n",
    "combined_nucleotide_count.to_csv('./hg38/hg38_triplet_counts_by_GCwindow_nmer51_chr'+str(chr_range)+'-22.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ce4841",
   "metadata": {},
   "source": [
    "### Load gnomAD SNV database and calculate trinucleotide mutation frequency <a name=\"GNOMAD_freq\"></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc9d8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SNV database\n",
    "gnomad_slim_all = dict()\n",
    "for chrom in range(chr_range, 23):\n",
    "    gnomad_slim_all[chrom] = pd.read_csv('./gnomad/gnomad_chr'+str(chrom)+'_lowN_AC-tri-qual.csv.gz', compression = 'gzip')\n",
    "    gnomad_slim_all[chrom].set_index('POS', inplace = True)\n",
    "    print('loaded chr' + str(chrom) + '      ', end=\"\\r\", flush=True)\n",
    "\n",
    "combined_nucleotide_count = pd.read_csv('./hg38/hg38_triplet_counts_by_GCwindow_nmer51_chr'+str(chr_range)+'-22.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a909263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of genomes in the the gnomAD 3.1 database\n",
    "gnomad_n_genomes = 76156\n",
    "\n",
    "# List of VQSLOD and InbreedingCoefficient values to use as QC filters\n",
    "#(the first set of values is for no filtration, and the second set corresponds to gnomAD's recommended passing score)\n",
    "qc_cutoff_list = [(-np.inf, -np.inf), (-2.774, -0.3), (0, -0.3), (4, -0.3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b31fdb6",
   "metadata": {},
   "source": [
    "#### Generate downsampled gnomAD files based on AC  <a name=\"GNOMAD_downsample_generate\"></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5ed5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_gnomad_files(chrom):\n",
    "\n",
    "    gnomad_current = pd.read_csv('./gnomad/all_variants_chr'+str(chrom)+'.csv.gz', compression = 'gzip', usecols = ['POS', 'REF', 'ALT', 'AC', 'AN', 'AS_VQSLOD', 'InbreedingCoeff'])\n",
    "    print('loaded chr' + str(chrom) + '    ', end=\"\\r\", flush=True)\n",
    "\n",
    "    # Select only rare variants\n",
    "    gnomad_current = gnomad_current.loc[gnomad_current['AC'] / gnomad_current['AN'] <  10**-4].copy()\n",
    "\n",
    "    # SNVs only\n",
    "    gnomad_current['ref_len'] = [len(ref) for ref in gnomad_current['REF']]\n",
    "    gnomad_current['alt_len'] = [len(alt) for alt in gnomad_current['ALT']]\n",
    "    gnomad_current = gnomad_current.loc[(gnomad_current['ref_len'] == 1) & (gnomad_current['alt_len'] == 1)].copy()\n",
    "    del gnomad_current['ref_len']; del gnomad_current['alt_len']\n",
    "\n",
    "    # How much to downsample:\n",
    "    for sample_frac in [0.1, 0.01, 0.004]:\n",
    "\n",
    "        # Random downsampling\n",
    "        current_sample = dict()\n",
    "        for AC in gnomad_current['AC'].value_counts().index:\n",
    "            current_sample[AC] = gnomad_current.loc[gnomad_current['AC'] == AC].sample(frac = min(sample_frac * AC, 1), random_state = 0)\n",
    "        current_sample = pd.concat(current_sample).reset_index(drop = True)\n",
    "\n",
    "        # One line per position, keeping AC and AS_VQSLOD quality scores per mutation type\n",
    "        gnomad_byalt = dict()\n",
    "        for alt in ['A', 'T', 'G', 'C']:\n",
    "            gnomad_byalt[alt] = current_sample.loc[current_sample['ALT'] == alt].copy()\n",
    "        gnomad_slim = pd.concat([gnomad_byalt[alt][['POS', 'AC']].set_index('POS') for alt in ['A', 'T', 'G', 'C']], axis=1).fillna(0).astype(int)\n",
    "        gnomad_slim.columns = ['A', 'T', 'G', 'C']\n",
    "        gnomad_slim = gnomad_slim.sort_index()\n",
    "        gnomad_slim['Tri'] = [tri_function(chrom,pos) for pos in gnomad_slim.index]\n",
    "        for alt in ['A', 'T', 'G', 'C']:\n",
    "            gnomad_slim['qual_'+alt] = gnomad_byalt[alt][['POS', 'AS_VQSLOD']].set_index('POS')\n",
    "            gnomad_slim['inbr_'+alt] = gnomad_byalt[alt][['POS', 'InbreedingCoeff']].set_index('POS')\n",
    "\n",
    "        nmer = 51\n",
    "        current_gc = pd.DataFrame(list(reference_genome[chrom]), columns = ['seq'])\n",
    "        current_gc['GC'] = current_gc['seq'].isin(['G', 'C'])\n",
    "        current_gc['N'] = current_gc['seq'] == 'N'\n",
    "        current_gc['GC_'+str(nmer)] = current_gc['GC'].rolling(nmer, center = True).mean()\n",
    "        current_gc['N_'+str(nmer)] = current_gc['N'].rolling(nmer, center = True).mean()\n",
    "        chrom_nucleotide_content = pd.DataFrame(current_gc.loc[current_gc['N_'+str(nmer)] == False]['GC_'+str(nmer)]).round(3)\n",
    "        chrom_nucleotide_content.index = chrom_nucleotide_content.index +1\n",
    "        gnomad_slim['GC_'+str(nmer)] = chrom_nucleotide_content['GC_'+str(nmer)].reindex(gnomad_slim.index)\n",
    "        chrom_nucleotide_content['Tri'] = [tri_function(chrom, pos) for pos in chrom_nucleotide_content.index]\n",
    "        chrom_nucleotide_content['count'] = 1\n",
    "            \n",
    "            \n",
    "        print('saving chr' + str(chrom) + 'sample_frac ' + str(sample_frac) + '        ', end=\"\\r\", flush=True)\n",
    "        gnomad_slim.to_csv('./gnomad/gnomad31_slim_downsample_'+str(sample_frac)+'_chr'+str(chrom)+'_AC-tri-qual.csv.gz', compression = 'gzip')\n",
    "          \n",
    "    print('finished chr' + str(chrom) + '    ', end=\"\\r\", flush=True)\n",
    "\n",
    "for chrom in range(chr_range, 23):\n",
    "    downsample_gnomad_files(chrom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f681f0",
   "metadata": {},
   "source": [
    "#### Correct allele count to better reflect number of independent mutations <a name=\"GNOMAD_AC_correction\"></a>\n",
    "- AC > 1 can reflect either shared ancestry or independent mutations\n",
    "- Correction here is simplified version of procedure detailed in Seplyarskiy et al, 2021, Science. (See Supplemental Methods)\n",
    "- Numbers included here reflect model using sample size of 75,000 and u of 1x10-7 (~50x higher than the background mutation rate)\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f65a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "AC_correction = pd.Series([0, 1, 1.426543, 1.608968, 1.698695, 1.749019, 1.779155, 1.797395, 1.808054, 1.813768, 1.816325, 1.816938, 1.816359, 1.815024, 1.813194, 1.811021, 1.808583], index = list(range(17)))\n",
    "\n",
    "for chrom in range(chr_range,23):\n",
    "    for base in ['A', 'T', 'G', 'C']:\n",
    "        gnomad_slim_all[chrom][base] = AC_correction.reindex(gnomad_slim_all[chrom][base]).set_axis(gnomad_slim_all[chrom].index)\n",
    "    print('finished chr' + str(chrom) + '      ', end=\"\\r\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f52753",
   "metadata": {},
   "source": [
    "#### Count total mutations in gnomAD database, using allele count <a name=\"GNOMAD_freq_AC\"></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c379fa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate counts\n",
    "genome_AC_totals = dict()\n",
    "for qc_cutoff in qc_cutoff_list:\n",
    "    genome_AC_totals[qc_cutoff[0]] = dict()\n",
    "    for chrom in range(chr_range,23):\n",
    "        genome_AC_totals[qc_cutoff[0]][chrom] = (gnomad_slim_all[chrom].set_index('Tri')[['A', 'T', 'G', 'C']]).mul((gnomad_slim_all[chrom][['qual_A', 'qual_T', 'qual_G', 'qual_C']] > qc_cutoff[0]).astype(int).values, axis=0).mul((gnomad_slim_all[chrom][['inbr_A', 'inbr_T', 'inbr_G', 'inbr_C']] > qc_cutoff[1]).astype(int).values, axis=0).reset_index().groupby(['Tri']).sum().reset_index()\n",
    "        print('finished qc' + str(qc_cutoff[0]) + ' chr' + str(chrom) + '         ', end=\"\\r\", flush=True)\n",
    "    genome_AC_totals[qc_cutoff[0]] = pd.concat(genome_AC_totals[qc_cutoff[0]]).groupby(['Tri']).sum()\n",
    "    print('finished qc' + str(qc_cutoff[0]) + '             ', end=\"\\r\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb70d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format counts\n",
    "genome_AC_totals_format = dict()\n",
    "for qc_cutoff in qc_cutoff_list:\n",
    "    genome_AC_totals_format[qc_cutoff[0]] = genome_AC_totals[qc_cutoff[0]].reindex(all_triplets).stack()\n",
    "    genome_AC_totals_format[qc_cutoff[0]].index = [tri+'_'+mut for tri, mut in zip(genome_AC_totals_format[qc_cutoff[0]].index.get_level_values(0), genome_AC_totals_format[qc_cutoff[0]].index.get_level_values(1))]\n",
    "    genome_AC_totals_format[qc_cutoff[0]] = genome_AC_totals_format[qc_cutoff[0]].reindex(triplet_mutations_und)\n",
    "genome_AC_totals_format = pd.concat(genome_AC_totals_format, axis=1)\n",
    "genome_AC_totals_RC = triplet_combine_RC(genome_AC_totals_format, mut_input = True)\n",
    "\n",
    "# Save\n",
    "genome_AC_totals_RC.to_csv('./gnomad/gnomad31_triplet_ACcorrected_counts_chr'+str(chr_range)+'-22.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fbf656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "genome_AC_totals_RC = pd.read_csv('./gnomad/gnomad31_triplet_ACcorrected_counts_chr'+str(chr_range)+'-22.csv', index_col = 0)\n",
    "genome_AC_totals_RC.columns = [qc_cutoff[0] for qc_cutoff in qc_cutoff_list]\n",
    "genome_triplet_totals = pd.read_csv('./hg38/triplet_totals_hg38_chr'+str(chr_range)+'-22.csv', index_col = 0)\n",
    "\n",
    "# Calculate frequency\n",
    "triplet_totals_RC_mut = triplet_combine_RC(genome_triplet_totals['hg38'], mut_output = True)\n",
    "genome_AC_freq_RC = genome_AC_totals_RC.div(triplet_totals_RC_mut, axis=0)\n",
    "genome_AC_freq_all = triplet_combine_RC(genome_AC_freq_RC, mut_input=True, decombine=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017f50b7",
   "metadata": {},
   "source": [
    "#### Ts/Tv ratio <a name=\"GNOMAD_freq_tstv\"></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c564e732",
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_mutations_und_Ts = [base1+base2+base3+'_'+mutbase for base1 in ['A', 'T', 'G', 'C'] for base2 in ['T', 'C'] for base3 in ['A', 'T', 'G', 'C'] for mutbase in ['T', 'C'] if mutbase != base2]\n",
    "triplet_mutations_und_Tv = [mut for mut in triplet_mutations_und_TC if mut not in triplet_mutations_und_Ts]\n",
    "\n",
    "ts_tv = pd.DataFrame()\n",
    "ts_tv['AC'] = pd.Series([genome_AC_totals_RC[qc_cutoff[0]].loc[triplet_mutations_und_Ts].sum() / genome_AC_totals_RC[qc_cutoff[0]].loc[triplet_mutations_und_Tv].sum() for qc_cutoff in qc_cutoff_list], index = [qc_cutoff[0] for qc_cutoff in qc_cutoff_list])\n",
    "ts_tv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496c2bf4",
   "metadata": {},
   "source": [
    "### Genome nucleotide content (GC%) correction <a name=\"GNOMAD_GC_correction\"></a>\n",
    "- generate mutation rate correction factor based on GC%\n",
    "\n",
    "#### Calculate GC content along the genome with a rolling window\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2be508",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_mut_gc = dict()\n",
    "nmer = 51\n",
    "for qc_cutoff in qc_cutoff_list:\n",
    "    current_mut_gc[qc_cutoff[0]] = dict()\n",
    "    for chrom in range(chr_range,23):\n",
    "        current_mut_gc[qc_cutoff[0]][chrom] = pd.concat([gnomad_slim_all[chrom][['Tri', 'GC_'+str(nmer)]], (gnomad_slim_all[chrom][['A', 'T', 'G', 'C']]).mul((gnomad_slim_all[chrom][['qual_A', 'qual_T', 'qual_G', 'qual_C']] > qc_cutoff[0]).astype(int).values, axis=0).mul((gnomad_slim_all[chrom][['inbr_A', 'inbr_T', 'inbr_G', 'inbr_C']] > qc_cutoff[1]).astype(int).values, axis=0)], axis=1).groupby(['GC_'+str(nmer), 'Tri']).sum()\n",
    "        print('\\r' + str(chrom), end='        ')\n",
    "    current_mut_gc[qc_cutoff[0]] = pd.concat(current_mut_gc[qc_cutoff[0]])\n",
    "    current_mut_gc[qc_cutoff[0]] = current_mut_gc[qc_cutoff[0]].groupby(['GC_'+str(nmer), 'Tri']).sum().unstack().transpose()\n",
    "    current_mut_gc[qc_cutoff[0]].index = current_mut_gc[qc_cutoff[0]].index.get_level_values('Tri') + '_' + current_mut_gc[qc_cutoff[0]].index.get_level_values(0)\n",
    "    current_mut_gc[qc_cutoff[0]] = triplet_combine_RC(current_mut_gc[qc_cutoff[0]], mut_input=True).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942d80d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_mut_gc = pd.concat(current_mut_gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0122ec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_mut_gc.to_csv('./gnomad/mut_counts_ACcorrected_by_GCwindow_nmer51_chr'+str(chr_range)+'-22.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2549eb8f",
   "metadata": {},
   "source": [
    "#### Load output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b38cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_nucleotide_count = pd.read_csv('./hg38/hg38_triplet_counts_by_GCwindow_nmer51_chr'+str(chr_range)+'-22.csv', index_col = 0)\n",
    "current_mut_gc = pd.read_csv('./gnomad/mut_counts_ACcorrected_by_GCwindow_nmer51_chr'+str(chr_range)+'-22.csv', index_col = [0,1])\n",
    "combined_nucleotide_count.columns = combined_nucleotide_count.columns.astype(float)\n",
    "current_mut_gc.columns = current_mut_gc.columns.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dccdcd",
   "metadata": {},
   "source": [
    "#### Calculate correction factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275a4b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_freq_gc = dict(); current_norm_gc = dict()\n",
    "for qc_cutoff in qc_cutoff_list:\n",
    "    current_freq_gc[qc_cutoff[0]] = current_mut_gc.loc[qc_cutoff[0]].dropna(how = 'all', axis=1).div(combined_nucleotide_count.dropna(how = 'all', axis=1), axis=0)\n",
    "    current_norm_gc[qc_cutoff[0]] = current_freq_gc[qc_cutoff[0]].div(genome_AC_freq_RC[qc_cutoff[0]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d7bd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_correction_bytri = dict()\n",
    "for qc_cutoff in qc_cutoff_list:\n",
    "    gc_correction_bytri[qc_cutoff[0]] = triplet_combine_RC(current_norm_gc[qc_cutoff[0]], mut_input = True, decombine = True).rolling(max(3, round(len(current_norm_gc[qc_cutoff[0]].columns)/10)), center = True, min_periods = 1, axis=1).mean().sort_index(axis=1).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8413c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_correction_bymut = dict()\n",
    "for qc_cutoff in qc_cutoff_list:\n",
    "    gc_correction_bymut[qc_cutoff[0]] = dict()\n",
    "    for mut in triplets_by_mut.index:\n",
    "        gc_correction_bymut[qc_cutoff[0]][mut] = pd.Series(np.ma.average(np.ma.MaskedArray(gc_correction_bytri[qc_cutoff[0]].transpose().loc[triplets_by_mut[mut]], mask=np.isnan(gc_correction_bytri[-np.inf].transpose().loc[triplets_by_mut[mut]])), weights=current_mut_gc.loc[qc_cutoff[0]].loc[triplets_by_mut[mut]].reindex(gc_correction_bytri[qc_cutoff[0]].index, axis=1), axis=0), index = gc_correction_bytri[qc_cutoff[0]].index)\n",
    "    gc_correction_bymut[qc_cutoff[0]] = pd.concat(gc_correction_bymut[qc_cutoff[0]], axis=1).interpolate(axis=0, limit_direction = 'both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caa89b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_correction_bymut_all = dict()\n",
    "for qc_cutoff in qc_cutoff_list:\n",
    "    gc_correction_bymut_all[qc_cutoff[0]] = dict()\n",
    "    for mut in triplets_by_mut.index:\n",
    "        gc_correction_bymut_all[qc_cutoff[0]][mut] = gc_correction_bymut[qc_cutoff[0]][[mut]*len(triplets_by_mut[mut])]\n",
    "        gc_correction_bymut_all[qc_cutoff[0]][mut].columns = triplets_by_mut[mut]\n",
    "    gc_correction_bymut_all[qc_cutoff[0]] = pd.concat(gc_correction_bymut_all[qc_cutoff[0]], axis=1)\n",
    "    gc_correction_bymut_all[qc_cutoff[0]].columns = gc_correction_bymut_all[qc_cutoff[0]].columns.get_level_values(1)\n",
    "    gc_correction_bymut_all[qc_cutoff[0]] = triplet_combine_RC(gc_correction_bymut_all[qc_cutoff[0]].transpose(), mut_input=True, decombine=True).transpose()\n",
    "    gc_correction_bymut_all[qc_cutoff[0]].index.name = 'GC_51'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3552d4",
   "metadata": {},
   "source": [
    "#### Plot correction factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ffba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_gc_figS8a = make_subplots(rows = 2, cols = 2, subplot_titles = ['no QC', 'pass', 'VQSLOD > 0', 'VQSLOD > 4'], shared_yaxes=True, shared_xaxes = True, vertical_spacing = 0.1, horizontal_spacing = 0.05)\n",
    "\n",
    "for qc_cutoff, rowval, colval in zip (qc_cutoff_list, [1,1,2,2], [1,2,1,2]):\n",
    "    for mut in triplets_by_mut.index:\n",
    "        if mut != 'CpG_T':\n",
    "            genome_gc_figS8a.add_trace(go.Scattergl(x = gc_correction_bymut[qc_cutoff[0]].index, y = gc_correction_bymut[qc_cutoff[0]][mut], name = mut, legendgroup = mut, showlegend = False if max(rowval, colval) > 1 else True, opacity = 0.7, line = dict(width = 5), marker = dict(color = colors['color'][mut])), row = rowval, col = colval)\n",
    "        else:\n",
    "            genome_gc_figS8a.add_trace(go.Scattergl(x = gc_correction_bymut[qc_cutoff[0]].index, y = gc_correction_bymut[qc_cutoff[0]][mut], name = mut, legendgroup = mut + 'CpG',  showlegend = False if max(rowval, colval) > 1 else True, opacity = 0.7, line = dict(dash = 'dash', width = 5), marker = dict(color = colors['color']['C_T'])), row = rowval, col = colval)\n",
    "\n",
    "    for group in colors.index:\n",
    "        for triplet in colors['ind'][group]:\n",
    "            if triplet[1:3] != 'CG':\n",
    "                genome_gc_figS8a.add_trace(go.Scattergl(x = gc_correction_bytri[qc_cutoff[0]].index, y = gc_correction_bytri[qc_cutoff[0]][triplet].replace(0, np.nan), name = triplet, legendgroup = group, showlegend = False, opacity = 0.1, marker = dict(color = colors['color'][group])), row = rowval, col = colval)\n",
    "            else:\n",
    "                genome_gc_figS8a.add_trace(go.Scattergl(x = gc_correction_bytri[qc_cutoff[0]].index, y = gc_correction_bytri[qc_cutoff[0]][triplet].replace(0, np.nan), name = triplet, legendgroup = group + 'CpG', showlegend = False, opacity = 0.1, line = dict(dash = 'dash'), marker = dict(color = colors['color'][group])), row = rowval, col = colval)\n",
    "            \n",
    "            \n",
    "genome_gc_figS8a.add_annotation(text = 'correction factor', showarrow = False, textangle = 270, yref = 'paper', y = 0.5, xref = 'paper', x = -0.075, font = dict(size = 18))\n",
    "genome_gc_figS8a.add_annotation(text = 'GC %', showarrow = False, yref = 'paper', y = -0.1, xref = 'paper', x = 0.5, font = dict(size = 18))\n",
    "            \n",
    "genome_gc_figS8a.update_yaxes(range = [-0.5,16.5])\n",
    "genome_gc_figS8a.update_layout(height = 500, width = 800, margin = dict(l = 55, r = 5, b = 50, t = 30), legend = dict(font = dict(size = 14)))\n",
    "\n",
    "genome_gc_figS8a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09555491",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_gc_figS8a.write_image('./plots/revision_gc_correction_fig_S8a.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adc90c7",
   "metadata": {},
   "source": [
    "### Downsampling gnomAD files <a name=\"GNOMAD_downsample\"></a>\n",
    "- downsampling adjusted for allele count\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf8f5de",
   "metadata": {},
   "source": [
    "#### Load downsampled gnomAD SNV database and calculate trinucleotide mutation frequency <a name=\"GNOMAD_freq\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae06311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SNV database\n",
    "gnomad_slim_downsample = dict()\n",
    "for sample_frac in [0.1, 0.01, 0.004]:\n",
    "    gnomad_slim_downsample[sample_frac] = dict()\n",
    "    for chrom in range(chr_range, 23):\n",
    "        gnomad_slim_downsample[sample_frac][chrom] = pd.read_csv('./gnomad/gnomad31_slim_downsample_'+str(sample_frac)+'_chr'+str(chrom)+'_AC-tri-qual.csv.gz', compression = 'gzip')\n",
    "        gnomad_slim_downsample[sample_frac][chrom].set_index('POS', inplace = True)\n",
    "        print('loaded chr' + str(chrom) + '      ', end=\"\\r\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51b095c",
   "metadata": {},
   "source": [
    "#### Correct allele count to better reflect number of independent mutations <a name=\"GNOMAD_downsample_AC_correction\"></a>\n",
    "- Numbers included here reflect model using sample size of 7,500 or 1,000 and u of 1x10-7 (~50x higher than the background mutation rate)\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef2893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "AC_correction_downsample = dict()\n",
    "AC_correction_downsample[0.1] = pd.Series([0, 1, 1.222990, 1.244288, 1.235160, 1.225334, 1.218234, 1.213315, 1.209864, 1.207440, 1.205780, 1.204691, 1.203996, 1.203544, 1.203226, 1.202975, 1.202767], index = list(range(17)))\n",
    "AC_correction_downsample[0.01] = pd.Series([0, 1, 1.076811, 1.068972, 1.067307, 1.067242, 1.067137, 1.066722, 1.066099, 1.065402, 1.064703, 1.064018, 1.063345, 1.062688, 1.062059, 1.061476, 1.060957], index = list(range(17)))\n",
    "AC_correction_downsample[0.004] = pd.Series([0, 1, 1.076811, 1.068972, 1.067307, 1.067242, 1.067137, 1.066722, 1.066099, 1.065402, 1.064703, 1.064018, 1.063345, 1.062688, 1.062059, 1.061476, 1.060957], index = list(range(17)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03046189",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_frac in [0.1, 0.01, 0.004]:\n",
    "    for chrom in range(chr_range,23):\n",
    "        for base in ['A', 'T', 'G', 'C']:\n",
    "            gnomad_slim_downsample[sample_frac][chrom][base] = AC_correction_downsample[sample_frac].reindex(gnomad_slim_all[chrom][base]).set_axis(gnomad_slim_all[chrom].index)\n",
    "        print('finished chr' + str(chrom) + '      ', end=\"\\r\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536e7244",
   "metadata": {},
   "source": [
    "#### Count total mutations in downsampled gnomAD database, using allele count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baa2f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate counts\n",
    "genome_AC_totals_downsample = dict()\n",
    "genome_AC_totals_downsample_format = dict()\n",
    "genome_AC_totals_RC_downsample = dict()\n",
    "\n",
    "for sample_frac in [0.1, 0.01, 0.004]:\n",
    "    genome_AC_totals_downsample[sample_frac] = dict()\n",
    "    for qc_cutoff in qc_cutoff_list:\n",
    "        genome_AC_totals_downsample[sample_frac][qc_cutoff[0]] = dict()\n",
    "        for chrom in range(chr_range,23):\n",
    "            genome_AC_totals_downsample[sample_frac][qc_cutoff[0]][chrom] = (gnomad_slim_downsample[sample_frac][chrom].set_index('Tri')[['A', 'T', 'G', 'C']]).mul((gnomad_slim_downsample[sample_frac][chrom][['qual_A', 'qual_T', 'qual_G', 'qual_C']] > qc_cutoff[0]).astype(int).values, axis=0).mul((gnomad_slim_downsample[sample_frac][chrom][['inbr_A', 'inbr_T', 'inbr_G', 'inbr_C']] > qc_cutoff[1]).astype(int).values, axis=0).reset_index().groupby(['Tri']).sum().reset_index()\n",
    "            print('finished qc' + str(qc_cutoff[0]) + ' chr' + str(chrom) + '         ', end=\"\\r\", flush=True)\n",
    "        genome_AC_totals_downsample[sample_frac][qc_cutoff[0]] = pd.concat(genome_AC_totals_downsample[sample_frac][qc_cutoff[0]]).groupby(['Tri']).sum()\n",
    "        print('finished qc' + str(qc_cutoff[0]) + '             ', end=\"\\r\", flush=True)\n",
    "\n",
    "    # Format counts\n",
    "    genome_AC_totals_downsample_format[sample_frac] = dict()\n",
    "    for qc_cutoff in qc_cutoff_list:\n",
    "        genome_AC_totals_downsample_format[sample_frac][qc_cutoff[0]] = genome_AC_totals_downsample[sample_frac][qc_cutoff[0]].reindex(all_triplets).stack()\n",
    "        genome_AC_totals_downsample_format[sample_frac][qc_cutoff[0]].index = [tri+'_'+mut for tri, mut in zip(genome_AC_totals_downsample_format[sample_frac][qc_cutoff[0]].index.get_level_values(0), genome_AC_totals_downsample_format[sample_frac][qc_cutoff[0]].index.get_level_values(1))]\n",
    "        genome_AC_totals_downsample_format[sample_frac][qc_cutoff[0]] = genome_AC_totals_downsample_format[sample_frac][qc_cutoff[0]].reindex(triplet_mutations_und)\n",
    "    genome_AC_totals_downsample_format[sample_frac] = pd.concat(genome_AC_totals_downsample_format[sample_frac], axis=1)\n",
    "    genome_AC_totals_RC_downsample[sample_frac] = triplet_combine_RC(genome_AC_totals_downsample_format[sample_frac], mut_input = True)\n",
    "\n",
    "    # Save\n",
    "    genome_AC_totals_RC_downsample[sample_frac].to_csv('./gnomad/gnomad31_triplet_ACcorrected_counts_downsample_'+str(sample_frac)+'_chr'+str(chr_range)+'-22.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e602d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and calculate frequency\n",
    "genome_AC_totals_RC_downsample = dict()\n",
    "genome_AC_freq_RC_downsample = dict()\n",
    "genome_AC_freq_all_downsample = dict()\n",
    "for sample_frac in [0.1, 0.01, 0.004]:\n",
    "    genome_AC_totals_RC_downsample[sample_frac] = pd.read_csv('./gnomad/gnomad31_triplet_ACcorrected_counts_downsample_'+str(sample_frac)+'_chr'+str(chr_range)+'-22.csv', index_col = 0)\n",
    "    genome_AC_totals_RC_downsample[sample_frac].columns = [qc_cutoff[0] for qc_cutoff in qc_cutoff_list]\n",
    "    genome_AC_freq_RC_downsample[sample_frac] = genome_AC_totals_RC_downsample[sample_frac].div(triplet_totals_RC_mut, axis=0)\n",
    "    genome_AC_freq_all_downsample[sample_frac] = triplet_combine_RC(genome_AC_freq_RC_downsample[sample_frac], mut_input=True, decombine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51445701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ts/Tv ratio\n",
    "ts_tv_downsample = pd.DataFrame()\n",
    "for sample_frac in [0.1, 0.01, 0.004]:\n",
    "    ts_tv_downsample[sample_frac] = pd.Series(genome_AC_totals_RC_downsample[sample_frac].loc[triplet_mutations_und_Ts].sum().div(genome_AC_totals_RC_downsample[sample_frac].loc[triplet_mutations_und_Tv].sum()))\n",
    "ts_tv_downsample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db3c060",
   "metadata": {},
   "source": [
    "## GNOMAD indels <a name=\"GNOMAD_indels\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)\n",
    "\n",
    "#### Evaluate QC scores in GNOMAD indels, compared to SNVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba04d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants_chrom = pd.read_csv('./gnomad/all_variants_chr1.csv.gz', compression = 'gzip', usecols = ['FILTER', 'POS', 'REF', 'ALT', 'AC', 'AN', 'InbreedingCoeff', 'AS_VQSLOD'])\n",
    "variants_rare = variants_chrom.loc[(variants_chrom['AN'] > variants_chrom['AN'].quantile(0.1)) & (variants_chrom['AC'] / variants_chrom['AN'] < 10**-4)].copy()\n",
    "variants_indel = variants_rare.loc[(variants_rare['REF'].str.len() > 1) | (variants_rare['ALT'].str.len() > 1)].copy()\n",
    "variants_snv = variants_rare.loc[(variants_rare['REF'].str.len() == 1) & (variants_rare['ALT'].str.len() == 1)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15f5832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inbreeding coefficient cutoff of -0.3 is already in effect\n",
    "variants_chrom.loc[variants_chrom['FILTER'] == 'AS_VQSR']['InbreedingCoeff'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07199f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AS_VSLOD cutoff for SNVs is -2.774, while for indels it is -1.0607\n",
    "variants_snv.loc[variants_snv['FILTER'] == 'AS_VQSR']['AS_VQSLOD'].max(), variants_indel.loc[variants_indel['FILTER'] == 'AS_VQSR']['AS_VQSLOD'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b747cbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AS_VQSLOD cutoff of 0 for SNVs is approximately equivalent for indels\n",
    "variants_snv['AS_VQSLOD'].quantile(0.13355), variants_indel['AS_VQSLOD'].quantile(0.13355)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251f98ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AS_VQSLOD cutoff of 4 for SNVs is approximately equivalent to 1.4 for indels\n",
    "variants_snv['AS_VQSLOD'].quantile(0.348), variants_indel['AS_VQSLOD'].quantile(0.348)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea99c5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex mutations are not included...\n",
    "variants_indel.loc[(variants_indel['REF'].str.len() > 1) & (variants_indel['ALT'].str.len() > 1)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f19b6b",
   "metadata": {},
   "source": [
    "#### Generate indel database <a name=\"GNOMAD_indels_makedb\"></a>\n",
    "- Load GNOMAD files, select indels\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3544fa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chrom in range(chr_range,23):\n",
    "    # load GNOMAD file\n",
    "    variants_chrom = pd.read_csv('./gnomad/all_variants_chr' + str(chrom) + '.csv.gz', compression = 'gzip', usecols = ['POS', 'REF', 'ALT', 'AC', 'AN', 'AS_VQSLOD'])\n",
    "    # select variants with a frequency of 10^-4\n",
    "    variants_rare = variants_chrom.loc[(variants_chrom['AN'] > variants_chrom['AN'].quantile(0.1)) & (variants_chrom['AC'] / variants_chrom['AN'] < 10**-4)].copy()\n",
    "    # select indels\n",
    "    variants_indel = variants_rare.loc[(variants_rare['REF'].str.len() > 1) | (variants_rare['ALT'].str.len() > 1)].copy()\n",
    "    variants_indel.to_csv('./gnomad/indels_rare_chr' + str(chrom) + '.csv.gz', compression = 'gzip', index = False)\n",
    "    print('finished chr' + str(chrom) + '      ', end=\"\\r\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d6f8f9",
   "metadata": {},
   "source": [
    "#### Load indels, format, count genome totals <a name=\"GNOMAD_indels_load\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5a43d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QC cutoff values for indels (see above)\n",
    "vqslod_list_indel = [-np.inf, -1.0607, 0, 1.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe40975",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants_indel_slim_AC = dict()\n",
    "variants_indel_slim_noAC = dict()\n",
    "variants_indel_count_AC = dict()\n",
    "variants_indel_count_noAC = dict()\n",
    "for chrom in range(chr_range,23):\n",
    "    # Load indels\n",
    "    variants_indel = pd.read_csv('./gnomad/indels_rare_chr' + str(chrom) + '.csv.gz', compression = 'gzip', usecols = ['POS', 'REF', 'ALT', 'AC', 'AN', 'AS_VQSLOD'])\n",
    "    # Center position for deletions (doesn't change position for insertions)\n",
    "    variants_indel['POS_mid'] = (variants_indel['POS'] + (variants_indel['REF'].str.len()/2)).astype(int)\n",
    "    variants_indel['indel'] = (variants_indel['REF'].str.len() > 1).replace(False, 'ins').replace(True, 'del')\n",
    "    variants_indel['Tri_mid'] = [tri_function(chrom, pos) for pos in variants_indel['POS_mid']]\n",
    "\n",
    "    variants_indel_slim_AC[chrom] = dict()\n",
    "    variants_indel_slim_noAC[chrom] = dict()\n",
    "    variants_indel_count_AC[chrom] = dict()\n",
    "    variants_indel_count_noAC[chrom] = dict()\n",
    "    for qc_cutoff in vqslod_list_indel:\n",
    "        variants_indel['AC_cutoff'] = variants_indel['AC'].mul((variants_indel['AS_VQSLOD'] >= qc_cutoff).values, axis=0)\n",
    "        variants_indel['count_cutoff'] = (variants_indel['AC'] > 0).astype(int).mul((variants_indel['AS_VQSLOD'] >= qc_cutoff).values, axis=0)\n",
    "        variants_indel_slim_AC[chrom][qc_cutoff] = variants_indel.groupby(['POS_mid', 'indel']).sum()['AC_cutoff'].unstack().fillna(0).astype(int)\n",
    "        variants_indel_slim_noAC[chrom][qc_cutoff] = variants_indel.groupby(['POS_mid', 'indel']).sum()['count_cutoff'].unstack().fillna(0).astype(int)\n",
    "\n",
    "        variants_indel_count_AC[chrom][qc_cutoff] = variants_indel.groupby(['Tri_mid', 'indel']).sum()['AC_cutoff'].unstack().fillna(0).astype(int)\n",
    "        variants_indel_count_noAC[chrom][qc_cutoff] = variants_indel.groupby(['Tri_mid', 'indel']).sum()['count_cutoff'].unstack().fillna(0).astype(int)\n",
    "    print('finished chr' + str(chrom) + '      ', end=\"\\r\", flush=True)\n",
    "\n",
    "for chrom in range(chr_range,23):\n",
    "    variants_indel_slim_AC[chrom] = pd.concat(variants_indel_slim_AC[chrom], axis=1)\n",
    "    variants_indel_slim_noAC[chrom] = pd.concat(variants_indel_slim_noAC[chrom], axis=1)\n",
    "    \n",
    "    variants_indel_count_AC[chrom] = pd.concat(variants_indel_count_AC[chrom], axis=1)\n",
    "    variants_indel_count_noAC[chrom] = pd.concat(variants_indel_count_noAC[chrom], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba84240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total indels for each QC cutoff, with and without using allele counts\n",
    "variants_indel_count_AC_sum = variants_indel_count_AC[22]\n",
    "for chrom in range(chr_range,22):\n",
    "    variants_indel_count_AC_sum += variants_indel_count_AC[chrom]\n",
    "\n",
    "variants_indel_count_noAC_sum = variants_indel_count_noAC[22]\n",
    "for chrom in range(chr_range,22):\n",
    "    variants_indel_count_noAC_sum += variants_indel_count_noAC[chrom]\n",
    "\n",
    "variants_indel_count_AC_sum_RC = triplet_combine_RC(variants_indel_count_AC_sum)\n",
    "variants_indel_count_AC_freq_RC = variants_indel_count_AC_sum_RC.div(triplet_combine_RC(genome_triplet_totals['hg38']), axis=0)\n",
    "\n",
    "variants_indel_count_AC_freq_RC = variants_indel_count_AC_freq_RC.stack()\n",
    "variants_indel_count_AC_freq_RC.index = [ind[0] + '_' + ind[1] for ind in variants_indel_count_AC_freq_RC.index]\n",
    "variants_indel_count_AC_freq_RC = variants_indel_count_AC_freq_RC.reindex(triplet_mutations_und_indel_TC)\n",
    "variants_indel_count_AC_freq_all = triplet_combine_RC_indel(variants_indel_count_AC_freq_RC, mut_input=True, decombine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6f1d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all indels into a single object\n",
    "variants_indel_all = dict()\n",
    "for chrom in range(chr_range,23):\n",
    "    # Load indels\n",
    "    variants_indel_all[chrom] = pd.read_csv('./gnomad/indels_rare_chr' + str(chrom) + '.csv.gz', compression = 'gzip', usecols = ['POS', 'REF', 'ALT', 'AC', 'AN', 'AS_VQSLOD'])\n",
    "    # Center position for deletions (doesn't change position for insertions)\n",
    "    variants_indel_all[chrom]['POS_mid'] = (variants_indel_all[chrom]['POS'] + (variants_indel_all[chrom]['REF'].str.len()/2)).astype(int)\n",
    "    variants_indel_all[chrom]['indel'] = (variants_indel_all[chrom]['REF'].str.len() > 1).replace(False, 'ins').replace(True, 'del')\n",
    "    variants_indel_all[chrom]['Tri_mid'] = [tri_function(chrom, pos) for pos in variants_indel_all[chrom]['POS_mid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dd289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of indels in gnomAD\n",
    "pd.Series([len(variants_indel_all[chrom]) for chrom in range(chr_range,23)]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9457dcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat indel list for easier access, and count indels\n",
    "\n",
    "# QC cutoff values for indels (see above)\n",
    "vqslod_list_indel = [-np.inf, -1.0607, 0, 1.4]\n",
    "\n",
    "variants_indel_slim_AC = dict()\n",
    "variants_indel_slim_noAC = dict()\n",
    "variants_indel_count_AC = dict()\n",
    "variants_indel_count_noAC = dict()\n",
    "for chrom in range(chr_range,23):\n",
    "    variants_indel_slim_AC[chrom] = dict()\n",
    "    variants_indel_slim_noAC[chrom] = dict()\n",
    "    variants_indel_count_AC[chrom] = dict()\n",
    "    variants_indel_count_noAC[chrom] = dict()\n",
    "    for qc_cutoff in vqslod_list_indel:\n",
    "        variants_indel_all[chrom]['AC_cutoff'] = variants_indel_all[chrom]['AC'].mul((variants_indel_all[chrom]['AS_VQSLOD'] >= qc_cutoff).values, axis=0)\n",
    "        variants_indel_all[chrom]['count_cutoff'] = (variants_indel_all[chrom]['AC'] > 0).astype(int).mul((variants_indel_all[chrom]['AS_VQSLOD'] >= qc_cutoff).values, axis=0)\n",
    "        variants_indel_slim_AC[chrom][qc_cutoff] = variants_indel_all[chrom].groupby(['POS_mid', 'indel']).sum()['AC_cutoff'].unstack().fillna(0).astype(int)\n",
    "        variants_indel_slim_noAC[chrom][qc_cutoff] = variants_indel_all[chrom].groupby(['POS_mid', 'indel']).sum()['count_cutoff'].unstack().fillna(0).astype(int)\n",
    "\n",
    "        variants_indel_count_AC[chrom][qc_cutoff] = variants_indel_all[chrom].groupby(['Tri_mid', 'indel']).sum()['AC_cutoff'].unstack().fillna(0).astype(int)\n",
    "        variants_indel_count_noAC[chrom][qc_cutoff] = variants_indel_all[chrom].groupby(['Tri_mid', 'indel']).sum()['count_cutoff'].unstack().fillna(0).astype(int)\n",
    "    print('finished chr' + str(chrom) + '      ', end=\"\\r\", flush=True)\n",
    "\n",
    "for chrom in range(chr_range,23):\n",
    "    variants_indel_slim_AC[chrom] = pd.concat(variants_indel_slim_AC[chrom], axis=1)\n",
    "    variants_indel_slim_noAC[chrom] = pd.concat(variants_indel_slim_noAC[chrom], axis=1)\n",
    "    \n",
    "    variants_indel_count_AC[chrom] = pd.concat(variants_indel_count_AC[chrom], axis=1)\n",
    "    variants_indel_count_noAC[chrom] = pd.concat(variants_indel_count_noAC[chrom], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d2f63e",
   "metadata": {},
   "source": [
    "#### Insertions and deletions longer/shorter than 5 nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d52cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants_ins_long = dict(); variants_ins_short = dict()\n",
    "for chrom in range(chr_range,23):\n",
    "    variants_ins_short[chrom] = variants_indel_all[chrom].loc[(variants_indel_all[chrom]['ALT'].str.len() > 1) & (variants_indel_all[chrom]['ALT'].str.len() <= 5)].copy()\n",
    "    variants_ins_long[chrom] = variants_indel_all[chrom].loc[variants_indel_all[chrom]['ALT'].str.len() > 5].copy()\n",
    "\n",
    "variants_del_long = dict(); variants_del_short = dict()\n",
    "for chrom in range(chr_range,23):\n",
    "    variants_del_short[chrom] = variants_indel_all[chrom].loc[(variants_indel_all[chrom]['REF'].str.len() > 1) & (variants_indel_all[chrom]['REF'].str.len() <= 5)].copy()\n",
    "    variants_del_long[chrom] = variants_indel_all[chrom].loc[variants_indel_all[chrom]['REF'].str.len() > 5].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c5c234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat indel list for easier access, and count indels\n",
    "\n",
    "# QC cutoff values for indels (see above)\n",
    "vqslod_list_indel = [-np.inf, -1.0607, 0, 1.4]\n",
    "\n",
    "variants_ins_slim_AC_long = dict(); variants_ins_slim_AC_short = dict()\n",
    "variants_ins_count_AC_long = dict(); variants_ins_count_AC_short = dict()\n",
    "for chrom in range(chr_range,23):\n",
    "    variants_ins_slim_AC_long[chrom] = dict(); variants_ins_slim_AC_short[chrom] = dict()\n",
    "    variants_ins_count_AC_long[chrom] = dict(); variants_ins_count_AC_short[chrom] = dict()\n",
    "    for qc_cutoff in vqslod_list_indel:\n",
    "        variants_ins_long[chrom]['AC_cutoff'] = variants_ins_long[chrom]['AC'].mul((variants_ins_long[chrom]['AS_VQSLOD'] >= qc_cutoff).values, axis=0)\n",
    "        variants_ins_long[chrom]['count_cutoff'] = (variants_ins_long[chrom]['AC'] > 0).astype(int).mul((variants_ins_long[chrom]['AS_VQSLOD'] >= qc_cutoff).values, axis=0)\n",
    "        variants_ins_slim_AC_long[chrom][qc_cutoff] = variants_ins_long[chrom].groupby(['POS_mid', 'indel']).sum()['AC_cutoff'].unstack().fillna(0).astype(int)\n",
    "        variants_ins_count_AC_long[chrom][qc_cutoff] = variants_ins_long[chrom].groupby(['Tri_mid', 'indel']).sum()['AC_cutoff'].unstack().fillna(0).astype(int)\n",
    "\n",
    "        variants_ins_short[chrom]['AC_cutoff'] = variants_ins_short[chrom]['AC'].mul((variants_ins_short[chrom]['AS_VQSLOD'] >= qc_cutoff).values, axis=0)\n",
    "        variants_ins_short[chrom]['count_cutoff'] = (variants_ins_short[chrom]['AC'] > 0).astype(int).mul((variants_ins_short[chrom]['AS_VQSLOD'] >= qc_cutoff).values, axis=0)\n",
    "        variants_ins_slim_AC_short[chrom][qc_cutoff] = variants_ins_short[chrom].groupby(['POS_mid', 'indel']).sum()['AC_cutoff'].unstack().fillna(0).astype(int)\n",
    "        variants_ins_count_AC_short[chrom][qc_cutoff] = variants_ins_short[chrom].groupby(['Tri_mid', 'indel']).sum()['AC_cutoff'].unstack().fillna(0).astype(int)\n",
    "    print('finished chr' + str(chrom) + '      ', end=\"\\r\", flush=True)\n",
    "\n",
    "for chrom in range(chr_range,23):\n",
    "    variants_ins_slim_AC_long[chrom] = pd.concat(variants_ins_slim_AC_long[chrom], axis=1)\n",
    "    variants_ins_slim_AC_short[chrom] = pd.concat(variants_ins_slim_AC_short[chrom], axis=1)\n",
    "    variants_ins_count_AC_long[chrom] = pd.concat(variants_ins_count_AC_long[chrom], axis=1)\n",
    "    variants_ins_count_AC_short[chrom] = pd.concat(variants_ins_count_AC_short[chrom], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91290b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total indels for each QC cutoff, with and without using allele counts\n",
    "variants_ins_count_AC_sum_long = variants_ins_count_AC_long[22]\n",
    "for chrom in range(chr_range,22):\n",
    "    variants_ins_count_AC_sum_long += variants_ins_count_AC_long[chrom]\n",
    "\n",
    "variants_ins_count_AC_sum_RC_long = triplet_combine_RC(variants_ins_count_AC_sum_long)\n",
    "variants_ins_count_AC_freq_RC_long = variants_ins_count_AC_sum_RC_long.div(triplet_combine_RC(genome_triplet_totals['hg38']), axis=0)\n",
    "\n",
    "variants_ins_count_AC_freq_RC_long = variants_ins_count_AC_freq_RC_long.stack()\n",
    "variants_ins_count_AC_freq_RC_long.index = [ind[0] + '_' + ind[1] for ind in variants_ins_count_AC_freq_RC_long.index]\n",
    "variants_ins_count_AC_freq_RC_long = variants_ins_count_AC_freq_RC_long.reindex(triplet_mutations_und_indel_TC)\n",
    "variants_ins_count_AC_freq_long = triplet_combine_RC_indel(variants_ins_count_AC_freq_RC_long, mut_input=True, decombine=True)\n",
    "\n",
    "# Count total indels for each QC cutoff, with and without using allele counts\n",
    "variants_ins_count_AC_sum_short = variants_ins_count_AC_short[22]\n",
    "for chrom in range(chr_range,22):\n",
    "    variants_ins_count_AC_sum_short += variants_ins_count_AC_short[chrom]\n",
    "\n",
    "variants_ins_count_AC_sum_RC_short = triplet_combine_RC(variants_ins_count_AC_sum_short)\n",
    "variants_ins_count_AC_freq_RC_short = variants_ins_count_AC_sum_RC_short.div(triplet_combine_RC(genome_triplet_totals['hg38']), axis=0)\n",
    "\n",
    "variants_ins_count_AC_freq_RC_short = variants_ins_count_AC_freq_RC_short.stack()\n",
    "variants_ins_count_AC_freq_RC_short.index = [ind[0] + '_' + ind[1] for ind in variants_ins_count_AC_freq_RC_short.index]\n",
    "variants_ins_count_AC_freq_RC_short = variants_ins_count_AC_freq_RC_short.reindex(triplet_mutations_und_indel_TC)\n",
    "variants_ins_count_AC_freq_short = triplet_combine_RC_indel(variants_ins_count_AC_freq_RC_short, mut_input=True, decombine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b148c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QC cutoff values for indels (see above)\n",
    "vqslod_list_indel = [-np.inf, -1.0607, 0, 1.4]\n",
    "\n",
    "variants_del_slim_AC_long = dict(); variants_del_slim_AC_short = dict()\n",
    "variants_del_count_AC_long = dict(); variants_del_count_AC_short = dict()\n",
    "for chrom in range(chr_range,23):\n",
    "    variants_del_slim_AC_long[chrom] = dict(); variants_del_slim_AC_short[chrom] = dict()\n",
    "    variants_del_count_AC_long[chrom] = dict(); variants_del_count_AC_short[chrom] = dict()\n",
    "    for qc_cutoff in vqslod_list_indel:\n",
    "        variants_del_long[chrom]['AC_cutoff'] = variants_del_long[chrom]['AC'].mul((variants_del_long[chrom]['AS_VQSLOD'] >= qc_cutoff).values, axis=0)\n",
    "        variants_del_long[chrom]['count_cutoff'] = (variants_del_long[chrom]['AC'] > 0).astype(int).mul((variants_del_long[chrom]['AS_VQSLOD'] >= qc_cutoff).values, axis=0)\n",
    "        variants_del_slim_AC_long[chrom][qc_cutoff] = variants_del_long[chrom].groupby(['POS_mid', 'indel']).sum()['AC_cutoff'].unstack().fillna(0).astype(int)\n",
    "        variants_del_count_AC_long[chrom][qc_cutoff] = variants_del_long[chrom].groupby(['Tri_mid', 'indel']).sum()['AC_cutoff'].unstack().fillna(0).astype(int)\n",
    "\n",
    "        variants_del_short[chrom]['AC_cutoff'] = variants_del_short[chrom]['AC'].mul((variants_del_short[chrom]['AS_VQSLOD'] >= qc_cutoff).values, axis=0)\n",
    "        variants_del_short[chrom]['count_cutoff'] = (variants_del_short[chrom]['AC'] > 0).astype(int).mul((variants_del_short[chrom]['AS_VQSLOD'] >= qc_cutoff).values, axis=0)\n",
    "        variants_del_slim_AC_short[chrom][qc_cutoff] = variants_del_short[chrom].groupby(['POS_mid', 'indel']).sum()['AC_cutoff'].unstack().fillna(0).astype(int)\n",
    "        variants_del_count_AC_short[chrom][qc_cutoff] = variants_del_short[chrom].groupby(['Tri_mid', 'indel']).sum()['AC_cutoff'].unstack().fillna(0).astype(int)\n",
    "    print('finished chr' + str(chrom) + '      ', end=\"\\r\", flush=True)\n",
    "\n",
    "for chrom in range(chr_range,23):\n",
    "    variants_del_slim_AC_long[chrom] = pd.concat(variants_del_slim_AC_long[chrom], axis=1)\n",
    "    variants_del_slim_AC_short[chrom] = pd.concat(variants_del_slim_AC_short[chrom], axis=1)\n",
    "    variants_del_count_AC_long[chrom] = pd.concat(variants_del_count_AC_long[chrom], axis=1)\n",
    "    variants_del_count_AC_short[chrom] = pd.concat(variants_del_count_AC_short[chrom], axis=1)\n",
    "\n",
    "# Count total indels for each QC cutoff, with and without using allele counts\n",
    "variants_del_count_AC_sum_long = variants_del_count_AC_long[22]\n",
    "for chrom in range(chr_range,22):\n",
    "    variants_del_count_AC_sum_long += variants_del_count_AC_long[chrom]\n",
    "\n",
    "variants_del_count_AC_sum_RC_long = triplet_combine_RC(variants_del_count_AC_sum_long)\n",
    "variants_del_count_AC_freq_RC_long = variants_del_count_AC_sum_RC_long.div(triplet_combine_RC(genome_triplet_totals['hg38']), axis=0)\n",
    "\n",
    "variants_del_count_AC_freq_RC_long = variants_del_count_AC_freq_RC_long.stack()\n",
    "variants_del_count_AC_freq_RC_long.index = [ind[0] + '_' + ind[1] for ind in variants_del_count_AC_freq_RC_long.index]\n",
    "variants_del_count_AC_freq_RC_long = variants_del_count_AC_freq_RC_long.reindex(triplet_mutations_und_indel_TC)\n",
    "variants_del_count_AC_freq_long = triplet_combine_RC_indel(variants_del_count_AC_freq_RC_long, mut_input=True, decombine=True)\n",
    "\n",
    "# Count total indels for each QC cutoff, with and without using allele counts\n",
    "variants_del_count_AC_sum_short = variants_del_count_AC_short[22]\n",
    "for chrom in range(chr_range,22):\n",
    "    variants_del_count_AC_sum_short += variants_del_count_AC_short[chrom]\n",
    "\n",
    "variants_del_count_AC_sum_RC_short = triplet_combine_RC(variants_del_count_AC_sum_short)\n",
    "variants_del_count_AC_freq_RC_short = variants_del_count_AC_sum_RC_short.div(triplet_combine_RC(genome_triplet_totals['hg38']), axis=0)\n",
    "\n",
    "variants_del_count_AC_freq_RC_short = variants_del_count_AC_freq_RC_short.stack()\n",
    "variants_del_count_AC_freq_RC_short.index = [ind[0] + '_' + ind[1] for ind in variants_del_count_AC_freq_RC_short.index]\n",
    "variants_del_count_AC_freq_RC_short = variants_del_count_AC_freq_RC_short.reindex(triplet_mutations_und_indel_TC)\n",
    "variants_del_count_AC_freq_short = triplet_combine_RC_indel(variants_del_count_AC_freq_RC_short, mut_input=True, decombine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54684c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GC correction for indels not implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217d10ae",
   "metadata": {},
   "source": [
    "# Prepare de novo SNV database  <a name=\"denovo\"></a>\n",
    "- Gather de novo data from all available public sources (trio/family sequencing)\n",
    "- Place files in directory './denovo/download/'\n",
    "\n",
    "[Return to Table of Contents](#TOC)\n",
    "\n",
    "### de novo data aligned to hg19 <a name=\"denovo_hg19\"></a>\n",
    "\n",
    "#### data from Goldman 2016 (hg19)\n",
    "- Parent-of-origin-specific signatures of de novo mutations\n",
    "- phased\n",
    "- 816 trios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f6a5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trio_gold = pd.read_excel('./denovo/download/41588_2016_BFng3597_MOESM69_ESM_hg19.xlsx', usecols = ['Chromosome', 'Start.position', 'Reference', 'Variant', 'parentOfOrigin'])\n",
    "trio_gold.columns = ['chrom', 'pos', 'ref', 'alt', 'parent']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8121007c",
   "metadata": {},
   "source": [
    "#### data from Goes et al 2021 (hg19)\n",
    "- De novo variation in bipolar disorder\n",
    "- unphased\n",
    "- 97 trios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a826fd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "goes2019 = pd.read_excel('./denovo/download/41380_2019_611_MOESM3_ESM.xlsx', usecols = ['chr_bp_ref_alt', 'SNV'])\n",
    "goes2019[['chrom', 'pos', 'ref', 'alt']] = goes2019['chr_bp_ref_alt'].str.split('_', expand = True)\n",
    "goes2019 = goes2019.dropna()[['chrom', 'pos', 'ref', 'alt']]\n",
    "goes2019['chrom'] = ['chr' + str(chrom) for chrom in goes2019['chrom']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b003e3",
   "metadata": {},
   "source": [
    "#### data from Yuen et al. 2016 (hg19)\n",
    "- Genome-wide characteristics of de novo mutations in autism\n",
    "- 192 trios\n",
    "- phased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24af9871",
   "metadata": {},
   "outputs": [],
   "source": [
    "yuen_trios = pd.read_excel('./denovo/download/41525_2016_BFnpjgenmed201627_MOESM431_ESM.xlsx', sheet_name='Table S4', skiprows = 1, usecols = ['Chromosome', 'Start', 'Reference', 'Allel', 'Parental Origin'])\n",
    "yuen_trios.columns = ['chrom', 'pos', 'ref', 'alt', 'parent']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad87fcd4",
   "metadata": {},
   "source": [
    "#### data from Sasani 2019 (hg19)\n",
    "- Large, three-generation human families reveal post-zygotic mosaicism and variability in germline mutation accumulation\n",
    "- phased\n",
    "- 350 3rd generation offspring, 70 2nd generation offspring (420 genomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b945460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnm_ceph_gen2 = pd.read_csv('./denovo/download/ceph-dnm-manuscript-master/data/second_gen.dnms.txt', sep = '\\t', usecols = ['chrom', 'start', 'ref', 'alt', 'paternal_age_at_birth', 'maternal_age_at_birth', 'phase'])\n",
    "dnm_ceph_gen3 = pd.read_csv('./denovo/download/ceph-dnm-manuscript-master/data/third_gen.dnms.txt', sep = '\\t', usecols = ['chrom', 'start', 'ref', 'alt', 'paternal_age_at_birth', 'maternal_age_at_birth', 'phase'])\n",
    "dnm_ceph_gen2_gon = pd.read_csv('./denovo/download/ceph-dnm-manuscript-master/data/gonosomal.dnms.txt', sep = '\\t', usecols = ['chrom', 'start', 'ref', 'alt', 'paternal_age_at_birth', 'maternal_age_at_birth', 'phase'])\n",
    "dnm_ceph_gen3_gon = pd.read_csv('./denovo/download/ceph-dnm-manuscript-master/data/post-pgcs.dnms.txt', sep = '\\t', usecols = ['chrom', 'start', 'ref', 'alt', 'paternal_age_at_birth', 'maternal_age_at_birth', 'phase'])\n",
    "\n",
    "dnm_ceph = pd.concat([dnm_ceph_gen2, dnm_ceph_gen2_gon, dnm_ceph_gen3, dnm_ceph_gen3_gon])\n",
    "dnm_ceph['chrom'] = ['chr' + str(chrom) for chrom in dnm_ceph['chrom']]\n",
    "\n",
    "dnm_ceph.columns = ['chrom', 'pos', 'ref', 'alt', 'paternal_age', 'maternal_age', 'phase']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c348a45",
   "metadata": {},
   "source": [
    "#### Liftover hg19 data to hg38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4577ab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "trio_hg19 = pd.concat([trio_gold, goes2019, dnm_ceph, yuen_trios]).reset_index(drop = True)\n",
    "trio_hg19['pos'] = trio_hg19['pos'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b33d74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liftover to hg38\n",
    "lo = LiftOver('hg19', 'hg38')\n",
    "trio_hg19['hg38_lo'] = [lo.convert_coordinate(chrom, pos) for chrom,pos in zip(trio_hg19['chrom'], trio_hg19['pos'])]\n",
    "trio_hg19['hg38_chr'] = [pos[0][0] if len(pos) >0 else np.nan for pos in trio_hg19['hg38_lo']]\n",
    "trio_hg19['hg38_pos'] = [pos[0][1] if len(pos) >0 else np.nan for pos in trio_hg19['hg38_lo']]\n",
    "\n",
    "trio_hg19 = trio_hg19.dropna(subset = ['hg38_chr'], axis=0)\n",
    "trio_hg19 = trio_hg19.loc[trio_hg19['hg38_chr'].isin(['chr'+str(n) for n in range(1,23)])].copy()\n",
    "trio_hg19['hg38_chr'] = [chrom[3:] for chrom in trio_hg19['hg38_chr']]\n",
    "trio_hg19['hg38_chr'] = trio_hg19['hg38_chr'].astype(int)\n",
    "\n",
    "trio_hg19['hg38_pos'] = trio_hg19['hg38_pos'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c007973",
   "metadata": {},
   "outputs": [],
   "source": [
    "trio_hg19['hg38_base'] = [reference_lookup(c,p,0) for c,p in zip(trio_hg19['hg38_chr'], trio_hg19['hg38_pos'])]\n",
    "\n",
    "trio_hg19 = trio_hg19.loc[trio_hg19['ref'] == trio_hg19['hg38_base']].copy()\n",
    "\n",
    "trio_hg19 = trio_hg19[['hg38_chr', 'hg38_pos', 'ref', 'alt', 'parent']].copy()\n",
    "trio_hg19.columns = ['chrom', 'pos', 'ref', 'alt', 'parent']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ad171d",
   "metadata": {},
   "source": [
    "### de novo data aligned to hg38 <a name=\"denovo_hg38\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)\n",
    "\n",
    "#### data from Halldorsson 2019 in Science (hg38)\n",
    "- Characterizing mutagenic effects of recombination through a sequence-level genetic map\n",
    "- phased\n",
    "- 2976 trios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fec6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "trio_set1 = pd.read_csv('./denovo/download/aau1043_DataS5_revision1.tsv', skiprows = 11, sep = '\\t', low_memory=False)\n",
    "trio_set1_ages = pd.read_csv('./denovo/download/aau1043_DataS7.tsv', skiprows = 4, sep = '\\t')\n",
    "\n",
    "trio_set1_ages.index = trio_set1_ages['Proband_id']\n",
    "trio_set1['Father_age'] = [trio_set1_ages['Father_age'][pro] for pro in trio_set1['Proband_id']]\n",
    "trio_set1['Mother_age'] = [trio_set1_ages['Mother_age'][pro] for pro in trio_set1['Proband_id']]\n",
    "\n",
    "trio_set1['Chr'] = pd.Series([chrom[3:] for chrom in trio_set1['Chr']]).astype(int)\n",
    "\n",
    "trio_set1 = trio_set1[['Chr', 'Pos', 'Ref', 'Alt', 'Phase_combined', 'Father_age', 'Mother_age']]\n",
    "trio_set1.columns = ['chrom', 'pos', 'ref', 'alt', 'parent', 'paternal_age', 'maternal_age']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f98aba",
   "metadata": {},
   "source": [
    "#### data from Jonnson 2017 in Nature (hg38)\n",
    "- Parental influence on human germline de novo mutations in 1,548 trios from Iceland\n",
    "- 1548 trios\n",
    "- phased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878b8f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "trio_set2 = pd.read_csv('./denovo/download/decode_DNMs.tsv', sep = '\\t', usecols = ['Chr', 'Pos_hg38', 'Ref', 'Alt', 'Discordant_in_3_gen_or_mz_twins', 'Fathers_age_at_conception', 'Mothers_age_at_conception', 'Phase_combined'])\n",
    "\n",
    "trio_set2['Chr'] = [chrom[3:] for chrom in trio_set2['Chr']]\n",
    "trio_set2 = trio_set2.loc[trio_set2['Chr'].isin([str(n) for n in range(1,23)])].copy()\n",
    "trio_set2['Chr'] = trio_set2['Chr'].astype(int)\n",
    "\n",
    "trio_set2.columns = ['chrom', 'pos', 'ref', 'alt', 'discordant', 'paternal_age', 'maternal_age', 'parent']\n",
    "trio_set2 = trio_set2.loc[trio_set2['discordant'] != 'Discordant']\n",
    "del trio_set2['discordant']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee676148",
   "metadata": {},
   "source": [
    "#### data from AN 2018 in Science (hg38)\n",
    "- Genome-wide de novo risk score implicates promoter variation in autism spectrum disorder\n",
    "- unphased\n",
    "- 1902 quartets (3804 genomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02de2033",
   "metadata": {},
   "outputs": [],
   "source": [
    "trio_an = pd.read_excel('./denovo/download/aat6576_Table-S2_hg38_notphased.xlsx', skiprows = 1, usecols = ['Chr', 'Pos', 'Ref', 'Alt'])\n",
    "\n",
    "trio_an['Chr'] = pd.Series([chrom[3:] for chrom in trio_an['Chr']]).astype(int)\n",
    "trio_an.columns = ['chrom', 'pos', 'ref', 'alt']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f01045",
   "metadata": {},
   "source": [
    "#### data from Jonsson et al 2021 (hg38)\n",
    "- Differences between germline genomes of monozygotic twins\n",
    "- 451 offspring in quads\n",
    "- 608 offspring in three-generation approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c95ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# de novo mutations from quads\n",
    "jonsson_quads = pd.read_csv('./denovo/download/41588_2020_755_MOESM5_ESM.tsv', sep = '\\t', usecols = ['Chr', 'Pos', 'Ref', 'Alt', 'Child_Fathers_Age_at_birth', 'Child_Mothers_Age_at_birth'])\n",
    "jonsson_quads.columns = ['chrom', 'pos', 'ref', 'alt', 'paternal_age', 'maternal_age']\n",
    "\n",
    "# de novo mutations from three-generation approach\n",
    "jonsson_3gen = pd.read_csv('./denovo/download/41588_2020_755_MOESM4_ESM.tsv', sep = '\\t', usecols = ['Chr', 'Pos', 'Ref', 'Alt'])\n",
    "jonsson_3gen.columns = ['chrom', 'pos', 'ref', 'alt']\n",
    "\n",
    "jonsson_quads['chrom'] = [chrom[3:] for chrom in jonsson_quads['chrom']]\n",
    "jonsson_quads = jonsson_quads.loc[jonsson_quads['chrom'].isin([str(n) for n in range(1,23)])].copy()\n",
    "jonsson_quads['chrom'] = jonsson_quads['chrom'].astype(int)\n",
    "\n",
    "jonsson_3gen['chrom'] = [chrom[3:] for chrom in jonsson_3gen['chrom']]\n",
    "jonsson_3gen = jonsson_3gen.loc[jonsson_3gen['chrom'].isin([str(n) for n in range(1,23)])].copy()\n",
    "jonsson_3gen['chrom'] = jonsson_3gen['chrom'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcf3e62",
   "metadata": {},
   "source": [
    "### Combine all into single de novo database <a name=\"denovo_combine\"></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e761f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_combined = pd.concat([trio_set1, trio_set2, trio_an, jonsson_3gen, jonsson_quads, trio_hg19]).reset_index(drop = True)\n",
    "denovo_combined = denovo_combined.loc[(denovo_combined['ref'].str.len() == 1) & (denovo_combined['alt'].str.len() == 1)].copy()\n",
    "denovo_combined['parent'] = denovo_combined['parent'].str.lower()\n",
    "denovo_combined['parent'] = denovo_combined['parent'].fillna('unassigned')\n",
    "denovo_combined['tri'] = [tri_function(chrom, pos) for chrom, pos in zip(denovo_combined['chrom'], denovo_combined['pos'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faddb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that all coordinates are base1\n",
    "len(denovo_combined) == len(denovo_combined.loc[[tri[1] == ref for tri, ref in zip(denovo_combined['tri'], denovo_combined['ref'])]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f633680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save databse\n",
    "denovo_combined.to_csv('./denovo/all_denovo_snvs.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d32572b",
   "metadata": {},
   "source": [
    "### Load database and calculate SNV frequencies <a name=\"denovo_load\"></a>\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b535a879",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_combined = pd.read_csv('./denovo/all_denovo_snvs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4f0b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of genomes\n",
    "denovo_n_genomes = 816 + 97 + 192 + 420 + 2976+ 1548 + 3804 + 451 + 608\n",
    "\n",
    "# Total number of SNVs in database, SNVs per genome\n",
    "len(denovo_combined), denovo_n_genomes, len(denovo_combined) / denovo_n_genomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c202658f",
   "metadata": {},
   "source": [
    "#### Calculate mutation frequency per trinucleotide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aae471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of mutations per triplet context\n",
    "denovo_totals = denovo_combined.groupby(['tri', 'alt']).count()['ref']\n",
    "denovo_totals.index = [tri+'_'+mut for tri, mut in zip(denovo_totals.index.get_level_values(0), denovo_totals.index.get_level_values(1))]\n",
    "denovo_totals = denovo_totals.reindex(triplet_mutations_und)\n",
    "denovo_totals_RC = triplet_combine_RC(denovo_totals, mut_input = True)\n",
    "\n",
    "# Calculate frequency\n",
    "denovo_freq_RC = denovo_totals_RC.div(triplet_combine_RC(genome_triplet_totals['hg38'], mut_output = True), axis=0)\n",
    "denovo_freq_all = pd.DataFrame(triplet_combine_RC(denovo_freq_RC, mut_input=True, decombine=True), columns = ['denovo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff167b8b",
   "metadata": {},
   "source": [
    "#### Reformat mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e03097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "denovo_slim = denovo_combined.groupby(['chrom', 'pos', 'tri', 'alt']).count()['ref'].unstack().fillna(0).astype(int)\n",
    "denovo_slim_reformat = dict()\n",
    "for chrom in range(chr_range,23):\n",
    "    denovo_slim_reformat[chrom] = denovo_slim.loc[1].reset_index().set_index('pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c3e067",
   "metadata": {},
   "source": [
    "#    Calculate mutation frequency surrounding motifs <a name=\"mutation_surrounding\"></a>\n",
    "\n",
    "### Define counting functions <a name=\"mutation_surrounding_functions\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d53c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_mut_flank_chrom(chrom, current_pos_chrom, input_mut_dict, distance, left_pos_col, right_pos_col, filter_cols, filter_distance, useful_cols, qc_cutoff_list, noAC, gc_nmer, ignore_qual):\n",
    "    print('\\r' + str(chrom), end='        ')\n",
    "    \n",
    "    # filter out motifs too close to masked elements\n",
    "    if len(filter_cols) > 0:\n",
    "        current_pos_chrom = current_pos_chrom.loc[current_pos_chrom[[col + '_min' for col in filter_cols]].fillna(0).min(axis=1) > filter_distance].copy()\n",
    "    \n",
    "    # make a single dataframe consisting of all search coordinates and their position relative to the original starts/ends of interest\n",
    "    \n",
    "    search_positions_left = dict()\n",
    "    for pos in range(-distance,0):\n",
    "        search_positions_left[pos] = pd.DataFrame(current_pos_chrom[left_pos_col] + pos)\n",
    "    search_positions_left = pd.concat(search_positions_left).reset_index()[[left_pos_col, 'level_0']]\n",
    "    for col in useful_cols:\n",
    "        search_positions_left[col] = list(current_pos_chrom[col])*distance\n",
    "    if len(filter_cols) > 0:\n",
    "        search_positions_left['filter_left'] = list(current_pos_chrom[[col + '_left' for col in filter_cols]].min(axis=1))*distance\n",
    "        search_positions_left = search_positions_left.loc[search_positions_left['level_0'].abs() <= (search_positions_left['filter_left'] - filter_distance)].copy()\n",
    "        del search_positions_left['filter_left']\n",
    "    search_positions_left.columns = ['POS', 'relative_pos'] + useful_cols\n",
    "\n",
    "    search_positions_right = dict()\n",
    "    for pos in range(1,distance+1):\n",
    "        search_positions_right[pos] = pd.DataFrame(current_pos_chrom[right_pos_col] + pos -1)\n",
    "    search_positions_right = pd.concat(search_positions_right).reset_index()[[right_pos_col, 'level_0']]\n",
    "    for col in useful_cols:\n",
    "        search_positions_right[col] = list(current_pos_chrom[col])*distance\n",
    "    if len(filter_cols) > 0:\n",
    "        search_positions_right['filter_right'] = list(current_pos_chrom[[col + '_right' for col in filter_cols]].min(axis=1))*distance\n",
    "        search_positions_right = search_positions_right.loc[search_positions_right['level_0'] <= (search_positions_right['filter_right'] - filter_distance)].copy()\n",
    "        del search_positions_right['filter_right']\n",
    "    search_positions_right.columns = ['POS', 'relative_pos'] + useful_cols\n",
    "\n",
    "    for col in filter_cols:\n",
    "        current_pos_chrom = current_pos_chrom.loc[current_pos_chrom[col + '_min'] >= filter_distance].copy()\n",
    "    current_pos_chrom['pos'] = [list(range(left,right)) for left, right in zip(current_pos_chrom[left_pos_col], current_pos_chrom[right_pos_col])]\n",
    "    for col in useful_cols:\n",
    "        current_pos_chrom[col] = [[entry]*len(pos) for entry, pos in zip(current_pos_chrom[col], current_pos_chrom['pos'])]\n",
    "    search_positions_middle = pd.DataFrame(flatten(current_pos_chrom['pos']), columns = ['POS'])\n",
    "    search_positions_middle['relative_pos'] = 0\n",
    "    for col in useful_cols:\n",
    "        search_positions_middle[col] = pd.DataFrame(flatten(current_pos_chrom[col]))\n",
    "\n",
    "    search_positions = pd.concat([search_positions_left, search_positions_right, search_positions_middle])\n",
    "        \n",
    "    # for each qc_cutoff in the mutation dataset, find mutations overlapping the search coordinates\n",
    "    \n",
    "    current_mut_count = dict()\n",
    "    \n",
    "    current_mut_chrom = input_mut_dict[chrom].copy()\n",
    "    current_mut_chrom.index = current_mut_chrom.index - 1     # change coordinates from base1 to base0\n",
    "    if noAC == True:\n",
    "        current_mut_chrom[['A', 'T', 'G', 'C']] = (current_mut_chrom[['A', 'T', 'G', 'C']] > 0).astype(int)  \n",
    "    \n",
    "    if ignore_qual != False:\n",
    "        current_mut_count[ignore_qual] = current_mut_chrom.reindex(search_positions['POS'])[['A', 'T', 'G', 'C']]\n",
    "        current_mut_count[ignore_qual]['pos'] = list(search_positions['relative_pos'])\n",
    "        current_mut_count[ignore_qual]['Tri'] = [tri_function(chrom, pos, base = 0) for pos in current_mut_count[ignore_qual].index]\n",
    "        for col in useful_cols:\n",
    "            current_mut_count[ignore_qual][col] = list(search_positions[col])\n",
    "        current_mut_count[ignore_qual]['tri_count'] = 1\n",
    "        current_mut_sum = dict()\n",
    "        current_mut_sum[ignore_qual] = current_mut_count[ignore_qual].loc[current_mut_count[ignore_qual]['Tri'].isin(all_triplets)].groupby(['pos'] + useful_cols + ['Tri']).sum().copy()\n",
    "\n",
    "    else:\n",
    "        for qc_cutoff in qc_cutoff_list:\n",
    "            print('\\r' + str(chrom) + ' qc: ' + str(qc_cutoff[0]), end='        ')\n",
    "            current_mut_qc = (current_mut_chrom[['A', 'T', 'G', 'C']]).mul((current_mut_chrom[['qual_A', 'qual_T', 'qual_G', 'qual_C']] >= qc_cutoff[0]).astype(int).values, axis=0).mul((current_mut_chrom[['inbr_A', 'inbr_T', 'inbr_G', 'inbr_C']] >= qc_cutoff[1]).astype(int).values, axis=0)\n",
    "            current_mut_count[qc_cutoff[0]] = current_mut_qc.reindex(search_positions['POS'])[['A', 'T', 'G', 'C']]\n",
    "            current_mut_count[qc_cutoff[0]]['pos'] = list(search_positions['relative_pos'])\n",
    "            current_mut_count[qc_cutoff[0]]['Tri'] = [tri_function(chrom, pos, base = 0) for pos in current_mut_count[qc_cutoff[0]].index]\n",
    "            if gc_nmer != False:\n",
    "                current_mut_count[qc_cutoff[0]]['seq_'+str(gc_nmer)] = [reference_lookup(chrom, pos, round((gc_nmer-1)/2)) for pos in current_mut_count[qc_cutoff[0]].index]\n",
    "                current_mut_count[qc_cutoff[0]]['seq_'+str(gc_nmer)] = current_mut_count[qc_cutoff[0]]['seq_'+str(gc_nmer)].astype(str)\n",
    "                current_mut_count[qc_cutoff[0]]['GC_'+str(gc_nmer)] = (current_mut_count[qc_cutoff[0]]['seq_'+str(gc_nmer)].str.count('G') + current_mut_count[qc_cutoff[0]]['seq_'+str(gc_nmer)].str.count('C')) / (gc_nmer - current_mut_count[qc_cutoff[0]]['seq_'+str(gc_nmer)].str.count('N'))\n",
    "            for col in useful_cols:\n",
    "                current_mut_count[qc_cutoff[0]][col] = list(search_positions[col])\n",
    "            current_mut_count[qc_cutoff[0]]['tri_count'] = 1   \n",
    "\n",
    "        # count mutations at each relative position using groupby\n",
    "        current_mut_sum = dict()\n",
    "        for qc_cutoff in qc_cutoff_list:\n",
    "            current_mut_sum[qc_cutoff[0]] = current_mut_count[qc_cutoff[0]].loc[current_mut_count[qc_cutoff[0]]['Tri'].isin(all_triplets)].groupby(['pos'] + useful_cols + ['Tri']).sum().copy()\n",
    "        \n",
    "    return current_mut_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f21093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_mut_flank(input_pos_df, input_mut_dict = gnomad_slim_all, distance = 500, qc_cutoff_list = [(-np.inf, -np.inf), (-2.774, -0.3), (0, -0.3), (4, -0.3)], left_pos_col = 'start', right_pos_col = 'end', chrom_col = 'chrom', strand_col = 'Strand', strand_names = ('+', '-'), filter_cols = ['RM_distance', 'STR_distance', 'nonSTR_distance', 'within_motif_distance'], filter_distance = 20, useful_cols = [], noAC = False, gc_correction_dict = gc_correction_bytri, gc_nmer = False, ignore_qual = False):\n",
    "   \n",
    "    current_mut_sum_chrom = dict()\n",
    "    for chrom in range(chr_range,23):\n",
    "        current_mut_sum_chrom[chrom] = count_mut_flank_chrom(chrom, input_pos_df.loc[input_pos_df[chrom_col] == chrom].copy(), input_mut_dict, distance = distance, left_pos_col = left_pos_col, right_pos_col = right_pos_col, filter_cols = filter_cols, filter_distance = filter_distance, useful_cols = useful_cols, qc_cutoff_list = qc_cutoff_list, noAC = noAC, gc_nmer = gc_nmer, ignore_qual = ignore_qual)\n",
    "    \n",
    "    current_mut_sum = dict()\n",
    "    if ignore_qual != False:\n",
    "        current_mut_sum[ignore_qual] = pd.concat([current_mut_sum_chrom[chrom][ignore_qual] for chrom in range(chr_range,23)])\n",
    "    else:\n",
    "        for qc_cutoff in qc_cutoff_list:\n",
    "            current_mut_sum[qc_cutoff[0]] = pd.concat([current_mut_sum_chrom[chrom][qc_cutoff[0]] for chrom in range(chr_range,23)])\n",
    "\n",
    "    # apply reverse complement to - strand triplets, mutation counts and positions\n",
    "    if strand_col in useful_cols:\n",
    "        useful_cols.remove(strand_col)\n",
    "        current_mut_sum_strand_F = dict()\n",
    "        current_mut_sum_strand_R = dict()\n",
    "        current_mut_sum_strand_other = dict()\n",
    "        current_mut_sum_bothstrands = dict()\n",
    "        for qc_cutoff in current_mut_sum:\n",
    "            current_mut_sum_strand_other[qc_cutoff] = current_mut_sum[qc_cutoff].loc[~current_mut_sum[qc_cutoff].index.get_level_values(strand_col).isin(strand_names)].copy()\n",
    "            current_mut_sum_strand_other[qc_cutoff] = current_mut_sum_strand_other[qc_cutoff].reset_index().groupby(['pos'] + useful_cols + ['Tri']).sum()\n",
    "            \n",
    "            current_mut_sum_strand_F[qc_cutoff] = current_mut_sum[qc_cutoff].loc[current_mut_sum[qc_cutoff].index.get_level_values(strand_col) == strand_names[0]].copy()\n",
    "            current_mut_sum_strand_F[qc_cutoff] = current_mut_sum_strand_F[qc_cutoff].reset_index().groupby(['pos'] + useful_cols + ['Tri']).sum()\n",
    "\n",
    "            current_mut_sum_strand_R[qc_cutoff] = current_mut_sum[qc_cutoff].loc[current_mut_sum[qc_cutoff].index.get_level_values(strand_col) == strand_names[1]].copy()\n",
    "            current_mut_sum_strand_R[qc_cutoff] = current_mut_sum_strand_R[qc_cutoff].reset_index()\n",
    "            current_mut_sum_strand_R[qc_cutoff]['Tri'] = current_mut_sum_strand_R[qc_cutoff]['Tri'].apply(reverse_complement)\n",
    "            current_mut_sum_strand_R[qc_cutoff]['pos'] = -current_mut_sum_strand_R[qc_cutoff]['pos']\n",
    "            current_mut_sum_strand_R[qc_cutoff] = current_mut_sum_strand_R[qc_cutoff].groupby(['pos'] + useful_cols + ['Tri']).sum()\n",
    "            if gc_nmer == False:\n",
    "                current_mut_sum_strand_R[qc_cutoff].columns = ['T', 'A', 'C', 'G', 'tri_count']\n",
    "                current_mut_sum_strand_R[qc_cutoff] = current_mut_sum_strand_R[qc_cutoff][['A', 'T', 'G', 'C', 'tri_count']]\n",
    "            else:\n",
    "                current_mut_sum_strand_R[qc_cutoff].columns = ['T', 'A', 'C', 'G', 'GC_'+str(gc_nmer), 'tri_count']\n",
    "                current_mut_sum_strand_R[qc_cutoff] = current_mut_sum_strand_R[qc_cutoff][['A', 'T', 'G', 'C', 'GC_'+str(gc_nmer), 'tri_count']]\n",
    "                \n",
    "\n",
    "            current_mut_sum_bothstrands[qc_cutoff] = current_mut_sum_strand_F[qc_cutoff].add(current_mut_sum_strand_R[qc_cutoff], fill_value = 0).add(current_mut_sum_strand_other[qc_cutoff], fill_value = 0)\n",
    "    else:\n",
    "        current_mut_sum_bothstrands = dict()\n",
    "        for qc_cutoff in current_mut_sum:\n",
    "            current_mut_sum_bothstrands[qc_cutoff] = current_mut_sum[qc_cutoff].reset_index().groupby(['pos'] + useful_cols + ['Tri']).sum().fillna(0)\n",
    "    \n",
    "    if gc_nmer != False:\n",
    "        for qc_cutoff in current_mut_sum:\n",
    "            current_mut_sum_bothstrands[qc_cutoff]['GC_'+str(gc_nmer)] = current_mut_sum_bothstrands[qc_cutoff]['GC_'+str(gc_nmer)] / current_mut_sum_bothstrands[qc_cutoff]['tri_count']\n",
    "    \n",
    "    #return current_mut_sum_bothstrands\n",
    "\n",
    "    # reformat output to NNN_N rows x pos columns, and split mut counts and trinucleotide counts\n",
    "    \n",
    "    current_tri_sum = current_mut_sum_bothstrands[qc_cutoff].reset_index().groupby(['pos', 'Tri']).sum().unstack().transpose().fillna(0).astype(int).loc['tri_count'].reindex(all_triplets).copy()\n",
    "\n",
    "    current_mut_sum_reformat = dict()\n",
    "    for qc_cutoff in current_mut_sum:\n",
    "        current_mut_sum_reformat[qc_cutoff] = current_mut_sum_bothstrands[qc_cutoff].reset_index().groupby(['pos', 'Tri']).sum()[['A', 'T', 'G', 'C']].unstack().transpose()\n",
    "        current_mut_sum_reformat[qc_cutoff].index = current_mut_sum_reformat[qc_cutoff].index.get_level_values('Tri') + '_' + current_mut_sum_reformat[qc_cutoff].index.get_level_values(0)\n",
    "        current_mut_sum_reformat[qc_cutoff] = current_mut_sum_reformat[qc_cutoff].reindex(triplet_mutations_und)\n",
    "        current_mut_sum_reformat[qc_cutoff].index.name = 'Mut'\n",
    "        \n",
    "    if gc_nmer == False:\n",
    "        return current_mut_sum_reformat.copy(), current_tri_sum.copy()\n",
    "\n",
    "    # GC window correction\n",
    "\n",
    "    else:\n",
    "        current_mut_sum_GCcorrect = dict()\n",
    "        \n",
    "        current_gc_by_pos = current_mut_sum_bothstrands[qc_cutoff].reset_index().groupby(['pos']).sum()['GC_'+str(gc_nmer)]\n",
    "        \n",
    "        for qc_cutoff in current_mut_sum:\n",
    "            # reformat output\n",
    "            current_mut_sum_GCcorrect[qc_cutoff] = current_mut_sum_bothstrands[qc_cutoff].reset_index().groupby(['pos', 'GC_'+str(gc_nmer), 'Tri']).sum()[['A', 'T', 'G', 'C']].unstack().transpose()\n",
    "            current_mut_sum_GCcorrect[qc_cutoff].index = current_mut_sum_GCcorrect[qc_cutoff].index.get_level_values('Tri') + '_' + current_mut_sum_GCcorrect[qc_cutoff].index.get_level_values(0)\n",
    "            current_mut_sum_GCcorrect[qc_cutoff] = current_mut_sum_GCcorrect[qc_cutoff].reindex(triplet_mutations_und)\n",
    "            current_mut_sum_GCcorrect[qc_cutoff].index.name = 'Mut'\n",
    "            # apply GC correction    \n",
    "            current_mut_sum_GCcorrect[qc_cutoff] = current_mut_sum_GCcorrect[qc_cutoff].transpose().fillna(0)\n",
    "            current_mut_sum_GCcorrect[qc_cutoff] = current_mut_sum_GCcorrect[qc_cutoff].mul(np.array(gc_correction_dict[qc_cutoff].iloc[np.searchsorted(gc_correction_dict[qc_cutoff].index, current_mut_sum_GCcorrect[qc_cutoff].index.get_level_values('GC_'+str(gc_nmer)))])).set_index(current_mut_sum_GCcorrect[qc_cutoff].index.get_level_values('pos'))\n",
    "            current_mut_sum_GCcorrect[qc_cutoff] = current_mut_sum_GCcorrect[qc_cutoff].groupby(current_mut_sum_GCcorrect[qc_cutoff].index).sum().transpose() \n",
    "                \n",
    "        return current_mut_sum_reformat.copy(), current_tri_sum.copy(), current_mut_sum_GCcorrect.copy(), current_gc_by_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5c9f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate normalized mutation frequency and binomial proportion confidence intervals\n",
    "def mut_norm_conf(count_input, noAC = False, genome_AC_freq_current = genome_AC_freq_all, genome_count_freq_current = None, n_genomes = gnomad_n_genomes, min_count = 25, normtorandom = False, random_normaverage = None, tri_subset = triplet_mutations_und, do_binconf = True, output_div = False, summary_cols = False, gc_correct = False, rolling = False, window_size = 10, snvindel = 'snv'):\n",
    "    mut_count_current = dict(); mut_freq = dict(); mut_div = dict(); mut_norm = dict(); mut_weights = dict(); mut_binconf_low = dict(); mut_binconf_high = dict(); mut_freq_expected = dict()\n",
    "\n",
    "    tri_count_in = count_input[1].copy()\n",
    "    if gc_correct == False:\n",
    "        mut_count_in = count_input[0].copy()\n",
    "    else:\n",
    "        mut_count_in = count_input[2].copy()\n",
    "    \n",
    "    if noAC == False:\n",
    "        genome_mut_frequencies = genome_AC_freq_current.reindex(tri_subset)\n",
    "    else:\n",
    "        genome_mut_frequencies = genome_count_freq_current.reindex(tri_subset)\n",
    "        \n",
    "    # Rolling windows\n",
    "    if rolling == True:\n",
    "        tri_count_in = tri_count_in.rolling(window_size, center=True, axis=1).sum()\n",
    "    \n",
    "    # Put trinucleotide counts in trinucleotide mutation format\n",
    "    if snvindel == 'snv':\n",
    "        tri_count_mut = tri_count_in.loc[flatten([[mut]*3 for mut in all_triplets])].copy()\n",
    "        tri_count_mut.index = triplet_mutations_und\n",
    "    if snvindel == 'indel':\n",
    "        tri_count_mut = pd.concat([tri_count_in, tri_count_in])\n",
    "        tri_count_mut.index = triplet_mutations_und_indel\n",
    "    tri_count_mut = tri_count_mut.reindex(tri_subset)\n",
    "    if summary_cols == True:\n",
    "        tri_count_mut.columns = tri_count_mut.columns.astype(str)\n",
    "    # Filter out positions with very low trinucleotide counts\n",
    "    tri_count_mut_sum = tri_count_mut.sum(axis=0)\n",
    "    tri_count_mut_sum = tri_count_mut_sum.reindex(mut_count_in[list(mut_count_in)[0]].columns)\n",
    "    tri_count_mut = tri_count_mut[tri_count_mut_sum.loc[tri_count_mut_sum > (min_count*3)].index]\n",
    "    \n",
    "    for qc_cutoff in mut_count_in:\n",
    "        mut_count_current[qc_cutoff] = mut_count_in[qc_cutoff].reindex(tri_subset).copy()\n",
    "        if summary_cols == True:\n",
    "            mut_count_current[qc_cutoff].columns = mut_count_current[qc_cutoff].columns.astype(str)\n",
    "        # Rolling windows\n",
    "        if rolling == True:\n",
    "            mut_count_current[qc_cutoff] = mut_count_current[qc_cutoff].rolling(window_size, center=True, axis=1).sum()\n",
    "        # Filter out positions with very low trinucleotide counts\n",
    "        mut_count_current[qc_cutoff] = mut_count_current[qc_cutoff][tri_count_mut.columns].fillna(0)#.sort_index()\n",
    "        # Calculate mutation frequencies\n",
    "        mut_freq[qc_cutoff] = mut_count_current[qc_cutoff].div(tri_count_mut) / n_genomes\n",
    "        mut_div[qc_cutoff] = mut_freq[qc_cutoff].div(genome_mut_frequencies[qc_cutoff], axis=0)#.reindex(tri_subset)\n",
    "        # Calculate weighted average of mutation frequencies based on trinucleotide counts        \n",
    "        mut_norm[qc_cutoff] =  pd.Series(np.ma.average(np.ma.MaskedArray(mut_div[qc_cutoff], mask = np.isnan(tri_count_mut.replace(0,np.nan))), weights = n_genomes * tri_count_mut.astype(np.uint64), axis=0), index = mut_div[qc_cutoff].columns)\n",
    "        if normtorandom == True:\n",
    "            mut_norm[qc_cutoff] = mut_norm[qc_cutoff] / random_normaverage[qc_cutoff]\n",
    "        # Expected mutation frequency based on trinucleotide counts\n",
    "        genome_mut_freq_reshape = np.array(list(genome_mut_frequencies[qc_cutoff])*len(tri_count_mut.columns))\n",
    "        genome_mut_freq_reshape.shape = (len(tri_count_mut.columns),len(genome_mut_frequencies))\n",
    "        genome_mut_freq_reshape = genome_mut_freq_reshape.transpose()\n",
    "        mut_freq_expected[qc_cutoff] = pd.Series(np.ma.average(np.ma.MaskedArray(genome_mut_freq_reshape, mask = np.isnan(tri_count_mut.replace(0,np.nan))), weights = n_genomes * tri_count_mut.astype(np.uint64), axis=0), index = mut_div[qc_cutoff].columns)\n",
    "        \n",
    "        if do_binconf == True:\n",
    "            # Calculate binomial proportion confidence intervals per trincleotide mutation\n",
    "            binconf_current = binconf(mut_count_current[qc_cutoff].sum(), (tri_count_mut.sum()) * n_genomes)\n",
    "            mut_binconf_low[qc_cutoff] = pd.Series(binconf_current[0], index = mut_freq[qc_cutoff].columns)\n",
    "            mut_binconf_high[qc_cutoff] = pd.Series(binconf_current[1], index = mut_freq[qc_cutoff].columns)\n",
    "            # Calculate weighted average of binomial proportion confidence intervals based on trinucleotide counts\n",
    "            mut_weights[qc_cutoff] = pd.Series(np.ma.average(np.ma.MaskedArray(mut_freq[qc_cutoff], mask = np.isnan(tri_count_mut.replace(0,np.nan))), weights = n_genomes * tri_count_mut.astype(np.uint64), axis=0), index = mut_freq[qc_cutoff].columns)\n",
    "                \n",
    "            mut_binconf_low[qc_cutoff] = mut_norm[qc_cutoff] * (mut_binconf_low[qc_cutoff] / mut_weights[qc_cutoff])\n",
    "            mut_binconf_high[qc_cutoff] = mut_norm[qc_cutoff] * (mut_binconf_high[qc_cutoff] / mut_weights[qc_cutoff])\n",
    "\n",
    "    if output_div == True:\n",
    "        return mut_div.copy(), tri_count_mut.copy(), mut_count_current.copy(), mut_freq.copy(), genome_mut_frequencies.copy()\n",
    "    else:        \n",
    "        if do_binconf == True:\n",
    "            return mut_norm.copy(), mut_binconf_low.copy(), mut_binconf_high.copy(), mut_freq_expected.copy()\n",
    "        else:\n",
    "            return mut_norm.copy(), mut_freq_expected.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974a8578",
   "metadata": {},
   "source": [
    "## Count and analyze flanking mutations and trinucleotides <a name=\"mutation_surrounding_analysis\"></a>\n",
    "    Make new directory \"./analysis/temp/\" for output of mutation counts\n",
    "\n",
    "[Return to Table of Contents](#TOC)\n",
    "\n",
    "### Random sequences <a name=\"mutation_surrounding_analysis_random\"></a>\n",
    "- Measure mutation frequency surrounding random non-motif sequences \n",
    "- Used to normalize for the effect of uneven distribution of low quality scores \n",
    "\n",
    "[Return to Table of Contents](#TOC)\n",
    "\n",
    "#### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad69029",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seq = pd.read_csv('./custom_db/random_sequences_set1_chr1-22.csv.gz', compression = 'gzip')\n",
    "random_seq_set2 = pd.read_csv('./custom_db/random_sequences_set2_chr1-22.csv.gz', compression = 'gzip')\n",
    "random_seq = pd.concat([random_seq, random_seq_set2])\n",
    "# assign random strand\n",
    "random_seq['Strand'] = np.random.randint(0,2, size=len(random_seq))\n",
    "random_seq['Strand'] = random_seq['Strand'].replace(0, '-').replace(1,'+')\n",
    "random_seq = distance_within_df(random_seq, 'within_motif')\n",
    "random_seq = random_seq.drop_duplicates(subset = ['chrom', 'start']).copy()\n",
    " \n",
    "random_seq = random_seq.loc[random_seq[['STR_distance_min', 'nonSTR_distance_min', 'within_motif_distance_min', 'RM_distance_min']].fillna(0).min(axis=1) > 20].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534da8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Larger set of random positions\n",
    "\n",
    "random_seq_larger = pd.read_csv('./custom_db/random_sequences_set3_chr1-22.csv.gz', compression = 'gzip')\n",
    "random_seq_larger_set2 = pd.read_csv('./custom_db/random_sequences_set4_chr1-22.csv.gz', compression = 'gzip')\n",
    "random_seq_larger = pd.concat([random_seq_larger, random_seq_larger_set2])\n",
    "# assign random strand\n",
    "random_seq_larger['Strand'] = np.random.randint(0,2, size=len(random_seq_larger))\n",
    "random_seq_larger['Strand'] = random_seq_larger['Strand'].replace(0, '-').replace(1,'+')\n",
    "random_seq_larger = distance_within_df(random_seq_larger, 'within_motif')\n",
    "random_seq_larger = random_seq_larger.drop_duplicates(subset = ['chrom', 'start']).copy()\n",
    "\n",
    "random_seq_larger = random_seq_larger.loc[random_seq_larger[['STR_distance_min', 'nonSTR_distance_min', 'within_motif_distance_min', 'RM_distance_min']].fillna(0).min(axis=1) > 20].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e3f66b",
   "metadata": {},
   "source": [
    "#### Count flanking mutations and trinucleotides, then normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44faf8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_random_all = count_mut_flank(random_seq, useful_cols = ['Strand'], gc_nmer = 51)\n",
    "\n",
    "norm_random_all = mut_norm_conf(count_random_all, gc_correct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfddafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median SNV frequencies for each QC filter, used to normalize all later mutation frequencies\n",
    "normtorandom_all = pd.Series([norm_random_all[0][qc_cutoff].loc[-50:50].median() for qc_cutoff in norm_random_all[0]], index = list(norm_random_all[0]))\n",
    "normtorandom_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464a269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_random_simple_freq = count_random_all[0][-np.inf].sum() / count_random_all[1].sum()\n",
    "normtorandom_simplefreq = norm_random_simple_freq.loc[-50:50].median()\n",
    "normtorandom_simplefreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebd463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_random_all_normtorandom = mut_norm_conf(count_random_all, normtorandom = True, random_normaverage = normtorandom_all, gc_correct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aec204",
   "metadata": {},
   "source": [
    "#### Plot mutation frequency surrounding random sequences\n",
    "- not used in paper, only used to confirm flat line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb65c7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqslod_list = [-np.inf, -2.774, 0, 4]\n",
    "QC_colors = make_colorscale(vqslod_list)\n",
    "default_colors = make_default_colors(vqslod_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cbfdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutnorm_all_binconf_fig = go.Figure()\n",
    "for qc_cutoff in vqslod_list:\n",
    "    mutnorm_all_binconf_fig.add_trace(go.Scatter(name = qc_cutoff, legendgroup = qc_cutoff, showlegend=False, fill=None, x = norm_random_all[2][qc_cutoff].dropna().index, y = norm_random_all[2][qc_cutoff].dropna(), mode = 'lines', line = dict(width = 0, color = QC_colors[0][qc_cutoff])))\n",
    "    mutnorm_all_binconf_fig.add_trace(go.Scatter(name = qc_cutoff, legendgroup = qc_cutoff, fill='tonexty', fillcolor = QC_colors[1][qc_cutoff], x = norm_random_all[0][qc_cutoff].dropna().index, y = norm_random_all[0][qc_cutoff].dropna(), mode = 'lines', line = dict(width = 2, color = QC_colors[0][qc_cutoff])))\n",
    "    mutnorm_all_binconf_fig.add_trace(go.Scatter(name = qc_cutoff, legendgroup = qc_cutoff, showlegend=False, fill='tonexty', fillcolor = QC_colors[1][qc_cutoff], x = norm_random_all[1][qc_cutoff].dropna().index, y = norm_random_all[1][qc_cutoff].dropna(), mode = 'lines', line = dict(width = 0, color = QC_colors[0][qc_cutoff])))\n",
    "mutnorm_all_binconf_fig.update_layout(title = 'random')\n",
    "mutnorm_all_binconf_fig.update_xaxes(range = [-500,500])\n",
    "#mutnorm_all_binconf_fig.update_yaxes(range = [0,pd.concat(norm_random_all[0], axis=1).max(axis=1).loc[-250:250].max()])\n",
    "mutnorm_all_binconf_fig.update_yaxes(zeroline = False)\n",
    "mutnorm_all_binconf_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e90f223",
   "metadata": {},
   "source": [
    "### Repeat motifs <a name=\"mutation_surrounding_analysis_repeat\"></a>\n",
    "- Measure mutation frequency surrounding repeat motif sequences \n",
    "\n",
    "[Return to Table of Contents](#TOC)\n",
    "\n",
    "#### Load motif database and define categories to analyze <a name=\"mutation_surrounding_analysis_categories\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d823117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load motif database\n",
    "all_motifs_unique = pd.read_pickle('./custom_db/all_motifs_unique_chr'+str(chr_range)+'-22.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b4fb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STR motifs with enough power to analyze, symmetric and asymmetric STR motifs\n",
    "repeats_highpower_asym = pd.Series([reverse_complement(repeat) for repeat in ['A', 'C',  'AC', 'AG', 'ACC', 'AAT', 'AAC', 'AAG', 'AGG', 'ATC', 'AGC', 'AAAT']], index = ['A', 'C',  'AC', 'AG', 'ACC', 'AAT', 'AAC', 'AAG', 'AGG', 'ATC', 'AGC', 'AAAT'])\n",
    "repeats_highpower_sym = ['AT', 'GC']\n",
    "repeats_highpower = list(repeats_highpower_asym.index) + list(repeats_highpower_asym) + repeats_highpower_sym\n",
    "\n",
    "# All frames for each STR motif\n",
    "def repeat_variations(current_repeat):\n",
    "    fwd_repeats = [current_repeat[start:] + current_repeat[:start - len(current_repeat)] for start in range(len(current_repeat))]\n",
    "    rc_repeats = [reverse_complement(repeat) for repeat in fwd_repeats]\n",
    "    return fwd_repeats, rc_repeats, fwd_repeats + rc_repeats\n",
    "repeats_highpower_allframes = list(set(flatten([repeat_variations(repeat)[2] for repeat in repeats_highpower])))\n",
    "\n",
    "# Restrict STR database to highpower motifs\n",
    "all_STRs_unique = all_motifs_unique.loc[(all_motifs_unique['Type'] == 'STR') & (all_motifs_unique['repeat'].isin(repeats_highpower_allframes))].dropna(axis = 1, how = 'all').copy()\n",
    "\n",
    "# Fix annoying naming of repeat frames which were not necesarily paired reverse complements\n",
    "all_STRs_unique['repeat'] = [repeat if repeat in repeats_highpower else repeat_variations(repeat)[0][1] if repeat_variations(repeat)[0][1] in repeats_highpower else repeat_variations(repeat)[0][2] if repeat_variations(repeat)[0][2] in repeats_highpower else repeat_variations(repeat)[0][3] if repeat_variations(repeat)[0][3] in repeats_highpower else np.nan for repeat in all_STRs_unique['repeat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9202a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove STRs with interruptions\n",
    "perfect_STRs = all_STRs_unique.loc[all_STRs_unique['status'] == 'perfect'].copy()\n",
    "\n",
    "# Remove very short STRs\n",
    "long_STRs = dict()\n",
    "for repeat in repeats_highpower:\n",
    "    long_STRs[repeat] = perfect_STRs.loc[(perfect_STRs['repeat'].isin(repeat_variations(repeat)[2])) & (perfect_STRs['length'] > perfect_STRs.loc[(perfect_STRs['repeat'].isin(repeat_variations(repeat)[2]))]['length'].quantile(0.8))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2360d82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverted repeats\n",
    "all_IRs = all_motifs_unique.loc[(all_motifs_unique['Type'] == 'IR')].dropna(axis = 1, how = 'all').copy()\n",
    "long_IRs = all_IRs.loc[all_IRs['stem_len'] > all_IRs['stem_len'].quantile(0.8)].copy()\n",
    "very_long_IRs = all_IRs.loc[all_IRs['stem_len'] > all_IRs['stem_len'].quantile(0.95)].copy()\n",
    "\n",
    "# Inverted repeats binned by on G/C content\n",
    "AT80_IRs = long_IRs.loc[(long_IRs['Sequence'].str.count('A') + long_IRs['Sequence'].str.count('T'))  / long_IRs['length'] > 0.8].copy()\n",
    "AT40_IRs = long_IRs.loc[(long_IRs['Sequence'].str.count('A') + long_IRs['Sequence'].str.count('T'))  / long_IRs['length'] < 0.4].copy()\n",
    "\n",
    "# IRs with shorter loop length\n",
    "long_IRs_loop10 = long_IRs.loc[long_IRs['spacer'] < 11]\n",
    "\n",
    "# Mirror repeats\n",
    "all_MRs = all_motifs_unique.loc[(all_motifs_unique['Type'] == 'MR')].dropna(axis = 1, how = 'all').copy()\n",
    "long_MRs = all_MRs.loc[all_MRs['stem_len'] > all_MRs['stem_len'].quantile(0.8)].copy()\n",
    "very_long_MRs = all_MRs.loc[all_MRs['stem_len'] > all_MRs['stem_len'].quantile(0.95)].copy()\n",
    "\n",
    "# Mirror repeats binned by homopurine/homopyrimidine status\n",
    "non_homopurine_MRs = all_MRs.loc[~(((all_MRs['seq_L'].str.count('A') + all_MRs['seq_L'].str.count('G') == 0) & (all_MRs['seq_R'].str.count('A') + all_MRs['seq_R'].str.count('G') == 0)) | ((all_MRs['seq_L'].str.count('T') + all_MRs['seq_L'].str.count('C') == 0) & (all_MRs['seq_R'].str.count('T') + all_MRs['seq_R'].str.count('C') == 0)))].copy()\n",
    "homopurine_MRs = dict()\n",
    "homopurine_MRs['+'] = all_MRs.loc[(all_MRs['seq_L'].str.count('A') + all_MRs['seq_L'].str.count('G') == 0) & (all_MRs['seq_R'].str.count('A') + all_MRs['seq_R'].str.count('G') == 0)].copy()\n",
    "homopurine_MRs['-'] = all_MRs.loc[(all_MRs['seq_L'].str.count('T') + all_MRs['seq_L'].str.count('C') == 0) & (all_MRs['seq_R'].str.count('T') + all_MRs['seq_R'].str.count('C') == 0)].copy()\n",
    "homopurine_MRs['+']['Strand'] = '+'; homopurine_MRs['+']['Strand'] = '-'\n",
    "homopurine_MRs = pd.concat(homopurine_MRs); homopurine_MRs.index = homopurine_MRs.index.get_level_values(1)\n",
    "perfect_homopurine_MRs = homopurine_MRs.loc[homopurine_MRs['#MM'] == 0].copy()\n",
    "\n",
    "# MRs with shorter loop length\n",
    "long_MRs_loop10 = long_MRs.loc[long_MRs['spacer'] < 11]\n",
    "\n",
    "# Direct repeats\n",
    "all_DRs = all_motifs_unique.loc[(all_motifs_unique['Type'] == 'DR')].dropna(axis = 1, how = 'all').copy()\n",
    "long_DRs = all_DRs.loc[all_DRs['stem_len'] > all_DRs['stem_len'].quantile(0.8)].copy()\n",
    "very_long_DRs = all_DRs.loc[all_DRs['stem_len'] > all_DRs['stem_len'].quantile(0.95)].copy()\n",
    "perfect_long_DRs = long_DRs.loc[long_DRs['#MM'] ==0].copy()\n",
    "\n",
    "# DRs with shorter loop length\n",
    "long_DRs_loop10 = long_DRs.loc[long_DRs['spacer'] < 11]\n",
    "\n",
    "# Z-DNA motifs\n",
    "all_ZDNAs = all_motifs_unique.loc[(all_motifs_unique['Type'] == 'ZDNA')].dropna(axis = 1, how = 'all').copy()\n",
    "long_ZDNAs = all_ZDNAs.loc[all_ZDNAs['length'] > all_ZDNAs['length'].quantile(0.8)].copy()\n",
    "ZDNAs_GY = all_ZDNAs.dropna(subset = ['Strand'])\n",
    "\n",
    "# G4 motifs\n",
    "all_G4s = all_motifs_unique.loc[all_motifs_unique['Type'] == 'G4'].dropna(axis = 1, how = 'all').copy()\n",
    "K_G4s = all_G4s.loc[all_G4s['status'].isin(['K+', 'both'])].copy()\n",
    "PDS_G4s = all_G4s.loc[all_G4s['status'] == 'PDS'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b303c4d1",
   "metadata": {},
   "source": [
    "### CG repeats in/outside of CpG islands <a name=\"mutation_surrounding_CGI\"></a>\n",
    "\n",
    "#### Download CpG island map <a name=\"mutation_surrounding_CGI_download\"></a>\n",
    "- Download CpG island map from UCSC Table Browser: https://genome.ucsc.edu/cgi-bin/hgTables\n",
    "- Select options:\n",
    "    - assembly: Dec 2013 (GRCh38/hg38)\n",
    "    - group: Regulation\n",
    "    - track: CpG Islands\n",
    "    - region: genome\n",
    "    - output format: all fields from selected table\n",
    "    - output filename: hg38_cpgislands.bed\n",
    "    - file type returned: gzip compressed\n",
    "- Place .bed.gz file in subfolder './hg38/'\n",
    "\n",
    "#### Measure distance between CG motifs and CpG islands <a name=\"mutation_surrounding_CGI_distance\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ba9c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpgislands = pd.read_csv('./hg38/hg38_cpgislands.bed.gz', compression = 'gzip', sep = '\\t', usecols = [1,2,3])\n",
    "cpgislands['chrom'] = [chrom[3:] for chrom in cpgislands['chrom']]\n",
    "cpgislands = cpgislands.loc[cpgislands['chrom'].isin([str(chrom) for chrom in range(chr_range,23)])]\n",
    "cpgislands['chrom'] = cpgislands['chrom'].astype(int)\n",
    "cpgislands.columns = ['chrom', 'start', 'end']\n",
    "# CpG island \"shores\" are within 2kb of CpG islands\n",
    "cpgislands['start'] = cpgislands['start'] - 2000\n",
    "cpgislands['end'] = cpgislands['end'] + 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a1613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure distance between CG motifs and CpG islands\n",
    "STRs_CG = measure_distance(long_STRs['GC'].copy(), cpgislands, 'CGI')\n",
    "STRs_CG = STRs_CG.loc[STRs_CG['CGI_distance_min'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a633e3a4",
   "metadata": {},
   "source": [
    "### Count mutations flanking repeats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f09099",
   "metadata": {},
   "source": [
    "#### STRs <a name=\"mutation_surrounding_analysis_str\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daa895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_long_STRs = dict()\n",
    "\n",
    "for repeat in repeats_highpower_asym.index:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    count_long_STRs[repeat] = count_mut_flank(long_STRs[repeat], useful_cols = ['Strand'], gc_nmer = 51)\n",
    "for repeat in repeats_highpower_sym:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    count_long_STRs[repeat] = count_mut_flank(long_STRs[repeat], gc_nmer = 51)\n",
    "\n",
    "count_long_STRs['GC_noCGI'] = count_mut_flank(STRs_CG, filter_cols = ['RM_distance', 'STR_distance', 'nonSTR_distance', 'within_motif_distance', 'CGI_distance'], gc_nmer = 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce15403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_long_STRs = dict()\n",
    "for repeat in count_long_STRs:\n",
    "    print('\\r' + '                               ' + repeat, end='  ')\n",
    "    norm_long_STRs[repeat] = mut_norm_conf(count_long_STRs[repeat], normtorandom = True, random_normaverage = normtorandom_all, do_binconf = True, gc_correct = True)\n",
    "\n",
    "norm_long_STRs['GC_noCGI'] = mut_norm_conf(count_long_STRs['GC_noCGI'], min_count = 10, normtorandom = True, random_normaverage = normtorandom_all, do_binconf = True, gc_correct = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c495877",
   "metadata": {},
   "source": [
    "#### Inverted repeats <a name=\"mutation_surrounding_analysis_ir\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217ef224",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_IRs = dict()\n",
    "for motif, name in zip([long_IRs, very_long_IRs, AT80_IRs, AT40_IRs, long_IRs_loop10], ['long_IRs', 'very_long_IRs', 'AT80_IRs', 'AT40_IRs', 'long_IRs_loop10']):\n",
    "    print('\\r' + '                     ' + name, end='  ')\n",
    "    count_IRs[name] = count_mut_flank(motif, gc_nmer = 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a63367",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_IRs = dict()\n",
    "for name in count_IRs:\n",
    "    print('\\r' + '                               ' + name, end='  ')\n",
    "    norm_IRs[name] = mut_norm_conf(count_IRs[name], normtorandom = True, random_normaverage = normtorandom_all, do_binconf = True, gc_correct = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaa9a7d",
   "metadata": {},
   "source": [
    "#### Mirror repeats <a name=\"mutation_surrounding_analysis_mr\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e933d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_MRs = dict()\n",
    "for motif, name in zip([long_MRs, very_long_MRs, non_homopurine_MRs, long_MRs_loop10], ['long_MRs', 'very_long_MRs', 'non_homopurine_MRs', 'long_MRs_loop10']):\n",
    "    print('\\r' + '                     ' + name, end='  ')\n",
    "    count_MRs[name] = count_mut_flank(motif, gc_nmer = 51)\n",
    "for motif, name in zip([homopurine_MRs], ['homopurine_MRs']):\n",
    "    print('\\r' + '                     ' + name, end='  ')\n",
    "    count_MRs[name] = count_mut_flank(motif, useful_cols = ['Strand'], gc_nmer = 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7e5068",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_MRs = dict()\n",
    "for name in count_MRs:\n",
    "    print('\\r' + '                               ' + name, end='  ')\n",
    "    norm_MRs[name] = mut_norm_conf(count_MRs[name], normtorandom = True, random_normaverage = normtorandom_all, do_binconf = True, gc_correct = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5df3ab",
   "metadata": {},
   "source": [
    "#### Direct repeats <a name=\"mutation_surrounding_analysis_dr\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3b33d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_DRs = dict()\n",
    "for motif, name in zip([long_DRs, very_long_DRs, perfect_long_DRs, long_DRs_loop10], ['long_DRs', 'very_long_DRs', 'perfect_long_DRs', 'long_DRs_loop10']):\n",
    "    print('\\r' + '                     ' + name, end='  ')\n",
    "    count_DRs[name] = count_mut_flank(motif, gc_nmer = 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fb1035",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_DRs = dict()\n",
    "for name in count_DRs:\n",
    "    print('\\r' + '                               ' + name, end='  ')\n",
    "    norm_DRs[name] = mut_norm_conf(count_DRs[name], normtorandom = True, random_normaverage = normtorandom_all, do_binconf = True, gc_correct = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3275fec",
   "metadata": {},
   "source": [
    "#### Z-DNA motifs <a name=\"mutation_surrounding_analysis_zdna\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea1ab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_ZDNAs = dict()\n",
    "for motif, name in zip([all_ZDNAs, long_ZDNAs], ['all_ZDNAs', 'long_ZDNAs']):\n",
    "    print('\\r' + '                     ' + name, end='  ')\n",
    "    count_ZDNAs[name] = count_mut_flank(motif, gc_nmer = 51)\n",
    "for motif, name in zip([ZDNAs_GY], ['ZDNAs_GY']):\n",
    "    print('\\r' + '                     ' + name, end='  ')\n",
    "    count_ZDNAs[name] = count_mut_flank(motif, useful_cols = ['Strand'], strand_names = ('G', 'C'), gc_nmer = 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b5b976",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_ZDNAs = dict()\n",
    "for name in count_ZDNAs:\n",
    "    print('\\r' + '                               ' + name, end='  ')\n",
    "    norm_ZDNAs[name] = mut_norm_conf(count_ZDNAs[name], normtorandom = True, random_normaverage = normtorandom_all, do_binconf = True, gc_correct = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e556f69d",
   "metadata": {},
   "source": [
    "#### G4 motifs <a name=\"mutation_surrounding_analysis_g4\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a488e946",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_G4s = dict()\n",
    "for motif, name in zip([K_G4s, PDS_G4s], ['K_G4s', 'PDS_G4s']):\n",
    "    print('\\r' + '                     ' + name, end='  ')\n",
    "    count_G4s[name] = count_mut_flank(motif, useful_cols = ['Strand'], gc_nmer = 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a559cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_G4s = dict()\n",
    "for name in count_G4s:\n",
    "    print('\\r' + '                               ' + name, end='  ')\n",
    "    norm_G4s[name] = mut_norm_conf(count_G4s[name], normtorandom = True, random_normaverage = normtorandom_all, do_binconf = True, gc_correct = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd069371",
   "metadata": {},
   "source": [
    "### Save / load mutation counts  <a name=\"mutation_surrounding_analysis_saveload\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ef7666",
   "metadata": {},
   "source": [
    "#### Save/load mutation counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4c8493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save temporary output of the mutation counts\n",
    "with open('./analysis/temp/long_STRs_flank_ACcorrect_mutcount_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(count_long_STRs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./analysis/temp/IRs_flank_ACcorrect_mutcount_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(count_IRs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./analysis/temp/DRs_flank_ACcorrect_mutcount_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(count_DRs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./analysis/temp/MRs_flank_ACcorrect_mutcount_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(count_MRs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./analysis/temp/ZDNAs_flank_ACcorrect_mutcount_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(count_ZDNAs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./analysis/temp/G4s_flank_ACcorrect_mutcount_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(count_G4s, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./analysis/temp/random_flank_ACcorrect_mutcount_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(count_random_all, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6756e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load temporary output of the mutation counts\n",
    "with open('./analysis/temp/long_STRs_flank_ACcorrect_mutcount_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    count_long_STRs = pickle.load(handle)\n",
    "with open('./analysis/temp/IRs_flank_ACcorrect_mutcount_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    count_IRs = pickle.load(handle)\n",
    "with open('./analysis/temp/DRs_flank_ACcorrect_mutcount_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    count_DRs = pickle.load(handle)\n",
    "with open('./analysis/temp/MRs_flank_ACcorrect_mutcount_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    count_MRs = pickle.load(handle)\n",
    "with open('./analysis/temp/ZDNAs_flank_ACcorrect_mutcount_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    count_ZDNAs = pickle.load(handle)\n",
    "with open('./analysis/temp/G4s_flank_ACcorrect_mutcount_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    count_G4s = pickle.load(handle)\n",
    "with open('./analysis/temp/random_flank_ACcorrect_mutcount_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    count_random_all = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b69bc7",
   "metadata": {},
   "source": [
    "#### Save/load normalized mutation rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fed07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save temporary output of the mutation counts\n",
    "\n",
    "flanking_norm_all = dict()\n",
    "flanking_norm_all['STR'] = norm_long_STRs.copy()\n",
    "flanking_norm_all['IR'] = norm_IRs.copy()\n",
    "flanking_norm_all['DR'] = norm_DRs.copy()\n",
    "flanking_norm_all['MR'] = norm_MRs.copy()\n",
    "flanking_norm_all['ZDNA'] = norm_ZDNAs.copy()\n",
    "flanking_norm_all['G4'] = norm_G4s.copy()\n",
    "flanking_norm_all['random'] = {'random': norm_random_all_normtorandom}.copy()\n",
    "flanking_norm_all['random_nonorm'] = {'random_nonorm': norm_random_all}.copy()\n",
    "\n",
    "with open('./analysis/temp/flank_norm_all_ACcorrect_GCcorrected_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(flanking_norm_all, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f49c904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load temporary output of the mutation counts\n",
    "with open('./analysis/temp/flank_norm_all_ACcorrect_GCcorrected_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    flanking_norm_all = pickle.load(handle)\n",
    "\n",
    "# Median SNV frequencies for each QC filter, used to normalize all later mutation frequencies\n",
    "normtorandom_all = pd.Series([flanking_norm_all['random_nonorm']['random_nonorm'][0][qc_cutoff].loc[-50:50].median() for qc_cutoff in flanking_norm_all['random']['random'][0]], index = list(flanking_norm_all['random']['random'][0]))\n",
    "norm_random_simple_freq = count_random_all[0][-np.inf].sum() / count_random_all[1].sum()\n",
    "normtorandom_simplefreq = norm_random_simple_freq.loc[-50:50].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c899a60",
   "metadata": {},
   "source": [
    "## Count de novo mutations surrounding motifs  <a name=\"mutation_surrounding_denovo\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e1b5b3",
   "metadata": {},
   "source": [
    "#### Random sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497133f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_random_denovo = count_mut_flank(random_seq_larger, useful_cols = ['Strand'], input_mut_dict = denovo_slim_reformat, ignore_qual = 'denovo')\n",
    "\n",
    "norm_random_denovo = mut_norm_conf(count_random_denovo, genome_AC_freq_current = denovo_freq_all, n_genomes = denovo_n_genomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11de94bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median SNV frequencies for each QC filter, used to normalize all later mutation frequencies\n",
    "normtorandom_denovo = pd.Series([norm_random_denovo[0][qc_cutoff].loc[-50:50].median() for qc_cutoff in norm_random_denovo[0]], index = list(norm_random_denovo[0]))\n",
    "normtorandom_denovo\n",
    "\n",
    "norm_random_simple_freq = count_random_denovo[0]['denovo'].sum() / count_random_denovo[1].sum()\n",
    "normtorandom_simplefreq = norm_random_simple_freq.loc[-50:50].median()\n",
    "normtorandom_simplefreq\n",
    "\n",
    "norm_random_denovo_normtorandom = mut_norm_conf(count_random_denovo, normtorandom = True, n_genomes = denovo_n_genomes, random_normaverage = normtorandom_denovo, genome_AC_freq_current = denovo_freq_all, rolling = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7857b4",
   "metadata": {},
   "source": [
    "#### STRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab2349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_long_STRs_denovo = dict()\n",
    "\n",
    "for repeat in ['A', 'C', 'AG', 'AC']:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    count_long_STRs_denovo[repeat] = count_mut_flank(long_STRs[repeat], useful_cols = ['Strand'], input_mut_dict = denovo_slim_reformat, ignore_qual = 'denovo')\n",
    "\n",
    "for repeat in ['AT']:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    count_long_STRs_denovo[repeat] = count_mut_flank(long_STRs[repeat], input_mut_dict = denovo_slim_reformat, ignore_qual = 'denovo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1ad61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_long_STRs_denovo = dict()\n",
    "for repeat in count_long_STRs_denovo:\n",
    "    print('\\r' + '                               ' + repeat, end='  ')\n",
    "    norm_long_STRs_denovo[repeat] = mut_norm_conf(count_long_STRs_denovo[repeat], normtorandom = True, random_normaverage = normtorandom_denovo, do_binconf = True, genome_AC_freq_current = denovo_freq_all, n_genomes = denovo_n_genomes, rolling=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0aa898",
   "metadata": {},
   "source": [
    "#### G4 motifs <a name=\"mutation_surrounding_analysis_g4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a0b8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_G4s_denovo = dict()\n",
    "count_G4s_denovo['K_G4s'] = count_mut_flank(K_G4s, useful_cols = ['Strand'], input_mut_dict = denovo_slim_reformat, ignore_qual = 'denovo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d798b63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_G4s_denovo = dict()\n",
    "for name in count_G4s_denovo:\n",
    "    print('\\r' + '                               ' + name, end='  ')\n",
    "    norm_G4s_denovo[name] = mut_norm_conf(count_G4s_denovo[name], normtorandom = True,  random_normaverage = normtorandom_denovo, do_binconf = True, genome_AC_freq_current = denovo_freq_all, n_genomes = denovo_n_genomes, rolling = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f295d091",
   "metadata": {},
   "source": [
    "#### Save/load normalized mutation rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5db427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save temporary output of the mutation counts\n",
    "with open('./analysis/temp/flank_count_random_denovo_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(count_random_denovo, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./analysis/temp/flank_count_long_STRs_denovo_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(count_long_STRs_denovo, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./analysis/temp/flank_count_G4s_denovo_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(count_G4s_denovo, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "flanking_norm_denovo = dict()\n",
    "flanking_norm_denovo['STR'] = norm_long_STRs_denovo.copy()\n",
    "flanking_norm_denovo['G4'] = norm_G4s_denovo.copy()\n",
    "flanking_norm_denovo['random'] = {'random': norm_random_denovo_normtorandom}.copy()\n",
    "flanking_norm_denovo['random_nonorm'] = {'random_nonorm': norm_random_denovo}.copy()\n",
    "\n",
    "with open('./analysis/temp/flank_norm_denovo_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(flanking_norm_denovo, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2967c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load temporary output of the mutation counts\n",
    "with open('./analysis/temp/flank_count_random_denovo_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    count_random_denovo = pickle.load(handle)\n",
    "with open('./analysis/temp/flank_count_long_STRs_denovo_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    count_long_STRs_denovo = pickle.load(handle)\n",
    "with open('./analysis/temp/flank_count_G4s_denovo_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    count_G4s_denovo = pickle.load(handle)\n",
    "with open('./analysis/temp/flank_norm_denovo_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    flanking_norm_denovo = pickle.load(handle)\n",
    "\n",
    "# Median SNV frequencies for each QC filter, used to normalize all later mutation frequencies\n",
    "normtorandom_denovo = pd.Series([flanking_norm_denovo['random_nonorm']['random_nonorm'][0]['denovo'].loc[-50:50].median() for qc_cutoff in flanking_norm_denovo['random']['random'][0]], index = list(flanking_norm_denovo['random']['random'][0]))\n",
    "norm_random_simple_freq = count_random_denovo[0]['denovo'].sum() / count_random_denovo[1].sum()\n",
    "normtorandom_simplefreq = norm_random_simple_freq.loc[-50:50].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716e9d7d",
   "metadata": {},
   "source": [
    "## Perform improper analysis of NonB Database (on purpose) <a name=\"mutation_surrounding_nonbdb\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e587323",
   "metadata": {},
   "source": [
    "#### Load NonBdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29582f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modified Non-B DB\n",
    "nonbdb = pd.read_csv('./nonbdb/nonbdb_modified_chr'+str(chr_range)+'-22.csv.gz', compression = 'gzip', low_memory = False)\n",
    "\n",
    "# Replace NaN for text string 'NA' for counting purposes\n",
    "for col in ['Type', 'length', 'repeat', 'Spacer', 'Tracts', 'Subset', 'Composition', 'Strand']:\n",
    "    nonbdb[col] = nonbdb[col].replace(np.nan, 'NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805dcef3",
   "metadata": {},
   "source": [
    "#### Separate categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa48f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STR motifs: mono- and dinucleotide\n",
    "nonbdb_all_STRs = nonbdb.loc[(nonbdb['Type'] == 'Short_Tandem_Repeat')].copy()\n",
    "nonbdb_STRs = dict()\n",
    "\n",
    "nonbdb_STRs['A'] = nonbdb_all_STRs.loc[nonbdb_all_STRs['Composition'] == '1A/0C/0G/0T'].copy()\n",
    "nonbdb_STRs['A']['Strand'] = '+'\n",
    "nonbdb_STRs['T'] = nonbdb_all_STRs.loc[nonbdb_all_STRs['Composition'] == '0A/0C/0G/1T'].copy()\n",
    "nonbdb_STRs['T']['Strand'] = '-'\n",
    "nonbdb_STRs['A'] = pd.concat([nonbdb_STRs['A'], nonbdb_STRs['T']])\n",
    "\n",
    "nonbdb_STRs['C'] = nonbdb_all_STRs.loc[nonbdb_all_STRs['Composition'] == '0A/1C/0G/0T'].copy()\n",
    "nonbdb_STRs['C']['Strand'] = '+'\n",
    "nonbdb_STRs['G'] = nonbdb_all_STRs.loc[nonbdb_all_STRs['Composition'] == '0A/0C/1G/0T'].copy()\n",
    "nonbdb_STRs['G']['Strand'] = '-'\n",
    "nonbdb_STRs['C'] = pd.concat([nonbdb_STRs['C'], nonbdb_STRs['G']])\n",
    "\n",
    "nonbdb_STRs['AG'] = nonbdb_all_STRs.loc[nonbdb_all_STRs['Composition'] == '1A/0C/1G/0T'].copy()\n",
    "nonbdb_STRs['AG']['Strand'] = '+'\n",
    "nonbdb_STRs['TC'] = nonbdb_all_STRs.loc[nonbdb_all_STRs['Composition'] == '0A/1C/0G/1T'].copy()\n",
    "nonbdb_STRs['TC']['Strand'] = '-'\n",
    "nonbdb_STRs['AG'] = pd.concat([nonbdb_STRs['AG'], nonbdb_STRs['TC']])\n",
    "\n",
    "nonbdb_STRs['AC'] = nonbdb_all_STRs.loc[nonbdb_all_STRs['Composition'] == '1A/1C/0G/0T'].copy()\n",
    "nonbdb_STRs['AC']['Strand'] = '+'\n",
    "nonbdb_STRs['TG'] = nonbdb_all_STRs.loc[nonbdb_all_STRs['Composition'] == '0A/0C/1G/1T'].copy()\n",
    "nonbdb_STRs['TG']['Strand'] = '-'\n",
    "nonbdb_STRs['AC'] = pd.concat([nonbdb_STRs['AC'], nonbdb_STRs['TG']])\n",
    "\n",
    "nonbdb_STRs['AT'] = nonbdb_all_STRs.loc[nonbdb_all_STRs['Composition'] == '1A/0C/0G/1T'].copy()\n",
    "nonbdb_STRs['GC'] = nonbdb_all_STRs.loc[nonbdb_all_STRs['Composition'] == '0A/1C/1G/0T'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2ba75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverted repeats\n",
    "nonbdb_IRs = dict()\n",
    "nonbdb_IRs['all'] = nonbdb.loc[(nonbdb['Type'] == 'Inverted_Repeat')].dropna(axis = 1, how = 'all').copy()\n",
    "nonbdb_IRs['long'] = nonbdb_IRs['all'].loc[nonbdb_IRs['all']['repeat'] > nonbdb_IRs['all']['repeat'].quantile(0.8)].copy()\n",
    "nonbdb_IRs['very_long'] = nonbdb_IRs['all'].loc[nonbdb_IRs['all']['repeat'] > nonbdb_IRs['all']['repeat'].quantile(0.95)].copy()\n",
    "# IRs with shorter loop length\n",
    "nonbdb_IRs['long_loop10'] = nonbdb_IRs['long'].loc[nonbdb_IRs['long']['Spacer'] < 11].copy()\n",
    "del nonbdb_IRs['all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5327c2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mirror repeats\n",
    "nonbdb_MRs = dict()\n",
    "nonbdb_MRs['all'] = nonbdb.loc[(nonbdb['Type'] == 'Mirror_Repeat')].dropna(axis = 1, how = 'all').copy()\n",
    "nonbdb_MRs['long'] = nonbdb_MRs['all'].loc[nonbdb_MRs['all']['repeat'] > nonbdb_MRs['all']['repeat'].quantile(0.8)].copy()\n",
    "nonbdb_very_long_MRs = nonbdb_MRs['all'].loc[nonbdb_MRs['all']['repeat'] > nonbdb_MRs['all']['repeat'].quantile(0.95)].copy()\n",
    "# MRs with shorter loop length\n",
    "nonbdb_MRs['long_loop10'] = nonbdb_MRs['long'].loc[nonbdb_MRs['long']['Spacer'] < 11].copy()\n",
    "\n",
    "nonbdb_MRs['long']['%purine'] = (nonbdb_MRs['long']['Sequence'].str.count('a') + nonbdb_MRs['long']['Sequence'].str.count('g')) / nonbdb_MRs['long']['length']\n",
    "\n",
    "nonbdb_MRs['long_homopurine_AG'] = nonbdb_MRs['long'].loc[nonbdb_MRs['long']['%purine'] == 1].copy()\n",
    "nonbdb_MRs['long_homopurine_AG']['Strand'] = '+'\n",
    "nonbdb_MRs['long_homopurine_TC'] = nonbdb_MRs['long'].loc[nonbdb_MRs['long']['%purine'] == 0].copy()\n",
    "nonbdb_MRs['long_homopurine_TC']['Strand'] = '-'\n",
    "nonbdb_MRs['long_homopurine'] = pd.concat([nonbdb_MRs['long_homopurine_AG'], nonbdb_MRs['long_homopurine_TC']])\n",
    "\n",
    "nonbdb_MRs['long_almost_homopurine_AG'] = nonbdb_MRs['long'].loc[nonbdb_MRs['long']['%purine'] > .90].copy()\n",
    "nonbdb_MRs['long_almost_homopurine_AG']['Strand'] = '+'\n",
    "nonbdb_MRs['long_almost_homopurine_TC'] = nonbdb_MRs['long'].loc[nonbdb_MRs['long']['%purine'] < 0.10].copy()\n",
    "nonbdb_MRs['long_almost_homopurine_TC']['Strand'] = '-'\n",
    "nonbdb_MRs['long_almost_homopurine'] = pd.concat([nonbdb_MRs['long_almost_homopurine_AG'], nonbdb_MRs['long_almost_homopurine_TC']])\n",
    "\n",
    "nonbdb_MRs['long_non_homopurine'] = nonbdb_MRs['long'].loc[(nonbdb_MRs['long']['%purine'] < .80) & (nonbdb_MRs['long']['%purine'] > .20)].copy()\n",
    "\n",
    "nonbdb_MRs['long_homopurine_loop10'] = nonbdb_MRs['long_homopurine'].loc[nonbdb_MRs['long_homopurine']['Spacer'] < 11]\n",
    "\n",
    "del nonbdb_MRs['all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d984eda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct repeats\n",
    "nonbdb_DRs = dict()\n",
    "nonbdb_DRs['all'] = nonbdb.loc[(nonbdb['Type'] == 'Direct_Repeat')].dropna(axis = 1, how = 'all').copy()\n",
    "nonbdb_DRs['long'] = nonbdb_DRs['all'].loc[nonbdb_DRs['all']['repeat'] > nonbdb_DRs['all']['repeat'].quantile(0.8)].copy()\n",
    "nonbdb_DRs['very_long'] = nonbdb_DRs['all'].loc[nonbdb_DRs['all']['repeat'] > nonbdb_DRs['all']['repeat'].quantile(0.95)].copy()\n",
    "# DRs with shorter loop length\n",
    "nonbdb_DRs['long_loop10'] = nonbdb_DRs['long'].loc[nonbdb_DRs['long']['Spacer'] < 11].copy()\n",
    "\n",
    "del nonbdb_DRs['all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3a0554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-DNA motifs\n",
    "nonbdb_ZDNAs = dict()\n",
    "nonbdb_ZDNAs['all'] = nonbdb.loc[(nonbdb['Type'] == 'Z_DNA_Motif')].dropna(axis = 1, how = 'all').copy()\n",
    "nonbdb_ZDNAs['long'] = nonbdb_ZDNAs['all'].loc[nonbdb_ZDNAs['all']['length'] > nonbdb_ZDNAs['all']['length'].quantile(0.8)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e6130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G4 motifs\n",
    "nonbdb_G4s = dict()\n",
    "nonbdb_G4s['all'] = nonbdb.loc[nonbdb['Type'] == 'G4'].dropna(axis = 1, how = 'all').copy()\n",
    "nonbdb_G4s['highscore'] = nonbdb_G4s['all'].loc[nonbdb_G4s['all']['Score'] > nonbdb_G4s['all']['Score'].quantile(0.8)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec30737f",
   "metadata": {},
   "source": [
    "### Count and analyze Non-B DB flanking mutations for each motif category <a name=\"mutation_surrounding_nonbdb_count\"></a>\n",
    "\n",
    "#### STRs <a name=\"mutation_surrounding_nonbdb_str\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812e23af",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonbdb_count_long_STRs = dict()\n",
    "\n",
    "for repeat in ['A', 'C', 'AC', 'AG']:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    nonbdb_count_long_STRs[repeat] = count_mut_flank(nonbdb_STRs[repeat].copy(), qc_cutoff_list = [(-np.inf, -np.inf)], filter_cols = [], strand_col = 'Strand', useful_cols = ['Strand'])\n",
    "for repeat in ['AT', 'GC']:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    nonbdb_count_long_STRs[repeat] = count_mut_flank(nonbdb_STRs[repeat].copy(), qc_cutoff_list = [(-np.inf, -np.inf)], filter_cols = [], useful_cols = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11ba067",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonbdb_count_long_STRs_noRM = dict()\n",
    "\n",
    "for repeat in ['A', 'C', 'AC', 'AG']:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    nonbdb_count_long_STRs_noRM[repeat] = count_mut_flank(nonbdb_STRs[repeat].loc[nonbdb_STRs[repeat]['RM_distance_min'] > 0].copy(), qc_cutoff_list = [(-np.inf, -np.inf)], filter_cols = ['RM_distance'], strand_col = 'Strand', useful_cols = ['Strand'])\n",
    "for repeat in ['AT', 'GC']:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    nonbdb_count_long_STRs_noRM[repeat] = count_mut_flank(nonbdb_STRs[repeat].loc[nonbdb_STRs[repeat]['RM_distance_min'] > 0].copy(), qc_cutoff_list = [(-np.inf, -np.inf)], filter_cols = ['RM_distance'], useful_cols = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e16e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonbdb_count_long_STRs_overlaps = dict()\n",
    "\n",
    "for repeat in ['A', 'C', 'AC', 'AG']:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    nonbdb_count_long_STRs_overlaps[repeat] = count_mut_flank(nonbdb_STRs[repeat].loc[(nonbdb_STRs[repeat]['RM_distance_min'] > 0) & (nonbdb_STRs[repeat]['nonbdb_distance_min'] > 0)].copy(), qc_cutoff_list = [(-np.inf, -np.inf)], filter_cols = ['RM_distance', 'nonbdb_distance'], strand_col = 'Strand', useful_cols = ['Strand'])\n",
    "for repeat in ['AT', 'GC']:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    nonbdb_count_long_STRs_overlaps[repeat] = count_mut_flank(nonbdb_STRs[repeat].loc[(nonbdb_STRs[repeat]['RM_distance_min'] > 0) & (nonbdb_STRs[repeat]['nonbdb_distance_min'] > 0)].copy(), qc_cutoff_list = [(-np.inf, -np.inf)], filter_cols = ['RM_distance', 'nonbdb_distance'], useful_cols = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc489a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save temporary output of the mutation counts\n",
    "# ACcorrect\n",
    "with open('./analysis/temp/nonbdb_STRs_flank_ACcorrect_mutcount_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(nonbdb_count_long_STRs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./analysis/temp/nonbdb_STRs_flank_ACcorrect_mutcount_noRM_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(nonbdb_count_long_STRs_noRM, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./analysis/temp/nonbdb_STRs_flank_ACcorrect_mutcount_overlaps_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(nonbdb_count_long_STRs_overlaps, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1479e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load temporary output of the mutation counts\n",
    "with open('./analysis/temp/nonbdb_STRs_flank_ACcorrect_mutcount_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    nonbdb_count_long_STRs = pickle.load(handle)\n",
    "with open('./analysis/temp/nonbdb_STRs_flank_ACcorrect_mutcount_noRM_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    nonbdb_count_long_STRs_noRM = pickle.load(handle)\n",
    "with open('./analysis/temp/nonbdb_STRs_flank_ACcorrect_mutcount_overlaps_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    nonbdb_count_long_STRs_overlaps = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d538f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonbdb_simple_freq_long_STRs = dict()\n",
    "for repeat in nonbdb_count_long_STRs:\n",
    "    nonbdb_simple_freq_long_STRs[repeat] = nonbdb_count_long_STRs[repeat][0][-np.inf].sum() / nonbdb_count_long_STRs[repeat][1].sum()\n",
    "\n",
    "nonbdb_simple_freq_long_STRs_noRM = dict()\n",
    "for repeat in nonbdb_count_long_STRs_noRM:\n",
    "    nonbdb_simple_freq_long_STRs_noRM[repeat] = nonbdb_count_long_STRs_noRM[repeat][0][-np.inf].sum() / nonbdb_count_long_STRs_noRM[repeat][1].sum()\n",
    "\n",
    "nonbdb_norm_long_STRs_noRM = dict()\n",
    "for repeat in nonbdb_count_long_STRs_noRM:\n",
    "    print('\\r' + '                               ' + repeat, end='  ')\n",
    "    nonbdb_norm_long_STRs_noRM[repeat] = mut_norm_conf(nonbdb_count_long_STRs_noRM[repeat], normtorandom = True, random_normaverage = normtorandom_all, do_binconf = True)\n",
    "\n",
    "nonbdb_norm_long_STRs_overlaps = dict()\n",
    "for repeat in nonbdb_count_long_STRs_overlaps:\n",
    "    print('\\r' + '                               ' + repeat, end='  ')\n",
    "    nonbdb_norm_long_STRs_overlaps[repeat] = mut_norm_conf(nonbdb_count_long_STRs_overlaps[repeat], normtorandom = True, random_normaverage = normtorandom_all, do_binconf = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de49424",
   "metadata": {},
   "source": [
    "#### IRs <a name=\"mutation_surrounding_nonbdb_ir\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8e3c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonbdb_count_IRs = dict()\n",
    "for repeat in nonbdb_IRs:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    nonbdb_count_IRs[repeat] = count_mut_flank(nonbdb_IRs[repeat].copy(), qc_cutoff_list = [(-np.inf, -np.inf)], filter_cols = [], useful_cols = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770c1976",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonbdb_count_IRs_noRM = dict()\n",
    "for repeat in nonbdb_IRs:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    nonbdb_count_IRs_noRM[repeat] = count_mut_flank(nonbdb_IRs[repeat].loc[nonbdb_IRs[repeat]['RM_distance_min'] > 0].copy(), qc_cutoff_list = [(-np.inf, -np.inf)], filter_cols = ['RM_distance'], useful_cols = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0c044d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonbdb_count_IRs_overlaps = dict()\n",
    "for repeat in nonbdb_IRs:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    nonbdb_count_IRs_overlaps[repeat] = count_mut_flank(nonbdb_IRs[repeat].loc[(nonbdb_IRs[repeat]['RM_distance_min'] > 0) & (nonbdb_IRs[repeat]['nonbdb_distance_min'] > 0)].copy(), qc_cutoff_list = [(-np.inf, -np.inf)], filter_cols = ['RM_distance', 'nonbdb_distance'], useful_cols = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b605012b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save temporary output of the mutation counts\n",
    "with open('./analysis/temp/nonbdb_IRs_flank_ACcorrect_mutcount_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(nonbdb_count_IRs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./analysis/temp/nonbdb_IRs_flank_ACcorrect_mutcount_noRM_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(nonbdb_count_IRs_noRM, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./analysis/temp/nonbdb_IRs_flank_ACcorrect_mutcount_overlaps_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(nonbdb_count_IRs_overlaps, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf40842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load temporary output of the mutation counts\n",
    "with open('./analysis/temp/nonbdb_IRs_flank_ACcorrect_mutcount_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    nonbdb_count_IRs = pickle.load(handle)\n",
    "with open('./analysis/temp/nonbdb_IRs_flank_ACcorrect_mutcount_noRM_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    nonbdb_count_IRs_noRM = pickle.load(handle)\n",
    "with open('./analysis/temp/nonbdb_IRs_flank_ACcorrect_mutcount_overlaps_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    nonbdb_count_IRs_overlaps = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71969ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonbdb_simple_freq_IRs = dict()\n",
    "for repeat in nonbdb_count_IRs:\n",
    "    nonbdb_simple_freq_IRs[repeat] = nonbdb_count_IRs[repeat][0][-np.inf].sum() / nonbdb_count_IRs[repeat][1].sum()\n",
    "\n",
    "nonbdb_simple_freq_IRs_noRM = dict()\n",
    "for repeat in nonbdb_count_IRs_noRM:\n",
    "    nonbdb_simple_freq_IRs_noRM[repeat] = nonbdb_count_IRs_noRM[repeat][0][-np.inf].sum() / nonbdb_count_IRs_noRM[repeat][1].sum()\n",
    "\n",
    "nonbdb_norm_IRs_noRM = dict()\n",
    "for repeat in nonbdb_count_IRs_noRM:\n",
    "    print('\\r' + '                               ' + repeat, end='  ')\n",
    "    nonbdb_norm_IRs_noRM[repeat] = mut_norm_conf(nonbdb_count_IRs_noRM[repeat], normtorandom = True, random_normaverage = normtorandom_all, do_binconf = True)\n",
    "\n",
    "nonbdb_norm_IRs_overlaps = dict()\n",
    "for repeat in nonbdb_count_IRs_overlaps:\n",
    "    print('\\r' + '                               ' + repeat, end='  ')\n",
    "    nonbdb_norm_IRs_overlaps[repeat] = mut_norm_conf(nonbdb_count_IRs_overlaps[repeat], normtorandom = True, random_normaverage = normtorandom_all, do_binconf = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f3f0cf",
   "metadata": {},
   "source": [
    "#### DRs  <a name=\"mutation_surrounding_nonbdb_dr\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6a7db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonbdb_count_DRs = dict()\n",
    "for repeat in nonbdb_DRs:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    nonbdb_count_DRs[repeat] = count_mut_flank(nonbdb_DRs[repeat].copy(), qc_cutoff_list = [(-np.inf, -np.inf)], filter_cols = [], useful_cols = [])\n",
    "\n",
    "nonbdb_count_DRs_noRM = dict()\n",
    "for repeat in nonbdb_DRs:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    nonbdb_count_DRs_noRM[repeat] = count_mut_flank(nonbdb_DRs[repeat].loc[nonbdb_DRs[repeat]['RM_distance_min'] > 0].copy(), qc_cutoff_list = [(-np.inf, -np.inf)], filter_cols = ['RM_distance'], useful_cols = [])\n",
    "\n",
    "nonbdb_count_DRs_overlaps = dict()\n",
    "for repeat in nonbdb_DRs:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    nonbdb_count_DRs_overlaps[repeat] = count_mut_flank(nonbdb_DRs[repeat].loc[(nonbdb_DRs[repeat]['RM_distance_min'] > 0) & (nonbdb_DRs[repeat]['nonbdb_distance_min'] > 0)].copy(), qc_cutoff_list = [(-np.inf, -np.inf)], filter_cols = ['RM_distance', 'nonbdb_distance'], useful_cols = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80b56ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save temporary output of the mutation counts\n",
    "with open('./analysis/temp/nonbdb_DRs_flank_ACcorrect_mutcount_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(nonbdb_count_DRs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./analysis/temp/nonbdb_DRs_flank_ACcorrect_mutcount_noRM_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(nonbdb_count_DRs_noRM, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./analysis/temp/nonbdb_DRs_flank_ACcorrect_mutcount_overlaps_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(nonbdb_count_DRs_overlaps, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4850f25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load temporary output of the mutation counts\n",
    "with open('./analysis/temp/nonbdb_DRs_flank_ACcorrect_mutcount_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    nonbdb_count_DRs = pickle.load(handle)\n",
    "with open('./analysis/temp/nonbdb_DRs_flank_ACcorrect_mutcount_noRM_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    nonbdb_count_DRs_noRM = pickle.load(handle)\n",
    "with open('./analysis/temp/nonbdb_DRs_flank_ACcorrect_mutcount_overlaps_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    nonbdb_count_DRs_overlaps = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc46500",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonbdb_simple_freq_DRs = dict()\n",
    "for repeat in nonbdb_count_DRs:\n",
    "    nonbdb_simple_freq_DRs[repeat] = nonbdb_count_DRs[repeat][0][-np.inf].sum() / nonbdb_count_DRs[repeat][1].sum()\n",
    "\n",
    "nonbdb_simple_freq_DRs_noRM = dict()\n",
    "for repeat in nonbdb_count_DRs_noRM:\n",
    "    nonbdb_simple_freq_DRs_noRM[repeat] = nonbdb_count_DRs_noRM[repeat][0][-np.inf].sum() / nonbdb_count_DRs_noRM[repeat][1].sum()\n",
    "\n",
    "nonbdb_norm_DRs_noRM = dict()\n",
    "for repeat in nonbdb_count_DRs_noRM:\n",
    "    print('\\r' + '                               ' + repeat, end='  ')\n",
    "    nonbdb_norm_DRs_noRM[repeat] = mut_norm_conf(nonbdb_count_DRs_noRM[repeat], normtorandom = True, random_normaverage = normtorandom_all, do_binconf = True)\n",
    "\n",
    "nonbdb_norm_DRs_overlaps = dict()\n",
    "for repeat in nonbdb_count_DRs_overlaps:\n",
    "    print('\\r' + '                               ' + repeat, end='  ')\n",
    "    nonbdb_norm_DRs_overlaps[repeat] = mut_norm_conf(nonbdb_count_DRs_overlaps[repeat], normtorandom = True, random_normaverage = normtorandom_all, do_binconf = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855ac233",
   "metadata": {},
   "source": [
    "#### MRs  <a name=\"mutation_surrounding_nonbdb_mr\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbe4e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonbdb_count_MRs = dict()\n",
    "for repeat in ['long', 'long_loop10']:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    nonbdb_count_MRs[repeat] = count_mut_flank(nonbdb_MRs[repeat].copy(), qc_cutoff_list = [(-np.inf, -np.inf)], filter_cols = [], strand_col = 'Strand', useful_cols = ['Strand'])\n",
    "for repeat in ['long_homopurine', 'long_almost_homopurine', 'long_homopurine_loop10']:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    nonbdb_count_MRs[repeat] = count_mut_flank(nonbdb_MRs[repeat].copy(), qc_cutoff_list = [(-np.inf, -np.inf)], filter_cols = [], useful_cols = [])\n",
    "\n",
    "nonbdb_count_MRs_noRM = dict()\n",
    "for repeat in ['long', 'long_loop10']:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    nonbdb_count_MRs_noRM[repeat] = count_mut_flank(nonbdb_MRs[repeat].loc[nonbdb_MRs[repeat]['RM_distance_min'] > 0].copy(), qc_cutoff_list = [(-np.inf, -np.inf)], filter_cols = ['RM_distance'], strand_col = 'Strand', useful_cols = ['Strand'])\n",
    "for repeat in ['long_homopurine', 'long_almost_homopurine', 'long_homopurine_loop10']:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    nonbdb_count_MRs_noRM[repeat] = count_mut_flank(nonbdb_MRs[repeat].loc[nonbdb_MRs[repeat]['RM_distance_min'] > 0].copy(), qc_cutoff_list = [(-np.inf, -np.inf)], filter_cols = ['RM_distance'], useful_cols = [])\n",
    "\n",
    "nonbdb_count_MRs_overlaps = dict()\n",
    "for repeat in ['long', 'long_loop10']:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    nonbdb_count_MRs_overlaps[repeat] = count_mut_flank(nonbdb_MRs[repeat].loc[(nonbdb_MRs[repeat]['RM_distance_min'] > 0) & (nonbdb_MRs[repeat]['nonbdb_distance_min'] > 0)].copy(), qc_cutoff_list = [(-np.inf, -np.inf)], filter_cols = ['RM_distance'], strand_col = 'Strand', useful_cols = ['Strand'])\n",
    "for repeat in ['long_homopurine', 'long_almost_homopurine', 'long_homopurine_loop10']:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    nonbdb_count_MRs_overlaps[repeat] = count_mut_flank(nonbdb_MRs[repeat].loc[(nonbdb_MRs[repeat]['RM_distance_min'] > 0) & (nonbdb_MRs[repeat]['nonbdb_distance_min'] > 0)].copy(), qc_cutoff_list = [(-np.inf, -np.inf)], filter_cols = ['RM_distance'], useful_cols = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea65253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save temporary output of the mutation counts\n",
    "with open('./analysis/temp/nonbdb_MRs_ACcorrect_flank_mutcount_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(nonbdb_count_MRs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./analysis/temp/nonbdb_MRs_ACcorrect_flank_mutcount_noRM_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(nonbdb_count_MRs_noRM, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./analysis/temp/nonbdb_MRs_ACcorrect_flank_mutcount_overlaps_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(nonbdb_count_MRs_overlaps, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb54f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load temporary output of the mutation counts\n",
    "with open('./analysis/temp/nonbdb_MRs_ACcorrect_flank_mutcount_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    nonbdb_count_MRs = pickle.load(handle)\n",
    "with open('./analysis/temp/nonbdb_MRs_ACcorrect_flank_mutcount_noRM_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    nonbdb_count_MRs_noRM = pickle.load(handle)\n",
    "with open('./analysis/temp/nonbdb_MRs_ACcorrect_flank_mutcount_overlaps_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    nonbdb_count_MRs_overlaps = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db8a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonbdb_simple_freq_MRs = dict()\n",
    "for repeat in nonbdb_count_MRs:\n",
    "    nonbdb_simple_freq_MRs[repeat] = nonbdb_count_MRs[repeat][0][-np.inf].sum() / nonbdb_count_MRs[repeat][1].sum()\n",
    "\n",
    "nonbdb_simple_freq_MRs_noRM = dict()\n",
    "for repeat in nonbdb_count_MRs_noRM:\n",
    "    nonbdb_simple_freq_MRs_noRM[repeat] = nonbdb_count_MRs_noRM[repeat][0][-np.inf].sum() / nonbdb_count_MRs_noRM[repeat][1].sum()\n",
    "\n",
    "nonbdb_norm_MRs_noRM = dict()\n",
    "for repeat in nonbdb_count_MRs_noRM:\n",
    "    print('\\r' + '                               ' + repeat, end='  ')\n",
    "    nonbdb_norm_MRs_noRM[repeat] = mut_norm_conf(nonbdb_count_MRs_noRM[repeat], normtorandom = True, random_normaverage = normtorandom_all, do_binconf = True)\n",
    "\n",
    "nonbdb_norm_MRs_overlaps = dict()\n",
    "for repeat in nonbdb_count_MRs_overlaps:\n",
    "    print('\\r' + '                               ' + repeat, end='  ')\n",
    "    nonbdb_norm_MRs_overlaps[repeat] = mut_norm_conf(nonbdb_count_MRs_overlaps[repeat], normtorandom = True, random_normaverage = normtorandom_all, do_binconf = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ac82f2",
   "metadata": {},
   "source": [
    "#### ZDNA  <a name=\"mutation_surrounding_nonbdb_zdna\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd49dfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonbdb_count_ZDNAs = dict()\n",
    "for repeat in nonbdb_ZDNAs:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    nonbdb_count_ZDNAs[repeat] = count_mut_flank(nonbdb_ZDNAs[repeat].copy(), qc_cutoff_list = [(-np.inf, -np.inf)], filter_cols = [], useful_cols = [])\n",
    "\n",
    "nonbdb_count_ZDNAs_noRM = dict()\n",
    "for repeat in nonbdb_ZDNAs:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    nonbdb_count_ZDNAs_noRM[repeat] = count_mut_flank(nonbdb_ZDNAs[repeat].loc[nonbdb_ZDNAs[repeat]['RM_distance_min'] > 0].copy(), qc_cutoff_list = [(-np.inf, -np.inf)], filter_cols = ['RM_distance'], useful_cols = [])\n",
    "\n",
    "nonbdb_count_ZDNAs_overlaps = dict()\n",
    "for repeat in nonbdb_ZDNAs:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    nonbdb_count_ZDNAs_overlaps[repeat] = count_mut_flank(nonbdb_ZDNAs[repeat].loc[(nonbdb_ZDNAs[repeat]['RM_distance_min'] > 0) & (nonbdb_ZDNAs[repeat]['nonbdb_distance_min'] > 0)].copy(), qc_cutoff_list = [(-np.inf, -np.inf)], filter_cols = ['RM_distance', 'nonbdb_distance'], useful_cols = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dc21c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save temporary output of the mutation counts\n",
    "with open('./analysis/temp/nonbdb_ZDNAs_ACcorrect_flank_mutcount_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(nonbdb_count_ZDNAs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./analysis/temp/nonbdb_ZDNAs_ACcorrect_flank_mutcount_noRM_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(nonbdb_count_ZDNAs_noRM, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./analysis/temp/nonbdb_ZDNAs_ACcorrect_flank_mutcount_overlaps_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(nonbdb_count_ZDNAs_overlaps, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c994d5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load temporary output of the mutation counts\n",
    "with open('./analysis/temp/nonbdb_ZDNAs_ACcorrect_flank_mutcount_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    nonbdb_count_ZDNAs = pickle.load(handle)\n",
    "with open('./analysis/temp/nonbdb_ZDNAs_ACcorrect_flank_mutcount_noRM_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    nonbdb_count_ZDNAs_noRM = pickle.load(handle)\n",
    "with open('./analysis/temp/nonbdb_ZDNAs_ACcorrect_flank_mutcount_overlaps_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    nonbdb_count_ZDNAs_overlaps = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f88397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonbdb_simple_freq_ZDNAs = dict()\n",
    "for repeat in nonbdb_count_ZDNAs:\n",
    "    nonbdb_simple_freq_ZDNAs[repeat] = nonbdb_count_ZDNAs[repeat][0][-np.inf].sum() / nonbdb_count_ZDNAs[repeat][1].sum()\n",
    "\n",
    "nonbdb_simple_freq_ZDNAs_noRM = dict()\n",
    "for repeat in nonbdb_count_ZDNAs_noRM:\n",
    "    nonbdb_simple_freq_ZDNAs_noRM[repeat] = nonbdb_count_ZDNAs_noRM[repeat][0][-np.inf].sum() / nonbdb_count_ZDNAs_noRM[repeat][1].sum()\n",
    "\n",
    "nonbdb_norm_ZDNAs_noRM = dict()\n",
    "for repeat in nonbdb_count_ZDNAs_noRM:\n",
    "    print('\\r' + '                               ' + repeat, end='  ')\n",
    "    nonbdb_norm_ZDNAs_noRM[repeat] = mut_norm_conf(nonbdb_count_ZDNAs_noRM[repeat], normtorandom = True, random_normaverage = normtorandom_all, do_binconf = True)\n",
    "\n",
    "nonbdb_norm_ZDNAs_overlaps = dict()\n",
    "for repeat in nonbdb_count_ZDNAs_overlaps:\n",
    "    print('\\r' + '                               ' + repeat, end='  ')\n",
    "    nonbdb_norm_ZDNAs_overlaps[repeat] = mut_norm_conf(nonbdb_count_ZDNAs_overlaps[repeat], normtorandom = True, random_normaverage = normtorandom_all, do_binconf = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c164cdd",
   "metadata": {},
   "source": [
    "#### G4  <a name=\"mutation_surrounding_nonbdb_g4\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacb0a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonbdb_count_G4s = dict()\n",
    "for repeat in nonbdb_G4s:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    nonbdb_count_G4s[repeat] = count_mut_flank(nonbdb_G4s[repeat].copy(), qc_cutoff_list = [(-np.inf, -np.inf)], filter_cols = [], strand_col = 'Strand', useful_cols = ['Strand'])\n",
    "\n",
    "nonbdb_count_G4s_noRM = dict()\n",
    "for repeat in nonbdb_G4s:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    nonbdb_count_G4s_noRM[repeat] = count_mut_flank(nonbdb_G4s[repeat].loc[nonbdb_G4s[repeat]['RM_distance_min'] > 0].copy(), qc_cutoff_list = [(-np.inf, -np.inf)], filter_cols = ['RM_distance'], strand_col = 'Strand', useful_cols = ['Strand'])\n",
    "\n",
    "nonbdb_count_G4s_overlaps = dict()\n",
    "for repeat in nonbdb_G4s:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    nonbdb_count_G4s_overlaps[repeat] = count_mut_flank(nonbdb_G4s[repeat].loc[(nonbdb_G4s[repeat]['RM_distance_min'] > 0) & (nonbdb_G4s[repeat]['nonbdb_distance_min'] > 0)].copy(), qc_cutoff_list = [(-np.inf, -np.inf)], filter_cols = ['RM_distance', 'nonbdb_distance'], strand_col = 'Strand', useful_cols = ['Strand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c886c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save temporary output of the mutation counts\n",
    "with open('./analysis/temp/nonbdb_G4s_flank_ACcorrect_mutcount_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(nonbdb_count_G4s, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./analysis/temp/nonbdb_G4s_flank_ACcorrect_mutcount_noRM_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(nonbdb_count_G4s_noRM, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('./analysis/temp/nonbdb_G4s_flank_ACcorrect_mutcount_overlaps_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(nonbdb_count_G4s_overlaps, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341f4cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load temporary output of the mutation counts\n",
    "with open('./analysis/temp/nonbdb_G4s_flank_ACcorrect_mutcount_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    nonbdb_count_G4s = pickle.load(handle)\n",
    "with open('./analysis/temp/nonbdb_G4s_flank_ACcorrect_mutcount_noRM_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    nonbdb_count_G4s_noRM = pickle.load(handle)\n",
    "with open('./analysis/temp/nonbdb_G4s_flank_ACcorrect_mutcount_overlaps_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    nonbdb_count_G4s_overlaps = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd13a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonbdb_simple_freq_G4s = dict()\n",
    "for repeat in nonbdb_count_G4s:\n",
    "    nonbdb_simple_freq_G4s[repeat] = nonbdb_count_G4s[repeat][0][-np.inf].sum() / nonbdb_count_G4s[repeat][1].sum()\n",
    "\n",
    "nonbdb_simple_freq_G4s_noRM = dict()\n",
    "for repeat in nonbdb_count_G4s_noRM:\n",
    "    nonbdb_simple_freq_G4s_noRM[repeat] = nonbdb_count_G4s_noRM[repeat][0][-np.inf].sum() / nonbdb_count_G4s_noRM[repeat][1].sum()\n",
    "\n",
    "nonbdb_norm_G4s_noRM = dict()\n",
    "for repeat in nonbdb_count_G4s_noRM:\n",
    "    print('\\r' + '                               ' + repeat, end='  ')\n",
    "    nonbdb_norm_G4s_noRM[repeat] = mut_norm_conf(nonbdb_count_G4s_noRM[repeat], normtorandom = True, random_normaverage = normtorandom_all, do_binconf = True)\n",
    "\n",
    "nonbdb_norm_G4s_overlaps = dict()\n",
    "for repeat in nonbdb_count_G4s_overlaps:\n",
    "    print('\\r' + '                               ' + repeat, end='  ')\n",
    "    nonbdb_norm_G4s_overlaps[repeat] = mut_norm_conf(nonbdb_count_G4s_overlaps[repeat], normtorandom = True, random_normaverage = normtorandom_all, do_binconf = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963d16e5",
   "metadata": {},
   "source": [
    "#### Save/load NonBDB mutation frequencies  <a name=\"mutation_surrounding_nonbdb_saveload\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cedb01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save temporary output of the mutation counts\n",
    "\n",
    "nonbdb_flanking_all = dict()\n",
    "\n",
    "nonbdb_flanking_all['simple_freq'] = dict()\n",
    "nonbdb_flanking_all['simple_freq']['STR'] = nonbdb_simple_freq_long_STRs.copy()\n",
    "nonbdb_flanking_all['simple_freq']['IR'] = nonbdb_simple_freq_IRs.copy()\n",
    "nonbdb_flanking_all['simple_freq']['DR'] = nonbdb_simple_freq_DRs.copy()\n",
    "nonbdb_flanking_all['simple_freq']['MR'] = nonbdb_simple_freq_MRs.copy()\n",
    "nonbdb_flanking_all['simple_freq']['ZDNA'] = nonbdb_simple_freq_ZDNAs.copy()\n",
    "nonbdb_flanking_all['simple_freq']['G4'] = nonbdb_simple_freq_G4s.copy()\n",
    "\n",
    "nonbdb_flanking_all['no_RM'] = dict()\n",
    "nonbdb_flanking_all['no_RM']['STR'] = nonbdb_simple_freq_long_STRs_noRM.copy()\n",
    "nonbdb_flanking_all['no_RM']['IR'] = nonbdb_simple_freq_IRs_noRM.copy()\n",
    "nonbdb_flanking_all['no_RM']['DR'] = nonbdb_simple_freq_DRs_noRM.copy()\n",
    "nonbdb_flanking_all['no_RM']['MR'] = nonbdb_simple_freq_MRs_noRM.copy()\n",
    "nonbdb_flanking_all['no_RM']['ZDNA'] = nonbdb_simple_freq_ZDNAs_noRM.copy()\n",
    "nonbdb_flanking_all['no_RM']['G4'] = nonbdb_simple_freq_G4s_noRM.copy()\n",
    "\n",
    "nonbdb_flanking_all['tri_norm'] = dict()\n",
    "nonbdb_flanking_all['tri_norm']['STR'] = nonbdb_norm_long_STRs_noRM.copy()\n",
    "nonbdb_flanking_all['tri_norm']['IR'] = nonbdb_norm_IRs_noRM.copy()\n",
    "nonbdb_flanking_all['tri_norm']['DR'] = nonbdb_norm_DRs_noRM.copy()\n",
    "nonbdb_flanking_all['tri_norm']['MR'] = nonbdb_norm_MRs_noRM.copy()\n",
    "nonbdb_flanking_all['tri_norm']['ZDNA'] = nonbdb_norm_ZDNAs_noRM.copy()\n",
    "nonbdb_flanking_all['tri_norm']['G4'] = nonbdb_norm_G4s_noRM.copy()\n",
    "\n",
    "nonbdb_flanking_all['no_overlaps'] = dict()\n",
    "nonbdb_flanking_all['no_overlaps']['STR'] = nonbdb_norm_long_STRs_overlaps.copy()\n",
    "nonbdb_flanking_all['no_overlaps']['IR'] = nonbdb_norm_IRs_overlaps.copy()\n",
    "nonbdb_flanking_all['no_overlaps']['DR'] = nonbdb_norm_DRs_overlaps.copy()\n",
    "nonbdb_flanking_all['no_overlaps']['MR'] = nonbdb_norm_MRs_overlaps.copy()\n",
    "nonbdb_flanking_all['no_overlaps']['ZDNA'] = nonbdb_norm_ZDNAs_overlaps.copy()\n",
    "nonbdb_flanking_all['no_overlaps']['G4'] = nonbdb_norm_G4s_overlaps.copy()\n",
    "\n",
    "with open('./analysis/temp/nonbdb_flank_all_ACcorrect_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(nonbdb_flanking_all, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d86d1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load temporary output of the mutation counts\n",
    "with open('./analysis/temp/nonbdb_flank_all_ACcorrect_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    nonbdb_flanking_all = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade452fd",
   "metadata": {},
   "source": [
    "### Count flanking mutations using subsampled gnomAD <a name=\"mutation_surrounding_subsample\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b61fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count mutations surrounding random sequences\n",
    "count_random_subsample = dict()\n",
    "for sample_frac in [0.1, 0.01, 0.004]:\n",
    "    print('\\r' + '                                   sample_frac ' + str(sample_frac), end='  ')\n",
    "    count_random_subsample[sample_frac] = count_mut_flank(random_seq, input_mut_dict = gnomad_slim_downsample[sample_frac], useful_cols = ['Strand'], gc_nmer = 51)\n",
    "\n",
    "norm_random_subsample = dict()\n",
    "for sample_frac in [0.1, 0.01, 0.004]:\n",
    "    print('\\r' + '                                   sample_frac ' + str(sample_frac), end='  ')\n",
    "    norm_random_subsample[sample_frac] = mut_norm_conf(count_random_subsample[sample_frac], genome_AC_freq_current = genome_AC_freq_all_downsample[sample_frac], n_genomes = round(gnomad_n_genomes * sample_frac), gc_correct = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcce319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median SNV frequencies for each QC filter, used to normalize all later mutation frequencies\n",
    "normtorandom_subsample = dict()\n",
    "for sample_frac in [0.1, 0.01, 0.004]:\n",
    "    normtorandom_subsample[sample_frac] = pd.Series([norm_random_subsample[sample_frac][0][qc_cutoff].loc[-50:50].median() for qc_cutoff in norm_random_subsample[sample_frac][0]], index = list(norm_random_subsample[sample_frac][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ced2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count mutations surrounding STRs\n",
    "count_long_STRs_subsample = dict()\n",
    "for sample_frac in [0.1, 0.01, 0.004]:\n",
    "    print('\\r' + '                                   sample_frac ' + str(sample_frac), end='  ')\n",
    "    count_long_STRs_subsample[sample_frac] = dict()\n",
    "    for repeat in ['A', 'C', 'AC', 'AG']:\n",
    "        print('\\r' + '                     ' + repeat, end='  ')\n",
    "        count_long_STRs_subsample[sample_frac][repeat] = count_mut_flank(long_STRs[repeat], input_mut_dict = gnomad_slim_downsample[sample_frac], useful_cols = ['Strand'], gc_nmer = 51)\n",
    "    for repeat in repeats_highpower_sym:\n",
    "        print('\\r' + '                     ' + repeat, end='  ')\n",
    "        count_long_STRs_subsample[sample_frac][repeat] = count_mut_flank(long_STRs[repeat], input_mut_dict = gnomad_slim_downsample[sample_frac], gc_nmer = 51)\n",
    "    count_long_STRs_subsample[sample_frac]['GC_noCGI'] = count_mut_flank(STRs_CG, input_mut_dict = gnomad_slim_downsample[sample_frac], filter_cols = ['RM_distance', 'STR_distance', 'nonSTR_distance', 'within_motif_distance', 'CGI_distance'], gc_nmer = 51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f721ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_long_STRs_subsample = dict()\n",
    "for sample_frac in [0.1, 0.01, 0.004]:\n",
    "    print('\\r' + '                                   sample_frac ' + str(sample_frac), end='  ')\n",
    "    norm_long_STRs_subsample[sample_frac] = dict()\n",
    "    for repeat in count_long_STRs_subsample[sample_frac]:\n",
    "        print('\\r' + '                               ' + repeat, end='  ')\n",
    "        norm_long_STRs_subsample[sample_frac][repeat] = mut_norm_conf(count_long_STRs_subsample[sample_frac][repeat], genome_AC_freq_current = genome_AC_freq_all_downsample[sample_frac], n_genomes = round(gnomad_n_genomes * sample_frac), normtorandom = True, random_normaverage = normtorandom_subsample[sample_frac], do_binconf = True, gc_correct = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd83a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save temporary output of the mutation counts\n",
    "flanking_norm_subsample = dict()\n",
    "for sample_frac in [0.1, 0.01, 0.004]:\n",
    "    flanking_norm_subsample[sample_frac] = dict()\n",
    "    flanking_norm_subsample[sample_frac]['STR'] = norm_long_STRs_subsample[sample_frac].copy()\n",
    "\n",
    "with open('./analysis/temp/flank_norm_ACcorrect_downsample_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(flanking_norm_subsample, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b332aba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load temporary output of the mutation counts\n",
    "with open('./analysis/temp/flank_norm_ACcorrect_downsample_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    flanking_norm_subsample = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a689d2c0",
   "metadata": {},
   "source": [
    "## Plot flanking mutation frequencies <a name=\"mutation_surrounding_plot\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c0e7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color scale for QC in plots\n",
    "vqslod_list = [-np.inf, -2.774, 0, 4]\n",
    "QC_colors = make_colorscale(vqslod_list)\n",
    "QC_colors = pd.DataFrame(QC_colors).transpose()\n",
    "QC_colors['name'] = ['no QC', 'pass', 'VQSLOD >0', 'VQSLOD >4']\n",
    "\n",
    "QC_colors_denovo = pd.Series(['rgba(0, 0, 0, 0.5)', 'rgba(0, 0, 0, 0.15)', 'de novo'], index = [0,1, 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b71d3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate individual plot traces\n",
    "def plot_flank_add(motif, category, display_name, plot_name, row_n, col_n, input_dict = flanking_norm_all, showleg = False):\n",
    "    for QCfilter in vqslod_list:\n",
    "        plot_name.add_trace(go.Scatter(name = QC_colors['name'][QCfilter], legendgroup = QCfilter, showlegend=False, fill=None, x = input_dict[motif][category][2][QCfilter].dropna().index, y = input_dict[motif][category][2][QCfilter].dropna(), mode = 'lines', line = dict(width = 0, color = QC_colors[0][QCfilter])), row=row_n, col=col_n)\n",
    "        plot_name.add_trace(go.Scatter(name = QC_colors['name'][QCfilter], legendgroup = QCfilter, showlegend = showleg, fill='tonexty', fillcolor = QC_colors[1][QCfilter], x = input_dict[motif][category][0][QCfilter].index, y = input_dict[motif][category][0][QCfilter], mode = 'lines', line = dict(width = 2, color = QC_colors[0][QCfilter])), row=row_n, col=col_n)\n",
    "        plot_name.add_trace(go.Scatter(name = QC_colors['name'][QCfilter], legendgroup = QCfilter, showlegend=False, fill='tonexty', fillcolor = QC_colors[1][QCfilter], x = input_dict[motif][category][1][QCfilter].dropna().index, y = input_dict[motif][category][1][QCfilter].dropna(), mode = 'lines', line = dict(width = 0, color = QC_colors[0][QCfilter])), row=row_n, col=col_n)\n",
    "    plot_name.add_shape(type='line', x0=-500, y0=1, x1=500, y1=1, line=dict(color='Black', width = .3), row=row_n, col=col_n)\n",
    "    plot_name.update_yaxes(zeroline = False, title = dict(text = display_name, font = dict(size = 18 if len(display_name) < 10 else round(18* (10/len(display_name))))), title_standoff = 0, row = row_n, col = col_n)\n",
    "\n",
    "def plot_flank_add_denovo(motif, category, display_name, plot_name, row_n, col_n, input_dict = flanking_norm_denovo, showleg = False):\n",
    "    plot_name.add_trace(go.Scatter(name = QC_colors_denovo['name'], legendgroup = 'denovo', showlegend=False, fill=None, x = input_dict[motif][category][2]['denovo'].dropna().index, y = input_dict[motif][category][2]['denovo'].dropna(), mode = 'lines', line = dict(width = 0, color = QC_colors_denovo[0])), row=row_n, col=col_n)\n",
    "    plot_name.add_trace(go.Scatter(name = QC_colors_denovo['name'], legendgroup = 'denovo', showlegend = showleg, fill='tonexty', fillcolor = QC_colors_denovo[1], x = input_dict[motif][category][0]['denovo'].index, y = input_dict[motif][category][0]['denovo'], mode = 'lines', line = dict(width = 2, color = QC_colors_denovo[0])), row=row_n, col=col_n)\n",
    "    plot_name.add_trace(go.Scatter(name = QC_colors_denovo['name'], legendgroup = 'denovo', showlegend=False, fill='tonexty', fillcolor = QC_colors_denovo[1], x = input_dict[motif][category][1]['denovo'].dropna().index, y = input_dict[motif][category][1]['denovo'].dropna(), mode = 'lines', line = dict(width = 0, color = QC_colors_denovo[0])), row=row_n, col=col_n)\n",
    "    plot_name.add_shape(type='line', x0=-500, y0=1, x1=500, y1=1, line=dict(color='Black', width = .3), row=row_n, col=col_n)\n",
    "    plot_name.update_yaxes(zeroline = False, title = dict(text = display_name, font = dict(size = 18 if len(display_name) < 10 else round(18* (10/len(display_name))))), title_standoff = 0, row = row_n, col = col_n)\n",
    "\n",
    "    \n",
    "# Function to generate individual plots\n",
    "def plot_flank(motif, category, input_dict = flanking_norm_all, denovo = False):\n",
    "    mutnorm_all_binconf_fig = make_subplots()\n",
    "    plot_flank_add(motif = motif, category = category, display_name = motif + ' ' + category, plot_name = mutnorm_all_binconf_fig, row_n = 1, col_n = 1, input_dict = input_dict, showleg = True)\n",
    "    if denovo == True:\n",
    "        plot_flank_add_denovo(motif = motif, category = category, display_name = motif + ' ' + category, plot_name = mutnorm_all_binconf_fig, row_n = 1, col_n = 1, showleg = True)\n",
    "    mutnorm_all_binconf_fig.update_xaxes(range = [-250,250])\n",
    "    mutnorm_all_binconf_fig.update_yaxes(range = [0.1,3.1], zeroline = False)\n",
    "    return mutnorm_all_binconf_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8683deb",
   "metadata": {},
   "source": [
    "#### Plot for Figure 2 <a name=\"mutation_surrounding_plot_fig2\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b822c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutnorm_all_binconf_fig_combined_fig2 = make_subplots(rows = 2, cols = 1, shared_xaxes = True, vertical_spacing=0.02, horizontal_spacing = 0.11)\n",
    "counter = 0\n",
    "for motif, category, name in zip(['STR'], ['A'], ['A-mono']):\n",
    "    counter +=1\n",
    "    plot_flank_add(motif = motif, category = category, display_name = name, plot_name = mutnorm_all_binconf_fig_combined_fig2, row_n = counter, col_n = 1, showleg = True)\n",
    "\n",
    "for motif, category, name in zip(['DR'], ['long_DRs'], ['Direct']):\n",
    "    counter +=1\n",
    "    plot_flank_add(motif = motif, category = category, display_name = name, plot_name = mutnorm_all_binconf_fig_combined_fig2, row_n = counter, col_n = 1)\n",
    "    mutnorm_all_binconf_fig_combined_fig2.add_trace(go.Scatter(showlegend = True, x = nonbdb_flanking_all['tri_norm'][motif]['long'][0][-np.inf].index, y = nonbdb_flanking_all['tri_norm'][motif]['long'][0][-np.inf], marker = dict(color = 'rgba(80,80,80,0.4)'), name = 'uncorrected', connectgaps = True, legendgroup = 'bad'), row = counter, col = 1)\n",
    "        \n",
    "mutnorm_all_binconf_fig_combined_fig2.update_yaxes(range = [0.25,3.1], row = 1, col = 1)\n",
    "mutnorm_all_binconf_fig_combined_fig2.update_yaxes(range = [0.25,3.1], row = 2, col = 1)\n",
    "mutnorm_all_binconf_fig_combined_fig2.update_xaxes(range = [-250,250], tickmode = 'array', tickvals = list(range(-250,300,50)))\n",
    "mutnorm_all_binconf_fig_combined_fig2.update_layout(height = 400, width = 650, margin = dict(l = 55, r = 20, b = 45, t = 40), legend=dict(y = 1.10, x = -0.05, orientation='h', itemwidth = 30))\n",
    "mutnorm_all_binconf_fig_combined_fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362e1839",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutnorm_all_binconf_fig_combined_fig2.write_image('./plots/revision_ACcor_flanking_mutation_fig_2.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec22e95b",
   "metadata": {},
   "source": [
    "#### Combination plot for Supplementary Figure S2A <a name=\"mutation_surrounding_plot_figS2A\"></a>\n",
    "- includes NonB-DB unfiltered mutation frequencies \n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b4ab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Supplementary Figure S2A\n",
    "\n",
    "mutnorm_all_binconf_fig_combined_figS2a = make_subplots(rows = 5, cols = 3, shared_xaxes = True, vertical_spacing=0.02, horizontal_spacing = 0.11, column_widths=[5/11, 3/11, 3/11])\n",
    "\n",
    "counter = 0\n",
    "motif = 'STR'\n",
    "for category, name in zip(['A', 'C', 'AT', 'AC', 'AG'], ['A', 'C', 'AT', 'AC', 'AG']):\n",
    "    counter +=1\n",
    "    plot_flank_add(motif = motif, category = category, display_name = name, plot_name = mutnorm_all_binconf_fig_combined_figS2a, row_n = counter, col_n = 1, showleg = True if counter == 1 else False)\n",
    "\n",
    "counter = 0\n",
    "for category, name in zip(['ACC', 'AAC', 'AAG', 'AAT', 'GC'], ['CAC', 'CAA', 'GAA', 'TAA', 'GC']):\n",
    "    counter +=1\n",
    "    plot_flank_add(motif = motif, category = category, display_name = name, plot_name = mutnorm_all_binconf_fig_combined_figS2a, row_n = counter, col_n = 2)\n",
    "    \n",
    "counter = 0\n",
    "for category, name in zip(['AGC', 'ATC', 'AGG', 'AAAT', 'GC_noCGI'], ['CAG', 'CAT', 'GGA', 'TAAA', 'GC (outside CGIs)']):\n",
    "    counter +=1\n",
    "    plot_flank_add(motif = motif, category = category, display_name = name, plot_name = mutnorm_all_binconf_fig_combined_figS2a, row_n = counter, col_n = 3)\n",
    "\n",
    "mutnorm_all_binconf_fig_combined_figS2a.update_yaxes(range = [0.25, 3.5])\n",
    "mutnorm_all_binconf_fig_combined_figS2a.update_xaxes(range = [-255,255], tickmode = 'array', tickvals = list(range(-250,300,50)), col = 1)\n",
    "mutnorm_all_binconf_fig_combined_figS2a.update_xaxes(range = [-155,155], tickmode = 'array', tickvals = list(range(-150,200,50)), col = 2)\n",
    "mutnorm_all_binconf_fig_combined_figS2a.update_xaxes(range = [-155,155], tickmode = 'array', tickvals = list(range(-150,200,50)), col = 3)\n",
    "mutnorm_all_binconf_fig_combined_figS2a.update_layout(height = 650, width = 650, margin = dict(l = 55, r = 20, b = 45, t = 30), legend=dict(y = 1.05, x = -0.1, orientation='h', itemwidth = 30))\n",
    "mutnorm_all_binconf_fig_combined_figS2a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc42f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutnorm_all_binconf_fig_combined_figS2a.write_image('./plots/revision_ACcor_flanking_mutation_fig_S2a.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ba4f6f",
   "metadata": {},
   "source": [
    "#### Combination plot for Supplementary Figure S2B <a name=\"mutation_surrounding_plot_figS2B\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1908ce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Supplementary Figure S2B\n",
    "\n",
    "mutnorm_all_binconf_fig_combined_figS2b = make_subplots(rows = 5, cols = 2, shared_xaxes = True, vertical_spacing=0.02, horizontal_spacing = 0.11)\n",
    "\n",
    "counter = 0\n",
    "motif = 'IR'\n",
    "for category, name in zip(['long_IRs', 'very_long_IRs', 'long_IRs_loop10', 'AT80_IRs', 'AT40_IRs'], ['IRs (len>80%)', 'IRs (len>95%)', 'IRs (loop<11nt)', 'IRs (GC<20%)', 'IRs (GC>60%)']):\n",
    "    counter +=1\n",
    "    plot_flank_add(motif = motif, category = category, display_name = name, plot_name = mutnorm_all_binconf_fig_combined_figS2b, row_n = counter, col_n = 1, showleg = True if counter == 1 else False)\n",
    "    mutnorm_all_binconf_fig_combined_figS2b.update_yaxes(range = [0.1,2.6], row = counter, col = 1)\n",
    "    \n",
    "counter = 0\n",
    "motif = 'MR'\n",
    "for category, name in zip(['long_MRs', 'very_long_MRs', 'long_MRs_loop10', 'homopurine_MRs', 'non_homopurine_MRs'], ['MRs (len>80%)', 'MRs (len>95%)', 'MRs (loop<11nt)', 'MRs (homopurine)', 'MRs (non-homopurine)']):\n",
    "    counter +=1\n",
    "    plot_flank_add(motif = motif, category = category, display_name = name, plot_name = mutnorm_all_binconf_fig_combined_figS2b, row_n = counter, col_n = 2)\n",
    "#    mutnorm_all_binconf_fig_combined_figS2b.add_trace(go.Scatter(showlegend = True if counter ==1 else False, x = nonbdb_flanking_all['simple_freq'][motif][nonb_category].index, y = nonbdb_flanking_all['simple_freq'][motif][nonb_category], marker = dict(color = 'rgba(80,80,80,0.2)'), name = 'simple', connectgaps = True, legendgroup = 'bad'), row = counter, col = 2)\n",
    "#    mutnorm_all_binconf_fig_combined_figS2b.add_trace(go.Scatter(showlegend = True if counter ==1 else False, x = nonbdb_flanking_all['tri_norm'][motif][nonb_category][0][-np.inf].index, y = nonbdb_flanking_all['tri_norm'][motif][nonb_category][0][-np.inf], marker = dict(color = 'rgba(50,50,50,0.4)'), name = 'uncorrected', connectgaps = True, legendgroup = 'bad'), row = counter, col = 2)\n",
    "    mutnorm_all_binconf_fig_combined_figS2b.update_yaxes(range = [0.1,2.6], row = counter, col = 2)\n",
    "    \n",
    "mutnorm_all_binconf_fig_combined_figS2b.update_xaxes(range = [-255,255], tickmode = 'array', tickvals = list(range(-250,300,50)))\n",
    "mutnorm_all_binconf_fig_combined_figS2b.update_layout(height = 650, width = 650, margin = dict(l = 55, r = 20, b = 45, t = 30), legend=dict(y = 1.05, x = -0.1, orientation='h', itemwidth = 30))\n",
    "mutnorm_all_binconf_fig_combined_figS2b.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db00d8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutnorm_all_binconf_fig_combined_figS2b.write_image('./plots/revision_ACcor_flanking_mutation_fig_S2b.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6768bf6b",
   "metadata": {},
   "source": [
    "#### Plot for Supplementary Figure S2C <a name=\"mutation_surrounding_plot_figS2C\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ba0da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Supplementary Figure S2C\n",
    "\n",
    "mutnorm_all_binconf_fig_combined_figS2c = make_subplots(rows = 5, cols = 2, shared_xaxes = True, vertical_spacing=0.02, horizontal_spacing = 0.11)\n",
    "\n",
    "counter = 0\n",
    "for motif, category, name in zip(['G4', 'G4', 'ZDNA', 'ZDNA', 'ZDNA'], ['K_G4s', 'PDS_G4s', 'all_ZDNAs', 'long_ZDNAs', 'ZDNAs_GY'], ['K+ G4', 'PDS G4', 'ZDNA', 'ZDNA (len>80%)', 'Z-DNA (GY motif)']):\n",
    "    counter +=1\n",
    "    plot_flank_add(motif = motif, category = category, display_name = name, plot_name = mutnorm_all_binconf_fig_combined_figS2c, row_n = counter, col_n = 1, showleg = True if counter == 1 else False)\n",
    "    mutnorm_all_binconf_fig_combined_figS2c.update_yaxes(range = [0.1,2.6], row = counter, col = 1)\n",
    "    \n",
    "counter = 0\n",
    "for motif, category, name in zip(['DR', 'DR', 'DR', 'DR', 'random'], ['long_DRs', 'very_long_DRs', 'perfect_long_DRs', 'long_DRs_loop10', 'random'], ['DRs (len>80%)', 'DRs (len>95%)', 'DRs (no int.)', 'DRs (loop<11nt)', 'random']):\n",
    "    counter +=1\n",
    "    plot_flank_add(motif = motif, category = category, display_name = name, plot_name = mutnorm_all_binconf_fig_combined_figS2c, row_n = counter, col_n = 2)\n",
    "#    mutnorm_all_binconf_fig_combined_figS2c.add_trace(go.Scatter(showlegend = True if counter ==1 else False, x = nonbdb_flanking_all['simple_freq'][motif][nonb_category].index, y = nonbdb_flanking_all['simple_freq'][motif][nonb_category], marker = dict(color = 'rgba(80,80,80,0.2)'), name = 'simple', connectgaps = True, legendgroup = 'bad'), row = counter, col = 2)\n",
    "#    mutnorm_all_binconf_fig_combined_figS2c.add_trace(go.Scatter(showlegend = True if counter ==1 else False, x = nonbdb_flanking_all['tri_norm'][motif][nonb_category][0][-np.inf].index, y = nonbdb_flanking_all['tri_norm'][motif][nonb_category][0][-np.inf], marker = dict(color = 'rgba(50,50,50,0.4)'), name = 'uncorrected', connectgaps = True, legendgroup = 'bad'), row = counter, col = 2)\n",
    "    mutnorm_all_binconf_fig_combined_figS2c.update_yaxes(range = [0.1,2.6], row = counter, col = 2)\n",
    "    \n",
    "mutnorm_all_binconf_fig_combined_figS2c.update_xaxes(range = [-255,255], tickmode = 'array', tickvals = list(range(-250,300,50)))\n",
    "mutnorm_all_binconf_fig_combined_figS2c.update_layout(height = 650, width = 650, margin = dict(l = 55, r = 20, b = 45, t = 30), legend=dict(y = 1.05, x = -0.1, orientation='h', itemwidth = 30))\n",
    "mutnorm_all_binconf_fig_combined_figS2c.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ca2be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutnorm_all_binconf_fig_combined_figS2c.write_image('./plots/revision_ACcor_flanking_mutation_fig_S2c.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacc3b01",
   "metadata": {},
   "source": [
    "#### Plot Supplementary Figure S2D <a name=\"mutation_surrounding_CGI_plot\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669f9fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color scale for nonBdb plots\n",
    "nonbdb_colors = make_default_colors(['simple freq', 'repeat-masked', 'tri-normalized', 'red', 'no overlaps', 'fully-corrected'], opacity=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc4e6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate individual plot traces\n",
    "def nonb_plot_flank_add(motif, category, correct_cat, display_name, plot_name, row_n, col_n, showleg = False):\n",
    "    plot_name.add_trace(go.Scatter(name = 'uncorr.', legendgroup = 'simple_freq', showlegend = showleg, x = nonbdb_flanking_all['simple_freq'][motif][category].index, y = nonbdb_flanking_all['simple_freq'][motif][category] / normtorandom_simplefreq, mode = 'lines', line = dict(width = 2, color = nonbdb_colors[1]['simple freq'])), row=row_n, col=col_n)\n",
    "    plot_name.add_trace(go.Scatter(name = 'Repeatmasker', legendgroup = 'no_RM', showlegend = showleg, x = nonbdb_flanking_all['no_RM'][motif][category].index, y = nonbdb_flanking_all['no_RM'][motif][category] / normtorandom_simplefreq, mode = 'lines', line = dict(width = 2, color = nonbdb_colors[1]['repeat-masked'])), row=row_n, col=col_n)\n",
    "    plot_name.add_trace(go.Scatter(name = 'tri-normalized', legendgroup = 'tri_norm', showlegend = showleg, x = nonbdb_flanking_all['tri_norm'][motif][category][0][-np.inf].index, y = nonbdb_flanking_all['tri_norm'][motif][category][0][-np.inf], mode = 'lines', line = dict(width = 2, color = nonbdb_colors[1]['tri-normalized'])), row=row_n, col=col_n)\n",
    "    plot_name.add_trace(go.Scatter(name = 'unique', legendgroup = 'no_overlaps', showlegend = showleg, x = nonbdb_flanking_all['no_overlaps'][motif][category][0][-np.inf].index, y = nonbdb_flanking_all['no_overlaps'][motif][category][0][-np.inf], mode = 'lines', line = dict(width = 2, color = nonbdb_colors[1]['no overlaps'])), row=row_n, col=col_n)\n",
    "    plot_name.add_trace(go.Scatter(name = 'full corr.', legendgroup = 'corrected', showlegend = showleg, x = flanking_norm_all[motif][correct_cat][0][-2.774].index, y = flanking_norm_all[motif][correct_cat][0][-2.774], mode = 'lines', line = dict(width = 2, color = nonbdb_colors[1]['fully-corrected'])), row=row_n, col=col_n)\n",
    "\n",
    "    plot_name.add_shape(type='line', x0=-500, y0=1, x1=500, y1=1, line=dict(color='Black', width = .3), row=row_n, col=col_n)\n",
    "    plot_name.update_yaxes(zeroline = False, title = dict(text = display_name, font = dict(size = 18 if len(display_name) < 10 else round(18* (10/len(display_name))))), title_standoff = 0, row = row_n, col = col_n)\n",
    "\n",
    "# Function to generate individual plots\n",
    "def nonb_plot_flank(motif, category, correct_cat):\n",
    "    mutnorm_all_binconf_fig = make_subplots()\n",
    "    nonb_plot_flank_add(motif = motif, category = category, correct_cat = correct_cat, display_name = motif + ' ' + category, plot_name = mutnorm_all_binconf_fig, row_n = 1, col_n = 1, showleg = True)\n",
    "    mutnorm_all_binconf_fig.update_xaxes(range = [-250,250])\n",
    "    mutnorm_all_binconf_fig.update_yaxes(range = [0.1,3.1], zeroline = False)\n",
    "    return mutnorm_all_binconf_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4728880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Supplementary Figure S2D\n",
    "\n",
    "mutnorm_all_fig_combined_figS2d = make_subplots(rows = 5, cols = 2, shared_xaxes = True, vertical_spacing=0.02, horizontal_spacing = 0.11)\n",
    "\n",
    "counter = 0\n",
    "motif = 'STR'\n",
    "for category in ['A', 'C', 'AT', 'AC', 'AG']:\n",
    "    counter +=1\n",
    "    nonb_plot_flank_add(motif = motif, correct_cat = category, category=category, display_name = category, plot_name = mutnorm_all_fig_combined_figS2d, row_n = counter, col_n = 1, showleg = True if counter == 1 else False)\n",
    "    \n",
    "counter = 0\n",
    "for motif, category, nonb_category, name in zip(['IR', 'DR', 'MR', 'ZDNA', 'G4'], ['long_IRs', 'long_DRs', 'long_MRs', 'all_ZDNAs', 'K_G4s'], ['long', 'long', 'long', 'all', 'all'], ['Inverted', 'Direct', 'Mirror', 'Z-DNA', 'G4']):\n",
    "    counter +=1\n",
    "    nonb_plot_flank_add(motif = motif, correct_cat = category, category=nonb_category, display_name = name, plot_name = mutnorm_all_fig_combined_figS2d, row_n = counter, col_n = 2)\n",
    "\n",
    "mutnorm_all_fig_combined_figS2d.update_yaxes(range = [0.1,4.5])\n",
    "mutnorm_all_fig_combined_figS2d.update_yaxes(range = [0.1,7.9], row = 1, col = 1)\n",
    "mutnorm_all_fig_combined_figS2d.update_yaxes(range = [0.1,10.9], row = 2, col = 1)\n",
    "mutnorm_all_fig_combined_figS2d.update_yaxes(range = [0.49,1.75], row = 1, col = 2)\n",
    "\n",
    "    \n",
    "mutnorm_all_fig_combined_figS2d.update_xaxes(range = [-255,255], tickmode = 'array', tickvals = list(range(-250,300,50)))\n",
    "mutnorm_all_fig_combined_figS2d.update_layout(height = 650, width = 650, margin = dict(l = 55, r = 20, b = 45, t = 30), legend=dict(y = 1.05, x = -0.1, orientation='h', itemwidth = 30))\n",
    "mutnorm_all_fig_combined_figS2d.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff41f172",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutnorm_all_fig_combined_figS2d.write_image('./plots/revision_ACcor_flanking_mutation_fig_S2d.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e06a907",
   "metadata": {},
   "source": [
    "## Mutation frequency with gnomAD subsampling <a name=\"mutation_surrounding_subsample\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674533d6",
   "metadata": {},
   "source": [
    "#### Plot Supplementary Figure S2E <a name=\"mutation_surrounding_subsample_plot\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c20349",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutnorm_perfect_downsample_fig_combined_figS2e = make_subplots(rows = 5, cols = 4, vertical_spacing = 0.025, horizontal_spacing = 0.025, shared_yaxes = True, shared_xaxes = True)\n",
    "\n",
    "counter = 0\n",
    "motif = 'STR'\n",
    "for category in ['A', 'C', 'AT', 'AC', 'AG']:\n",
    "    counter +=1\n",
    "    plot_flank_add(motif = motif, category = category, input_dict = flanking_norm_all, display_name = category, plot_name = mutnorm_perfect_downsample_fig_combined_figS2e, row_n = counter, col_n = 1, showleg = True if counter == 1 else False)\n",
    "\n",
    "counter = 0\n",
    "for category in ['A', 'C', 'AT', 'AC', 'AG']:\n",
    "    counter +=1\n",
    "    plot_flank_add(motif = motif, category = category, input_dict = flanking_norm_subsample[0.1], display_name = category, plot_name = mutnorm_perfect_downsample_fig_combined_figS2e, row_n = counter, col_n = 2)\n",
    "\n",
    "counter = 0\n",
    "for category in ['A', 'C', 'AT', 'AC', 'AG']:\n",
    "    counter +=1\n",
    "    plot_flank_add(motif = motif, category = category, input_dict = flanking_norm_subsample[0.01], display_name = category, plot_name = mutnorm_perfect_downsample_fig_combined_figS2e, row_n = counter, col_n = 3)\n",
    "    \n",
    "counter = 0\n",
    "for category in ['A', 'C', 'AT', 'AC', 'AG']:\n",
    "    counter +=1\n",
    "    plot_flank_add(motif = motif, category = category, input_dict = flanking_norm_subsample[0.004], display_name = category, plot_name = mutnorm_perfect_downsample_fig_combined_figS2e, row_n = counter, col_n = 4)\n",
    "\n",
    "mutnorm_perfect_downsample_fig_combined_figS2e.update_yaxes(range = [0.25,4.25])\n",
    "\n",
    "mutnorm_perfect_downsample_fig_combined_figS2e.update_xaxes(title = dict(text = 'no subsample', standoff = 0, font = dict(size = 16)), row = 5, col = 1)\n",
    "mutnorm_perfect_downsample_fig_combined_figS2e.update_xaxes(title = dict(text = 'subsample 1/10', standoff = 0, font = dict(size = 16)), row = 5, col = 2)\n",
    "mutnorm_perfect_downsample_fig_combined_figS2e.update_xaxes(title = dict(text = 'subsample 1/100', standoff = 0, font = dict(size = 16)), row = 5, col = 3)\n",
    "mutnorm_perfect_downsample_fig_combined_figS2e.update_xaxes(title = dict(text = 'subsample 1/250', standoff = 0, font = dict(size = 16)), row = 5, col = 4)\n",
    "                \n",
    "for cols in range(1,5):\n",
    "    for rows in range(1,6):\n",
    "        mutnorm_perfect_downsample_fig_combined_figS2e.add_shape(type='line', x0=-100, y0=1, x1=250, y1=1, line=dict(color='Black', width = .3), row = rows, col = cols)\n",
    "mutnorm_perfect_downsample_fig_combined_figS2e.update_xaxes(range = [-100,100], tickmode = 'array', tickvals = [-100, -50, 0, 50, 100])\n",
    "mutnorm_perfect_downsample_fig_combined_figS2e.update_layout(width = 800, height = 500, margin = dict(l = 35, r = 25, b = 0, t = 20), legend=dict(y = -0.085, x = 0.2, orientation='h'))\n",
    "mutnorm_perfect_downsample_fig_combined_figS2e.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2826db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutnorm_perfect_downsample_fig_combined_figS2e.write_image('./plots/revision_ACcor_flanking_mutation_fig_S2E.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88baae67",
   "metadata": {},
   "source": [
    "### Plot de novo flanking mutagenesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45126586",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutnorm_denovo_figS2f = make_subplots(rows = 5, cols = 1, vertical_spacing = 0.025, horizontal_spacing = 0.025, shared_yaxes = True, shared_xaxes = True)\n",
    "\n",
    "counter = 0\n",
    "motif = 'STR'\n",
    "for category in ['A', 'AT', 'AC', 'AG']:\n",
    "    counter +=1\n",
    "    plot_flank_add(motif = motif, category = category, input_dict = flanking_norm_all, display_name = category, plot_name = mutnorm_denovo_figS2f, row_n = counter, col_n = 1, showleg = True if counter == 1 else False)\n",
    "    plot_flank_add_denovo(motif = motif, category = category, input_dict = flanking_norm_denovo, display_name = category, plot_name = mutnorm_denovo_figS2f, row_n = counter, col_n = 1, showleg = True if counter == 1 else False)\n",
    "counter +=1\n",
    "plot_flank_add(motif = 'G4', category = 'K_G4s', input_dict = flanking_norm_all, display_name = 'K+ G4', plot_name = mutnorm_denovo_figS2f, row_n = counter, col_n = 1, showleg = True if counter == 1 else False)\n",
    "plot_flank_add_denovo(motif = 'G4', category = 'K_G4s', input_dict = flanking_norm_denovo, display_name = 'K+ G4', plot_name = mutnorm_denovo_figS2f, row_n = counter, col_n = 1, showleg = True if counter == 1 else False)\n",
    "\n",
    "mutnorm_denovo_figS2f.update_yaxes(range = [0,4.25])\n",
    "\n",
    "mutnorm_denovo_figS2f.update_xaxes(range = [-100,100], tickmode = 'array', tickvals = [-100, -50, 0, 50, 100])\n",
    "mutnorm_denovo_figS2f.update_layout(width = 800, height = 600, margin = dict(l = 35, r = 25, b = 20, t = 20), legend=dict(y = -0.03, x = 0.2, orientation='h'))\n",
    "mutnorm_denovo_figS2f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a793bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutnorm_denovo_figS2f.write_image('./plots/revision_flanking_mutation_denovo_fig_S2F.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34ac2ab",
   "metadata": {},
   "source": [
    "## Mutation frequency per-mutation-type surrounding STRs  <a name=\"mutation_surrounding_bymut\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82babd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign plot colors for mutation types\n",
    "colors['ind_F'] = [mut for mut in triplet_mutations_und_TC if (mut[1] == 'C') & (mut[4] == 'A')], [mut for mut in triplet_mutations_und_TC if (mut[1] == 'C') & (mut[4] == 'G')], [mut for mut in triplet_mutations_und_TC if (mut[1] == 'C') & (mut[4] == 'T')], [mut for mut in triplet_mutations_und_TC if (mut[1] == 'T') & (mut[4] == 'A')], [mut for mut in triplet_mutations_und_TC if (mut[1] == 'T') & (mut[4] == 'C')], [mut for mut in triplet_mutations_und_TC if (mut[1] == 'T') & (mut[4] == 'G')]\n",
    "colors['ind_RC'] = [[reverse_complement_mut(mut) for mut in triplets] for triplets in colors['ind_F']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a71b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate normalized frequencies per mutation type for random sequences\n",
    "norm_random_bymut = dict()\n",
    "for mut_type in colors.index:\n",
    "    norm_random_bymut[mut_type] = mut_norm_conf(count_random_all, tri_subset = colors['ind_F'][mut_type], do_binconf = False, gc_correct = True)\n",
    "    norm_random_bymut[reverse_complement_mut(mut_type)] = mut_norm_conf(count_random_all, tri_subset = colors['ind_RC'][mut_type], do_binconf = False, gc_correct = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc92323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median SNV frequencies for each QC filter, used to normalize all later mutation frequencies\n",
    "normtorandom_bymut = dict()\n",
    "for mut_type in list(norm_random_bymut):\n",
    "    normtorandom_bymut[mut_type] = pd.Series([norm_random_bymut[mut_type][0][qc_cutoff].loc[-50:50].median() for qc_cutoff in norm_random_bymut[mut_type][0]], index = list(norm_random_bymut[mut_type][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd01b890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate normalized frequencies per mutation type for STRs\n",
    "norm_long_STRs_bymut = dict()\n",
    "for repeat in ['A', 'C', 'AT', 'AC', 'AG']:\n",
    "    norm_long_STRs_bymut[repeat] = dict()\n",
    "    print('\\r' + '                               ' + repeat, end='  ')\n",
    "    for mut_type in colors.index:\n",
    "        norm_long_STRs_bymut[repeat][mut_type] = mut_norm_conf(count_long_STRs[repeat], normtorandom = True, random_normaverage = normtorandom_bymut[mut_type], tri_subset = colors['ind_F'][mut_type], do_binconf = False, gc_correct = True)\n",
    "        norm_long_STRs_bymut[repeat][reverse_complement_mut(mut_type)] = mut_norm_conf(count_long_STRs[repeat], normtorandom = True, random_normaverage = normtorandom_bymut[mut_type], tri_subset = colors['ind_RC'][mut_type], do_binconf = False, gc_correct = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ced1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save temporary output of the mutation counts\n",
    "flanking_norm_bymut = dict()\n",
    "flanking_norm_bymut['STR'] = norm_long_STRs_bymut.copy()\n",
    "flanking_norm_bymut['random'] = norm_random_bymut.copy()\n",
    "\n",
    "with open('./analysis/temp/flank_norm_ACcor_bymut_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(flanking_norm_bymut, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c788e99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load temporary output of the mutation counts\n",
    "with open('./analysis/temp/flank_norm_ACcor_bymut_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    flanking_norm_bymut = pickle.load(handle)\n",
    "\n",
    "# Median SNV frequencies for each QC filter, used to normalize all later mutation frequencies\n",
    "normtorandom_bymut = dict()\n",
    "for mut_type in list(flanking_norm_bymut['random']):\n",
    "    normtorandom_bymut[mut_type] = pd.Series([flanking_norm_bymut['random'][mut_type][0][qc_cutoff].loc[-50:50].median() for qc_cutoff in flanking_norm_bymut['random'][mut_type][0]], index = list(flanking_norm_bymut['random'][mut_type][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbad274",
   "metadata": {},
   "source": [
    "#### Plot Supplementary Figure S4 <a name=\"mutation_surrounding_bymut_plot\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c9dd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate individual plot traces\n",
    "def plot_flank_add_bymut(motif, category, display_name, plot_name, row_n, col_n, input_dict, QCfilter, showleg = False):\n",
    "    for mut_type in colors.index:\n",
    "        plot_name.add_trace(go.Scatter(name = mut_type.replace('_', '>'), legendgroup = mut_type, showlegend = showleg, x = input_dict[motif][category][mut_type][0][QCfilter].index, y = input_dict[motif][category][mut_type][0][QCfilter], mode = 'lines', line = dict(width = 2, color = colors['color'][mut_type]), connectgaps=True), row=row_n, col=col_n)\n",
    "        plot_name.add_trace(go.Scatter(name = reverse_complement_mut(mut_type).replace('_', '>'), legendgroup = mut_type, showlegend = showleg, x = input_dict[motif][category][reverse_complement_mut(mut_type)][0][QCfilter].index, y = input_dict[motif][category][reverse_complement_mut(mut_type)][0][QCfilter], mode = 'lines', line = dict(width = 2, dash = 'dot', color = colors['color'][mut_type]), connectgaps=True), row=row_n, col=col_n)\n",
    "    plot_name.add_shape(type='line', x0=-500, y0=1, x1=500, y1=1, line=dict(color='Black', width = .3), row=row_n, col=col_n)\n",
    "    plot_name.update_yaxes(zeroline = False, title = dict(text = display_name, font = dict(size = 18 if len(display_name) < 10 else round(18* (10/len(display_name))))), title_standoff = 0, row = row_n, col = col_n)\n",
    "\n",
    "# Function to generate individual plots\n",
    "def plot_flank_bymut(motif, category, QCfilter, input_dict = flanking_norm_bymut):\n",
    "    mutnorm_all_binconf_fig = make_subplots()\n",
    "    plot_flank_add_bymut(motif = motif, category = category, display_name = motif + ' ' + category, plot_name = mutnorm_all_binconf_fig, row_n = 1, col_n = 1, input_dict = input_dict, QCfilter = QCfilter, showleg = True)\n",
    "    mutnorm_all_binconf_fig.update_xaxes(range = [-50,50])\n",
    "    mutnorm_all_binconf_fig.update_yaxes(range = [0.1,15.1], zeroline = False)\n",
    "    return mutnorm_all_binconf_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0312bea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutnorm_perfect_bymut_fig_combined_figS2g = make_subplots(rows = 5, cols = 4, vertical_spacing = 0.025, horizontal_spacing = 0.025, shared_yaxes = True, shared_xaxes = True)\n",
    "\n",
    "counter = 0\n",
    "motif = 'STR'\n",
    "for category in ['A', 'C', 'AT', 'AC', 'AG']:\n",
    "    counter +=1\n",
    "    plot_flank_add_bymut(motif = motif, category = category, QCfilter = -np.inf, input_dict = flanking_norm_bymut, display_name = category, plot_name = mutnorm_perfect_bymut_fig_combined_figS2g, row_n = counter, col_n = 1, showleg = True if counter == 1 else False)\n",
    "\n",
    "counter = 0\n",
    "for category in ['A', 'C', 'AT', 'AC', 'AG']:\n",
    "    counter +=1\n",
    "    plot_flank_add_bymut(motif = motif, category = category, QCfilter = -2.774, input_dict = flanking_norm_bymut, display_name = category, plot_name = mutnorm_perfect_bymut_fig_combined_figS2g, row_n = counter, col_n = 2)\n",
    "\n",
    "counter = 0\n",
    "for category in ['A', 'C', 'AT', 'AC', 'AG']:\n",
    "    counter +=1\n",
    "    plot_flank_add_bymut(motif = motif, category = category, QCfilter = 0, input_dict = flanking_norm_bymut, display_name = category, plot_name = mutnorm_perfect_bymut_fig_combined_figS2g, row_n = counter, col_n = 3)\n",
    "    \n",
    "counter = 0\n",
    "for category in ['A', 'C', 'AT', 'AC', 'AG']:\n",
    "    counter +=1\n",
    "    plot_flank_add_bymut(motif = motif, category = category, QCfilter = 4, input_dict = flanking_norm_bymut, display_name = category, plot_name = mutnorm_perfect_bymut_fig_combined_figS2g, row_n = counter, col_n = 4)\n",
    "\n",
    "mutnorm_perfect_bymut_fig_combined_figS2g.update_yaxes(range = [0.25,10.2], row = 1)\n",
    "mutnorm_perfect_bymut_fig_combined_figS2g.update_yaxes(range = [0.25,5.1], row = 2)\n",
    "mutnorm_perfect_bymut_fig_combined_figS2g.update_yaxes(range = [0.25,8.2], row = 3)\n",
    "mutnorm_perfect_bymut_fig_combined_figS2g.update_yaxes(range = [0.25,5.1], row = 4)\n",
    "mutnorm_perfect_bymut_fig_combined_figS2g.update_yaxes(range = [0.25,5.1], row = 5)\n",
    "\n",
    "mutnorm_perfect_bymut_fig_combined_figS2g.update_xaxes(title = dict(text = 'no QC', standoff = 0, font = dict(size = 16)), row = 5, col = 1)\n",
    "mutnorm_perfect_bymut_fig_combined_figS2g.update_xaxes(title = dict(text = 'pass', standoff = 0, font = dict(size = 16)), row = 5, col = 2)\n",
    "mutnorm_perfect_bymut_fig_combined_figS2g.update_xaxes(title = dict(text = 'VQSLOD>0', standoff = 0, font = dict(size = 16)), row = 5, col = 3)\n",
    "mutnorm_perfect_bymut_fig_combined_figS2g.update_xaxes(title = dict(text = 'VQSLOD>4', standoff = 0, font = dict(size = 16)), row = 5, col = 4)\n",
    "                \n",
    "for cols in range(1,5):\n",
    "    for rows in range(1,6):\n",
    "        mutnorm_perfect_bymut_fig_combined_figS2g.add_shape(type='line', x0=-100, y0=1, x1=250, y1=1, line=dict(color='Black', width = .3), row = rows, col = cols)\n",
    "mutnorm_perfect_bymut_fig_combined_figS2g.update_xaxes(range = [-25,25], tickmode = 'array', tickvals = [-20, -10, 0, 10, 20])\n",
    "mutnorm_perfect_bymut_fig_combined_figS2g.update_layout(width = 800, height = 800, margin = dict(l = 35, r = 25, b = 0, t = 20), legend=dict(y = -0.085, x = 0.2, orientation='h'))\n",
    "mutnorm_perfect_bymut_fig_combined_figS2g.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c035011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutnorm_perfect_bymut_fig_combined_figS2g.write_image('./plots/revision_ACcor_flanking_mutation_fig_S2G.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bd1894",
   "metadata": {},
   "source": [
    "# Indels flanking motifs <a name=\"indel_analysis_flank\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)\n",
    "\n",
    "#### Define counting functions for indels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde36c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_indel_flank_chrom(chrom, current_pos_chrom, input_mut_dict, distance, left_pos_col, right_pos_col, filter_cols, filter_distance, useful_cols, vqslod_list_indel, indel_types):\n",
    "    print('\\r' + str(chrom), end='        ')\n",
    "\n",
    "    # filter out motifs too close to masked elements\n",
    "    current_pos_chrom = current_pos_chrom.loc[current_pos_chrom[[col + '_min' for col in filter_cols]].fillna(0).min(axis=1) > filter_distance].copy()\n",
    "  \n",
    "    # make a single dataframe consisting of all search coordinates and their position relative to the original starts/ends of interest\n",
    "    \n",
    "    search_positions_left = dict()\n",
    "    for pos in range(-distance,0):\n",
    "        search_positions_left[pos] = pd.DataFrame(current_pos_chrom[left_pos_col] + pos)\n",
    "    search_positions_left = pd.concat(search_positions_left).reset_index()[[left_pos_col, 'level_0']]\n",
    "    for col in useful_cols:\n",
    "        search_positions_left[col] = list(current_pos_chrom[col])*distance\n",
    "    if len(filter_cols) > 0:\n",
    "        search_positions_left['filter_left'] = list(current_pos_chrom[[col + '_left' for col in filter_cols]].min(axis=1))*distance\n",
    "        search_positions_left = search_positions_left.loc[search_positions_left['level_0'].abs() <= (search_positions_left['filter_left'] - filter_distance)].copy()\n",
    "        del search_positions_left['filter_left']\n",
    "    search_positions_left.columns = ['POS_mid', 'relative_pos'] + useful_cols\n",
    "\n",
    "    search_positions_right = dict()\n",
    "    for pos in range(1,distance+1):\n",
    "        search_positions_right[pos] = pd.DataFrame(current_pos_chrom[right_pos_col] + pos -1)\n",
    "    search_positions_right = pd.concat(search_positions_right).reset_index()[[right_pos_col, 'level_0']]\n",
    "    for col in useful_cols:\n",
    "        search_positions_right[col] = list(current_pos_chrom[col])*distance\n",
    "    if len(filter_cols) > 0:\n",
    "        search_positions_right['filter_right'] = list(current_pos_chrom[[col + '_right' for col in filter_cols]].min(axis=1))*distance\n",
    "        search_positions_right = search_positions_right.loc[search_positions_right['level_0'] <= (search_positions_right['filter_right'] - filter_distance)].copy()\n",
    "        del search_positions_right['filter_right']\n",
    "    search_positions_right.columns = ['POS_mid', 'relative_pos'] + useful_cols\n",
    "\n",
    "    for col in filter_cols:\n",
    "        current_pos_chrom = current_pos_chrom.loc[current_pos_chrom[col + '_min'] >= filter_distance].copy()\n",
    "    current_pos_chrom['pos'] = [list(range(left,right)) for left, right in zip(current_pos_chrom[left_pos_col], current_pos_chrom[right_pos_col])]\n",
    "    for col in useful_cols:\n",
    "        current_pos_chrom[col] = [[entry]*len(pos) for entry, pos in zip(current_pos_chrom[col], current_pos_chrom['pos'])]\n",
    "    search_positions_middle = pd.DataFrame(flatten(current_pos_chrom['pos']), columns = ['POS_mid'])\n",
    "    search_positions_middle['relative_pos'] = 0\n",
    "    for col in useful_cols:\n",
    "        search_positions_middle[col] = pd.DataFrame(flatten(current_pos_chrom[col]))\n",
    "\n",
    "    search_positions = pd.concat([search_positions_left, search_positions_right, search_positions_middle])\n",
    "        \n",
    "    # for each qc_cutoff in the mutation dataset, find mutations overlapping the search coordinates\n",
    "    current_mut_count = dict()\n",
    "    current_mut_chrom = input_mut_dict[chrom].copy()\n",
    "    current_mut_chrom.index = current_mut_chrom.index - 1     # change coordinates from base1 to base0\n",
    "\n",
    "    print('\\r' + str(chrom), end='        ')\n",
    "    current_mut_count = current_mut_chrom.reindex(search_positions['POS_mid'])\n",
    "    current_mut_count['pos'] = list(search_positions['relative_pos'])\n",
    "    current_mut_count['Tri'] = [tri_function(chrom, pos, base = 0) for pos in current_mut_count.index]\n",
    "\n",
    "    for col in useful_cols:\n",
    "        current_mut_count[col] = list(search_positions[col])\n",
    "    current_mut_count['tri_count'] = 1    \n",
    "    current_mut_count = current_mut_count.loc[current_mut_count['Tri'].isin(all_triplets)]\n",
    "    \n",
    "    # count mutations at each relative position using groupby\n",
    "    current_mut_sum_group = current_mut_count.groupby(['pos'] + useful_cols + ['Tri']).sum()\n",
    "    current_mut_sum = dict()\n",
    "    for qc_cutoff in vqslod_list_indel:\n",
    "        current_mut_sum[qc_cutoff] = current_mut_sum_group[[qc_cutoff, 'tri_count']].astype(int)\n",
    "        current_mut_sum[qc_cutoff].columns = indel_types + ['tri_count']\n",
    "        \n",
    "    return current_mut_sum\n",
    "\n",
    "def count_indel_flank(input_pos_df, input_mut_dict = variants_indel_slim_AC, distance = 500, left_pos_col = 'start', right_pos_col = 'end', chrom_col = 'chrom', strand_col = 'Strand', strand_names = ('+', '-'), filter_cols = ['RM_distance'], filter_distance = 20, useful_cols = [], indel_types = ['del', 'ins']):\n",
    "   \n",
    "    current_mut_sum_chrom = dict()\n",
    "    for chrom in range(chr_range,23):\n",
    "        current_mut_sum_chrom[chrom] = count_indel_flank_chrom(chrom, input_pos_df.loc[input_pos_df[chrom_col] == chrom], input_mut_dict, distance = distance, left_pos_col = left_pos_col, right_pos_col = right_pos_col, filter_cols = filter_cols, filter_distance = filter_distance, useful_cols = useful_cols, vqslod_list_indel = vqslod_list_indel, indel_types = indel_types)\n",
    "    \n",
    "    current_mut_sum = dict()\n",
    "    for qc_cutoff in vqslod_list_indel:\n",
    "        current_mut_sum[qc_cutoff] = pd.concat([current_mut_sum_chrom[chrom][qc_cutoff] for chrom in range(chr_range,23)])\n",
    "        \n",
    "    # apply reverse complement to - strand triplets, mutation counts and positions          \n",
    "    \n",
    "    if strand_col in useful_cols:\n",
    "        useful_cols.remove(strand_col)\n",
    "        current_mut_sum_strand_F = dict()\n",
    "        current_mut_sum_strand_R = dict()\n",
    "        current_mut_sum_strand_other = dict()\n",
    "        current_mut_sum_bothstrands = dict()\n",
    "        for qc_cutoff in current_mut_sum:\n",
    "            current_mut_sum_strand_other[qc_cutoff] = current_mut_sum[qc_cutoff].loc[~current_mut_sum[qc_cutoff].index.get_level_values(strand_col).isin(strand_names)]\n",
    "            current_mut_sum_strand_other[qc_cutoff] = current_mut_sum_strand_other[qc_cutoff].reset_index().groupby(['pos'] + useful_cols + ['Tri']).sum()\n",
    "            \n",
    "            current_mut_sum_strand_F[qc_cutoff] = current_mut_sum[qc_cutoff].loc[current_mut_sum[qc_cutoff].index.get_level_values(strand_col) == strand_names[0]]\n",
    "            current_mut_sum_strand_F[qc_cutoff] = current_mut_sum_strand_F[qc_cutoff].reset_index().groupby(['pos'] + useful_cols + ['Tri']).sum()\n",
    "\n",
    "            current_mut_sum_strand_R[qc_cutoff] = current_mut_sum[qc_cutoff].loc[current_mut_sum[qc_cutoff].index.get_level_values(strand_col) == strand_names[1]]\n",
    "            current_mut_sum_strand_R[qc_cutoff] = current_mut_sum_strand_R[qc_cutoff].reset_index()\n",
    "            current_mut_sum_strand_R[qc_cutoff]['Tri'] = current_mut_sum_strand_R[qc_cutoff]['Tri'].apply(reverse_complement)\n",
    "            current_mut_sum_strand_R[qc_cutoff]['pos'] = -current_mut_sum_strand_R[qc_cutoff]['pos']\n",
    "            current_mut_sum_strand_R[qc_cutoff] = current_mut_sum_strand_R[qc_cutoff].groupby(['pos'] + useful_cols + ['Tri']).sum()\n",
    "            current_mut_sum_strand_R[qc_cutoff].columns = indel_types + ['tri_count']\n",
    "            current_mut_sum_strand_R[qc_cutoff] = current_mut_sum_strand_R[qc_cutoff][indel_types + ['tri_count']]\n",
    "\n",
    "            current_mut_sum_bothstrands[qc_cutoff] = current_mut_sum_strand_F[qc_cutoff].add(current_mut_sum_strand_R[qc_cutoff], fill_value = 0).add(current_mut_sum_strand_other[qc_cutoff], fill_value = 0).astype(int)\n",
    "    else:\n",
    "        current_mut_sum_bothstrands = dict()\n",
    "        for qc_cutoff in current_mut_sum:\n",
    "            current_mut_sum_bothstrands[qc_cutoff] = current_mut_sum[qc_cutoff].reset_index().groupby(['pos'] + useful_cols + ['Tri']).sum().fillna(0).astype(int)\n",
    "\n",
    "    # reformat output to NNN_N rows x pos columns, and split mut counts and trinucleotide counts\n",
    "    \n",
    "    current_mut_sum_reformat = dict()\n",
    "    for qc_cutoff in current_mut_sum:\n",
    "        current_mut_sum_reformat[qc_cutoff] = dict()\n",
    "        for mut in indel_types:\n",
    "            current_mut_sum_reformat[qc_cutoff][mut] = current_mut_sum_bothstrands[qc_cutoff].unstack().transpose().fillna(0).astype(int).loc[mut]\n",
    "            current_mut_sum_reformat[qc_cutoff][mut].index = [tri+'_'+mut for tri in current_mut_sum_reformat[qc_cutoff][mut].index]\n",
    "        current_mut_sum_reformat[qc_cutoff] = pd.concat(current_mut_sum_reformat[qc_cutoff]).reset_index().groupby(['level_1']).sum().reindex(triplet_mutations_und_indel)\n",
    "        current_mut_sum_reformat[qc_cutoff].index.name = 'Mut'\n",
    "\n",
    "    current_tri_sum = current_mut_sum_bothstrands[qc_cutoff].unstack().transpose().fillna(0).astype(int).loc['tri_count'].reindex(all_triplets)\n",
    "\n",
    "    return current_mut_sum_reformat.copy(), current_tri_sum.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31abde34",
   "metadata": {},
   "source": [
    "### Count indels <a name=\"indel_analysis_flank_count\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)\n",
    "\n",
    "#### Random sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0fe5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count indels (all)\n",
    "count_random_indel = count_indel_flank(random_seq, left_pos_col = 'start', right_pos_col = 'end', filter_cols = ['RM_distance', 'STR_distance', 'nonSTR_distance', 'within_motif_distance'], useful_cols = ['Strand'])\n",
    "\n",
    "norm_random_indel = dict()\n",
    "norm_random_indel['ins'] = mut_norm_conf(count_random_indel, snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins)\n",
    "norm_random_indel['del'] = mut_norm_conf(count_random_indel, snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del)\n",
    "\n",
    "normtorandom_indel = pd.DataFrame()\n",
    "normtorandom_indel['ins'] = pd.Series([norm_random_indel['ins'][0][qc_cutoff].loc[-50:50].median() for qc_cutoff in norm_random_indel['ins'][0]], index = vqslod_list_indel)\n",
    "normtorandom_indel['del'] = pd.Series([norm_random_indel['del'][0][qc_cutoff].loc[-50:50].median() for qc_cutoff in norm_random_indel['del'][0]], index = vqslod_list_indel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4234c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count long/short indels\n",
    "count_random_indel_long = count_indel_flank(random_seq, input_mut_dict = variants_ins_slim_AC_long, left_pos_col = 'start', right_pos_col = 'end', filter_cols = ['RM_distance', 'STR_distance', 'nonSTR_distance', 'within_motif_distance'], useful_cols = ['Strand'], indel_types = ['ins'])\n",
    "norm_random_indel['ins_long'] = mut_norm_conf(count_random_indel_long, snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_ins_count_AC_freq_long, tri_subset = triplet_mutations_und_ins)\n",
    "normtorandom_indel['ins_long'] = pd.Series([norm_random_indel['ins_long'][0][qc_cutoff].loc[-50:50].median() for qc_cutoff in norm_random_indel['ins_long'][0]], index = vqslod_list_indel)\n",
    "\n",
    "count_random_indel_short = count_indel_flank(random_seq, input_mut_dict = variants_ins_slim_AC_short, left_pos_col = 'start', right_pos_col = 'end', filter_cols = ['RM_distance', 'STR_distance', 'nonSTR_distance', 'within_motif_distance'], useful_cols = ['Strand'], indel_types = ['ins'])\n",
    "norm_random_indel['ins_short'] = mut_norm_conf(count_random_indel_short, snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_ins_count_AC_freq_short, tri_subset = triplet_mutations_und_ins)\n",
    "normtorandom_indel['ins_short'] = pd.Series([norm_random_indel['ins_short'][0][qc_cutoff].loc[-50:50].median() for qc_cutoff in norm_random_indel['ins_short'][0]], index = vqslod_list_indel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8ccb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign color scheme for indel plots\n",
    "QC_colors_indel = make_colorscale(vqslod_list_indel)\n",
    "QC_colors_indel = pd.DataFrame(QC_colors_indel).transpose()\n",
    "QC_colors_indel['name'] = ['no QC', 'pass', 'VQSLOD >0', 'VQSLOD >1.4']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c841aa10",
   "metadata": {},
   "source": [
    "#### Count STRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46341b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_STRs_indel = dict()\n",
    "norm_STRs_indel = dict()\n",
    "for repeat in repeats_highpower_asym[:11].index:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    count_STRs_indel[repeat] = count_indel_flank(long_STRs[repeat], filter_cols = ['RM_distance', 'STR_distance', 'nonSTR_distance', 'within_motif_distance'], useful_cols = ['Strand'])\n",
    "for repeat in repeats_highpower_sym:\n",
    "    print('\\r' + '                     ' + repeat, end='  ')\n",
    "    count_STRs_indel[repeat] = count_indel_flank(long_STRs[repeat], filter_cols = ['RM_distance', 'STR_distance', 'nonSTR_distance', 'within_motif_distance'], useful_cols = [])\n",
    "count_STRs_indel['GC_noCGI'] = count_indel_flank(STRs_CG, filter_cols = ['RM_distance', 'STR_distance', 'nonSTR_distance', 'within_motif_distance', 'CGI_distance'])\n",
    "for repeat in count_STRs_indel:\n",
    "    norm_STRs_indel[repeat] = dict()\n",
    "    norm_STRs_indel[repeat]['ins'] = mut_norm_conf(count_STRs_indel[repeat], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "    norm_STRs_indel[repeat]['del'] = mut_norm_conf(count_STRs_indel[repeat], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2d3b2d",
   "metadata": {},
   "source": [
    "#### Count IRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6777083",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_IRs_indel = dict()\n",
    "norm_IRs_indel = dict()\n",
    "for motif, name in zip([long_IRs, very_long_IRs, AT80_IRs, AT40_IRs, long_IRs_loop10], ['long_IRs', 'very_long_IRs', 'AT80_IRs', 'AT40_IRs', 'long_IRs_loop10']):\n",
    "    print('\\r' + '                     ' + name, end='  ')\n",
    "    count_IRs_indel[name] = count_indel_flank(motif, filter_cols = ['RM_distance', 'STR_distance', 'nonSTR_distance', 'within_motif_distance'], useful_cols = [])\n",
    "    norm_IRs_indel[name] = dict()\n",
    "    norm_IRs_indel[name]['ins'] = mut_norm_conf(count_IRs_indel[name], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "    norm_IRs_indel[name]['del'] = mut_norm_conf(count_IRs_indel[name], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b2ef27",
   "metadata": {},
   "source": [
    "#### Count MRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18173d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_MRs_indel = dict()\n",
    "norm_MRs_indel = dict()\n",
    "for motif, name in zip([long_MRs, very_long_MRs, non_homopurine_MRs, long_MRs_loop10], ['long_MRs', 'very_long_MRs', 'non_homopurine_MRs', 'long_MRs_loop10']):\n",
    "    print('\\r' + '                     ' + name, end='  ')\n",
    "    count_MRs_indel[name] = count_indel_flank(motif, filter_cols = ['RM_distance', 'STR_distance', 'nonSTR_distance', 'within_motif_distance'], useful_cols = [])\n",
    "for motif, name in zip([homopurine_MRs], ['homopurine_MRs']):\n",
    "    print('\\r' + '                     ' + name, end='  ')\n",
    "    count_MRs_indel[name] = count_indel_flank(motif, filter_cols = ['RM_distance', 'STR_distance', 'nonSTR_distance', 'within_motif_distance'], useful_cols = ['Strand'])\n",
    "for name in count_MRs_indel:\n",
    "    norm_MRs_indel[name] = dict()\n",
    "    norm_MRs_indel[name]['ins'] = mut_norm_conf(count_MRs_indel[name], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "    norm_MRs_indel[name]['del'] = mut_norm_conf(count_MRs_indel[name], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b41378d",
   "metadata": {},
   "source": [
    "#### Count DRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27df601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_DRs_indel = dict()\n",
    "norm_DRs_indel = dict()\n",
    "for motif, name in zip([long_DRs, very_long_DRs, perfect_long_DRs, long_DRs_loop10], ['long_DRs', 'very_long_DRs', 'perfect_long_DRs', 'long_DRs_loop10']):\n",
    "    print('\\r' + '                     ' + name, end='  ')\n",
    "    count_DRs_indel[name] = count_indel_flank(motif, filter_cols = ['RM_distance', 'STR_distance', 'nonSTR_distance', 'within_motif_distance'], useful_cols = [])\n",
    "    norm_DRs_indel[name] = dict()\n",
    "    norm_DRs_indel[name]['ins'] = mut_norm_conf(count_DRs_indel[name], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "    norm_DRs_indel[name]['del'] = mut_norm_conf(count_DRs_indel[name], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53efe620",
   "metadata": {},
   "source": [
    "#### Count ZDNAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6201612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_ZDNAs_indel = dict()\n",
    "norm_ZDNAs_indel = dict()\n",
    "for motif, name in zip([all_ZDNAs, long_ZDNAs], ['all_ZDNAs', 'long_ZDNAs']):\n",
    "    print('\\r' + '                     ' + name, end='  ')\n",
    "    count_ZDNAs_indel[name] = count_indel_flank(motif, filter_cols = ['RM_distance', 'STR_distance', 'nonSTR_distance', 'within_motif_distance'], useful_cols = [])\n",
    "for motif, name in zip([ZDNAs_GY], ['ZDNAs_GY']):\n",
    "    print('\\r' + '                     ' + name, end='  ')\n",
    "    count_ZDNAs_indel[name] = count_indel_flank(motif, filter_cols = ['RM_distance', 'STR_distance', 'nonSTR_distance', 'within_motif_distance'], useful_cols = ['Strand'])\n",
    "for name in count_ZDNAs_indel:\n",
    "    norm_ZDNAs_indel[name] = dict()\n",
    "    norm_ZDNAs_indel[name]['ins'] = mut_norm_conf(count_ZDNAs_indel[name], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "    norm_ZDNAs_indel[name]['del'] = mut_norm_conf(count_ZDNAs_indel[name], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822e7bc6",
   "metadata": {},
   "source": [
    "#### Count G4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8fbea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_G4s_indel = dict()\n",
    "norm_G4s_indel = dict()\n",
    "for motif, name in zip([K_G4s, PDS_G4s], ['K_G4s', 'PDS_G4s']):\n",
    "    print('\\r' + '                     ' + name, end='  ')\n",
    "    count_G4s_indel[name] = count_indel_flank(motif, left_pos_col = 'start', right_pos_col = 'end', filter_cols = ['RM_distance', 'STR_distance', 'nonSTR_distance', 'within_motif_distance'], useful_cols = ['Strand'])\n",
    "    norm_G4s_indel[name] = dict()\n",
    "    norm_G4s_indel[name]['ins'] = mut_norm_conf(count_G4s_indel[name], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "    norm_G4s_indel[name]['del'] = mut_norm_conf(count_G4s_indel[name], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87836c98",
   "metadata": {},
   "source": [
    "### Save/load <a name=\"indel_analysis_flank_load\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e8a2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save temporary output of the mutation counts\n",
    "flanking_norm_indel = dict()\n",
    "flanking_norm_indel['STR'] = norm_STRs_indel.copy()\n",
    "flanking_norm_indel['IR'] = norm_IRs_indel.copy()\n",
    "flanking_norm_indel['MR'] = norm_MRs_indel.copy()\n",
    "flanking_norm_indel['DR'] = norm_DRs_indel.copy()\n",
    "flanking_norm_indel['ZDNA'] = norm_ZDNAs_indel.copy()\n",
    "flanking_norm_indel['G4'] = norm_G4s_indel.copy()\n",
    "flanking_norm_indel['random'] =norm_random_indel.copy()\n",
    "\n",
    "with open('./analysis/temp/flanking_norm_indel_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(flanking_norm_indel, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb9b4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load temporary output of the mutation counts\n",
    "with open('./analysis/temp/flanking_norm_indel_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    flanking_norm_indel = pickle.load(handle)\n",
    "\n",
    "normtorandom_indel = pd.DataFrame()\n",
    "normtorandom_indel['ins'] = pd.Series([flanking_norm_indel['random']['ins'][0][qc_cutoff].loc[-50:50].median() for qc_cutoff in flanking_norm_indel['random']['ins'][0]], index = vqslod_list_indel)\n",
    "normtorandom_indel['del'] = pd.Series([flanking_norm_indel['random']['del'][0][qc_cutoff].loc[-50:50].median() for qc_cutoff in flanking_norm_indel['random']['del'][0]], index = vqslod_list_indel)\n",
    "\n",
    "normtorandom_indel['ins_long'] = pd.Series([flanking_norm_indel['random']['ins_long'][0][qc_cutoff].loc[-50:50].median() for qc_cutoff in flanking_norm_indel['random']['ins_long'][0]], index = vqslod_list_indel)\n",
    "normtorandom_indel['ins_short'] = pd.Series([flanking_norm_indel['random']['ins_short'][0][qc_cutoff].loc[-50:50].median() for qc_cutoff in flanking_norm_indel['random']['ins_short'][0]], index = vqslod_list_indel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820376af",
   "metadata": {},
   "source": [
    "### Plot <a name=\"indel_analysis_flank_plot\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6052e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color scale for indel QC cutoffs\n",
    "vqslod_list_indel = [-np.inf, -1.0607, 0, 1.4]\n",
    "QC_colors_indel = make_colorscale(vqslod_list_indel)\n",
    "QC_colors_indel = pd.DataFrame(QC_colors_indel).transpose()\n",
    "QC_colors_indel['name'] = ['no QC', 'pass', 'VQSLOD >0', 'VQSLOD >1.4']\n",
    "\n",
    "# Function to generate individual plot traces\n",
    "def plot_indel_flank_add(motif, category, mut_type, display_name, plot_name, row_n, col_n, input_dict = flanking_norm_indel, showleg = False):\n",
    "    for QCfilter in QC_colors_indel[0].index:\n",
    "        plot_name.add_trace(go.Scatter(name = QC_colors_indel['name'][QCfilter], legendgroup = QCfilter, showlegend=False, fill=None, x = input_dict[motif][category][mut_type][2][QCfilter].dropna().index, y = input_dict[motif][category][mut_type][2][QCfilter].dropna(), mode = 'lines', line = dict(width = 0, color = QC_colors_indel[0][QCfilter])), row=row_n, col=col_n)\n",
    "        plot_name.add_trace(go.Scatter(name = QC_colors_indel['name'][QCfilter], legendgroup = QCfilter, showlegend = showleg, fill='tonexty', fillcolor = QC_colors_indel[1][QCfilter], x = input_dict[motif][category][mut_type][0][QCfilter].index, y = input_dict[motif][category][mut_type][0][QCfilter], mode = 'lines', line = dict(width = 2, color = QC_colors_indel[0][QCfilter])), row=row_n, col=col_n)\n",
    "        plot_name.add_trace(go.Scatter(name = QC_colors_indel['name'][QCfilter], legendgroup = QCfilter, showlegend=False, fill='tonexty', fillcolor = QC_colors_indel[1][QCfilter], x = input_dict[motif][category][mut_type][1][QCfilter].dropna().index, y = input_dict[motif][category][mut_type][1][QCfilter].dropna(), mode = 'lines', line = dict(width = 0, color = QC_colors_indel[0][QCfilter])), row=row_n, col=col_n)\n",
    "    plot_name.add_shape(type='line', x0=-500, y0=1, x1=500, y1=1, line=dict(color='Black', width = .3), row=row_n, col=col_n)\n",
    "    plot_name.update_yaxes(zeroline = False, title = dict(text = display_name, font = dict(size = 18 if len(display_name) < 10 else round(18* (10/len(display_name))))), title_standoff = 0, row = row_n, col = col_n)\n",
    "\n",
    "# Function to generate individual plots\n",
    "def plot_indel_flank(motif, category, input_dict = flanking_norm_indel, log = False, yrange = [.01, 10]):\n",
    "    mutnorm_all_binconf_fig = make_subplots(rows = 2, shared_xaxes = True)\n",
    "    plot_indel_flank_add(motif = motif, category = category, mut_type = 'ins', display_name = motif + ' ' + category + ' ins', plot_name = mutnorm_all_binconf_fig, row_n = 1, col_n = 1, input_dict = input_dict, showleg = True)\n",
    "    plot_indel_flank_add(motif = motif, category = category, mut_type = 'del', display_name = motif + ' ' + category + ' del', plot_name = mutnorm_all_binconf_fig, row_n = 2, col_n = 1, input_dict = input_dict, showleg = False)\n",
    "    mutnorm_all_binconf_fig.update_xaxes(range = [-250,250])\n",
    "    mutnorm_all_binconf_fig.update_yaxes(range = yrange, zeroline = False, type = 'log' if log == True else 'linear')\n",
    "    return mutnorm_all_binconf_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc03daa",
   "metadata": {},
   "source": [
    "#### Supplementary figure S2H <a name=\"indel_analysis_flank_plot_S2H\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c6ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Supplementary Figure S2H\n",
    "\n",
    "indel_fig_combined_figS2h = make_subplots(rows = 5, cols = 4, shared_xaxes = True, vertical_spacing=0.02, horizontal_spacing = 0.11, subplot_titles = ['insertion', 'deletion', 'insertion', 'deletion'])\n",
    "\n",
    "counter = 0\n",
    "motif = 'STR'\n",
    "for category in ['A', 'C', 'AT', 'AC', 'AG']:\n",
    "    counter +=1\n",
    "    plot_indel_flank_add(motif = motif, category = category, mut_type = 'ins', display_name = category, plot_name = indel_fig_combined_figS2h, row_n = counter, col_n = 1, showleg = True if counter == 1 else False)\n",
    "    plot_indel_flank_add(motif = motif, category = category, mut_type = 'del', display_name = '', plot_name = indel_fig_combined_figS2h, row_n = counter, col_n = 2, showleg = False)\n",
    "\n",
    "    \n",
    "counter = 0\n",
    "for motif, category, name in zip(['IR', 'DR', 'MR', 'ZDNA', 'G4'], ['long_IRs_loop10', 'long_DRs_loop10', 'long_MRs_loop10', 'long_ZDNAs', 'K_G4s'], ['Inverted', 'Direct', 'Mirror', 'Z-DNA', 'G4']):\n",
    "    counter +=1\n",
    "    plot_indel_flank_add(motif = motif, category = category, mut_type = 'ins', display_name = name, plot_name = indel_fig_combined_figS2h, row_n = counter, col_n = 3)\n",
    "    plot_indel_flank_add(motif = motif, category = category, mut_type = 'del', display_name = '', plot_name = indel_fig_combined_figS2h, row_n = counter, col_n = 4)\n",
    "    \n",
    "indel_fig_combined_figS2h.update_xaxes(domain=[0, 0.21], col = 1)\n",
    "indel_fig_combined_figS2h.update_xaxes(domain=[0.23, 0.44], col = 2)\n",
    "indel_fig_combined_figS2h.update_xaxes(domain=[0.56, 0.77], col = 3)\n",
    "indel_fig_combined_figS2h.update_xaxes(domain=[0.79, 1], col = 4)\n",
    "\n",
    "indel_fig_combined_figS2h.update_yaxes(range = [-0.299,2.75], type = 'log', dtick = 1)\n",
    "indel_fig_combined_figS2h.update_yaxes(showticklabels = False, col = 2)\n",
    "indel_fig_combined_figS2h.update_yaxes(showticklabels = False, col = 4)\n",
    "\n",
    "    \n",
    "indel_fig_combined_figS2h.update_xaxes(range = [-50,50], tickmode = 'array', tickvals = list(range(-40,60,20)))\n",
    "indel_fig_combined_figS2h.update_layout(height = 650, width = 800, margin = dict(l = 55, r = 25, b = 45, t = 30), legend=dict(y = -.075, x = -0.075, orientation='h', itemwidth = 30))\n",
    "indel_fig_combined_figS2h.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29699d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "indel_fig_combined_figS2h.write_image('./plots/revision_flanking_indel_fig_S2H.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92529583",
   "metadata": {},
   "source": [
    "# Calculate mutation frequency at internal motif positions <a name=\"mutation_internal\"></a>\n",
    "\n",
    "## Annotate positions within motifs <a name=\"mutation_internal_annotate\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ec2283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Re)Load motif database\n",
    "all_motifs_unique = pd.read_pickle('./custom_db/all_motifs_unique_chr'+str(chr_range)+'-22.pickle')\n",
    "\n",
    "random_seq = pd.read_csv('./custom_db/random_sequences_set1_chr1-22.csv.gz', compression = 'gzip')\n",
    "random_seq_set2 = pd.read_csv('./custom_db/random_sequences_set2_chr1-22.csv.gz', compression = 'gzip')\n",
    "random_seq = pd.concat([random_seq, random_seq_set2])\n",
    "# assign random strand\n",
    "random_seq['Strand'] = np.random.randint(0,2, size=len(random_seq))\n",
    "random_seq['Strand'] = random_seq['Strand'].replace(0, '-').replace(1,'+')\n",
    "random_seq = distance_within_df(random_seq, 'within_motif')\n",
    "random_seq = random_seq.drop_duplicates(subset = ['chrom', 'start']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd2a8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STR distance filter of 20 and non-STR distance filter of 5 for all motifs\n",
    "all_motifs_unique = all_motifs_unique.loc[(all_motifs_unique['STR_distance_min'] > 20) & (all_motifs_unique[['nonSTR_distance_min', 'within_motif_distance_min', 'RM_distance_min']].fillna(0).min(axis=1) > 5)]\n",
    "random_seq = random_seq.loc[(random_seq['STR_distance_min'] > 20) & (random_seq[['nonSTR_distance_min', 'within_motif_distance_min', 'RM_distance_min']].fillna(0).min(axis=1) > 5)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9016ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate positions within motifs\n",
    "pos_expand_all = dict()\n",
    "\n",
    "def pos_expand(input_df):\n",
    "    \n",
    "    useful_cols = [category for category in ['chrom', 'Type', 'repeat', 'status', 'Strand', 'GC%_stem', 'purine', '#MM', 'stem_len', 'spacer', 'length'] if category in input_df.columns]\n",
    "    \n",
    "    single_count_position_list = [category for category in [\"5'_motif_pos\", \"3'_motif_pos\", \"5'_flank_pos\", \"3'_flank_pos\"] if category in input_df.columns]\n",
    "    count_position_list = [category for category in ['run_positions_middle', 'loop_positions_middle', 'run_positions_edge', 'loop_positions_edge', 'spacer_middle_pos', 'motif_pos_genome_middle'] if category in input_df.columns]\n",
    "    single_pred_position_list = pd.Series([\"spacer_5'_pred\", \"spacer_3'_pred\", \"5'_flank_pred\", \"3'_flank_pred\"], index = [\"spacer_5'_pos\", \"spacer_3'_pos\", \"5'_flank_pos\", \"3'_flank_pos\"])\n",
    "    single_pred_position_list = single_pred_position_list.loc[single_pred_position_list.isin(input_df.columns)]\n",
    "    single_count_position_list = [category for category in single_count_position_list if category not in single_pred_position_list.index]\n",
    "    pred_position_list = pd.Series(['MM_pred', 'MM_pred_L', 'MM_pred_R'], index = ['MM_pos_genome', 'MM_pos_L', 'MM_pos_R'])\n",
    "    pred_position_list = pred_position_list.loc[pred_position_list.isin(input_df.columns)]\n",
    "    \n",
    "    pos_expand_current = dict()\n",
    "    for position in single_count_position_list:\n",
    "        pos_expand_current[position] = input_df[[position] + useful_cols].copy()\n",
    "        pos_expand_current[position].columns = ['pos'] + useful_cols\n",
    "        pos_expand_current[position]['category'] = position\n",
    "    for position in count_position_list:\n",
    "        pos_expand_current[position] = pd.DataFrame(flatten(input_df[position].dropna()), columns = ['pos'])\n",
    "        pos_expand_current[position]['category'] = position\n",
    "        for col in useful_cols:\n",
    "            pos_expand_current[position][col] = flatten([[length]*len(pos) for length, pos in zip(input_df[col].loc[input_df[position].dropna().index], input_df[position].dropna())])\n",
    "    pos_expand_current = pd.concat(pos_expand_current).reset_index(drop = True)\n",
    "\n",
    "    if (len(single_pred_position_list) + len(pred_position_list)) > 0:    \n",
    "        pos_expand_current_pred = dict()\n",
    "        for position in single_pred_position_list.index:\n",
    "            pos_expand_current_pred[position] = pd.DataFrame(input_df[position].dropna().astype(int))\n",
    "            pos_expand_current_pred[position].columns = ['pos']\n",
    "            pos_expand_current_pred[position]['category'] = position\n",
    "            pos_expand_current_pred[position]['pred'] = input_df[single_pred_position_list[position]].loc[input_df[position].dropna().index]\n",
    "            for col in useful_cols:\n",
    "                pos_expand_current_pred[position][col] = input_df[col].loc[input_df[position].dropna().index]\n",
    "        for position in pred_position_list.index:\n",
    "            pos_expand_current_pred[position] = pd.DataFrame(flatten(input_df[position].dropna()), columns = ['pos'])\n",
    "            pos_expand_current_pred[position]['category'] = position\n",
    "            pos_expand_current_pred[position]['pred'] = flatten(input_df[pred_position_list[position]].loc[input_df[position].dropna().index])\n",
    "            for col in useful_cols:\n",
    "                pos_expand_current_pred[position][col] = flatten([[length]*len(pos) for length, pos in zip(input_df[col].loc[input_df[position].dropna().index], input_df[position].dropna())])\n",
    "        pos_expand_current_pred = pd.concat(pos_expand_current_pred).reset_index(drop = True)\n",
    "        pos_expand_current_all = pd.concat([pos_expand_current, pos_expand_current_pred]).reset_index(drop = True)  \n",
    "        return pos_expand_current_all\n",
    "    else:\n",
    "        return pos_expand_current"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1bab4f",
   "metadata": {},
   "source": [
    "### Locate interruptions within motifs and predict reversion mutations <a name=\"mutation_internal_annotate_interruptions\"></a>\n",
    "[Return to Table of Contents](#TOC)\n",
    "\n",
    "#### STR motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e85b937",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_STRs_unique = all_motifs_unique.loc[(all_motifs_unique['Type'] == 'STR') & (all_motifs_unique['repeat'].isin(repeats_highpower_allframes))].dropna(axis = 1, how = 'all').copy()\n",
    "# Fix annoying naming of repeat frames which were not necesarily paired reverse complements\n",
    "all_STRs_unique['repeat'] = [repeat if repeat in repeats_highpower else repeat_variations(repeat)[0][1] if repeat_variations(repeat)[0][1] in repeats_highpower else repeat_variations(repeat)[0][2] if repeat_variations(repeat)[0][2] in repeats_highpower else repeat_variations(repeat)[0][3] if repeat_variations(repeat)[0][3] in repeats_highpower else np.nan for repeat in all_STRs_unique['repeat']]\n",
    "\n",
    "# STR in-frame interrupions\n",
    "all_STRs_unique['MM_pos'] = [np.where([a!=b for a,b in zip(seq1, (frame*length)[:length])])[0] for seq1, frame, length in zip(all_STRs_unique['Sequence'], all_STRs_unique['repeat_frame_L'], all_STRs_unique['length'])]\n",
    "all_STRs_unique['MM_pred'] = [[(frame*length)[:length][pos] for pos in positions] for chrom, start, positions, frame, length in zip(all_STRs_unique['chrom'], all_STRs_unique['start'], all_STRs_unique['MM_pos'], all_STRs_unique['repeat_frame_L'], all_STRs_unique['length'])]\n",
    "all_STRs_unique['MM_pos'] = [pos_list if status == 'inframe' else np.nan for pos_list, status in zip(all_STRs_unique['MM_pos'], all_STRs_unique['status'])]\n",
    "all_STRs_unique['MM_pred'] = [pred_list if status == 'inframe' else np.nan for pred_list, status in zip(all_STRs_unique['MM_pred'], all_STRs_unique['status'])]\n",
    "all_STRs_unique['MM_pos_genome'] = [[start+pos for pos in positions] if type(positions) != float else np.nan for start, positions in zip(all_STRs_unique['start'], all_STRs_unique['MM_pos'])]\n",
    "\n",
    "all_STRs_unique[\"5'_motif_pos\"] = all_STRs_unique['start']\n",
    "all_STRs_unique[\"3'_motif_pos\"] = all_STRs_unique['end']-1\n",
    "all_STRs_unique[\"5'_flank_pos\"] = all_STRs_unique['start']-1\n",
    "all_STRs_unique[\"3'_flank_pos\"] = all_STRs_unique['end']\n",
    "\n",
    "# Non-interruption positions\n",
    "all_STRs_unique['motif_pos_genome_middle'] = [[pos for pos in range(start+1,end-1) if pos not in positions] if type(positions) != float else [pos for pos in range(start+1,end-1)] for start, end, positions in zip(all_STRs_unique[\"5'_motif_pos\"], all_STRs_unique[\"3'_motif_pos\"], all_STRs_unique['MM_pos_genome'])]\n",
    "\n",
    "all_STRs_unique['Strand'] = all_STRs_unique['Strand'].fillna('+')\n",
    "\n",
    "pos_expand_all['STR'] = pos_expand(all_STRs_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbd64ba",
   "metadata": {},
   "source": [
    "#### IR/MR/DR motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c91fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_IRs = all_motifs_unique.loc[(all_motifs_unique['Type'] == 'IR')].dropna(axis = 1, how = 'all').copy()\n",
    "\n",
    "# Find location of interruptions within each IR\n",
    "all_IRs['MM_pos'] = [np.where([a!=b for a,b in zip(seq1, seq2)]) for seq1, seq2 in zip(all_IRs['seq_L'], all_IRs['RC_seq_R'])]\n",
    "all_IRs['MM_pos'] = [pos[0] for pos in all_IRs['MM_pos']]\n",
    "all_IRs['MM_pos_L'] = [[start+pos for pos in positions] for start, positions in zip(all_IRs['start'], all_IRs['MM_pos'])]\n",
    "all_IRs['MM_pos_R'] = [[end-pos-1 for pos in positions] for end, positions in zip(all_IRs['end'], all_IRs['MM_pos'])]\n",
    "all_IRs['MM_pred_L'] = [[reverse_complement(reference_genome[chrom][pos]) for pos in positions] for chrom, positions in zip(all_IRs['chrom'], all_IRs['MM_pos_R'])]\n",
    "all_IRs['MM_pred_R'] = [[reverse_complement(reference_genome[chrom][pos]) for pos in positions] for chrom, positions in zip(all_IRs['chrom'], all_IRs['MM_pos_L'])]\n",
    "\n",
    "# Spacer position predictions\n",
    "all_IRs['spacer_pos'] = [list(range(start+length, end-length)) for start, end, length in zip(all_IRs['start'], all_IRs['end'], all_IRs['stem_len'].astype(int))]\n",
    "all_IRs[\"spacer_5'_pos\"] = [pos[0] if s_len>1 else 0 for pos, s_len in zip(all_IRs['spacer_pos'], all_IRs['spacer'].astype(int))]\n",
    "all_IRs[\"spacer_middle_pos\"] = [pos[1:-1] if s_len>1 else pos if s_len == 1 else [] for pos, s_len in zip(all_IRs['spacer_pos'], all_IRs['spacer'].astype(int))]\n",
    "all_IRs[\"spacer_3'_pos\"] = [pos[-1] if s_len>1 else 0 for pos, s_len in zip(all_IRs['spacer_pos'], all_IRs['spacer'].astype(int))]\n",
    "all_IRs[\"spacer_5'_pred\"] = [reverse_complement(reference_genome[chrom][pos]) if pos > 0 else np.nan for chrom, pos in zip(all_IRs['chrom'], all_IRs[\"spacer_3'_pos\"])]\n",
    "all_IRs[\"spacer_3'_pred\"] = [reverse_complement(reference_genome[chrom][pos]) if pos > 0 else np.nan  for chrom, pos in zip(all_IRs['chrom'], all_IRs[\"spacer_5'_pos\"])]\n",
    "\n",
    "# Immediate flank position predictions\n",
    "all_IRs[\"5'_motif_pos\"] = all_IRs['start']\n",
    "all_IRs[\"3'_motif_pos\"] = all_IRs['end']-1\n",
    "all_IRs[\"5'_flank_pos\"] = all_IRs['start']-1\n",
    "all_IRs[\"3'_flank_pos\"] = all_IRs['end']\n",
    "all_IRs[\"5'_flank_pred\"] = [reverse_complement(reference_genome[chrom][pos]) for chrom, pos in zip(all_IRs['chrom'], all_IRs[\"3'_flank_pos\"])]\n",
    "all_IRs[\"3'_flank_pred\"] = [reverse_complement(reference_genome[chrom][pos]) for chrom, pos in zip(all_IRs['chrom'], all_IRs[\"5'_flank_pos\"])]\n",
    "\n",
    "# Non-interruption positions\n",
    "all_IRs['motif_pos_genome_middle'] = [[pos for pos in range(start+1,end-1) if pos not in positions] if type(positions) != float else [pos for pos in range(start+1,end-1)] for start, end, positions in zip(all_IRs['start'], all_IRs['end'], all_IRs['MM_pos_L'])]\n",
    "all_IRs['motif_pos_genome_middle'] = [[pos for pos in motif_pos if pos not in positions] if type(positions) != float else [pos for pos in motif_pos] for motif_pos, positions in zip(all_IRs['motif_pos_genome_middle'], all_IRs['MM_pos_R'])]\n",
    "all_IRs['motif_pos_genome_middle'] = [[pos for pos in motif_pos if pos not in positions] if type(positions) != float else [pos for pos in motif_pos] for motif_pos, positions in zip(all_IRs['motif_pos_genome_middle'], all_IRs['spacer_pos'])]\n",
    "\n",
    "# GC content not including spacer\n",
    "all_IRs['GC%_stem'] = ((all_IRs['seq_L'].str.count('C') + all_IRs['seq_L'].str.count('G') + all_IRs['seq_R'].str.count('C') + all_IRs['seq_R'].str.count('G')) / (all_IRs['stem_len'] *2)).round(2)\n",
    "\n",
    "pos_expand_all['IR'] = pos_expand(all_IRs)\n",
    "pos_expand_all['IR'] = pos_expand_all['IR'].loc[pos_expand_all['IR']['pos'] > 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e482e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_MRs = all_motifs_unique.loc[(all_motifs_unique['Type'] == 'MR')].dropna(axis = 1, how = 'all').copy()\n",
    "\n",
    "# Find location of interruptions within each MR\n",
    "all_MRs['MM_pos'] = [np.where([a!=b for a,b in zip(seq1, seq2)]) for seq1, seq2 in zip(all_MRs['seq_L'], all_MRs['rev_seq_R'])]\n",
    "all_MRs['MM_pos'] = [pos[0] for pos in all_MRs['MM_pos']]\n",
    "all_MRs['MM_pos_L'] = [[start+pos for pos in positions] for start, positions in zip(all_MRs['start'], all_MRs['MM_pos'])]\n",
    "all_MRs['MM_pos_R'] = [[end-pos-1 for pos in positions] for end, positions in zip(all_MRs['end'], all_MRs['MM_pos'])]\n",
    "all_MRs['MM_pred_L'] = [[reference_genome[chrom][pos] for pos in positions] for chrom, positions in zip(all_MRs['chrom'], all_MRs['MM_pos_R'])]\n",
    "all_MRs['MM_pred_R'] = [[reference_genome[chrom][pos] for pos in positions] for chrom, positions in zip(all_MRs['chrom'], all_MRs['MM_pos_L'])]\n",
    "\n",
    "# Spacer position predictions\n",
    "all_MRs['spacer_pos'] = [list(range(start+length, end-length)) for start, end, length in zip(all_MRs['start'], all_MRs['end'], all_MRs['stem_len'].astype(int))]\n",
    "all_MRs[\"spacer_5'_pos\"] = [pos[0] if s_len>1 else 0 for pos, s_len in zip(all_MRs['spacer_pos'], all_MRs['spacer'].astype(int))]\n",
    "all_MRs[\"spacer_middle_pos\"] = [pos[1:-1] if s_len>0 else [] for pos, s_len in zip(all_MRs['spacer_pos'], all_MRs['spacer'].astype(int))]\n",
    "all_MRs[\"spacer_3'_pos\"] = [pos[-1] if s_len>1 else 0 for pos, s_len in zip(all_MRs['spacer_pos'], all_MRs['spacer'].astype(int))]\n",
    "all_MRs[\"spacer_5'_pred\"] = [reference_genome[chrom][pos] if pos > 0 else np.nan for chrom, pos in zip(all_MRs['chrom'], all_MRs[\"spacer_3'_pos\"])]\n",
    "all_MRs[\"spacer_3'_pred\"] = [reference_genome[chrom][pos] if pos > 0 else np.nan for chrom, pos in zip(all_MRs['chrom'], all_MRs[\"spacer_5'_pos\"])]\n",
    "\n",
    "# Immediate flank positions\n",
    "all_MRs[\"5'_motif_pos\"] = all_MRs['start']\n",
    "all_MRs[\"3'_motif_pos\"] = all_MRs['end']-1\n",
    "all_MRs[\"5'_flank_pos\"] = all_MRs['start']-1\n",
    "all_MRs[\"3'_flank_pos\"] = all_MRs['end']\n",
    "all_MRs[\"5'_flank_pred\"] = [reference_genome[chrom][pos] for chrom, pos in zip(all_MRs['chrom'], all_MRs[\"3'_flank_pos\"])]\n",
    "all_MRs[\"3'_flank_pred\"] = [reference_genome[chrom][pos] for chrom, pos in zip(all_MRs['chrom'], all_MRs[\"5'_flank_pos\"])]\n",
    "\n",
    "# Non-interruption positions\n",
    "all_MRs['motif_pos_genome_middle'] = [[pos for pos in range(start+1,end-1) if pos not in positions] if type(positions) != float else [pos for pos in range(start+1,end-1)] for start, end, positions in zip(all_MRs['start'], all_MRs['end'], all_MRs['MM_pos_L'])]\n",
    "all_MRs['motif_pos_genome_middle'] = [[pos for pos in motif_pos if pos not in positions] if type(positions) != float else [pos for pos in motif_pos] for motif_pos, positions in zip(all_MRs['motif_pos_genome_middle'], all_MRs['MM_pos_R'])]\n",
    "all_MRs['motif_pos_genome_middle'] = [[pos for pos in motif_pos if pos not in positions] if type(positions) != float else [pos for pos in motif_pos] for motif_pos, positions in zip(all_MRs['motif_pos_genome_middle'], all_MRs['spacer_pos'])]\n",
    "\n",
    "# GC content not including spacer\n",
    "all_MRs['GC%_stem'] = ((all_MRs['seq_L'].str.count('C') + all_MRs['seq_L'].str.count('G') + all_MRs['seq_R'].str.count('C') + all_MRs['seq_R'].str.count('G')) / (all_MRs['stem_len'] *2)).round(2)\n",
    "\n",
    "# purine content not including spacer, with 0 being 50% purine and 0.5 being homopurine/homopyrimidine, with + strand being more purine on the reference strand\n",
    "all_MRs['purine'] = (all_MRs['seq_L'].str.count('A') + all_MRs['seq_L'].str.count('G') + all_MRs['seq_R'].str.count('A') + all_MRs['seq_R'].str.count('G')) / (all_MRs['stem_len'] *2)\n",
    "all_MRs['purine'] = 0.5 - all_MRs['purine']\n",
    "all_MRs['Strand'] = ['+' if purine > 0 else '-' for purine in all_MRs['purine']]\n",
    "all_MRs['purine'] = abs(all_MRs['purine'].round(2))\n",
    "\n",
    "pos_expand_all['MR'] = pos_expand(all_MRs)\n",
    "pos_expand_all['MR'] = pos_expand_all['MR'].loc[pos_expand_all['MR']['pos'] > 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cee77f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_DRs = all_motifs_unique.loc[(all_motifs_unique['Type'] == 'DR')].dropna(axis = 1, how = 'all').copy()\n",
    "\n",
    "# Find location of interruptions within each DR\n",
    "all_DRs['MM_pos'] = [np.where([a!=b for a,b in zip(seq1, seq2)]) for seq1, seq2 in zip(all_DRs['seq_L'], all_DRs['seq_R'])]\n",
    "all_DRs['MM_pos'] = [pos[0] for pos in all_DRs['MM_pos']]\n",
    "all_DRs['MM_pos_L'] = [[start+pos for pos in positions] for start, positions in zip(all_DRs['start'], all_DRs['MM_pos'])]\n",
    "all_DRs['MM_pos_R'] = [[start+pos+stem+spacer for pos in positions] for start, positions, stem, spacer in zip(all_DRs['start'], all_DRs['MM_pos'], all_DRs['stem_len'].astype(int), all_DRs['spacer'].astype(int))]\n",
    "all_DRs['MM_pred_L'] = [[reference_genome[chrom][pos] for pos in positions][::-1] for chrom, positions in zip(all_DRs['chrom'], all_DRs['MM_pos_R'])]\n",
    "all_DRs['MM_pred_R'] = [[reference_genome[chrom][pos] for pos in positions][::-1] for chrom, positions in zip(all_DRs['chrom'], all_DRs['MM_pos_L'])]\n",
    "\n",
    "# DDRect repeat spacer/flank predictions\n",
    "all_DRs['spacer_pos'] = [list(range(start+length, end-length)) for start, end, length in zip(all_DRs['start'], all_DRs['end'], all_DRs['stem_len'].astype(int))]\n",
    "all_DRs[\"spacer_5'_pos\"] = [pos[0] if s_len>1 else 0 for pos, s_len in zip(all_DRs['spacer_pos'], all_DRs['spacer'].astype(int))]\n",
    "all_DRs[\"spacer_middle_pos\"] = [pos[1:-1] if s_len>0 else [] for pos, s_len in zip(all_DRs['spacer_pos'], all_DRs['spacer'].astype(int))]\n",
    "all_DRs[\"spacer_3'_pos\"] = [pos[-1] if s_len>1 else 0 for pos, s_len in zip(all_DRs['spacer_pos'], all_DRs['spacer'].astype(int))]\n",
    "\n",
    "all_DRs[\"5'_motif_pos\"] = all_DRs['start']\n",
    "all_DRs[\"3'_motif_pos\"] = all_DRs['end']-1\n",
    "all_DRs[\"5'_flank_pos\"] = all_DRs['start']-1\n",
    "all_DRs[\"3'_flank_pos\"] = all_DRs['end']\n",
    "\n",
    "all_DRs[\"5'_flank_pred\"] = [reference_genome[chrom][pos] for chrom, pos in zip(all_DRs['chrom'], all_DRs[\"spacer_3'_pos\"])]\n",
    "all_DRs[\"3'_flank_pred\"] = [reference_genome[chrom][pos] for chrom, pos in zip(all_DRs['chrom'], all_DRs[\"spacer_5'_pos\"])]\n",
    "all_DRs[\"spacer_5'_pred\"] = [reference_genome[chrom][pos] for chrom, pos in zip(all_DRs['chrom'], all_DRs[\"3'_flank_pos\"])]\n",
    "all_DRs[\"spacer_3'_pred\"] = [reference_genome[chrom][pos] for chrom, pos in zip(all_DRs['chrom'], all_DRs[\"5'_flank_pos\"])]\n",
    "\n",
    "# Non-interruption positions\n",
    "all_DRs['motif_pos_genome_middle'] = [[pos for pos in range(start+1,end-1) if pos not in positions] if type(positions) != float else [pos for pos in range(start+1,end-1)] for start, end, positions in zip(all_DRs['start'], all_DRs['end'], all_DRs['MM_pos_L'])]\n",
    "all_DRs['motif_pos_genome_middle'] = [[pos for pos in motif_pos if pos not in positions] if type(positions) != float else [pos for pos in motif_pos] for motif_pos, positions in zip(all_DRs['motif_pos_genome_middle'], all_DRs['MM_pos_R'])]\n",
    "all_DRs['motif_pos_genome_middle'] = [[pos for pos in motif_pos if pos not in positions] if type(positions) != float else [pos for pos in motif_pos] for motif_pos, positions in zip(all_DRs['motif_pos_genome_middle'], all_DRs['spacer_pos'])]\n",
    "\n",
    "# GC content not including spacer\n",
    "all_DRs['GC%_stem'] = ((all_DRs['seq_L'].str.count('C') + all_DRs['seq_L'].str.count('G') + all_DRs['seq_R'].str.count('C') + all_DRs['seq_R'].str.count('G')) / (all_DRs['stem_len'] *2)).round(2)\n",
    "\n",
    "pos_expand_all['DR'] = pos_expand(all_DRs)\n",
    "pos_expand_all['DR'] = pos_expand_all['DR'].loc[pos_expand_all['DR']['pos'] > 0].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e011d57f",
   "metadata": {},
   "source": [
    "### Annotate other positions <a name=\"mutation_internal_annotate_other\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)\n",
    "\n",
    "#### G4 positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952e0b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_G4s = all_motifs_unique.loc[(all_motifs_unique['Type'] == 'G4')].dropna(axis = 1, how = 'all').copy()\n",
    "\n",
    "# Find locations of G-runs and loops\n",
    "all_G4s['run_positions'] = [[pos.start(0) for pos in re.finditer('GGG', seq, overlapped=True)] if strand == '+' else [pos.start(0) for pos in re.finditer('CCC', seq, overlapped=True)] for seq, strand in zip(all_G4s['Sequence'], all_G4s['Strand'])]\n",
    "all_G4s['run_positions'] = [sorted(list(set(positions + [pos+1 for pos in positions] + [pos+2 for pos in positions]))) for positions in all_G4s['run_positions']]\n",
    "all_G4s['loop_positions'] = [[pos for pos in range(len(seq)) if pos not in positions] for seq, positions in zip(all_G4s['Sequence'], all_G4s['run_positions'])]\n",
    "\n",
    "# Separate G4 runs and loops into middle and edge positions\n",
    "all_G4s['run_positions_middle'] = [[pos for pos in positions if (pos+1 in positions) & (pos-1 in positions)] if type(positions) != float else np.nan for positions in all_G4s['run_positions']]\n",
    "all_G4s['loop_positions_middle'] = [[pos for pos in positions if (pos+1 in positions) & (pos-1 in positions)] if type(positions) != float else np.nan for positions in all_G4s['loop_positions']]\n",
    "all_G4s['run_positions_edge'] = [[pos for pos in positions if pos not in middles] if type(positions) != float else np.nan for positions, middles in zip(all_G4s['run_positions'], all_G4s['run_positions_middle'])]\n",
    "all_G4s['loop_positions_edge'] = [[pos for pos in positions if pos not in middles] if type(positions) != float else np.nan for positions, middles in zip(all_G4s['loop_positions'], all_G4s['loop_positions_middle'])]\n",
    "\n",
    "all_G4s['run_positions_middle'] = [[start+pos for pos in positions] if type(positions) != float else np.nan for start, positions in zip(all_G4s['start'], all_G4s['run_positions_middle'])]\n",
    "all_G4s['loop_positions_middle'] = [[start+pos for pos in positions] if type(positions) != float else np.nan for start, positions in zip(all_G4s['start'], all_G4s['loop_positions_middle'])]\n",
    "all_G4s['run_positions_edge'] = [[start+pos for pos in positions] if type(positions) != float else np.nan for start, positions in zip(all_G4s['start'], all_G4s['run_positions_edge'])]\n",
    "all_G4s['loop_positions_edge'] = [[start+pos for pos in positions] if type(positions) != float else np.nan for start, positions in zip(all_G4s['start'], all_G4s['loop_positions_edge'])]\n",
    "\n",
    "# Immediate flanking positions\n",
    "all_G4s[\"5'_flank_pos\"] = all_G4s['start']-1\n",
    "all_G4s[\"3'_flank_pos\"] = all_G4s['end']\n",
    "\n",
    "pos_expand_all['G4'] = pos_expand(all_G4s)\n",
    "pos_expand_all['G4']['pred'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbff815",
   "metadata": {},
   "source": [
    "#### Z-DNA positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2638900b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ZDNAs = all_motifs_unique.loc[(all_motifs_unique['Type'] == 'ZDNA')].dropna(axis = 1, how = 'all').copy()\n",
    "\n",
    "all_ZDNAs[\"5'_motif_pos\"] = all_ZDNAs['start']\n",
    "all_ZDNAs[\"3'_motif_pos\"] = all_ZDNAs['end']-1\n",
    "all_ZDNAs[\"5'_flank_pos\"] = all_ZDNAs['start']-1\n",
    "all_ZDNAs[\"3'_flank_pos\"] = all_ZDNAs['end']\n",
    "all_ZDNAs['motif_pos_genome_middle'] = [[pos for pos in range(start+1,end-1)] for start, end in zip(all_ZDNAs[\"5'_motif_pos\"], all_ZDNAs[\"3'_motif_pos\"])]\n",
    "\n",
    "ZDNAs_GY = all_ZDNAs.dropna(subset = ['Strand'])\n",
    "all_ZDNAs['Strand'] = all_ZDNAs['Strand'].fillna('+')\n",
    "\n",
    "pos_expand_all['ZDNA'] = pos_expand(all_ZDNAs)\n",
    "pos_expand_all['ZDNA_GY'] = pos_expand(ZDNAs_GY)\n",
    "\n",
    "pos_expand_all['ZDNA']['pred'] = np.nan\n",
    "pos_expand_all['ZDNA_GY']['pred'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dce8ac",
   "metadata": {},
   "source": [
    "#### Random positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144028d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seq['motif_pos_genome_middle'] = [[pos for pos in range(start+1,end-1)] for start, end in zip(random_seq['start'], random_seq['end'])]\n",
    "random_seq[\"5'_motif_pos\"] = random_seq['start']\n",
    "random_seq[\"3'_motif_pos\"] = random_seq['end']-1\n",
    "random_seq[\"5'_flank_pos\"] = random_seq['start']-1\n",
    "random_seq[\"3'_flank_pos\"] = random_seq['end']\n",
    "\n",
    "pos_expand_all['random'] = pos_expand(random_seq)\n",
    "\n",
    "pos_expand_all['random']['pred'] = np.nan\n",
    "pos_expand_all['random']['Type'] = 'random'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5c1501",
   "metadata": {},
   "source": [
    "### Combine all positions into database <a name=\"mutation_internal_annotate_combine\"></a>\n",
    "- one line per position\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e57397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save temporary output of the motif positions\n",
    "with open('./analysis/temp/motif_internal_positions_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(pos_expand_all, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f677db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load temporary output of the motif positions\n",
    "with open('./analysis/temp/motif_internal_positions_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    pos_expand_all = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff350b83",
   "metadata": {},
   "source": [
    "## Calculate mutation frequency at specified internal positions <a name=\"mutation_internal_count\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)\n",
    "\n",
    "#### Functions to count and analyze mutations within motifs <a name=\"mutation_internal_count_functions\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58f05de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_internal_mut_pos_chrom(chrom, pos_current, input_mut_dict, useful_cols, qc_cutoff_list, noAC, gc_nmer, pos_col):\n",
    "    # for each qc_cutoff in the mutation dataset, find mutations overlapping the search coordinates\n",
    "    current_mut_sum = dict()\n",
    "\n",
    "    current_mut_chrom = input_mut_dict[chrom].copy()\n",
    "    if noAC == True:\n",
    "        current_mut_chrom[['A', 'T', 'G', 'C']] = (current_mut_chrom[['A', 'T', 'G', 'C']] > 0).astype(int)  \n",
    "    for qc_cutoff in qc_cutoff_list:\n",
    "        current_mut_sum[qc_cutoff[0]] = dict()\n",
    "        current_mut_qc = (current_mut_chrom[['A', 'T', 'G', 'C']]).mul((current_mut_chrom[['qual_A', 'qual_T', 'qual_G', 'qual_C']] >= qc_cutoff[0]).astype(int).values, axis=0).mul((current_mut_chrom[['inbr_A', 'inbr_T', 'inbr_G', 'inbr_C']] >= qc_cutoff[1]).astype(int).values, axis=0)\n",
    "        current_mut_qc.index = current_mut_qc.index - 1    # change gnomad from base1 to base0\n",
    "\n",
    "        # non-pred positions\n",
    "        pos_current_other = pd.DataFrame(pos_current.loc[pos_current['pred'].isna()].groupby([pos_col] + useful_cols).count()['Type'])\n",
    "        pos_current_other[['A', 'T', 'G', 'C']] = 1\n",
    "        \n",
    "        if len(pos_current['pred'].dropna()) > 0:\n",
    "\n",
    "            # predicted positions\n",
    "            pred_current = pos_current.dropna(subset = ['pred']).groupby([pos_col] + useful_cols +  ['pred']).count()['Type'].unstack().fillna(0)\n",
    "\n",
    "            # predicted mutations\n",
    "            current_mut_qc_pred = current_mut_qc.reindex(pred_current.index.get_level_values(pos_col)).mul((pred_current >0)[['A', 'T', 'G', 'C']]).fillna(0).reset_index().set_index([pos_col])\n",
    "            current_mut_qc_pred['Tri'] = [tri_function(chrom, pos, base = 0) for pos in current_mut_qc_pred.index]\n",
    "            current_mut_qc_pred['tri_count'] = 1   \n",
    "            current_mut_qc_pred['seq_'+str(gc_nmer)] = [reference_lookup(chrom, pos, round((gc_nmer-1)/2)) for pos in current_mut_qc_pred.index]\n",
    "            current_mut_qc_pred['GC_'+str(gc_nmer)] = (current_mut_qc_pred['seq_'+str(gc_nmer)].str.count('G') + current_mut_qc_pred['seq_'+str(gc_nmer)].str.count('C')) / (gc_nmer - current_mut_qc_pred['seq_'+str(gc_nmer)].str.count('N'))\n",
    "            current_mut_sum[qc_cutoff[0]]['pred'] = current_mut_qc_pred.loc[current_mut_qc_pred['Tri'].isin(all_triplets)].groupby(useful_cols + ['Tri']).sum().copy()\n",
    "\n",
    "            #return current_mut_qc_pred\n",
    "            \n",
    "            # against prediction\n",
    "            current_mut_qc_againstpred = current_mut_qc.reindex(pred_current.index.get_level_values(pos_col)).mul((pred_current == 0)[['A', 'T', 'G', 'C']]).fillna(0).reset_index().set_index([pos_col])\n",
    "            current_mut_qc_againstpred['Tri'] = [tri_function(chrom, pos, base = 0) for pos in current_mut_qc_againstpred.index]\n",
    "            current_mut_qc_againstpred['tri_count'] = 1   \n",
    "            current_mut_qc_againstpred['seq_'+str(gc_nmer)] = [reference_lookup(chrom, pos, round((gc_nmer-1)/2)) for pos in current_mut_qc_againstpred.index]\n",
    "            current_mut_qc_againstpred['GC_'+str(gc_nmer)] = (current_mut_qc_againstpred['seq_'+str(gc_nmer)].str.count('G') + current_mut_qc_againstpred['seq_'+str(gc_nmer)].str.count('C')) / (gc_nmer - current_mut_qc_againstpred['seq_'+str(gc_nmer)].str.count('N'))\n",
    "            current_mut_sum[qc_cutoff[0]]['against_pred'] = current_mut_qc_againstpred.loc[current_mut_qc_againstpred['Tri'].isin(all_triplets)].groupby(useful_cols + ['Tri']).sum().copy()\n",
    "\n",
    "        # non-predicted positions\n",
    "        current_mut_qc_nonpredicted = current_mut_qc.reindex(pos_current_other.index.get_level_values(pos_col)).mul(pos_current_other[['A', 'T', 'G', 'C']]).fillna(0).reset_index().set_index([pos_col])       \n",
    "        current_mut_qc_nonpredicted['Tri'] = [tri_function(chrom, pos, base = 0) for pos in current_mut_qc_nonpredicted.index]\n",
    "        current_mut_qc_nonpredicted['tri_count'] = 1   \n",
    "        current_mut_qc_nonpredicted['seq_'+str(gc_nmer)] = [reference_lookup(chrom, pos, round((gc_nmer-1)/2)) for pos in current_mut_qc_nonpredicted.index]\n",
    "        current_mut_qc_nonpredicted['GC_'+str(gc_nmer)] = (current_mut_qc_nonpredicted['seq_'+str(gc_nmer)].str.count('G') + current_mut_qc_nonpredicted['seq_'+str(gc_nmer)].str.count('C')) / (gc_nmer - current_mut_qc_nonpredicted['seq_'+str(gc_nmer)].str.count('N'))\n",
    "        current_mut_sum[qc_cutoff[0]]['non_pred'] = current_mut_qc_nonpredicted.loc[current_mut_qc_nonpredicted['Tri'].isin(all_triplets)].groupby(useful_cols + ['Tri']).sum().copy()\n",
    "\n",
    "        current_mut_sum[qc_cutoff[0]] = pd.concat(current_mut_sum[qc_cutoff[0]])\n",
    "        current_mut_sum[qc_cutoff[0]].index.rename('prediction', level = 0, inplace = True)\n",
    "    return current_mut_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2756e1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: removed several astype(int) commands for compatibility with non-integer mutation counts (due to AC correction factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856fd5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_internal_mut_pos(input_pos_df, input_mut_dict = gnomad_slim_all, qc_cutoff_list = [(-np.inf, -np.inf), (-2.774, -0.3), (0, -0.3), (4, -0.3)], pos_col = 'pos', chrom_col = 'chrom', strand_col = 'Strand', strand_names = ('+', '-'), useful_cols = [], noAC = False, gc_correction_dict = gc_correction_bytri, gc_nmer = False, combine_LR = False):\n",
    "   \n",
    "    current_mut_sum_chrom = dict()\n",
    "    for chrom in range(chr_range,23):\n",
    "        current_mut_sum_chrom[chrom] = count_internal_mut_pos_chrom(chrom, input_pos_df.loc[input_pos_df[chrom_col] == chrom].copy(), input_mut_dict, pos_col = pos_col, useful_cols = useful_cols, qc_cutoff_list = qc_cutoff_list, noAC = noAC, gc_nmer = gc_nmer)\n",
    "        print('finished chr' + str(chrom) + '    ', end=\"\\r\", flush=True)\n",
    "\n",
    "    current_mut_sum = dict()\n",
    "    for qc_cutoff in qc_cutoff_list:\n",
    "        current_mut_sum[qc_cutoff[0]] = pd.concat([current_mut_sum_chrom[chrom][qc_cutoff[0]] for chrom in range(chr_range,23)])\n",
    "    \n",
    "    useful_cols = ['prediction'] + useful_cols\n",
    "    \n",
    "    # apply reverse complement to - strand triplets, mutation counts and positions\n",
    "    if strand_col in useful_cols:\n",
    "        useful_cols.remove(strand_col)\n",
    "        internal_position_categories = pd.Series(['MM_pos', 'MM_pred', 'MM_pos_genome', \"3'_motif_pos\", \"5'_motif_pos\", \"3'_flank_pos\", \"5'_flank_pos\", 'motif_pos_genome_middle', 'MM_pos_R', 'MM_pos_L', 'MM_pred_R', 'MM_pred_L', 'spacer_pos', \"spacer_3'_pos\", \"spacer_middle_pos\", \"spacer_5'_pos\", \"spacer_3'_pred\", \"spacer_5'_pred\", \"3'_flank_pred\", \"5'_flank_pred\", 'run_positions', 'loop_positions', 'run_positions_middle', 'loop_positions_middle', 'run_positions_edge', 'loop_positions_edge'], index = ['MM_pos', 'MM_pred', 'MM_pos_genome', \"5'_motif_pos\", \"3'_motif_pos\", \"5'_flank_pos\", \"3'_flank_pos\", 'motif_pos_genome_middle', 'MM_pos_L', 'MM_pos_R', 'MM_pred_L', 'MM_pred_R', 'spacer_pos', \"spacer_5'_pos\", \"spacer_middle_pos\", \"spacer_3'_pos\", \"spacer_5'_pred\", \"spacer_3'_pred\", \"5'_flank_pred\", \"3'_flank_pred\", 'run_positions', 'loop_positions', 'run_positions_middle', 'loop_positions_middle', 'run_positions_edge', 'loop_positions_edge'])\n",
    "\n",
    "        current_mut_sum_strand_F = dict()\n",
    "        current_mut_sum_strand_R = dict()\n",
    "        current_mut_sum_bothstrands = dict()\n",
    "        for qc_cutoff in current_mut_sum:\n",
    "            current_mut_sum_strand_F[qc_cutoff] = current_mut_sum[qc_cutoff].reset_index().loc[current_mut_sum[qc_cutoff].reset_index()['Strand'] == '+']\n",
    "            current_mut_sum_strand_R[qc_cutoff] = current_mut_sum[qc_cutoff].reset_index().loc[current_mut_sum[qc_cutoff].reset_index()['Strand'] == '-']\n",
    "            current_mut_sum_strand_R[qc_cutoff]['category'] = internal_position_categories.reindex(current_mut_sum_strand_R[qc_cutoff]['category']).values\n",
    "            if 'repeat' in useful_cols:\n",
    "                current_mut_sum_strand_R[qc_cutoff]['repeat'] = current_mut_sum_strand_R[qc_cutoff]['repeat'].apply(reverse_complement)\n",
    "            current_mut_sum_strand_R[qc_cutoff]['Tri'] = current_mut_sum_strand_R[qc_cutoff]['Tri'].apply(reverse_complement)\n",
    "            current_mut_sum_strand_R[qc_cutoff][['A', 'T', 'G', 'C']] = current_mut_sum_strand_R[qc_cutoff][['T', 'A', 'C', 'G']].values\n",
    "            current_mut_sum_bothstrands[qc_cutoff] = pd.concat([current_mut_sum_strand_F[qc_cutoff], current_mut_sum_strand_R[qc_cutoff]]).groupby(useful_cols + ['Tri']).sum()#.fillna(0)\n",
    "    else:\n",
    "        current_mut_sum_bothstrands = dict()\n",
    "        for qc_cutoff in current_mut_sum:\n",
    "            current_mut_sum_bothstrands[qc_cutoff] = current_mut_sum[qc_cutoff].reset_index().groupby(useful_cols + ['Tri']).sum()#.fillna(0)\n",
    "    \n",
    "    if combine_LR == True:\n",
    "        for qc_cutoff in current_mut_sum:\n",
    "            current_mut_sum_bothstrands[qc_cutoff] = current_mut_sum_bothstrands[qc_cutoff].reset_index()\n",
    "            current_mut_sum_bothstrands[qc_cutoff]['category'] = current_mut_sum_bothstrands[qc_cutoff]['category'].str.replace(\"3'_\", '').str.replace(\"5'_\", '').str.replace('_L', '').str.replace('_R', '')\n",
    "            current_mut_sum_bothstrands[qc_cutoff] = current_mut_sum_bothstrands[qc_cutoff].groupby(useful_cols + ['Tri']).sum()\n",
    "\n",
    "    if gc_nmer != False:\n",
    "        for qc_cutoff in current_mut_sum:\n",
    "            current_mut_sum_bothstrands[qc_cutoff]['GC_'+str(gc_nmer)] = (current_mut_sum_bothstrands[qc_cutoff]['GC_'+str(gc_nmer)] / current_mut_sum_bothstrands[qc_cutoff]['tri_count']).round(3)\n",
    "    \n",
    "    # reformat output to NNN_N rows x pos columns, and split mut counts and trinucleotide counts    \n",
    "\n",
    "    current_tri_sum = current_mut_sum_bothstrands[qc_cutoff].reset_index().groupby(useful_cols + ['Tri']).sum()['tri_count'].unstack().transpose().fillna(0).astype(int)\n",
    "\n",
    "    current_mut_sum_reformat = dict()\n",
    "    if gc_nmer != False:\n",
    "        useful_cols = useful_cols + ['GC_'+str(gc_nmer)]\n",
    "    for qc_cutoff in current_mut_sum:\n",
    "        current_mut_sum_reformat[qc_cutoff] = current_mut_sum_bothstrands[qc_cutoff].reset_index().groupby(useful_cols + ['Tri']).sum()[['A', 'T', 'G', 'C']].unstack().transpose().fillna(0)\n",
    "        current_mut_sum_reformat[qc_cutoff].index = current_mut_sum_reformat[qc_cutoff].index.get_level_values('Tri') + '_' + current_mut_sum_reformat[qc_cutoff].index.get_level_values(0)\n",
    "        current_mut_sum_reformat[qc_cutoff] = current_mut_sum_reformat[qc_cutoff].reindex(triplet_mutations_und)\n",
    "        current_mut_sum_reformat[qc_cutoff].index.name = 'Mut' \n",
    "    \n",
    "    if gc_nmer == False:\n",
    "        return current_mut_sum_reformat.copy(), current_tri_sum.copy()\n",
    "    \n",
    "    # GC window correction\n",
    "    current_mut_sum_GCcorrect = dict()\n",
    "    for qc_cutoff in current_mut_sum:\n",
    "        current_mut_sum_GCcorrect[qc_cutoff] = current_mut_sum_reformat[qc_cutoff].mul((gc_correction_dict[qc_cutoff].iloc[np.searchsorted(gc_correction_dict[qc_cutoff].index, current_mut_sum_reformat[qc_cutoff].columns.get_level_values('GC_'+str(gc_nmer)))]).transpose().values)\n",
    "        current_mut_sum_GCcorrect[qc_cutoff] = current_mut_sum_GCcorrect[qc_cutoff].transpose().reset_index().groupby(useful_cols[:-1]).sum().transpose().reindex(triplet_mutations_und)\n",
    "        current_mut_sum_reformat[qc_cutoff] = current_mut_sum_reformat[qc_cutoff].transpose().reset_index().groupby(useful_cols[:-1]).sum().transpose().reindex(triplet_mutations_und)\n",
    "\n",
    "    return current_mut_sum_reformat.copy(), current_tri_sum.copy(), current_mut_sum_GCcorrect.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8794bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_internal_resum(input_count_dict, useful_cols, tri_subset = triplet_mutations_und, selections = False, gc_correct = True):\n",
    "    output_dict = dict()\n",
    "    output_dict[0] = dict()\n",
    "    for qc_cutoff in input_count_dict[0]:\n",
    "        output_dict[0][qc_cutoff] = input_count_dict[0][qc_cutoff].copy().transpose().reset_index().groupby(useful_cols).sum().transpose().reindex(tri_subset)\n",
    "    output_dict[1] = input_count_dict[1].copy().transpose().reset_index().groupby(useful_cols).sum().transpose().reindex(all_triplets)\n",
    "    if gc_correct == True:\n",
    "        output_dict[2] = dict()\n",
    "        for qc_cutoff in input_count_dict[2]:\n",
    "            output_dict[2][qc_cutoff] = input_count_dict[2][qc_cutoff].copy().transpose().reset_index().groupby(useful_cols).sum().transpose().reindex(tri_subset)    \n",
    "    if selections != False:\n",
    "        for qc_cutoff in input_count_dict[0]:\n",
    "            output_dict[0][qc_cutoff] = output_dict[0][qc_cutoff].transpose().reset_index()\n",
    "            if gc_correct == True:\n",
    "                output_dict[2][qc_cutoff] = output_dict[2][qc_cutoff].transpose().reset_index()\n",
    "        output_dict[1] = output_dict[1].transpose().reset_index()\n",
    "        for col, choice in zip(useful_cols, selections):\n",
    "            if choice != False:\n",
    "                if type(choice) == list:\n",
    "                    for qc_cutoff in input_count_dict[0]:\n",
    "                        output_dict[0][qc_cutoff] =  output_dict[0][qc_cutoff].loc[output_dict[0][qc_cutoff][col].isin(choice)]\n",
    "                        if gc_correct == True:\n",
    "                            output_dict[2][qc_cutoff] =  output_dict[2][qc_cutoff].loc[output_dict[2][qc_cutoff][col].isin(choice)]\n",
    "                    output_dict[1] =  output_dict[1].loc[output_dict[1][col].isin(choice)]\n",
    "                else:\n",
    "                    for qc_cutoff in input_count_dict[0]:\n",
    "                        output_dict[0][qc_cutoff] =  output_dict[0][qc_cutoff].loc[output_dict[0][qc_cutoff][col] == choice]\n",
    "                        if gc_correct == True:\n",
    "                            output_dict[2][qc_cutoff] =  output_dict[2][qc_cutoff].loc[output_dict[2][qc_cutoff][col] == choice]\n",
    "                    output_dict[1] =  output_dict[1].loc[output_dict[1][col] == choice]\n",
    "        for qc_cutoff in input_count_dict[0]:\n",
    "            output_dict[0][qc_cutoff] = output_dict[0][qc_cutoff].groupby(useful_cols).sum().transpose().reindex(tri_subset)\n",
    "            if gc_correct == True:\n",
    "                output_dict[2][qc_cutoff] = output_dict[2][qc_cutoff].groupby(useful_cols).sum().transpose().reindex(tri_subset)\n",
    "        output_dict[1] = output_dict[1].groupby(useful_cols).sum().transpose().reindex(all_triplets)\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9f7da9",
   "metadata": {},
   "source": [
    "### Count and analyze <a name=\"mutation_internal_count_analyze\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243bc2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_internal_all = dict()\n",
    "norm_internal_all = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718615cc",
   "metadata": {},
   "source": [
    "#### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72915e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_internal_all['random'] = count_internal_mut_pos(pos_expand_all['random'].copy(), useful_cols = ['category'], gc_nmer = 51, combine_LR = True)\n",
    "\n",
    "norm_internal_all['random'] = mut_norm_conf(count_internal_resum(count_internal_all['random'], ['prediction', 'category']) , min_count = 0, normtorandom = False, gc_correct=True)\n",
    "\n",
    "normtorandom_internal = pd.Series([norm_internal_all['random'][0][qc_filter]['non_pred']['motif_pos'] for qc_filter in vqslod_list], index = vqslod_list)\n",
    "\n",
    "norm_internal_all['random_norm'] = mut_norm_conf(count_internal_resum(count_internal_all['random'], ['prediction', 'category']) , min_count = 0, normtorandom = True, random_normaverage = normtorandom_all, gc_correct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf20256",
   "metadata": {},
   "source": [
    "#### STR motifs <a name=\"mutation_internal_count_analyze_STR\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd5a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_internal_all['STR'] = count_internal_mut_pos(pos_expand_all['STR'].copy(), useful_cols = ['Strand', 'repeat', 'category', 'status', 'length'], gc_nmer = 51, combine_LR = True)\n",
    "\n",
    "norm_internal_all['STR'] = mut_norm_conf(count_internal_all['STR'], min_count = 10, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e27f860",
   "metadata": {},
   "source": [
    "#### Inverted/Mirror/Direct motifs <a name=\"mutation_internal_count_analyze_IRDMRDR\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3535d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_internal_all['IR'] = count_internal_mut_pos(pos_expand_all['IR'].copy(), useful_cols = ['category', '#MM', 'GC%_stem', 'stem_len', 'spacer'], gc_nmer = 51, combine_LR = True)\n",
    "\n",
    "norm_internal_all['IR'] = mut_norm_conf(count_internal_resum(count_internal_all['IR'], ['prediction', 'category', '#MM', 'stem_len', 'spacer']) , min_count = 0, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)\n",
    "\n",
    "# Group normalized values by certain data columns\n",
    "norm_internal_all['IR_stemlen_byspacer'] = mut_norm_conf(count_internal_resum(count_internal_all['IR'], ['prediction', 'category', '#MM', 'spacer', 'stem_len']) , min_count = 0, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)\n",
    "norm_internal_all['IR_stemlen'] = mut_norm_conf(count_internal_resum(count_internal_all['IR'], ['prediction', 'category', '#MM', 'stem_len']) , min_count = 0, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)\n",
    "norm_internal_all['IR_spacer'] = mut_norm_conf(count_internal_resum(count_internal_all['IR'], ['prediction', 'category', '#MM', 'spacer']) , min_count = 0, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)\n",
    "norm_internal_all['IR_GC'] = mut_norm_conf(count_internal_resum(count_internal_all['IR'], ['prediction', 'category', '#MM', 'GC%_stem']) , min_count = 0, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)\n",
    "\n",
    "# IRs with spacer length requirements\n",
    "\n",
    "count_internal_IR_spacer10 = count_internal_resum(count_internal_all['IR'], ['prediction', 'category', '#MM', 'stem_len', 'spacer'], selections=[False, False, 1, False, list(range(11))])\n",
    "count_internal_IR_spacer10 = count_internal_resum(count_internal_IR_spacer10, ['prediction', 'category', 'stem_len'])\n",
    "\n",
    "norm_internal_all['IR_stemlen_spacer10'] = mut_norm_conf(count_internal_IR_spacer10 , min_count = 10, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)\n",
    "\n",
    "count_internal_IR_spacer3 = count_internal_resum(count_internal_all['IR'], ['prediction', 'category', '#MM', 'stem_len', 'spacer'], selections=[False, False, 1, False, list(range(4))])\n",
    "count_internal_IR_spacer3 = count_internal_resum(count_internal_IR_spacer3, ['prediction', 'category', 'stem_len'])\n",
    "\n",
    "count_internal_IR_spacer410 = count_internal_resum(count_internal_all['IR'], ['prediction', 'category', '#MM', 'stem_len', 'spacer'], selections=[False, False, 1, False, list(range(4,11))])\n",
    "count_internal_IR_spacer410 = count_internal_resum(count_internal_IR_spacer410, ['prediction', 'category', 'stem_len'])\n",
    "\n",
    "count_internal_IR_spacer_over10 = count_internal_resum(count_internal_all['IR'], ['prediction', 'category', '#MM', 'stem_len', 'spacer'], selections=[False, False, 1, False, list(range(11,100))])\n",
    "count_internal_IR_spacer_over10 = count_internal_resum(count_internal_IR_spacer_over10, ['prediction', 'category', 'stem_len'])\n",
    "\n",
    "norm_internal_all['IR_stemlen_spacer3'] = mut_norm_conf(count_internal_IR_spacer3 , min_count = 20, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)\n",
    "norm_internal_all['IR_stemlen_spacer410'] = mut_norm_conf(count_internal_IR_spacer410 , min_count = 20, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)\n",
    "norm_internal_all['IR_stemlen_spacer_over10'] = mut_norm_conf(count_internal_IR_spacer_over10 , min_count = 20, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c4a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_internal_all['DR'] = count_internal_mut_pos(pos_expand_all['DR'].copy(), useful_cols = ['category', '#MM', 'GC%_stem', 'stem_len', 'spacer'], gc_nmer = 51, combine_LR = True)\n",
    "\n",
    "# Group normalized values by certain data columns\n",
    "norm_internal_all['DR_stemlen'] = mut_norm_conf(count_internal_resum(count_internal_all['DR'], ['prediction', 'category', '#MM', 'stem_len']) , min_count = 0, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)\n",
    "norm_internal_all['DR_spacer'] = mut_norm_conf(count_internal_resum(count_internal_all['DR'], ['prediction', 'category', '#MM', 'spacer']) , min_count = 0, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)\n",
    "norm_internal_all['DR_GC'] = mut_norm_conf(count_internal_resum(count_internal_all['DR'], ['prediction', 'category', '#MM', 'GC%_stem']) , min_count = 0, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)\n",
    "\n",
    "# DRs with spacer length requirements\n",
    "\n",
    "count_internal_DR_spacer3 = count_internal_resum(count_internal_all['DR'], ['prediction', 'category', '#MM', 'stem_len', 'spacer'], selections=[False, False, 1, False, list(range(4))])\n",
    "count_internal_DR_spacer3 = count_internal_resum(count_internal_DR_spacer3, ['prediction', 'category', 'stem_len'])\n",
    "\n",
    "count_internal_DR_spacer410 = count_internal_resum(count_internal_all['DR'], ['prediction', 'category', '#MM', 'stem_len', 'spacer'], selections=[False, False, 1, False, list(range(4,11))])\n",
    "count_internal_DR_spacer410 = count_internal_resum(count_internal_DR_spacer410, ['prediction', 'category', 'stem_len'])\n",
    "\n",
    "count_internal_DR_spacer_over10 = count_internal_resum(count_internal_all['DR'], ['prediction', 'category', '#MM', 'stem_len', 'spacer'], selections=[False, False, 1, False, list(range(11,100))])\n",
    "count_internal_DR_spacer_over10 = count_internal_resum(count_internal_DR_spacer_over10, ['prediction', 'category', 'stem_len'])\n",
    "\n",
    "norm_internal_all['DR_stemlen_spacer3'] = mut_norm_conf(count_internal_DR_spacer3 , min_count = 20, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)\n",
    "norm_internal_all['DR_stemlen_spacer410'] = mut_norm_conf(count_internal_DR_spacer410 , min_count = 20, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)\n",
    "norm_internal_all['DR_stemlen_spacer_over10'] = mut_norm_conf(count_internal_DR_spacer_over10 , min_count = 20, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6632e9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_internal_all['MR'] = count_internal_mut_pos(pos_expand_all['MR'].copy(), useful_cols = ['category', '#MM', 'GC%_stem', 'purine', 'stem_len', 'spacer'], gc_nmer = 51, combine_LR = True)\n",
    "\n",
    "# Group normalized values by certain data columns\n",
    "norm_internal_all['MR_stemlen'] = mut_norm_conf(count_internal_resum(count_internal_all['MR'], ['prediction', 'category', '#MM', 'stem_len']) , min_count = 0, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)\n",
    "norm_internal_all['MR_spacer'] = mut_norm_conf(count_internal_resum(count_internal_all['MR'], ['prediction', 'category', '#MM', 'spacer']) , min_count = 0, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)\n",
    "norm_internal_all['MR_GC'] = mut_norm_conf(count_internal_resum(count_internal_all['MR'], ['prediction', 'category', '#MM', 'GC%_stem']) , min_count = 0, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)\n",
    "norm_internal_all['MR_purine'] = mut_norm_conf(count_internal_resum(count_internal_all['MR'], ['prediction', 'category', '#MM', 'purine']) , min_count = 0, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)\n",
    "\n",
    "# MRs with spacer length requirements\n",
    "count_internal_MR_spacer3 = count_internal_resum(count_internal_all['MR'], ['prediction', 'category', '#MM', 'stem_len', 'spacer'], selections=[False, False, 1, False, list(range(4))])\n",
    "count_internal_MR_spacer3 = count_internal_resum(count_internal_MR_spacer3, ['prediction', 'category', 'stem_len'])\n",
    "\n",
    "count_internal_MR_spacer410 = count_internal_resum(count_internal_all['MR'], ['prediction', 'category', '#MM', 'stem_len', 'spacer'], selections=[False, False, 1, False, list(range(4,11))])\n",
    "count_internal_MR_spacer410 = count_internal_resum(count_internal_MR_spacer410, ['prediction', 'category', 'stem_len'])\n",
    "\n",
    "count_internal_MR_spacer_over10 = count_internal_resum(count_internal_all['MR'], ['prediction', 'category', '#MM', 'stem_len', 'spacer'], selections=[False, False, 1, False, list(range(11,100))])\n",
    "count_internal_MR_spacer_over10 = count_internal_resum(count_internal_MR_spacer_over10, ['prediction', 'category', 'stem_len'])\n",
    "\n",
    "norm_internal_all['MR_stemlen_spacer3'] = mut_norm_conf(count_internal_MR_spacer3 , min_count = 20, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)\n",
    "norm_internal_all['MR_stemlen_spacer410'] = mut_norm_conf(count_internal_MR_spacer410 , min_count = 20, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)\n",
    "norm_internal_all['MR_stemlen_spacer_over10'] = mut_norm_conf(count_internal_MR_spacer_over10 , min_count = 20, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a84d6b",
   "metadata": {},
   "source": [
    "#### G4 motifs <a name=\"mutation_internal_count_analyze_G4\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804604ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_internal_all['G4'] = count_internal_mut_pos(pos_expand_all['G4'].copy(), useful_cols = ['Strand', 'status', 'category', 'length'], gc_nmer = 51, combine_LR = True)\n",
    "\n",
    "# Select G4s appearing in K+ conditions\n",
    "count_internal_all['G4_K+'] = count_internal_resum(count_internal_all['G4'], ['status', 'category'], selections = [['K+', 'both'], False])\n",
    "count_internal_all['G4_K+'] = count_internal_resum(count_internal_all['G4_K+'], ['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ca0e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate 5' and 3' positions based on trinucleotide (position of G in triplet is determinant)\n",
    "norm_internal_G4_positions = dict()\n",
    "norm_internal_G4_positions[\"run 5'\"] = mut_norm_conf(count_internal_resum(count_internal_all['G4_K+'], ['category'], selections = ['run_positions_edge']), tri_subset = [mut for mut in triplet_mutations_und if (mut[0] != 'G')], min_count = 0, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)\n",
    "norm_internal_G4_positions[\"run 3'\"] = mut_norm_conf(count_internal_resum(count_internal_all['G4_K+'], ['category'], selections = ['run_positions_edge']), tri_subset = [mut for mut in triplet_mutations_und if (mut[2] != 'G')], min_count = 0, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)\n",
    "norm_internal_G4_positions[\"loop 5'\"] = mut_norm_conf(count_internal_resum(count_internal_all['G4_K+'], ['category'], selections = ['loop_positions_edge']), tri_subset = [mut for mut in triplet_mutations_und if (mut[2] != 'G')], min_count = 0, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)\n",
    "norm_internal_G4_positions[\"loop 3'\"] = mut_norm_conf(count_internal_resum(count_internal_all['G4_K+'], ['category'], selections = ['loop_positions_edge']), tri_subset = [mut for mut in triplet_mutations_und if (mut[0] != 'G')], min_count = 0, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)\n",
    "norm_internal_G4_positions[\"loop 1nt\"] = mut_norm_conf(count_internal_resum(count_internal_all['G4_K+'], ['category'], selections = ['loop_positions_edge']), tri_subset = [mut for mut in triplet_mutations_und if (mut[0] == 'G') & (mut[2] == 'G')], min_count = 0, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)\n",
    "norm_internal_G4_positions['run_positions_middle'] =  mut_norm_conf(count_internal_resum(count_internal_all['G4_K+'], ['category'], selections = ['run_positions_middle']), min_count = 0, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)\n",
    "norm_internal_G4_positions['loop_positions_middle'] =  mut_norm_conf(count_internal_resum(count_internal_all['G4_K+'], ['category'], selections = ['loop_positions_middle']), min_count = 0, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)\n",
    "\n",
    "# Reorganize data structure\n",
    "G4_positionorder = [\"run 5'\", \"run_positions_middle\", \"run 3'\", \"loop 5'\", \"loop_positions_middle\",  \"loop 3'\", \"loop 1nt\"]\n",
    "G4_norm_summary = dict()\n",
    "G4_norm_summary[0] = pd.DataFrame(); G4_norm_summary[1] = pd.DataFrame(); G4_norm_summary[2] = pd.DataFrame()\n",
    "for QC_cutoff in vqslod_list:\n",
    "    G4_norm_summary[0][QC_cutoff] = pd.Series(list(pd.concat([norm_internal_G4_positions[category][0][QC_cutoff] for category in norm_internal_G4_positions])), index = list(norm_internal_G4_positions)).reindex(G4_positionorder)\n",
    "    G4_norm_summary[1][QC_cutoff] = pd.Series(list(pd.concat([norm_internal_G4_positions[category][1][QC_cutoff] for category in norm_internal_G4_positions])), index = list(norm_internal_G4_positions)).reindex(G4_positionorder)\n",
    "    G4_norm_summary[2][QC_cutoff] = pd.Series(list(pd.concat([norm_internal_G4_positions[category][2][QC_cutoff] for category in norm_internal_G4_positions])), index = list(norm_internal_G4_positions)).reindex(G4_positionorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c056de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triplet-level data for G4 positions\n",
    "norm_internal_G4_positions_tri = dict()\n",
    "norm_internal_G4_positions_tri[\"run 5'\"] = mut_norm_conf(count_internal_resum(count_internal_all['G4_K+'], ['category'], selections = ['run_positions_edge']), tri_subset = [mut for mut in triplet_mutations_und if (mut[0] != 'G')], min_count = 10, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True, output_div=True)\n",
    "norm_internal_G4_positions_tri[\"run 3'\"] = mut_norm_conf(count_internal_resum(count_internal_all['G4_K+'], ['category'], selections = ['run_positions_edge']), tri_subset = [mut for mut in triplet_mutations_und if (mut[2] != 'G')], min_count = 10, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True, output_div=True)\n",
    "norm_internal_G4_positions_tri[\"loop 5'\"] = mut_norm_conf(count_internal_resum(count_internal_all['G4_K+'], ['category'], selections = ['loop_positions_edge']), tri_subset = [mut for mut in triplet_mutations_und if (mut[2] != 'G')], min_count = 10, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True, output_div=True)\n",
    "norm_internal_G4_positions_tri[\"loop 3'\"] = mut_norm_conf(count_internal_resum(count_internal_all['G4_K+'], ['category'], selections = ['loop_positions_edge']), tri_subset = [mut for mut in triplet_mutations_und if (mut[0] != 'G')], min_count = 10, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True, output_div=True)\n",
    "norm_internal_G4_positions_tri[\"loop 1nt\"] = mut_norm_conf(count_internal_resum(count_internal_all['G4_K+'], ['category'], selections = ['loop_positions_edge']), tri_subset = [mut for mut in triplet_mutations_und if (mut[0] == 'G') & (mut[2] == 'G')], min_count = 10, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True, output_div=True)\n",
    "norm_internal_G4_positions_tri['run_positions_middle'] =  mut_norm_conf(count_internal_resum(count_internal_all['G4_K+'], ['category'], selections = ['run_positions_middle']), min_count = 10, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True, output_div=True)\n",
    "norm_internal_G4_positions_tri['loop_positions_middle'] =  mut_norm_conf(count_internal_resum(count_internal_all['G4_K+'], ['category'], selections = ['loop_positions_middle']), min_count = 10, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True, output_div=True)\n",
    "\n",
    "# Reorganize data structure\n",
    "G4_norm_summary_tri = dict()\n",
    "for QC_cutoff in vqslod_list:\n",
    "    G4_norm_summary_tri[QC_cutoff] = pd.concat([norm_internal_G4_positions_tri[category][0][QC_cutoff] for category in norm_internal_G4_positions_tri], axis=1) / normtorandom_all[QC_cutoff]\n",
    "    G4_norm_summary_tri[QC_cutoff].columns = list(norm_internal_G4_positions_tri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ec6564",
   "metadata": {},
   "source": [
    "#### Z-DNA motifs <a name=\"mutation_internal_count_analyze_ZDNA\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6d2f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_internal_all['ZDNA'] = count_internal_mut_pos(pos_expand_all['ZDNA'].copy(), useful_cols = ['category', 'length'], gc_nmer = 51, combine_LR = True)\n",
    "count_internal_all['ZDNA_GY'] = count_internal_mut_pos(pos_expand_all['ZDNA_GY'].copy(), useful_cols = ['Strand', 'category', 'length'], gc_nmer = 51, combine_LR = True)\n",
    "\n",
    "norm_internal_all['ZDNA'] = mut_norm_conf(count_internal_all['ZDNA'], min_count = 10, normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d81078",
   "metadata": {},
   "source": [
    "#### Save/load internal mutation counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfa5ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save temporary output of the mutation counts\n",
    "with open('./analysis/temp/mut_internal_counts_ACcor_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(count_internal_all, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Save temporary output of the normalized mutation counts\n",
    "with open('./analysis/temp/mut_internal_norm_ACcor_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(norm_internal_all, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a282997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load temporary output of the mutation counts\n",
    "with open('./analysis/temp/mut_internal_counts_ACcor_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    count_internal_all = pickle.load(handle)\n",
    "\n",
    "# Load temporary output of the mutation counts\n",
    "with open('./analysis/temp/mut_internal_norm_ACcor_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    norm_internal_all = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ca8b53",
   "metadata": {},
   "source": [
    "## Plot mutation frequency within motifs <a name=\"mutation_internal_count_plot\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fce4277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign colors to QC cutoffs\n",
    "QC_colors_internal = make_colorscale(vqslod_list, 0.5)\n",
    "QC_colors_internal = pd.DataFrame(QC_colors_internal).transpose()\n",
    "QC_colors_internal['name'] = ['no QC', 'pass', 'VQSLOD >0', 'VQSLOD >4']\n",
    "QC_colors_internal_passfail = QC_colors_internal.reindex([-np.inf, -2.774])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d119ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate individual plot traces\n",
    "def plot_internal_add(motif, plot_range, useful_cols, row_n, col_n, input_dict, showleg, plot_name, pred_factor, QC_colors_current = QC_colors_internal):\n",
    "    for QCfilter in QC_colors_current.index:\n",
    "        plot_series = input_dict[motif][0][QCfilter]; plot_high = input_dict[motif][2][QCfilter]; plot_low = input_dict[motif][1][QCfilter]\n",
    "        for level in useful_cols:\n",
    "            plot_series = plot_series.loc[level]; plot_high = plot_high.loc[level]; plot_low = plot_low.loc[level]\n",
    "        plot_series = plot_series.reindex(list(range(plot_range[0], plot_range[1]+1))); plot_high = plot_high.reindex(list(range(plot_range[0], plot_range[1]+1))); plot_low = plot_low.reindex(list(range(plot_range[0], plot_range[1]+1)))\n",
    "        \n",
    "        plot_name.add_trace(go.Scatter(x = plot_series.index, y = plot_series * pred_factor, name = QC_colors_current['name'][QCfilter], marker = dict(color = QC_colors_current[0][QCfilter]), mode = 'lines', legendgroup = QCfilter, showlegend=showleg,\n",
    "        error_y=dict(type='data', symmetric=False, array = (plot_high -  plot_series) * pred_factor, arrayminus =  (plot_series - plot_low) * pred_factor, color=QC_colors_current[1][QCfilter], thickness=1.5, width=3),), row = row_n, col = col_n)\n",
    "    plot_name.update_xaxes(range = [plot_range[0]-1, plot_range[1]+1], row = row_n, col = col_n)\n",
    "    plot_name.add_shape(type='line', x0=plot_range[0]-1, y0=1, x1=plot_range[1]+1, y1=1, line=dict(color='Black', width = .5), row = row_n, col = col_n)\n",
    "\n",
    "# Function to generate individual plots\n",
    "def plot_internal(motif, useful_cols, plot_range = [10,20], input_dict = norm_internal_all, row_n = 1, col_n = 1, pred_factor = 1, QC_colors_current = QC_colors_internal, log = False, yrange = [-0.55,12]):\n",
    "    mutnorm_internal_fig = make_subplots()\n",
    "    plot_internal_add(motif = motif, useful_cols = useful_cols, row_n = 1, col_n = 1, plot_range = plot_range, input_dict = input_dict, showleg = True, plot_name = mutnorm_internal_fig, pred_factor = pred_factor, QC_colors_current = QC_colors_current)\n",
    "    mutnorm_internal_fig.add_shape(type='line', x0=0, y0=1, x1=50, y1=1, line=dict(color='Black', width = .3), row=row_n, col=col_n)\n",
    "    mutnorm_internal_fig.update_xaxes(dtick = 5, range = [plot_range[0]-1, plot_range[1]+1])\n",
    "    mutnorm_internal_fig.update_yaxes(range = yrange, tickmode = 'array', tickvals = [1,5,10], zeroline = False,  type = 'log' if log == True else 'linear')\n",
    "    return mutnorm_internal_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f48d15",
   "metadata": {},
   "source": [
    "#### STR A-mononucleotide motifs (Fig 3A) <a name=\"mutation_internal_count_plot_3A\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f83fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inframe_mut_fig3a = make_subplots(rows=1, cols=5, shared_yaxes=True, shared_xaxes = True, vertical_spacing = 0.025, horizontal_spacing = 0.02, subplot_titles = ['Flank', 'Start/end', 'Within motif', 'Perfecting', 'Non-perfecting'])\n",
    "plot_internal_add('STR', [6,31], ['non_pred', 'A', 'flank_pos', 'perfect'], 1, 1, norm_internal_all, showleg = False, plot_name = inframe_mut_fig3a, pred_factor = 1)\n",
    "plot_internal_add('STR', [6,31], ['non_pred', 'A', 'motif_pos', 'perfect'], 1, 2, norm_internal_all, showleg = False, plot_name = inframe_mut_fig3a, pred_factor = 1)\n",
    "plot_internal_add('STR', [6,30], ['non_pred', 'A', 'motif_pos_genome_middle', 'perfect'], 1, 3, norm_internal_all, showleg = False, plot_name = inframe_mut_fig3a, pred_factor = 1)\n",
    "plot_internal_add('STR', [10,30], ['pred', 'A', 'MM_pos_genome', 'inframe'], 1, 4, norm_internal_all, showleg = True, plot_name = inframe_mut_fig3a, pred_factor = 3)\n",
    "plot_internal_add('STR', [10,30], ['against_pred', 'A', 'MM_pos_genome', 'inframe'], 1, 5, norm_internal_all, showleg = False, plot_name = inframe_mut_fig3a, pred_factor = 1.5)\n",
    "inframe_mut_fig3a.update_yaxes(title = dict(text = 'A-mono', font = dict(size = 18), standoff = 0), row = 1, col = 1)\n",
    "\n",
    "inframe_mut_fig3a.update_yaxes(zeroline = False, range = [-0.5,11], dtick = 2)\n",
    "inframe_mut_fig3a.update_xaxes(title = dict(text = 'motif length', font = dict(size = 14), standoff = 0), row = 1, col = 1)\n",
    "inframe_mut_fig3a.update_layout(width = 750, height = 200, margin = dict(l = 35, r = 25, b = 0, t = 20), legend=dict(y = -0.10, x = 0.25, orientation='h'))\n",
    "inframe_mut_fig3a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f155e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "inframe_mut_fig3a.write_image('./plots/revision_ACcor_internal_mutation_fig_3a.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8229121",
   "metadata": {},
   "source": [
    "#### STR motifs (Fig. S3B) <a name=\"mutation_internal_count_plot_S3B\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf8fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unused figure: additional STRs\n",
    "repeats_figlist = ['A', 'C', 'AT', 'AC', 'AG', 'ACC', 'AGG', 'ATC', 'AGC', 'AAG', 'AAC', 'AAT', 'AAAT']\n",
    "\n",
    "inframe_mut_figS3b = make_subplots(rows=len(repeats_figlist), cols=5, shared_yaxes=True, shared_xaxes = True, vertical_spacing = 0.015, horizontal_spacing = 0.02, subplot_titles = ['Flank', 'Start/end', 'Within motif', 'Perfecting', 'Non-perfecting'])\n",
    "counter = 0\n",
    "for repeat in repeats_figlist:\n",
    "    counter +=1\n",
    "    plot_internal_add('STR', [8,31], ['non_pred', repeat, 'flank_pos', 'perfect'], counter, 1, norm_internal_all, showleg = True if counter == 1 else False, plot_name = inframe_mut_figS3b, pred_factor = 1)\n",
    "    plot_internal_add('STR', [8,31], ['non_pred', repeat, 'motif_pos', 'perfect'], counter, 2, norm_internal_all, showleg = False, plot_name = inframe_mut_figS3b, pred_factor = 1)\n",
    "    plot_internal_add('STR', [8,30], ['non_pred', repeat, 'motif_pos_genome_middle', 'perfect'], counter, 3, norm_internal_all, showleg = False, plot_name = inframe_mut_figS3b, pred_factor = 1)\n",
    "    plot_internal_add('STR', [14,30], ['pred', repeat, 'MM_pos_genome', 'inframe'], counter, 4, norm_internal_all, showleg = False, plot_name = inframe_mut_figS3b, pred_factor = 3)\n",
    "    plot_internal_add('STR', [14,30], ['against_pred', repeat, 'MM_pos_genome', 'inframe'], counter, 5, norm_internal_all, showleg = False, plot_name = inframe_mut_figS3b, pred_factor = 1.5)\n",
    "    inframe_mut_figS3b.update_yaxes(title = dict(text = repeat, font = dict(size = 18), standoff = 0), row = counter, col = 1)\n",
    "\n",
    "inframe_mut_figS3b.update_yaxes(zeroline = False, range = [-0.5,15.99], dtick = 4)\n",
    "inframe_mut_figS3b.update_xaxes(dtick = 5)\n",
    "inframe_mut_figS3b.update_xaxes(title = dict(text = 'motif length', font = dict(size = 14), standoff = 0), row = counter, col = 1)\n",
    "inframe_mut_figS3b.update_layout(width = 600, height = 100*len(repeats_figlist), margin = dict(l = 35, r = 25, b = 0, t = 20), legend=dict(y = -0.02, x = 0.25, orientation='h'))\n",
    "inframe_mut_figS3b.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b637cfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inframe_mut_figS3b.write_image('./plots/revision_ACcor_internal_mutation_fig_S3B.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67700201",
   "metadata": {},
   "source": [
    "#### IR motifs (Fig S5A) <a name=\"mutation_internal_count_plot_S5A\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75450452",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_order = [\"Flank\", 'Motif int.', \"Spacer ends\", \"Flank\", 'Motif int.', \"Spacer ends\", 'Motif', 'Spacer mid']\n",
    "\n",
    "other_pos_stemlen_figS5a = make_subplots(cols=len(name_order), rows = 4, vertical_spacing = 0, horizontal_spacing = 0.02, subplot_titles = name_order, shared_yaxes=True)\n",
    "\n",
    "plot_internal_add('IR_stemlen_spacer3', [10,19], ['pred', 'flank_pos'], 1, 1, norm_internal_all, showleg = True, plot_name = other_pos_stemlen_figS5a, pred_factor = 3)\n",
    "plot_internal_add('IR_stemlen_spacer3', [10,19], ['pred', 'MM_pos'], 1, 2, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 3)\n",
    "plot_internal_add('IR_stemlen_spacer3', [10,19], ['pred', 'spacer_pos'], 1, 3, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 3)\n",
    "\n",
    "plot_internal_add('IR_stemlen_spacer3', [10,19], ['against_pred', 'flank_pos'], 1, 4, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 1.5)\n",
    "plot_internal_add('IR_stemlen_spacer3', [10,19], ['against_pred', 'MM_pos'], 1, 5, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 1.5)\n",
    "plot_internal_add('IR_stemlen_spacer3', [10,19], ['against_pred', 'spacer_pos'], 1, 6, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 1.5)\n",
    "\n",
    "plot_internal_add('IR_stemlen_spacer3', [10,19], ['non_pred', 'motif_pos_genome_middle'], 1, 7, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 1)\n",
    "plot_internal_add('IR_stemlen_spacer3', [10,19], ['non_pred', 'spacer_middle_pos'], 1, 8, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 1)\n",
    "\n",
    "\n",
    "plot_internal_add('IR_stemlen_spacer410', [10,19], ['pred', 'flank_pos'], 2, 1, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 3)\n",
    "plot_internal_add('IR_stemlen_spacer410', [10,19], ['pred', 'MM_pos'], 2, 2, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 3)\n",
    "plot_internal_add('IR_stemlen_spacer410', [10,19], ['pred', 'spacer_pos'], 2, 3, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 3)\n",
    "\n",
    "plot_internal_add('IR_stemlen_spacer410', [10,19], ['against_pred', 'flank_pos'], 2, 4, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 1.5)\n",
    "plot_internal_add('IR_stemlen_spacer410', [10,19], ['against_pred', 'MM_pos'], 2, 5, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 1.5)\n",
    "plot_internal_add('IR_stemlen_spacer410', [10,19], ['against_pred', 'spacer_pos'], 2, 6, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 1.5)\n",
    "\n",
    "plot_internal_add('IR_stemlen_spacer410', [10,19], ['non_pred', 'motif_pos_genome_middle'], 2, 7, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 1)\n",
    "plot_internal_add('IR_stemlen_spacer410', [10,19], ['non_pred', 'spacer_middle_pos'], 2, 8, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 1)\n",
    "\n",
    "\n",
    "plot_internal_add('IR_stemlen_spacer_over10', [10,19], ['pred', 'flank_pos'], 3, 1, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 3)\n",
    "plot_internal_add('IR_stemlen_spacer_over10', [10,19], ['pred', 'MM_pos'], 3, 2, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 3)\n",
    "plot_internal_add('IR_stemlen_spacer_over10', [10,19], ['pred', 'spacer_pos'], 3, 3, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 3)\n",
    "\n",
    "plot_internal_add('IR_stemlen_spacer_over10', [10,19], ['against_pred', 'flank_pos'], 3, 4, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 1.5)\n",
    "plot_internal_add('IR_stemlen_spacer_over10', [10,19], ['against_pred', 'MM_pos'], 3, 5, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 1.5)\n",
    "plot_internal_add('IR_stemlen_spacer_over10', [10,19], ['against_pred', 'spacer_pos'], 3, 6, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 1.5)\n",
    "\n",
    "plot_internal_add('IR_stemlen_spacer_over10', [10,19], ['non_pred', 'motif_pos_genome_middle'], 3, 7, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 1)\n",
    "plot_internal_add('IR_stemlen_spacer_over10', [10,19], ['non_pred', 'spacer_middle_pos'], 3, 8, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 1)\n",
    "\n",
    "\n",
    "\n",
    "plot_internal_add('IR_spacer', [0,11], ['pred', 'flank_pos', 0], 4, 1, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 3)\n",
    "plot_internal_add('IR_spacer', [0,11], ['pred', 'MM_pos', 1], 4, 2, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 3)\n",
    "plot_internal_add('IR_spacer', [0,11], ['pred', 'spacer_pos', 0], 4, 3, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 3)\n",
    "\n",
    "plot_internal_add('IR_spacer', [0,11], ['against_pred', 'flank_pos', 0], 4, 4, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 1.5)\n",
    "plot_internal_add('IR_spacer', [0,11], ['against_pred', 'MM_pos', 1], 4, 5, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 1.5)\n",
    "plot_internal_add('IR_spacer', [0,11], ['against_pred', 'spacer_pos', 0], 4, 6, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 1.5)\n",
    "\n",
    "plot_internal_add('IR_spacer', [0,11], ['non_pred', 'motif_pos_genome_middle', 0], 4, 7, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 1)\n",
    "plot_internal_add('IR_spacer', [0,11], ['non_pred', 'spacer_middle_pos', 0], 4, 8, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS5a, pred_factor = 1)\n",
    "\n",
    "\n",
    "other_pos_stemlen_figS5a.add_shape(type='line', x0=0.375, y0=-0.025, x1=0.375, y1=1.025, xref='paper', yref='paper', line=dict(color='rgb(150,150,150)', width = 3))\n",
    "other_pos_stemlen_figS5a.add_shape(type='line', x0=0.755, y0=-0.025, x1=0.76, y1=1.025, xref='paper', yref='paper', line=dict(color='rgb(150,150,150)', width = 3))\n",
    "\n",
    "other_pos_stemlen_figS5a.update_yaxes(range = [-0.1, 7.5], zeroline = False)\n",
    "\n",
    "other_pos_stemlen_figS5a.update_yaxes(title = dict(text = 'Spacer 1-3', font = dict(size = 14)), title_standoff = 0, col = 1, row = 1)\n",
    "other_pos_stemlen_figS5a.update_yaxes(title = dict(text = 'Spacer 4-10', font = dict(size = 14)), title_standoff = 0, col = 1, row = 2)\n",
    "other_pos_stemlen_figS5a.update_yaxes(title = dict(text = 'Spacer >10', font = dict(size = 14)), title_standoff = 0, col = 1, row = 3)\n",
    "other_pos_stemlen_figS5a.update_yaxes(title = dict(text = 'Motif >9 nt', font = dict(size = 14)), title_standoff = 0, col = 1, row = 4)\n",
    "\n",
    "other_pos_stemlen_figS5a.update_xaxes(title = dict(text = 'Motif length', font = dict(size = 14)), title_standoff = 0, col = 2, row = 3)\n",
    "other_pos_stemlen_figS5a.update_xaxes(title = dict(text = 'Spacer length', font = dict(size = 14)), title_standoff = 0, col = 2, row = 4)\n",
    "other_pos_stemlen_figS5a.update_xaxes(zeroline = False, row = 4)\n",
    "\n",
    "other_pos_stemlen_figS5a.update_xaxes(showticklabels=False, row = 1); other_pos_stemlen_figS5a.update_xaxes(showticklabels=False, row = 2)\n",
    "other_pos_stemlen_figS5a.update_xaxes(range = [9, 21], row = 1); other_pos_stemlen_figS5a.update_xaxes(range = [9, 21], row = 2); other_pos_stemlen_figS5a.update_xaxes(range = [9, 21], row = 3); other_pos_stemlen_figS5a.update_xaxes(range = [-1.5, 12], row = 4)\n",
    "\n",
    "other_pos_stemlen_figS5a.update_yaxes(domain = [0.01, 0.22], row = 4)\n",
    "other_pos_stemlen_figS5a.update_yaxes(domain = [0.32, 0.52], row = 3)\n",
    "other_pos_stemlen_figS5a.update_yaxes(domain = [0.55, 0.75], row = 2)\n",
    "other_pos_stemlen_figS5a.update_yaxes(domain = [0.78, 0.99], row = 1)\n",
    "\n",
    "other_pos_stemlen_figS5a.update_layout(title = dict(text = 'Perfecting mutations                        Non-perfecting mutations                  Other mutations', x = 0.125, font = dict(size = 18)),\n",
    "    height = 550, width = 1000, margin = dict(l = 55, r = 25, b = 25, t = 55), legend=dict(y = -0.03, x = 0.45, orientation='h'))\n",
    "\n",
    "\n",
    "other_pos_stemlen_figS5a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3a88c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_pos_stemlen_figS5a.write_image('./plots/revision_ACcor_internal_mutation_IR_fig_S5a.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63009dba",
   "metadata": {},
   "source": [
    "#### Mutation spectrum for IR spacer mutations (Fig. S5c) <a name=\"mutation_internal_count_plot_S5C\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaf7598",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_apobec = colors.copy()\n",
    "colors_apobec.loc['APOBEC'] = ['purple', ['TCA_T', 'TCT_T', 'TCG_T', 'TCC_T'], [], 7, ['TCA_T', 'TCT_T', 'TCG_T', 'TCC_T'], ['TGA_A', 'AGA_A', 'CGA_A', 'GGA_A'], ['TCA_T', 'TCT_T', 'TCG_T', 'TCC_T', 'TGA_A', 'AGA_A', 'CGA_A', 'GGA_A']]\n",
    "\n",
    "norm_internal_bymut = dict()\n",
    "norm_internal_bymut['IR_stemlen_spacer3'] = dict()\n",
    "for mut_type in colors_apobec.index:\n",
    "    norm_internal_bymut['IR_stemlen_spacer3'][mut_type] = mut_norm_conf(count_internal_IR_spacer3 , min_count = 5, tri_subset = colors_apobec['ind_all'][mut_type], normtorandom = True, random_normaverage=normtorandom_all, gc_correct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "face71a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IR_bymut_figS5c = go.Figure()\n",
    "for mut_type in colors_apobec.index:\n",
    "    IR_bymut_figS5c.add_trace(go.Scatter(x = norm_internal_bymut['IR_stemlen_spacer3'][mut_type][0][-np.inf]['non_pred']['spacer_middle_pos'].index, y = norm_internal_bymut['IR_stemlen_spacer3'][mut_type][0][-np.inf]['non_pred']['spacer_middle_pos'], name = mut_type, mode = 'lines', opacity = 0.75, line = dict(color = colors_apobec.loc[mut_type]['color'], )))\n",
    "\n",
    "IR_bymut_figS5c.add_shape(type='line', x0=9, y0=1, x1=16, y1=1, line=dict(color='Black', width = .5))\n",
    "IR_bymut_figS5c.update_yaxes(zeroline = False, tickmode = 'array', tickvals = [1,3,5,7], title = dict(text = 'Spacer 1-3 mid', standoff = 0, font = dict(size = 14)))\n",
    "IR_bymut_figS5c.update_xaxes(range = [9.5, 15.5], dtick = 1, title = dict(text = 'Motif length', standoff = 0, font = dict(size = 14)))\n",
    "IR_bymut_figS5c.update_layout(height = 235, width = 520, margin = dict(l = 35, r = 25, b = 35, t = 25))\n",
    "IR_bymut_figS5c.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fea024",
   "metadata": {},
   "outputs": [],
   "source": [
    "IR_bymut_figS5c.write_image('./plots/revision_ACcor_internal_IR_bymut_apobec_figS5c.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595b34b9",
   "metadata": {},
   "source": [
    "#### MR/DR motifs (Fig S4a, S6a) <a name=\"mutation_internal_count_plot_S6A\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454c7397",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_order = [\"Flank\", 'Motif int.', \"Spacer ends\", \"Flank\", 'Motif int.', \"Spacer ends\", 'Motif', 'Spacer mid']\n",
    "\n",
    "other_pos_stemlen_figS4a = make_subplots(cols=len(name_order), rows = 4, horizontal_spacing = 0.025, subplot_titles = name_order, shared_yaxes=True)\n",
    "\n",
    "plot_internal_add('DR_stemlen_spacer3', [10,19], ['pred', 'flank_pos'], 1, 1, norm_internal_all, showleg = True, plot_name = other_pos_stemlen_figS4a, pred_factor = 3)\n",
    "plot_internal_add('DR_stemlen_spacer3', [10,19], ['pred', 'MM_pos'], 1, 2, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 3)\n",
    "plot_internal_add('DR_stemlen_spacer3', [10,19], ['pred', 'spacer_pos'], 1, 3, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 3)\n",
    "\n",
    "plot_internal_add('DR_stemlen_spacer3', [10,19], ['against_pred', 'flank_pos'], 1, 4, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 1.5)\n",
    "plot_internal_add('DR_stemlen_spacer3', [10,19], ['against_pred', 'MM_pos'], 1, 5, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 1.5)\n",
    "plot_internal_add('DR_stemlen_spacer3', [10,19], ['against_pred', 'spacer_pos'], 1, 6, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 1.5)\n",
    "\n",
    "plot_internal_add('DR_stemlen_spacer3', [10,19], ['non_pred', 'motif_pos_genome_middle'], 1, 7, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 1)\n",
    "plot_internal_add('DR_stemlen_spacer3', [10,19], ['non_pred', 'spacer_middle_pos'], 1, 8, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 1)\n",
    "\n",
    "plot_internal_add('DR_stemlen_spacer410', [10,19], ['pred', 'flank_pos'], 2, 1, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 3)\n",
    "plot_internal_add('DR_stemlen_spacer410', [10,19], ['pred', 'MM_pos'], 2, 2, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 3)\n",
    "plot_internal_add('DR_stemlen_spacer410', [10,19], ['pred', 'spacer_pos'], 2, 3, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 3)\n",
    "\n",
    "plot_internal_add('DR_stemlen_spacer410', [10,19], ['against_pred', 'flank_pos'], 2, 4, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 1.5)\n",
    "plot_internal_add('DR_stemlen_spacer410', [10,19], ['against_pred', 'MM_pos'], 2, 5, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 1.5)\n",
    "plot_internal_add('DR_stemlen_spacer410', [10,19], ['against_pred', 'spacer_pos'], 2, 6, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 1.5)\n",
    "\n",
    "plot_internal_add('DR_stemlen_spacer410', [10,19], ['non_pred', 'motif_pos_genome_middle'], 2, 7, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 1)\n",
    "plot_internal_add('DR_stemlen_spacer410', [10,19], ['non_pred', 'spacer_middle_pos'], 2, 8, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 1)\n",
    "\n",
    "plot_internal_add('DR_stemlen_spacer_over10', [10,19], ['pred', 'flank_pos'], 3, 1, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 3)\n",
    "plot_internal_add('DR_stemlen_spacer_over10', [10,19], ['pred', 'MM_pos'], 3, 2, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 3)\n",
    "plot_internal_add('DR_stemlen_spacer_over10', [10,19], ['pred', 'spacer_pos'], 3, 3, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 3)\n",
    "\n",
    "plot_internal_add('DR_stemlen_spacer_over10', [10,19], ['against_pred', 'flank_pos'], 3, 4, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 1.5)\n",
    "plot_internal_add('DR_stemlen_spacer_over10', [10,19], ['against_pred', 'MM_pos'], 3, 5, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 1.5)\n",
    "plot_internal_add('DR_stemlen_spacer_over10', [10,19], ['against_pred', 'spacer_pos'], 3, 6, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 1.5)\n",
    "\n",
    "plot_internal_add('DR_stemlen_spacer_over10', [10,19], ['non_pred', 'motif_pos_genome_middle'], 3, 7, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 1)\n",
    "plot_internal_add('DR_stemlen_spacer_over10', [10,19], ['non_pred', 'spacer_middle_pos'], 3, 8, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 1)\n",
    "\n",
    "plot_internal_add('DR_spacer', [0,11], ['pred', 'flank_pos', 0], 4, 1, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 3)\n",
    "plot_internal_add('DR_spacer', [0,11], ['pred', 'MM_pos', 1], 4, 2, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 3)\n",
    "plot_internal_add('DR_spacer', [0,11], ['pred', 'spacer_pos', 0], 4, 3, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 3)\n",
    "\n",
    "plot_internal_add('DR_spacer', [0,11], ['against_pred', 'flank_pos', 0], 4, 4, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 1.5)\n",
    "plot_internal_add('DR_spacer', [0,11], ['against_pred', 'MM_pos', 1], 4, 5, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 1.5)\n",
    "plot_internal_add('DR_spacer', [0,11], ['against_pred', 'spacer_pos', 0], 4, 6, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 1.5)\n",
    "\n",
    "plot_internal_add('DR_spacer', [0,11], ['non_pred', 'motif_pos_genome_middle', 0], 4, 7, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 1)\n",
    "plot_internal_add('DR_spacer', [0,11], ['non_pred', 'spacer_middle_pos', 0], 4, 8, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS4a, pred_factor = 1)\n",
    "\n",
    "\n",
    "other_pos_stemlen_figS4a.add_shape(type='line', x0=0.375, y0=-0.025, x1=0.375, y1=1.025, xref='paper', yref='paper', line=dict(color='rgb(150,150,150)', width = 3))\n",
    "other_pos_stemlen_figS4a.add_shape(type='line', x0=0.76, y0=-0.025, x1=0.76, y1=1.025, xref='paper', yref='paper', line=dict(color='rgb(150,150,150)', width = 3))\n",
    "\n",
    "other_pos_stemlen_figS4a.update_yaxes(range = [-0.1, 4.25], zeroline = False)\n",
    "\n",
    "other_pos_stemlen_figS4a.update_yaxes(title = dict(text = 'Spacer 1-3', font = dict(size = 14)), title_standoff = 0, col = 1, row = 1)\n",
    "other_pos_stemlen_figS4a.update_yaxes(title = dict(text = 'Spacer 4-10', font = dict(size = 14)), title_standoff = 0, col = 1, row = 2)\n",
    "other_pos_stemlen_figS4a.update_yaxes(title = dict(text = 'Spacer >10', font = dict(size = 14)), title_standoff = 0, col = 1, row = 3)\n",
    "other_pos_stemlen_figS4a.update_yaxes(title = dict(text = 'Motif >9 nt', font = dict(size = 14)), title_standoff = 0, col = 1, row = 4)\n",
    "\n",
    "other_pos_stemlen_figS4a.update_xaxes(title = dict(text = 'Motif length', font = dict(size = 14)), title_standoff = 0, col = 2, row = 3)\n",
    "other_pos_stemlen_figS4a.update_xaxes(title = dict(text = 'Spacer length', font = dict(size = 14)), title_standoff = 0, col = 2, row = 4)\n",
    "other_pos_stemlen_figS4a.update_xaxes(zeroline = False, row = 4)\n",
    "\n",
    "other_pos_stemlen_figS4a.update_xaxes(showticklabels=False, row = 1); other_pos_stemlen_figS4a.update_xaxes(showticklabels=False, row = 2)\n",
    "other_pos_stemlen_figS4a.update_xaxes(range = [9, 21], row = 1); other_pos_stemlen_figS4a.update_xaxes(range = [9, 21], row = 2); other_pos_stemlen_figS4a.update_xaxes(range = [9, 21], row = 3); other_pos_stemlen_figS4a.update_xaxes(range = [-1.5, 12], row = 4)\n",
    "\n",
    "other_pos_stemlen_figS4a.update_yaxes(domain = [0.01, 0.22], row = 4)\n",
    "other_pos_stemlen_figS4a.update_yaxes(domain = [0.32, 0.52], row = 3)\n",
    "other_pos_stemlen_figS4a.update_yaxes(domain = [0.55, 0.75], row = 2)\n",
    "other_pos_stemlen_figS4a.update_yaxes(domain = [0.78, 0.99], row = 1)\n",
    "\n",
    "other_pos_stemlen_figS4a.update_layout(title = dict(text = 'Perfecting mutations                        Non-perfecting mutations                  Other mutations', x = 0.125, font = dict(size = 18)),\n",
    "    height = 550, width = 1000, margin = dict(l = 55, r = 25, b = 25, t = 55), legend=dict(y = -0.03, x = 0.45, orientation='h'))\n",
    "\n",
    "other_pos_stemlen_figS4a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac515f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_pos_stemlen_figS4a.write_image('./plots/revision_ACcor_DR_SNVfreq_figS4a.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff2f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_order = [\"Flank\", 'Motif int.', \"Spacer ends\", \"Flank\", 'Motif int.', \"Spacer ends\", 'Motif', 'Spacer mid']\n",
    "\n",
    "other_pos_stemlen_figS6a = make_subplots(cols=len(name_order), rows = 4, vertical_spacing = 0, horizontal_spacing = 0.015, subplot_titles = name_order, shared_yaxes=True)\n",
    "\n",
    "plot_internal_add('MR_stemlen_spacer3', [10,19], ['pred', 'flank_pos'], 1, 1, norm_internal_all, showleg = True, plot_name = other_pos_stemlen_figS6a, pred_factor = 3)\n",
    "plot_internal_add('MR_stemlen_spacer3', [10,19], ['pred', 'MM_pos'], 1, 2, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 3)\n",
    "plot_internal_add('MR_stemlen_spacer3', [10,19], ['pred', 'spacer_pos'], 1, 3, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 3)\n",
    "\n",
    "plot_internal_add('MR_stemlen_spacer3', [10,19], ['against_pred', 'flank_pos'], 1, 4, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 1.5)\n",
    "plot_internal_add('MR_stemlen_spacer3', [10,19], ['against_pred', 'MM_pos'], 1, 5, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 1.5)\n",
    "plot_internal_add('MR_stemlen_spacer3', [10,19], ['against_pred', 'spacer_pos'], 1, 6, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 1.5)\n",
    "\n",
    "plot_internal_add('MR_stemlen_spacer3', [10,19], ['non_pred', 'motif_pos_genome_middle'], 1, 7, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 1)\n",
    "plot_internal_add('MR_stemlen_spacer3', [10,19], ['non_pred', 'spacer_middle_pos'], 1, 8, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 1)\n",
    "\n",
    "\n",
    "plot_internal_add('MR_stemlen_spacer410', [10,19], ['pred', 'flank_pos'], 2, 1, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 3)\n",
    "plot_internal_add('MR_stemlen_spacer410', [10,19], ['pred', 'MM_pos'], 2, 2, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 3)\n",
    "plot_internal_add('MR_stemlen_spacer410', [10,19], ['pred', 'spacer_pos'], 2, 3, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 3)\n",
    "\n",
    "plot_internal_add('MR_stemlen_spacer410', [10,19], ['against_pred', 'flank_pos'], 2, 4, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 1.5)\n",
    "plot_internal_add('MR_stemlen_spacer410', [10,19], ['against_pred', 'MM_pos'], 2, 5, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 1.5)\n",
    "plot_internal_add('MR_stemlen_spacer410', [10,19], ['against_pred', 'spacer_pos'], 2, 6, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 1.5)\n",
    "\n",
    "plot_internal_add('MR_stemlen_spacer410', [10,19], ['non_pred', 'motif_pos_genome_middle'], 2, 7, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 1)\n",
    "plot_internal_add('MR_stemlen_spacer410', [10,19], ['non_pred', 'spacer_middle_pos'], 2, 8, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 1)\n",
    "\n",
    "\n",
    "plot_internal_add('MR_stemlen_spacer_over10', [10,19], ['pred', 'flank_pos'], 3, 1, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 3)\n",
    "plot_internal_add('MR_stemlen_spacer_over10', [10,19], ['pred', 'MM_pos'], 3, 2, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 3)\n",
    "plot_internal_add('MR_stemlen_spacer_over10', [10,19], ['pred', 'spacer_pos'], 3, 3, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 3)\n",
    "\n",
    "plot_internal_add('MR_stemlen_spacer_over10', [10,19], ['against_pred', 'flank_pos'], 3, 4, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 1.5)\n",
    "plot_internal_add('MR_stemlen_spacer_over10', [10,19], ['against_pred', 'MM_pos'], 3, 5, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 1.5)\n",
    "plot_internal_add('MR_stemlen_spacer_over10', [10,19], ['against_pred', 'spacer_pos'], 3, 6, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 1.5)\n",
    "\n",
    "plot_internal_add('MR_stemlen_spacer_over10', [10,19], ['non_pred', 'motif_pos_genome_middle'], 3, 7, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 1)\n",
    "plot_internal_add('MR_stemlen_spacer_over10', [10,19], ['non_pred', 'spacer_middle_pos'], 3, 8, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 1)\n",
    "\n",
    "\n",
    "\n",
    "plot_internal_add('MR_spacer', [0,11], ['pred', 'flank_pos', 0], 4, 1, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 3)\n",
    "plot_internal_add('MR_spacer', [0,11], ['pred', 'MM_pos', 1], 4, 2, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 3)\n",
    "plot_internal_add('MR_spacer', [0,11], ['pred', 'spacer_pos', 0], 4, 3, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 3)\n",
    "\n",
    "plot_internal_add('MR_spacer', [0,11], ['against_pred', 'flank_pos', 0], 4, 4, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 1.5)\n",
    "plot_internal_add('MR_spacer', [0,11], ['against_pred', 'MM_pos', 1], 4, 5, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 1.5)\n",
    "plot_internal_add('MR_spacer', [0,11], ['against_pred', 'spacer_pos', 0], 4, 6, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 1.5)\n",
    "\n",
    "plot_internal_add('MR_spacer', [0,11], ['non_pred', 'motif_pos_genome_middle', 0], 4, 7, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 1)\n",
    "plot_internal_add('MR_spacer', [0,11], ['non_pred', 'spacer_middle_pos', 0], 4, 8, norm_internal_all, showleg = False, plot_name = other_pos_stemlen_figS6a, pred_factor = 1)\n",
    "\n",
    "\n",
    "other_pos_stemlen_figS6a.add_shape(type='line', x0=0.373, y0=-0.025, x1=0.373, y1=1.025, xref='paper', yref='paper', line=dict(color='rgb(150,150,150)', width = 3))\n",
    "other_pos_stemlen_figS6a.add_shape(type='line', x0=0.755, y0=-0.025, x1=0.755, y1=1.025, xref='paper', yref='paper', line=dict(color='rgb(150,150,150)', width = 3))\n",
    "\n",
    "other_pos_stemlen_figS6a.update_yaxes(range = [0, 7.5],zeroline = False)\n",
    "\n",
    "other_pos_stemlen_figS6a.update_yaxes(title = dict(text = 'Spacer 1-3', font = dict(size = 14)), title_standoff = 0, col = 1, row = 1)\n",
    "other_pos_stemlen_figS6a.update_yaxes(title = dict(text = 'Spacer 4-10', font = dict(size = 14)), title_standoff = 0, col = 1, row = 2)\n",
    "other_pos_stemlen_figS6a.update_yaxes(title = dict(text = 'Spacer >10', font = dict(size = 14)), title_standoff = 0, col = 1, row = 3)\n",
    "other_pos_stemlen_figS6a.update_yaxes(title = dict(text = 'Stem >9 nt', font = dict(size = 14)), title_standoff = 0, col = 1, row = 4)\n",
    "\n",
    "other_pos_stemlen_figS6a.update_xaxes(title = dict(text = 'Stem length', font = dict(size = 14)), title_standoff = 0, col = 2, row = 3)\n",
    "other_pos_stemlen_figS6a.update_xaxes(title = dict(text = 'Spacer length', font = dict(size = 14)), title_standoff = 0, col = 2, row = 4)\n",
    "other_pos_stemlen_figS6a.update_xaxes(zeroline = False, row = 4)\n",
    "\n",
    "other_pos_stemlen_figS6a.update_xaxes(showticklabels=False, row = 1); other_pos_stemlen_figS6a.update_xaxes(showticklabels=False, row = 2)\n",
    "other_pos_stemlen_figS6a.update_xaxes(range = [9, 21], row = 1); other_pos_stemlen_figS6a.update_xaxes(range = [9, 21], row = 2); other_pos_stemlen_figS6a.update_xaxes(range = [9, 21], row = 3); other_pos_stemlen_figS6a.update_xaxes(range = [-1.5, 12], row = 4)\n",
    "\n",
    "other_pos_stemlen_figS6a.update_yaxes(domain = [0.01, 0.22], row = 4)\n",
    "other_pos_stemlen_figS6a.update_yaxes(domain = [0.32, 0.52], row = 3)\n",
    "other_pos_stemlen_figS6a.update_yaxes(domain = [0.55, 0.75], row = 2)\n",
    "other_pos_stemlen_figS6a.update_yaxes(domain = [0.78, 0.99], row = 1)\n",
    "\n",
    "other_pos_stemlen_figS6a.update_layout(title = dict(text = 'Perfecting mutations                        Non-perfecting mutations                  Other mutations', x = 0.125, font = dict(size = 18)),\n",
    "    height = 500, width = 1016, margin = dict(l = 55, r = 25, b = 25, t = 55), legend=dict(y = -0.03, x = 0.45, orientation='h'))\n",
    "\n",
    "other_pos_stemlen_figS6a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713c17c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_pos_stemlen_figS6a.write_image('./plots/revision_ACcor_MR_SNVfreq_figS6a.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1217926f",
   "metadata": {},
   "source": [
    "#### G4 motifs (Fig. 5A) <a name=\"mutation_internal_count_plot_5A\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a13018c",
   "metadata": {},
   "outputs": [],
   "source": [
    "G4_QCeffect = G4_norm_summary_tri[-2.774] - G4_norm_summary_tri[-np.inf]\n",
    "\n",
    "G4_newlistofpositions = [\"run 5'\", \"run_positions_middle\", \"run 3'\", \"loop 5'\", \"loop_positions_middle\",  \"loop 3'\", \"loop 1nt\"]\n",
    "G4_newlistofnames = [\"5'\", 'mid',\"3'\", \"5'\", 'mid', \"3'\", '1nt']\n",
    "\n",
    "G4_QCeffect_up = dict()\n",
    "G4_QCeffect_down = dict()\n",
    "\n",
    "count = -0.35\n",
    "for position in G4_newlistofpositions:\n",
    "    G4_QCeffect_up[position] = pd.DataFrame(G4_QCeffect[position].loc[G4_QCeffect[position] >0].copy())\n",
    "    G4_QCeffect_down[position] = pd.DataFrame(G4_QCeffect[position].loc[G4_QCeffect[position] <0].copy())\n",
    "\n",
    "    G4_QCeffect_up[position][-np.inf] = G4_norm_summary_tri[-np.inf][position].loc[G4_QCeffect_up[position].index].copy()\n",
    "    G4_QCeffect_down[position][-np.inf] = G4_norm_summary_tri[-np.inf][position].loc[G4_QCeffect_down[position].index].copy()\n",
    "    G4_QCeffect_up[position][-2.774] = G4_norm_summary_tri[-2.774][position].loc[G4_QCeffect_up[position].index].copy()\n",
    "    G4_QCeffect_down[position][-2.774] = G4_norm_summary_tri[-2.774][position].loc[G4_QCeffect_down[position].index].copy()\n",
    "\n",
    "    G4_QCeffect_up[position]['random'] = count + (0.75* np.random.random(len(G4_QCeffect_up[position])))\n",
    "    G4_QCeffect_down[position]['random'] = count + (0.75* np.random.random(len(G4_QCeffect_down[position])))\n",
    "\n",
    "    G4_QCeffect_up[position]['name'] = [str(name).replace('_', '>') if G4_QCeffect_up[position][position][name] >1.85 else '' for name in G4_QCeffect_up[position].index]\n",
    "    G4_QCeffect_down[position]['name'] = [str(name).replace('_', '>') if G4_QCeffect_down[position][position][name] <-1.85 else '' for name in G4_QCeffect_down[position].index]\n",
    "\n",
    "    count +=1\n",
    "\n",
    "# Set y-axis location for particular trinucleotides\n",
    "G4_QCeffect_down[\"loop 5'\"].loc['GTC_G', 'random'] = 2.65\n",
    "G4_QCeffect_down[\"loop 5'\"].loc['GTA_G', 'random'] = 3\n",
    "G4_QCeffect_down[\"loop 5'\"].loc['GTT_G', 'random'] = 3.35\n",
    "\n",
    "G4_QCeffect_down[\"loop 3'\"].loc['TTG_G', 'random'] = 4.65\n",
    "G4_QCeffect_down[\"loop 3'\"].loc['TAG_T', 'random'] = 5\n",
    "G4_QCeffect_down[\"loop 3'\"].loc['CAG_T', 'random'] = 5.35\n",
    "\n",
    "G4_QCeffect_down['loop 1nt'].loc['GTG_G', 'random'] = 5.8\n",
    "G4_QCeffect_down['loop 1nt'].loc['GAG_T', 'random'] = 6.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cefeaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "G4_arrow_fig = go.Figure()\n",
    "\n",
    "for QC_filter in vqslod_list:\n",
    "    G4_arrow_fig.add_trace(go.Bar(x = list(range(7)), y = G4_norm_summary[0][QC_filter] -1, base = 1, marker = dict(color = QC_colors_internal[0][QC_filter]), showlegend = True, name = QC_colors_internal['name'][QC_filter], error_y=dict(type='data', symmetric=False, array = pd.Series(G4_norm_summary[2][QC_filter] - G4_norm_summary[0][QC_filter]), arrayminus = pd.Series(G4_norm_summary[0][QC_filter] - G4_norm_summary[1][QC_filter]), color=QC_colors_internal[1][QC_filter], thickness=1.5, width=3)))\n",
    "\n",
    "list_of_annotations = []\n",
    "for pos in G4_QCeffect_down:\n",
    "    current_group = G4_QCeffect_down[pos]\n",
    "    if len(current_group) > 0:\n",
    "        current_lines = [dict(x=current_group['random'][mut], ax=current_group['random'][mut], y=current_group[-2.774][mut], ay=current_group[-np.inf][mut], xref='x1', yref='y1', axref='x1', ayref='y1', text = current_group['name'][mut], showarrow=True, arrowhead=2, arrowsize=1, arrowwidth=1.5, arrowcolor='rgba(255,0,0,0.5)', font = dict(color = 'rgb(0,0,0)')) for mut in current_group.index]\n",
    "        list_of_annotations = list_of_annotations + current_lines\n",
    "    current_group = G4_QCeffect_up[pos]\n",
    "    if len(current_group) > 0:\n",
    "        current_lines = [dict(x=current_group['random'][mut], ax=current_group['random'][mut], y=current_group[-2.774][mut], ay=current_group[-np.inf][mut], xref='x1', yref='y1', axref='x1', ayref='y1', text = current_group['name'][mut], showarrow=True, arrowhead=2, arrowsize=1, arrowwidth=1.5, arrowcolor='rgba(0,0,0,0.5)', font = dict(color = 'rgb(0,0,0)')) for mut in current_group.index]\n",
    "        list_of_annotations = list_of_annotations + current_lines\n",
    "\n",
    "list_of_annotations = list_of_annotations + [dict(text = 'G4 stem                                     spacer', font = dict(size = 18), x = 0.16, y = 0, showarrow = False, xref = 'paper', yref = 'paper')]\n",
    "G4_arrow_fig.add_shape(type='line', x0=0.4275, x1=0.4275, y0=-0.1, y1=1, xref='paper', yref='paper', line=dict(color='rgb(150,150,150)', width = 3))\n",
    "\n",
    "G4_arrow_fig.update_xaxes(tickmode = 'array', tickvals = list(range(7)), ticktext = G4_newlistofnames)\n",
    "G4_arrow_fig.update_yaxes(range = [0.05, 8.05], dtick = 1, title = dict(text = 'Relative mutation frequency', standoff = 0, font = dict(size = 18)))\n",
    "G4_arrow_fig.update_layout(annotations= list_of_annotations)\n",
    "\n",
    "G4_arrow_fig.update_layout(height = 520, width = 700, margin = dict(l = 40, r = 10, b = 10, t = 10), legend=dict(y = -0.04, x = 0.2, orientation='h'))\n",
    "G4_arrow_fig.update_layout(barmode = 'overlay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed760c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "G4_arrow_fig.write_image('./plots/revision_ACcor_internal_mutation_fig_5a.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784e0e0a",
   "metadata": {},
   "source": [
    "## Indels at internal positions <a name=\"mutation_internal_indels\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)\n",
    "\n",
    "#### Functions to count indels at internal positions  <a name=\"mutation_internal_indels_functions\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9093aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_internal_indel_pos_chrom(chrom, pos_current, input_mut_dict, useful_cols, qc_cutoff_list, pos_col):\n",
    "    # for each qc_cutoff in the mutation dataset, find mutations overlapping the search coordinates\n",
    "\n",
    "    current_mut_chrom = input_mut_dict[chrom].copy()\n",
    "    current_mut_chrom.index = current_mut_chrom.index - 1     # change coordinates from base1 to base0\n",
    "\n",
    "    pos_current = pd.DataFrame(pos_current.groupby([pos_col] + useful_cols).count()['Type']).copy()\n",
    "    pos_current[['del', 'ins']] = 1\n",
    "    \n",
    "    current_mut_sum = dict()\n",
    "    for qc_cutoff in qc_cutoff_list:\n",
    "        current_mut_qc = pos_current[['del', 'ins']].mul(current_mut_chrom[qc_cutoff].reindex(pos_current.index.get_level_values(pos_col)).fillna(0).astype(int)).copy()\n",
    "        current_mut_qc['Tri'] = [tri_function(chrom, pos, base = 0) for pos in current_mut_qc.index.get_level_values(pos_col)]\n",
    "        current_mut_qc['tri_count'] = 1   \n",
    "        current_mut_sum[qc_cutoff] = current_mut_qc.loc[current_mut_qc['Tri'].isin(all_triplets)].groupby(useful_cols + ['Tri']).sum().copy()\n",
    "    return current_mut_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f78f353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_internal_indel_pos(input_pos_df, input_mut_dict = variants_indel_slim_AC, qc_cutoff_list = vqslod_list_indel, pos_col = 'pos', chrom_col = 'chrom', strand_col = 'Strand', strand_names = ('+', '-'), useful_cols = ['category'], combine_LR = False):\n",
    "   \n",
    "    current_mut_sum_chrom = dict()\n",
    "    for chrom in range(chr_range,23):\n",
    "        current_mut_sum_chrom[chrom] = count_internal_indel_pos_chrom(chrom, input_pos_df.loc[input_pos_df[chrom_col] == chrom].copy(), input_mut_dict, pos_col = pos_col, useful_cols = useful_cols, qc_cutoff_list = qc_cutoff_list)\n",
    "        print('finished chr' + str(chrom) + '    ', end=\"\\r\", flush=True)\n",
    "\n",
    "    current_mut_sum = dict()\n",
    "    for qc_cutoff in vqslod_list_indel:\n",
    "        current_mut_sum[qc_cutoff] = pd.concat([current_mut_sum_chrom[chrom][qc_cutoff] for chrom in range(chr_range,23)])\n",
    "    \n",
    "    # apply reverse complement to - strand triplets, mutation counts and positions\n",
    "    if strand_col in useful_cols:\n",
    "        useful_cols.remove(strand_col)\n",
    "        internal_position_categories = pd.Series(['MM_pos', 'MM_pos_genome', \"3'_motif_pos\", \"5'_motif_pos\", \"3'_flank_pos\", \"5'_flank_pos\", 'motif_pos_genome_middle', 'MM_pos_R', 'MM_pos_L', 'spacer_pos', \"spacer_3'_pos\", \"spacer_middle_pos\", \"spacer_5'_pos\", 'run_positions', 'loop_positions', 'run_positions_middle', 'loop_positions_middle', 'run_positions_edge', 'loop_positions_edge'], index = ['MM_pos', 'MM_pos_genome', \"5'_motif_pos\", \"3'_motif_pos\", \"5'_flank_pos\", \"3'_flank_pos\", 'motif_pos_genome_middle', 'MM_pos_L', 'MM_pos_R', 'spacer_pos', \"spacer_5'_pos\", \"spacer_middle_pos\", \"spacer_3'_pos\", 'run_positions', 'loop_positions', 'run_positions_middle', 'loop_positions_middle', 'run_positions_edge', 'loop_positions_edge'])\n",
    "\n",
    "        current_mut_sum_strand_F = dict()\n",
    "        current_mut_sum_strand_R = dict()\n",
    "        current_mut_sum_bothstrands = dict()\n",
    "        for qc_cutoff in current_mut_sum:\n",
    "            current_mut_sum_strand_F[qc_cutoff] = current_mut_sum[qc_cutoff].reset_index().loc[current_mut_sum[qc_cutoff].reset_index()['Strand'] == '+']\n",
    "            current_mut_sum_strand_R[qc_cutoff] = current_mut_sum[qc_cutoff].reset_index().loc[current_mut_sum[qc_cutoff].reset_index()['Strand'] == '-']\n",
    "            current_mut_sum_strand_R[qc_cutoff]['category'] = internal_position_categories.reindex(current_mut_sum_strand_R[qc_cutoff]['category']).values\n",
    "            if 'repeat' in useful_cols:\n",
    "                current_mut_sum_strand_R[qc_cutoff]['repeat'] = current_mut_sum_strand_R[qc_cutoff]['repeat'].apply(reverse_complement)\n",
    "            current_mut_sum_strand_R[qc_cutoff]['Tri'] = current_mut_sum_strand_R[qc_cutoff]['Tri'].apply(reverse_complement)\n",
    "            current_mut_sum_bothstrands[qc_cutoff] = pd.concat([current_mut_sum_strand_F[qc_cutoff], current_mut_sum_strand_R[qc_cutoff]]).groupby(useful_cols + ['Tri']).sum()#.fillna(0)\n",
    "    else:\n",
    "        current_mut_sum_bothstrands = dict()\n",
    "        for qc_cutoff in current_mut_sum:\n",
    "            current_mut_sum_bothstrands[qc_cutoff] = current_mut_sum[qc_cutoff].reset_index().groupby(useful_cols + ['Tri']).sum()#.fillna(0)\n",
    "    \n",
    "    if combine_LR == True:\n",
    "        for qc_cutoff in current_mut_sum:\n",
    "            current_mut_sum_bothstrands[qc_cutoff] = current_mut_sum_bothstrands[qc_cutoff].reset_index()\n",
    "            current_mut_sum_bothstrands[qc_cutoff]['category'] = current_mut_sum_bothstrands[qc_cutoff]['category'].str.replace(\"3'_\", '').str.replace(\"5'_\", '').str.replace('_L', '').str.replace('_R', '')\n",
    "            current_mut_sum_bothstrands[qc_cutoff] = current_mut_sum_bothstrands[qc_cutoff].groupby(useful_cols + ['Tri']).sum()\n",
    "\n",
    "    # reformat output to NNN_N rows x pos columns, and split mut counts and trinucleotide counts    \n",
    "\n",
    "    current_tri_sum = current_mut_sum_bothstrands[qc_cutoff].reset_index().groupby(useful_cols + ['Tri']).sum()['tri_count'].unstack().transpose().fillna(0).astype(int)\n",
    "\n",
    "    current_mut_sum_reformat = dict()\n",
    "    for qc_cutoff in current_mut_sum:\n",
    "        current_mut_sum_reformat[qc_cutoff] = current_mut_sum_bothstrands[qc_cutoff].reset_index().groupby(useful_cols + ['Tri']).sum()[['del', 'ins']].unstack().transpose().fillna(0).astype(int)\n",
    "        current_mut_sum_reformat[qc_cutoff].index = current_mut_sum_reformat[qc_cutoff].index.get_level_values('Tri') + '_' + current_mut_sum_reformat[qc_cutoff].index.get_level_values(0)\n",
    "        current_mut_sum_reformat[qc_cutoff] = current_mut_sum_reformat[qc_cutoff].reindex(triplet_mutations_und_indel)\n",
    "        current_mut_sum_reformat[qc_cutoff].index.name = 'Mut' \n",
    "    \n",
    "    return current_mut_sum_reformat.copy(), current_tri_sum.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3336a6",
   "metadata": {},
   "source": [
    "#### Counting and analysis of indels  - STRs, DRs, MRs, IRs, ZDNA <a name=\"mutation_internal_indels_analysis\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2060ffea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting\n",
    "count_internal_indel = dict()\n",
    "\n",
    "count_internal_indel['STR'] = count_internal_indel_pos(pos_expand_all['STR'].copy(), useful_cols = ['Strand', 'repeat', 'category', 'status', 'length'], combine_LR = True)\n",
    "\n",
    "count_internal_indel['IR'] = count_internal_indel_pos(pos_expand_all['IR'], variants_indel_slim_AC, useful_cols = ['category', '#MM', 'GC%_stem', 'stem_len', 'spacer'], combine_LR = True)\n",
    "count_internal_indel['MR'] = count_internal_indel_pos(pos_expand_all['MR'], variants_indel_slim_AC, useful_cols = ['category', '#MM', 'GC%_stem', 'purine', 'stem_len', 'spacer'], combine_LR = True)\n",
    "count_internal_indel['DR'] = count_internal_indel_pos(pos_expand_all['DR'], variants_indel_slim_AC, useful_cols = ['category', '#MM', 'GC%_stem', 'stem_len', 'spacer'], combine_LR = True)\n",
    "\n",
    "count_internal_indel['ZDNA'] = count_internal_indel_pos(pos_expand_all['ZDNA'], variants_indel_slim_AC, useful_cols = ['category', 'length'], combine_LR = True)\n",
    "count_internal_indel['ZDNA_GY'] = count_internal_indel_pos(pos_expand_all['ZDNA_GY'], variants_indel_slim_AC, useful_cols = ['Strand', 'category', 'length'], combine_LR = True)\n",
    "\n",
    "count_internal_indel['G4'] = count_internal_indel_pos(pos_expand_all['G4'], variants_indel_slim_AC, useful_cols = ['Strand', 'status', 'category', 'length'], combine_LR = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eb6108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "norm_internal_indel_ins = dict(); norm_internal_indel_del = dict()\n",
    "\n",
    "norm_internal_indel_ins['STR'] = mut_norm_conf(count_internal_resum(count_internal_indel['STR'], useful_cols= ['repeat', 'category', 'status', 'length'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "norm_internal_indel_del['STR'] = mut_norm_conf(count_internal_resum(count_internal_indel['STR'], useful_cols= ['repeat', 'category', 'status', 'length'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3d329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_internal_indel_ins['DR_stemlen'] = mut_norm_conf(count_internal_resum(count_internal_indel['DR'], useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, False]), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "norm_internal_indel_del['DR_stemlen'] = mut_norm_conf(count_internal_resum(count_internal_indel['DR'], useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, False]), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)\n",
    "\n",
    "# Loop length restrictions\n",
    "norm_internal_indel_ins['DR_stemlen_loop10'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['DR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(11)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "norm_internal_indel_del['DR_stemlen_loop10'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['DR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(11)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)\n",
    "\n",
    "# Long vs. short insertions\n",
    "count_internal_indel['DR_longins'] = count_internal_indel_pos(pos_expand_all['DR'], variants_ins_slim_AC_long, useful_cols = ['category', '#MM', 'GC%_stem', 'stem_len', 'spacer'], combine_LR = True)\n",
    "count_internal_indel['DR_shortins'] = count_internal_indel_pos(pos_expand_all['DR'], variants_ins_slim_AC_short, useful_cols = ['category', '#MM', 'GC%_stem', 'stem_len', 'spacer'], combine_LR = True)\n",
    "\n",
    "norm_internal_indel_ins['DR_longins_stemlen_loop10'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['DR_longins'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(11)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_ins_count_AC_freq_long, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins_long'], do_binconf = True)\n",
    "norm_internal_indel_ins['DR_shortins_stemlen_loop10'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['DR_shortins'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(11)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_ins_count_AC_freq_short, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins_short'], do_binconf = True)\n",
    "\n",
    "# combine loop edge and middle for main figure\n",
    "norm_internal_indel_ins['DR_longins_stemlen_loop10_loopcombined'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['DR_longins'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[['spacer_pos', 'spacer_pos_middle'], 1, list(range(11)), False]), useful_cols= ['#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_ins_count_AC_freq_long, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins_long'], do_binconf = True)\n",
    "norm_internal_indel_del['DR_stemlen_loop10_loopcombined'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['DR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[['spacer_pos', 'spacer_pos_middle'], 1, list(range(11)), False]), useful_cols= ['#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)\n",
    "\n",
    "# Loop length restrictions\n",
    "\n",
    "norm_internal_indel_ins['DR_stemlen_loopmorethan10'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['DR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(11,100)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "norm_internal_indel_del['DR_stemlen_loopmorethan10'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['DR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(11,100)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)\n",
    "\n",
    "norm_internal_indel_ins['DR_stemlen_loop1050'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['DR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(11,50)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "norm_internal_indel_del['DR_stemlen_loop1050'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['DR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(11,50)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)\n",
    "\n",
    "norm_internal_indel_ins['DR_stemlen_loop50100'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['DR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(51,100)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "norm_internal_indel_del['DR_stemlen_loop50100'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['DR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(51,100)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)\n",
    "\n",
    "norm_internal_indel_ins['DR_stemlen_loop1020'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['DR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(11,20)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "norm_internal_indel_del['DR_stemlen_loop1020'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['DR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(11,20)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)\n",
    "\n",
    "norm_internal_indel_ins['DR_stemlen_loop20100'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['DR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(21,100)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "norm_internal_indel_del['DR_stemlen_loop20100'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['DR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(21,100)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)\n",
    "\n",
    "norm_internal_indel_ins['DR_stemlen_loop04'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['DR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(5)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "norm_internal_indel_del['DR_stemlen_loop04'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['DR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(5)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)\n",
    "\n",
    "norm_internal_indel_ins['DR_stemlen_loop510'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['DR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(5,10)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "norm_internal_indel_del['DR_stemlen_loop510'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['DR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(5,10)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9294dd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_internal_indel_ins['IR_stemlen'] = mut_norm_conf(count_internal_resum(count_internal_indel['IR'], useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, False]), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "norm_internal_indel_del['IR_stemlen'] = mut_norm_conf(count_internal_resum(count_internal_indel['IR'], useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, False]), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)\n",
    "\n",
    "norm_internal_indel_ins['IR_stemlen_loop10'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['IR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(11)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "norm_internal_indel_del['IR_stemlen_loop10'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['IR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(11)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)\n",
    "\n",
    "norm_internal_indel_ins['IR_stemlen_loop04'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['IR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(5)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "norm_internal_indel_del['IR_stemlen_loop04'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['IR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(5)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)\n",
    "\n",
    "norm_internal_indel_ins['IR_stemlen_loop510'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['IR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(5,10)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "norm_internal_indel_del['IR_stemlen_loop510'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['IR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(5,10)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)\n",
    "\n",
    "norm_internal_indel_ins['IR_stemlen_loop1020'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['IR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(11,20)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "norm_internal_indel_del['IR_stemlen_loop1020'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['IR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(11,20)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)\n",
    "\n",
    "norm_internal_indel_ins['IR_stemlen_loop20100'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['IR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(21,100)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "norm_internal_indel_del['IR_stemlen_loop20100'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['IR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(21,100)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b42107",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_internal_indel_ins['MR_stemlen'] = mut_norm_conf(count_internal_resum(count_internal_indel['MR'], useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, False]), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "norm_internal_indel_del['MR_stemlen'] = mut_norm_conf(count_internal_resum(count_internal_indel['MR'], useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, False]), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)\n",
    "\n",
    "norm_internal_indel_ins['MR_stemlen_loop10'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['MR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(11)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "norm_internal_indel_del['MR_stemlen_loop10'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['MR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(11)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)\n",
    "\n",
    "norm_internal_indel_ins['MR_stemlen_loop04'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['MR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(5)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "norm_internal_indel_del['MR_stemlen_loop04'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['MR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(5)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)\n",
    "\n",
    "norm_internal_indel_ins['MR_stemlen_loop510'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['MR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(5,10)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "norm_internal_indel_del['MR_stemlen_loop510'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['MR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(5,10)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)\n",
    "\n",
    "norm_internal_indel_ins['MR_stemlen_loop1020'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['MR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(11,20)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "norm_internal_indel_del['MR_stemlen_loop1020'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['MR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(11,20)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)\n",
    "\n",
    "norm_internal_indel_ins['MR_stemlen_loop20100'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['MR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(21,100)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "norm_internal_indel_del['MR_stemlen_loop20100'] = mut_norm_conf(count_internal_resum(count_internal_resum(count_internal_indel['MR'], useful_cols= ['category', '#MM', 'spacer', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel, selections=[False, 1, list(range(21,100)), False]), useful_cols= ['category', '#MM', 'stem_len'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f077145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_internal_indel_ins['ZDNA'] = mut_norm_conf(count_internal_resum(count_internal_indel['ZDNA'], useful_cols= ['category', 'length'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "norm_internal_indel_del['ZDNA'] = mut_norm_conf(count_internal_resum(count_internal_indel['ZDNA'], useful_cols= ['category', 'length'], gc_correct=False, tri_subset = triplet_mutations_und_indel), snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc272785",
   "metadata": {},
   "source": [
    "#### Counting and analysis of indels  - G4s <a name=\"mutation_internal_indels_analysis_G4\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9956b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_internal_indel['G4_K+'] = count_internal_resum(count_internal_indel['G4'], useful_cols= ['status', 'category'], selections = [['K+', 'both'], False], gc_correct=False, tri_subset = triplet_mutations_und_indel)\n",
    "\n",
    "norm_internal_indel_ins['G4'] = mut_norm_conf(count_internal_indel['G4_K+'], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_ins, normtorandom = True, random_normaverage = normtorandom_indel['ins'], do_binconf = True)\n",
    "norm_internal_indel_del['G4'] = mut_norm_conf(count_internal_indel['G4_K+'], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, tri_subset = triplet_mutations_und_del, normtorandom = True, random_normaverage = normtorandom_indel['del'], do_binconf = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10af6861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization by position\n",
    "norm_internal_indel_G4_positions_ins = dict()\n",
    "norm_internal_indel_G4_positions_ins[\"run 5'\"] = mut_norm_conf(count_internal_resum(count_internal_indel['G4_K+'], ['category'], selections = ['run_positions_edge'], gc_correct=False, tri_subset = triplet_mutations_und_indel), tri_subset = [mut for mut in triplet_mutations_und_ins if (mut[0] != 'G')], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, normtorandom = True, random_normaverage=normtorandom_indel['ins'], gc_correct=False)\n",
    "norm_internal_indel_G4_positions_ins[\"run 3'\"] = mut_norm_conf(count_internal_resum(count_internal_indel['G4_K+'], ['category'], selections = ['run_positions_edge'], gc_correct=False, tri_subset = triplet_mutations_und_indel), tri_subset = [mut for mut in triplet_mutations_und_ins if (mut[2] != 'G')],snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, normtorandom = True, random_normaverage=normtorandom_indel['ins'], gc_correct=False)\n",
    "norm_internal_indel_G4_positions_ins[\"loop 5'\"] = mut_norm_conf(count_internal_resum(count_internal_indel['G4_K+'], ['category'], selections = ['loop_positions_edge'], gc_correct=False, tri_subset = triplet_mutations_und_indel), tri_subset = [mut for mut in triplet_mutations_und_ins if (mut[2] != 'G')], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, normtorandom = True, random_normaverage=normtorandom_indel['ins'], gc_correct=False)\n",
    "norm_internal_indel_G4_positions_ins[\"loop 3'\"] = mut_norm_conf(count_internal_resum(count_internal_indel['G4_K+'], ['category'], selections = ['loop_positions_edge'], gc_correct=False, tri_subset = triplet_mutations_und_indel), tri_subset = [mut for mut in triplet_mutations_und_ins if (mut[0] != 'G')], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, normtorandom = True, random_normaverage=normtorandom_indel['ins'], gc_correct=False)\n",
    "norm_internal_indel_G4_positions_ins[\"loop 1nt\"] = mut_norm_conf(count_internal_resum(count_internal_indel['G4_K+'], ['category'], selections = ['loop_positions_edge'], gc_correct=False, tri_subset = triplet_mutations_und_indel), tri_subset = [mut for mut in triplet_mutations_und_ins if (mut[0] == 'G') & (mut[2] == 'G')], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, normtorandom = True, random_normaverage=normtorandom_indel['ins'], gc_correct=False)\n",
    "norm_internal_indel_G4_positions_ins['run_positions_middle'] =  mut_norm_conf(count_internal_resum(count_internal_indel['G4_K+'], ['category'], selections = ['run_positions_middle'], gc_correct=False, tri_subset = triplet_mutations_und_indel), tri_subset = triplet_mutations_und_ins, snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, normtorandom = True, random_normaverage=normtorandom_indel['ins'], gc_correct=False)\n",
    "norm_internal_indel_G4_positions_ins['loop_positions_middle'] =  mut_norm_conf(count_internal_resum(count_internal_indel['G4_K+'], ['category'], selections = ['loop_positions_middle'], gc_correct=False, tri_subset = triplet_mutations_und_indel), tri_subset = triplet_mutations_und_ins, snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, normtorandom = True, random_normaverage=normtorandom_indel['ins'], gc_correct=False)\n",
    "\n",
    "norm_internal_indel_G4_positions_del = dict()\n",
    "norm_internal_indel_G4_positions_del[\"run 5'\"] = mut_norm_conf(count_internal_resum(count_internal_indel['G4_K+'], ['category'], selections = ['run_positions_edge'], gc_correct=False, tri_subset = triplet_mutations_und_indel), tri_subset = [mut for mut in triplet_mutations_und_del if (mut[0] != 'G')], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, normtorandom = True, random_normaverage=normtorandom_indel['del'], gc_correct=False)\n",
    "norm_internal_indel_G4_positions_del[\"run 3'\"] = mut_norm_conf(count_internal_resum(count_internal_indel['G4_K+'], ['category'], selections = ['run_positions_edge'], gc_correct=False, tri_subset = triplet_mutations_und_indel), tri_subset = [mut for mut in triplet_mutations_und_del if (mut[2] != 'G')],snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, normtorandom = True, random_normaverage=normtorandom_indel['del'], gc_correct=False)\n",
    "norm_internal_indel_G4_positions_del[\"loop 5'\"] = mut_norm_conf(count_internal_resum(count_internal_indel['G4_K+'], ['category'], selections = ['loop_positions_edge'], gc_correct=False, tri_subset = triplet_mutations_und_indel), tri_subset = [mut for mut in triplet_mutations_und_del if (mut[2] != 'G')], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, normtorandom = True, random_normaverage=normtorandom_indel['del'], gc_correct=False)\n",
    "norm_internal_indel_G4_positions_del[\"loop 3'\"] = mut_norm_conf(count_internal_resum(count_internal_indel['G4_K+'], ['category'], selections = ['loop_positions_edge'], gc_correct=False, tri_subset = triplet_mutations_und_indel), tri_subset = [mut for mut in triplet_mutations_und_del if (mut[0] != 'G')], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, normtorandom = True, random_normaverage=normtorandom_indel['del'], gc_correct=False)\n",
    "norm_internal_indel_G4_positions_del[\"loop 1nt\"] = mut_norm_conf(count_internal_resum(count_internal_indel['G4_K+'], ['category'], selections = ['loop_positions_edge'], gc_correct=False, tri_subset = triplet_mutations_und_indel), tri_subset = [mut for mut in triplet_mutations_und_del if (mut[0] == 'G') & (mut[2] == 'G')], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, normtorandom = True, random_normaverage=normtorandom_indel['del'], gc_correct=False)\n",
    "norm_internal_indel_G4_positions_del['run_positions_middle'] =  mut_norm_conf(count_internal_resum(count_internal_indel['G4_K+'], ['category'], selections = ['run_positions_middle'], gc_correct=False, tri_subset = triplet_mutations_und_indel), tri_subset = triplet_mutations_und_del, snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, normtorandom = True, random_normaverage=normtorandom_indel['del'], gc_correct=False)\n",
    "norm_internal_indel_G4_positions_del['loop_positions_middle'] =  mut_norm_conf(count_internal_resum(count_internal_indel['G4_K+'], ['category'], selections = ['loop_positions_middle'], gc_correct=False, tri_subset = triplet_mutations_und_indel), tri_subset = triplet_mutations_und_del, snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, normtorandom = True, random_normaverage=normtorandom_indel['del'], gc_correct=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef0f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganize data structure\n",
    "G4_positionorder = [\"run 5'\", \"run_positions_middle\", \"run 3'\", \"loop 5'\", \"loop_positions_middle\",  \"loop 3'\", \"loop 1nt\"]\n",
    "G4_norm_summary_ins = dict()\n",
    "G4_norm_summary_ins[0] = pd.DataFrame(); G4_norm_summary_ins[1] = pd.DataFrame(); G4_norm_summary_ins[2] = pd.DataFrame()\n",
    "for QC_cutoff in vqslod_list_indel:\n",
    "    G4_norm_summary_ins[0][QC_cutoff] = pd.Series(list(pd.concat([norm_internal_indel_G4_positions_ins[category][0][QC_cutoff] for category in norm_internal_indel_G4_positions_ins])), index = list(norm_internal_indel_G4_positions_ins)).reindex(G4_positionorder)\n",
    "    G4_norm_summary_ins[1][QC_cutoff] = pd.Series(list(pd.concat([norm_internal_indel_G4_positions_ins[category][1][QC_cutoff] for category in norm_internal_indel_G4_positions_ins])), index = list(norm_internal_indel_G4_positions_ins)).reindex(G4_positionorder)\n",
    "    G4_norm_summary_ins[2][QC_cutoff] = pd.Series(list(pd.concat([norm_internal_indel_G4_positions_ins[category][2][QC_cutoff] for category in norm_internal_indel_G4_positions_ins])), index = list(norm_internal_indel_G4_positions_ins)).reindex(G4_positionorder)\n",
    "\n",
    "G4_positionorder = [\"run 5'\", \"run_positions_middle\", \"run 3'\", \"loop 5'\", \"loop_positions_middle\",  \"loop 3'\", \"loop 1nt\"]\n",
    "G4_norm_summary_del = dict()\n",
    "G4_norm_summary_del[0] = pd.DataFrame(); G4_norm_summary_del[1] = pd.DataFrame(); G4_norm_summary_del[2] = pd.DataFrame()\n",
    "for QC_cutoff in vqslod_list_indel:\n",
    "    G4_norm_summary_del[0][QC_cutoff] = pd.Series(list(pd.concat([norm_internal_indel_G4_positions_del[category][0][QC_cutoff] for category in norm_internal_indel_G4_positions_del])), index = list(norm_internal_indel_G4_positions_del)).reindex(G4_positionorder)\n",
    "    G4_norm_summary_del[1][QC_cutoff] = pd.Series(list(pd.concat([norm_internal_indel_G4_positions_del[category][1][QC_cutoff] for category in norm_internal_indel_G4_positions_del])), index = list(norm_internal_indel_G4_positions_del)).reindex(G4_positionorder)\n",
    "    G4_norm_summary_del[2][QC_cutoff] = pd.Series(list(pd.concat([norm_internal_indel_G4_positions_del[category][2][QC_cutoff] for category in norm_internal_indel_G4_positions_del])), index = list(norm_internal_indel_G4_positions_del)).reindex(G4_positionorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fba174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triplet-level data for G4 positions\n",
    "norm_internal_indel_G4_positions_tri_ins = dict()\n",
    "norm_internal_indel_G4_positions_tri_ins[\"run 5'\"] = mut_norm_conf(count_internal_resum(count_internal_indel['G4_K+'], ['category'], selections = ['run_positions_edge'], gc_correct=False, tri_subset = triplet_mutations_und_indel), tri_subset = [mut for mut in triplet_mutations_und_ins if (mut[0] != 'G')], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, normtorandom = True, random_normaverage=normtorandom_indel['ins'], gc_correct=False, output_div=True)\n",
    "norm_internal_indel_G4_positions_tri_ins[\"run 3'\"] = mut_norm_conf(count_internal_resum(count_internal_indel['G4_K+'], ['category'], selections = ['run_positions_edge'], gc_correct=False, tri_subset = triplet_mutations_und_indel), tri_subset = [mut for mut in triplet_mutations_und_ins if (mut[2] != 'G')],snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, normtorandom = True, random_normaverage=normtorandom_indel['ins'], gc_correct=False, output_div=True)\n",
    "norm_internal_indel_G4_positions_tri_ins[\"loop 5'\"] = mut_norm_conf(count_internal_resum(count_internal_indel['G4_K+'], ['category'], selections = ['loop_positions_edge'], gc_correct=False, tri_subset = triplet_mutations_und_indel), tri_subset = [mut for mut in triplet_mutations_und_ins if (mut[2] != 'G')], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, normtorandom = True, random_normaverage=normtorandom_indel['ins'], gc_correct=False, output_div=True)\n",
    "norm_internal_indel_G4_positions_tri_ins[\"loop 3'\"] = mut_norm_conf(count_internal_resum(count_internal_indel['G4_K+'], ['category'], selections = ['loop_positions_edge'], gc_correct=False, tri_subset = triplet_mutations_und_indel), tri_subset = [mut for mut in triplet_mutations_und_ins if (mut[0] != 'G')], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, normtorandom = True, random_normaverage=normtorandom_indel['ins'], gc_correct=False, output_div=True)\n",
    "norm_internal_indel_G4_positions_tri_ins[\"loop 1nt\"] = mut_norm_conf(count_internal_resum(count_internal_indel['G4_K+'], ['category'], selections = ['loop_positions_edge'], gc_correct=False, tri_subset = triplet_mutations_und_indel), tri_subset = [mut for mut in triplet_mutations_und_ins if (mut[0] == 'G') & (mut[2] == 'G')], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, normtorandom = True, random_normaverage=normtorandom_indel['ins'], gc_correct=False, output_div=True)\n",
    "norm_internal_indel_G4_positions_tri_ins['run_positions_middle'] =  mut_norm_conf(count_internal_resum(count_internal_indel['G4_K+'], ['category'], selections = ['run_positions_middle'], gc_correct=False, tri_subset = triplet_mutations_und_indel), tri_subset = triplet_mutations_und_ins, snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, normtorandom = True, random_normaverage=normtorandom_indel['ins'], gc_correct=False, output_div=True)\n",
    "norm_internal_indel_G4_positions_tri_ins['loop_positions_middle'] =  mut_norm_conf(count_internal_resum(count_internal_indel['G4_K+'], ['category'], selections = ['loop_positions_middle'], gc_correct=False, tri_subset = triplet_mutations_und_indel), tri_subset = triplet_mutations_und_ins, snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, normtorandom = True, random_normaverage=normtorandom_indel['ins'], gc_correct=False, output_div=True)\n",
    "\n",
    "norm_internal_indel_G4_positions_tri_del = dict()\n",
    "norm_internal_indel_G4_positions_tri_del[\"run 5'\"] = mut_norm_conf(count_internal_resum(count_internal_indel['G4_K+'], ['category'], selections = ['run_positions_edge'], gc_correct=False, tri_subset = triplet_mutations_und_indel), tri_subset = [mut for mut in triplet_mutations_und_del if (mut[0] != 'G')], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, normtorandom = True, random_normaverage=normtorandom_indel['del'], gc_correct=False, output_div=True)\n",
    "norm_internal_indel_G4_positions_tri_del[\"run 3'\"] = mut_norm_conf(count_internal_resum(count_internal_indel['G4_K+'], ['category'], selections = ['run_positions_edge'], gc_correct=False, tri_subset = triplet_mutations_und_indel), tri_subset = [mut for mut in triplet_mutations_und_del if (mut[2] != 'G')],snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, normtorandom = True, random_normaverage=normtorandom_indel['del'], gc_correct=False, output_div=True)\n",
    "norm_internal_indel_G4_positions_tri_del[\"loop 5'\"] = mut_norm_conf(count_internal_resum(count_internal_indel['G4_K+'], ['category'], selections = ['loop_positions_edge'], gc_correct=False, tri_subset = triplet_mutations_und_indel), tri_subset = [mut for mut in triplet_mutations_und_del if (mut[2] != 'G')], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, normtorandom = True, random_normaverage=normtorandom_indel['del'], gc_correct=False, output_div=True)\n",
    "norm_internal_indel_G4_positions_tri_del[\"loop 3'\"] = mut_norm_conf(count_internal_resum(count_internal_indel['G4_K+'], ['category'], selections = ['loop_positions_edge'], gc_correct=False, tri_subset = triplet_mutations_und_indel), tri_subset = [mut for mut in triplet_mutations_und_del if (mut[0] != 'G')], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, normtorandom = True, random_normaverage=normtorandom_indel['del'], gc_correct=False, output_div=True)\n",
    "norm_internal_indel_G4_positions_tri_del[\"loop 1nt\"] = mut_norm_conf(count_internal_resum(count_internal_indel['G4_K+'], ['category'], selections = ['loop_positions_edge'], gc_correct=False, tri_subset = triplet_mutations_und_indel), tri_subset = [mut for mut in triplet_mutations_und_del if (mut[0] == 'G') & (mut[2] == 'G')], snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, normtorandom = True, random_normaverage=normtorandom_indel['del'], gc_correct=False, output_div=True)\n",
    "norm_internal_indel_G4_positions_tri_del['run_positions_middle'] =  mut_norm_conf(count_internal_resum(count_internal_indel['G4_K+'], ['category'], selections = ['run_positions_middle'], gc_correct=False, tri_subset = triplet_mutations_und_indel), tri_subset = triplet_mutations_und_del, snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, normtorandom = True, random_normaverage=normtorandom_indel['del'], gc_correct=False, output_div=True)\n",
    "norm_internal_indel_G4_positions_tri_del['loop_positions_middle'] =  mut_norm_conf(count_internal_resum(count_internal_indel['G4_K+'], ['category'], selections = ['loop_positions_middle'], gc_correct=False, tri_subset = triplet_mutations_und_indel), tri_subset = triplet_mutations_und_del, snvindel = 'indel', min_count = 10, genome_AC_freq_current = variants_indel_count_AC_freq_all, normtorandom = True, random_normaverage=normtorandom_indel['del'], gc_correct=False, output_div=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af853f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganize data structure\n",
    "G4_norm_summary_ins_tri = dict()\n",
    "for QC_cutoff in vqslod_list_indel:\n",
    "    G4_norm_summary_ins_tri[QC_cutoff] = pd.concat([norm_internal_indel_G4_positions_tri_ins[category][0][QC_cutoff] for category in norm_internal_indel_G4_positions_tri_ins], axis=1) / normtorandom_indel['ins'][QC_cutoff]\n",
    "    G4_norm_summary_ins_tri[QC_cutoff].columns = list(norm_internal_indel_G4_positions_tri_ins)\n",
    "\n",
    "G4_norm_summary_del_tri = dict()\n",
    "for QC_cutoff in vqslod_list_indel:\n",
    "    G4_norm_summary_del_tri[QC_cutoff] = pd.concat([norm_internal_indel_G4_positions_tri_del[category][0][QC_cutoff] for category in norm_internal_indel_G4_positions_tri_del], axis=1) / normtorandom_indel['del'][QC_cutoff]\n",
    "    G4_norm_summary_del_tri[QC_cutoff].columns = list(norm_internal_indel_G4_positions_tri_del)\n",
    "\n",
    "G4_norm_summary_indel_tri = dict()\n",
    "for QC_cutoff in vqslod_list_indel:\n",
    "    G4_norm_summary_indel_tri[QC_cutoff] = pd.concat([G4_norm_summary_ins_tri[QC_cutoff], G4_norm_summary_del_tri[QC_cutoff]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575b8b1a",
   "metadata": {},
   "source": [
    "#### Save/load internal indel counts <a name=\"mutation_internal_indels_saveload\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3112842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save temporary output of the mutation counts\n",
    "with open('./analysis/temp/mut_internal_indel_counts_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(count_internal_indel, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Save temporary output of the normalized mutation counts\n",
    "with open('./analysis/temp/mut_internal_ins_norm_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(norm_internal_indel_ins, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('./analysis/temp/mut_internal_del_norm_chr'+str(chr_range)+'-22.pickle', 'wb') as handle:\n",
    "    pickle.dump(norm_internal_indel_del, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcd0dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load temporary output of the mutation counts\n",
    "with open('./analysis/temp/mut_internal_indel_counts_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    count_internal_indel = pickle.load(handle)\n",
    "\n",
    "# Load temporary output of the mutation counts\n",
    "with open('./analysis/temp/mut_internal_ins_norm_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    norm_internal_indel_ins = pickle.load(handle)\n",
    "with open('./analysis/temp/mut_internal_del_norm_chr'+str(chr_range)+'-22.pickle', 'rb') as handle:\n",
    "    norm_internal_indel_del = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51a7410",
   "metadata": {},
   "source": [
    "### Plots  <a name=\"mutation_internal_indels_plots\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561318e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign colors for plots\n",
    "QC_colors_internal_indel = make_colorscale(vqslod_list_indel, 0.5)\n",
    "QC_colors_internal_indel = pd.DataFrame(QC_colors_internal_indel).transpose()\n",
    "QC_colors_internal_indel['name'] = ['no QC', 'pass', 'VQSLOD >0', 'VQSLOD >1.4']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53dc6bf",
   "metadata": {},
   "source": [
    "#### Plot Fig 4a - indels within direct repeats  <a name=\"mutation_internal_indels_plots_fig4A\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdd74a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "inframe_mut_fig4a = make_subplots(rows=1, cols=1, shared_yaxes=True, shared_xaxes = True, vertical_spacing = 0.030, horizontal_spacing = 0.02, subplot_titles = ['Insertions >5 nt'])\n",
    "counter =1\n",
    "inframe_mut_fig4a.update_yaxes(title = dict(text = 'DR', font = dict(size = 16)), row = counter, col = 1)\n",
    "plot_internal_add('DR_longins_stemlen_loop10', [10,20], ['flank_pos', 1], counter, 1, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_fig4a, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "inframe_mut_fig4a.update_yaxes(zeroline = False, range = [-0.1,2.6], type = 'log', dtick = 1)\n",
    "inframe_mut_fig4a.update_xaxes(title = dict(text = 'motif length', font = dict(size = 14), standoff = 0), row = 1, col = 1)\n",
    "inframe_mut_fig4a.update_layout(width = 250, height = 200, margin = dict(l = 45, r = 25, b = 40, t = 30), legend=dict(y = -0.25, x = 0.175, orientation='h'))\n",
    "\n",
    "inframe_mut_fig4a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bec9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inframe_mut_fig4a.write_image('./plots/revision_DR_indelfreq_simpler_fig4a.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b08c72",
   "metadata": {},
   "source": [
    "#### Plot for Fig. S4b - DRs  <a name=\"mutation_internal_indels_plots_figS4B\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aba676a",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "inframe_mut_figS4b = make_subplots(rows=6, cols=10, shared_yaxes=True, shared_xaxes = True, vertical_spacing = 0.030, horizontal_spacing = 0.02, subplot_titles = ['Flank', 'Within Motif', 'MM pos.', 'Sp. ends', 'Sp. mid', 'Flank', 'Within Motif', 'MM pos.', 'Sp. ends', 'Sp. mid'])\n",
    "counter =1\n",
    "plot_internal_add('DR_stemlen_loop04', [10,20], ['flank_pos', 1], counter, 1, norm_internal_indel_ins, showleg = True if counter == 1 else False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop04', [10,20], ['motif_pos_genome_middle', 1], counter, 2, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop04', [10,20], ['MM_pos', 1], counter, 3, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop04', [10,20], ['spacer_pos', 1], counter, 4, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop04', [10,20], ['spacer_middle_pos', 1], counter, 5, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop04', [10,20], ['flank_pos', 1], counter, 6, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop04', [10,20], ['motif_pos_genome_middle', 1], counter, 7, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop04', [10,20], ['MM_pos', 1], counter, 8, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop04', [10,20], ['spacer_pos', 1], counter, 9, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop04', [10,20], ['spacer_middle_pos', 1], counter, 10, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "inframe_mut_figS4b.update_yaxes(title = dict(text = 'Spacer 0-4'), row = counter, col = 1)\n",
    "counter +=1\n",
    "plot_internal_add('DR_stemlen_loop510', [10,20], ['flank_pos', 1], counter, 1, norm_internal_indel_ins, showleg = True if counter == 1 else False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop510', [10,20], ['motif_pos_genome_middle', 1], counter, 2, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop510', [10,20], ['MM_pos', 1], counter, 3, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop510', [10,20], ['spacer_pos', 1], counter, 4, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop510', [10,20], ['spacer_middle_pos', 1], counter, 5, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop510', [10,20], ['flank_pos', 1], counter, 6, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop510', [10,20], ['motif_pos_genome_middle', 1], counter, 7, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop510', [10,20], ['MM_pos', 1], counter, 8, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop510', [10,20], ['spacer_pos', 1], counter, 9, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop510', [10,20], ['spacer_middle_pos', 1], counter, 10, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "inframe_mut_figS4b.update_yaxes(title = dict(text = 'Spacer 5-10'), row = counter, col = 1)\n",
    "counter +=1\n",
    "plot_internal_add('DR_stemlen_loop1020', [10,20], ['flank_pos', 1], counter, 1, norm_internal_indel_ins, showleg = True if counter == 1 else False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop1020', [10,20], ['motif_pos_genome_middle', 1], counter, 2, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop1020', [10,20], ['MM_pos', 1], counter, 3, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop1020', [10,20], ['spacer_pos', 1], counter, 4, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop1020', [10,20], ['spacer_middle_pos', 1], counter, 5, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop1020', [10,20], ['flank_pos', 1], counter, 6, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop1020', [10,20], ['motif_pos_genome_middle', 1], counter, 7, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop1020', [10,20], ['MM_pos', 1], counter, 8, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop1020', [10,20], ['spacer_pos', 1], counter, 9, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop1020', [10,20], ['spacer_middle_pos', 1], counter, 10, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "inframe_mut_figS4b.update_yaxes(title = dict(text = 'Spacer 11-20'), row = counter, col = 1)\n",
    "counter +=1\n",
    "plot_internal_add('DR_stemlen_loop20100', [10,20], ['flank_pos', 1], counter, 1, norm_internal_indel_ins, showleg = True if counter == 1 else False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop20100', [10,20], ['motif_pos_genome_middle', 1], counter, 2, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop20100', [10,20], ['MM_pos', 1], counter, 3, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop20100', [10,20], ['spacer_pos', 1], counter, 4, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop20100', [10,20], ['spacer_middle_pos', 1], counter, 5, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop20100', [10,20], ['flank_pos', 1], counter, 6, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop20100', [10,20], ['motif_pos_genome_middle', 1], counter, 7, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop20100', [10,20], ['MM_pos', 1], counter, 8, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop20100', [10,20], ['spacer_pos', 1], counter, 9, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_stemlen_loop20100', [10,20], ['spacer_middle_pos', 1], counter, 10, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "inframe_mut_figS4b.update_yaxes(title = dict(text = 'Spacer >20'), row = counter, col = 1)\n",
    "counter +=1\n",
    "plot_internal_add('DR_longins_stemlen_loop10', [10,20], ['flank_pos', 1], counter, 1, norm_internal_indel_ins, showleg = True if counter == 1 else False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_longins_stemlen_loop10', [10,20], ['motif_pos_genome_middle', 1], counter, 2, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_longins_stemlen_loop10', [10,20], ['MM_pos', 1], counter, 3, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_longins_stemlen_loop10', [10,20], ['spacer_pos', 1], counter, 4, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_longins_stemlen_loop10', [10,20], ['spacer_middle_pos', 1], counter, 5, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "inframe_mut_figS4b.update_yaxes(title = dict(text = 'Ins. len >5'), row = counter, col = 1)\n",
    "counter +=1\n",
    "plot_internal_add('DR_shortins_stemlen_loop10', [10,20], ['flank_pos', 1], counter, 1, norm_internal_indel_ins, showleg = True if counter == 1 else False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_shortins_stemlen_loop10', [10,20], ['motif_pos_genome_middle', 1], counter, 2, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_shortins_stemlen_loop10', [10,20], ['MM_pos', 1], counter, 3, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_shortins_stemlen_loop10', [10,20], ['spacer_pos', 1], counter, 4, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('DR_shortins_stemlen_loop10', [10,20], ['spacer_middle_pos', 1], counter, 5, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS4b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "inframe_mut_figS4b.update_yaxes(title = dict(text = 'Ins. len <=5'), row = counter, col = 1)\n",
    "inframe_mut_figS4b.update_yaxes(zeroline = False, range = [-1.1,2.6], type = 'log', dtick = 1)\n",
    "inframe_mut_figS4b.add_shape(type='line', x0=0.5, x1=0.5, y0=-0.25, y1=1.05, xref='paper', yref='paper', line=dict(color='rgb(150,150,150)', width = 3))\n",
    "inframe_mut_figS4b.update_layout(title = dict(text = 'Insertions                                                               Deletions', x = 0.225, font = dict(size = 18)))\n",
    "inframe_mut_figS4b.update_xaxes(title = dict(text = 'Motif length', font = dict(size = 14), standoff = 0), row = 6, col = 1)\n",
    "inframe_mut_figS4b.update_layout(xaxis36_showticklabels=True); inframe_mut_figS4b.update_layout(xaxis37_showticklabels=True); inframe_mut_figS4b.update_layout(xaxis38_showticklabels=True); inframe_mut_figS4b.update_layout(xaxis39_showticklabels=True); inframe_mut_figS4b.update_layout(xaxis40_showticklabels=True)\n",
    "inframe_mut_figS4b.update_layout(width = 1000, height = 800, margin = dict(l = 45, r = 25, b = 35, t = 50), legend=dict(y = 0.32, x = 0.52, orientation='h'))\n",
    "\n",
    "inframe_mut_figS4b.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb80179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inframe_mut_figS4b.write_image('./plots/revision_DR_indelfreq_figS4b.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d59e8e",
   "metadata": {},
   "source": [
    "#### Plot for Fig. S5b - IRs  <a name=\"mutation_internal_indels_plots_figS5B\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83e2f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "inframe_mut_figS5b = make_subplots(rows=4, cols=10, shared_yaxes=True, shared_xaxes = True, vertical_spacing = 0.030, horizontal_spacing = 0.02, subplot_titles = ['Flank', 'Within Motif', 'MM pos.', 'Sp. ends', 'Sp. mid', 'Flank', 'Within Motif', 'MM pos.', 'Sp. ends', 'Sp. mid'])\n",
    "counter =1\n",
    "plot_internal_add('IR_stemlen_loop04', [10,20], ['flank_pos', 1], counter, 1, norm_internal_indel_ins, showleg = True if counter == 1 else False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop04', [10,20], ['motif_pos_genome_middle', 1], counter, 2, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop04', [10,20], ['MM_pos', 1], counter, 3, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop04', [10,20], ['spacer_pos', 1], counter, 4, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop04', [10,20], ['spacer_middle_pos', 1], counter, 5, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop04', [10,20], ['flank_pos', 1], counter, 6, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop04', [10,20], ['motif_pos_genome_middle', 1], counter, 7, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop04', [10,20], ['MM_pos', 1], counter, 8, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop04', [10,20], ['spacer_pos', 1], counter, 9, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop04', [10,20], ['spacer_middle_pos', 1], counter, 10, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "inframe_mut_figS5b.update_yaxes(title = dict(text = 'Spacer 0-4'), row = counter, col = 1)\n",
    "counter +=1\n",
    "plot_internal_add('IR_stemlen_loop510', [10,20], ['flank_pos', 1], counter, 1, norm_internal_indel_ins, showleg = True if counter == 1 else False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop510', [10,20], ['motif_pos_genome_middle', 1], counter, 2, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop510', [10,20], ['MM_pos', 1], counter, 3, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop510', [10,20], ['spacer_pos', 1], counter, 4, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop510', [10,20], ['spacer_middle_pos', 1], counter, 5, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop510', [10,20], ['flank_pos', 1], counter, 6, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop510', [10,20], ['motif_pos_genome_middle', 1], counter, 7, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop510', [10,20], ['MM_pos', 1], counter, 8, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop510', [10,20], ['spacer_pos', 1], counter, 9, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop510', [10,20], ['spacer_middle_pos', 1], counter, 10, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "inframe_mut_figS5b.update_yaxes(title = dict(text = 'Spacer 5-10'), row = counter, col = 1)\n",
    "counter +=1\n",
    "plot_internal_add('IR_stemlen_loop1020', [10,20], ['flank_pos', 1], counter, 1, norm_internal_indel_ins, showleg = True if counter == 1 else False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop1020', [10,20], ['motif_pos_genome_middle', 1], counter, 2, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop1020', [10,20], ['MM_pos', 1], counter, 3, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop1020', [10,20], ['spacer_pos', 1], counter, 4, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop1020', [10,20], ['spacer_middle_pos', 1], counter, 5, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop1020', [10,20], ['flank_pos', 1], counter, 6, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop1020', [10,20], ['motif_pos_genome_middle', 1], counter, 7, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop1020', [10,20], ['MM_pos', 1], counter, 8, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop1020', [10,20], ['spacer_pos', 1], counter, 9, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop1020', [10,20], ['spacer_middle_pos', 1], counter, 10, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "inframe_mut_figS5b.update_yaxes(title = dict(text = 'Spacer 11-20'), row = counter, col = 1)\n",
    "counter +=1\n",
    "plot_internal_add('IR_stemlen_loop20100', [10,20], ['flank_pos', 1], counter, 1, norm_internal_indel_ins, showleg = True if counter == 1 else False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop20100', [10,20], ['motif_pos_genome_middle', 1], counter, 2, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop20100', [10,20], ['MM_pos', 1], counter, 3, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop20100', [10,20], ['spacer_pos', 1], counter, 4, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop20100', [10,20], ['spacer_middle_pos', 1], counter, 5, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop20100', [10,20], ['flank_pos', 1], counter, 6, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop20100', [10,20], ['motif_pos_genome_middle', 1], counter, 7, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop20100', [10,20], ['MM_pos', 1], counter, 8, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop20100', [10,20], ['spacer_pos', 1], counter, 9, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('IR_stemlen_loop20100', [10,20], ['spacer_middle_pos', 1], counter, 10, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS5b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "inframe_mut_figS5b.update_yaxes(title = dict(text = 'Spacer >20'), row = counter, col = 1)\n",
    "\n",
    "inframe_mut_figS5b.update_yaxes(zeroline = False, range = [-1.1,2.6], type = 'log', dtick = 1)\n",
    "inframe_mut_figS5b.add_shape(type='line', x0=0.5, x1=0.5, y0=-0.04, y1=1.05, xref='paper', yref='paper', line=dict(color='rgb(150,150,150)', width = 3))\n",
    "inframe_mut_figS5b.update_layout(title = dict(text = 'Insertions                                                               Deletions', x = 0.225, font = dict(size = 18)))\n",
    "inframe_mut_figS5b.update_xaxes(title = dict(text = 'Motif length', font = dict(size = 14), standoff = 0), row = 4, col = 1)\n",
    "inframe_mut_figS5b.update_layout(xaxis36_showticklabels=True); inframe_mut_figS5b.update_layout(xaxis37_showticklabels=True); inframe_mut_figS5b.update_layout(xaxis38_showticklabels=True); inframe_mut_figS5b.update_layout(xaxis39_showticklabels=True); inframe_mut_figS5b.update_layout(xaxis40_showticklabels=True)\n",
    "inframe_mut_figS5b.update_layout(width = 1000, height = 550, margin = dict(l = 45, r = 25, b = 35, t = 50), legend=dict(y = -0.03, x = 0.52, orientation='h'))\n",
    "\n",
    "inframe_mut_figS5b.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c3d05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inframe_mut_figS5b.write_image('./plots/revision_IR_indelfreq_figS5b.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1aabec",
   "metadata": {},
   "source": [
    "#### Plot for Fig. S6b - MRs  <a name=\"mutation_internal_indels_plots_figS6B\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a442ce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "inframe_mut_figS6b = make_subplots(rows=4, cols=10, shared_yaxes=True, shared_xaxes = True, vertical_spacing = 0.025, horizontal_spacing = 0.025, subplot_titles = ['Flank', 'Within Motif', 'MM pos.', 'Sp. ends', 'Sp. mid', 'Flank', 'Within Motif', 'MM pos.', 'Sp. ends', 'Sp. mid'])\n",
    "counter =1\n",
    "plot_internal_add('MR_stemlen_loop04', [10,17], ['flank_pos', 1], counter, 1, norm_internal_indel_ins, showleg = True if counter == 1 else False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop04', [10,17], ['motif_pos_genome_middle', 1], counter, 2, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop04', [10,17], ['MM_pos', 1], counter, 3, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop04', [10,17], ['spacer_pos', 1], counter, 4, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop04', [10,17], ['spacer_middle_pos', 1], counter, 5, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop04', [10,17], ['flank_pos', 1], counter, 6, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop04', [10,17], ['motif_pos_genome_middle', 1], counter, 7, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop04', [10,17], ['MM_pos', 1], counter, 8, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop04', [10,17], ['spacer_pos', 1], counter, 9, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop04', [10,17], ['spacer_middle_pos', 1], counter, 10, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "inframe_mut_figS6b.update_yaxes(title = dict(text = 'Spacer 0-4'), row = counter, col = 1)\n",
    "counter +=1\n",
    "plot_internal_add('MR_stemlen_loop510', [10,17], ['flank_pos', 1], counter, 1, norm_internal_indel_ins, showleg = True if counter == 1 else False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop510', [10,17], ['motif_pos_genome_middle', 1], counter, 2, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop510', [10,17], ['MM_pos', 1], counter, 3, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop510', [10,17], ['spacer_pos', 1], counter, 4, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop510', [10,17], ['spacer_middle_pos', 1], counter, 5, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop510', [10,17], ['flank_pos', 1], counter, 6, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop510', [10,17], ['motif_pos_genome_middle', 1], counter, 7, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop510', [10,17], ['MM_pos', 1], counter, 8, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop510', [10,17], ['spacer_pos', 1], counter, 9, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop510', [10,17], ['spacer_middle_pos', 1], counter, 10, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "inframe_mut_figS6b.update_yaxes(title = dict(text = 'Spacer 5-10'), row = counter, col = 1)\n",
    "counter +=1\n",
    "plot_internal_add('MR_stemlen_loop1020', [10,17], ['flank_pos', 1], counter, 1, norm_internal_indel_ins, showleg = True if counter == 1 else False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop1020', [10,17], ['motif_pos_genome_middle', 1], counter, 2, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop1020', [10,17], ['MM_pos', 1], counter, 3, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop1020', [10,17], ['spacer_pos', 1], counter, 4, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop1020', [10,17], ['spacer_middle_pos', 1], counter, 5, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop1020', [10,17], ['flank_pos', 1], counter, 6, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop1020', [10,17], ['motif_pos_genome_middle', 1], counter, 7, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop1020', [10,17], ['MM_pos', 1], counter, 8, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop1020', [10,17], ['spacer_pos', 1], counter, 9, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop1020', [10,17], ['spacer_middle_pos', 1], counter, 10, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "inframe_mut_figS6b.update_yaxes(title = dict(text = 'Spacer 11-20'), row = counter, col = 1)\n",
    "counter +=1\n",
    "plot_internal_add('MR_stemlen_loop20100', [10,17], ['flank_pos', 1], counter, 1, norm_internal_indel_ins, showleg = True if counter == 1 else False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop20100', [10,17], ['motif_pos_genome_middle', 1], counter, 2, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop20100', [10,17], ['MM_pos', 1], counter, 3, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop20100', [10,17], ['spacer_pos', 1], counter, 4, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop20100', [10,17], ['spacer_middle_pos', 1], counter, 5, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop20100', [10,17], ['flank_pos', 1], counter, 6, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop20100', [10,17], ['motif_pos_genome_middle', 1], counter, 7, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop20100', [10,17], ['MM_pos', 1], counter, 8, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop20100', [10,17], ['spacer_pos', 1], counter, 9, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('MR_stemlen_loop20100', [10,17], ['spacer_middle_pos', 1], counter, 10, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS6b, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "inframe_mut_figS6b.update_yaxes(title = dict(text = 'Spacer >20'), row = counter, col = 1)\n",
    "\n",
    "inframe_mut_figS6b.update_yaxes(zeroline = False, range = [-1.1,2.6], type = 'log', dtick = 1)\n",
    "inframe_mut_figS6b.add_shape(type='line', x0=0.5, x1=0.5, y0=-0.04, y1=1.05, xref='paper', yref='paper', line=dict(color='rgb(150,150,150)', width = 3))\n",
    "inframe_mut_figS6b.update_layout(title = dict(text = 'Insertions                                                               Deletions', x = 0.225, font = dict(size = 18)))\n",
    "inframe_mut_figS6b.update_xaxes(dtick = 3)\n",
    "inframe_mut_figS6b.update_xaxes(title = dict(text = 'Motif length', font = dict(size = 14), standoff = 0), row = 4, col = 1)\n",
    "inframe_mut_figS6b.update_layout(xaxis36_showticklabels=True); inframe_mut_figS6b.update_layout(xaxis37_showticklabels=True); inframe_mut_figS6b.update_layout(xaxis38_showticklabels=True); inframe_mut_figS6b.update_layout(xaxis39_showticklabels=True); inframe_mut_figS6b.update_layout(xaxis40_showticklabels=True)\n",
    "inframe_mut_figS6b.update_layout(width = 1023, height = 513, margin = dict(l = 45, r = 25, b = 35, t = 50), legend=dict(y = -0.04, x = 0.52, orientation='h'))\n",
    "\n",
    "inframe_mut_figS6b.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34719596",
   "metadata": {},
   "outputs": [],
   "source": [
    "inframe_mut_figS6b.write_image('./plots/revision_MR_indelfreq_figS6b.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e867bd9",
   "metadata": {},
   "source": [
    "#### Plot for Fig. S3a - STRs  <a name=\"mutation_internal_indels_plots_figS3A\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7517d5e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "repeats_figlist = ['A', 'C', 'AT', 'AC', 'AG', 'ACC', 'AGG', 'ATC', 'AGC', 'AAG', 'AAC', 'AAT']\n",
    "counter = 0\n",
    "inframe_mut_figS3a = make_subplots(rows=len(repeats_figlist), cols=8, shared_yaxes=True, shared_xaxes = True, vertical_spacing = 0.015, horizontal_spacing = 0.02, subplot_titles = ['Flank', 'Start/end', 'Within Motif', 'MM position', 'Flank', 'Start/end', 'Within Motif', 'MM position'])\n",
    "for repeat in repeats_figlist:\n",
    "    counter +=1\n",
    "    plot_internal_add('STR', [6,25], [repeat, 'flank_pos', 'perfect'], counter, 1, norm_internal_indel_ins, showleg = True if counter ==1 else False, plot_name = inframe_mut_figS3a, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "    plot_internal_add('STR', [6,25], [repeat, 'motif_pos', 'perfect'], counter, 2, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS3a, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "    plot_internal_add('STR', [6,25], [repeat, 'motif_pos_genome_middle', 'perfect'], counter, 3, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS3a, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "    plot_internal_add('STR', [10,25], [repeat, 'MM_pos_genome', 'inframe'], counter, 4, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS3a, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "    plot_internal_add('STR', [6,25], [repeat, 'flank_pos', 'perfect'], counter, 5, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS3a, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "    plot_internal_add('STR', [6,25], [repeat, 'motif_pos', 'perfect'], counter, 6, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS3a, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "    plot_internal_add('STR', [6,25], [repeat, 'motif_pos_genome_middle', 'perfect'], counter, 7, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS3a, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "    plot_internal_add('STR', [10,25], [repeat, 'MM_pos_genome', 'inframe'], counter, 8, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS3a, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "\n",
    "    inframe_mut_figS3a.update_yaxes(title = dict(text = repeat, font = dict(size = 18), standoff = 0), row = counter, col = 1)\n",
    "\n",
    "inframe_mut_figS3a.update_yaxes(zeroline = False, range = [-1.1,3.1], type = 'log', dtick = 1)\n",
    "inframe_mut_figS3a.add_shape(type='line', x0=0.5, x1=0.5, y0=-0.25, y1=1.05, xref='paper', yref='paper', line=dict(color='rgb(150,150,150)', width = 3))\n",
    "inframe_mut_figS3a.update_layout(title = dict(text = 'Insertions                                                               Deletions', x = 0.225, font = dict(size = 18)))\n",
    "\n",
    "inframe_mut_figS3a.update_xaxes(domain=[0, 0.11], col = 1)\n",
    "inframe_mut_figS3a.update_xaxes(domain=[0.13, 0.24], col = 2)\n",
    "inframe_mut_figS3a.update_xaxes(domain=[0.26, 0.37], col = 3)\n",
    "inframe_mut_figS3a.update_xaxes(domain=[0.39, 0.48], col = 4)\n",
    "inframe_mut_figS3a.update_xaxes(domain=[0.52, 0.63], col = 5)\n",
    "inframe_mut_figS3a.update_xaxes(domain=[0.65, 0.76], col = 6)\n",
    "inframe_mut_figS3a.update_xaxes(domain=[0.78, 0.89], col = 7)\n",
    "inframe_mut_figS3a.update_xaxes(domain=[0.91, 1], col = 8)\n",
    "\n",
    "inframe_mut_figS3a.update_xaxes(title = dict(text = 'motif length', font = dict(size = 14), standoff = 0), row = counter, col = 1)\n",
    "inframe_mut_figS3a.update_layout(width = 1000, height = 100*len(repeats_figlist), margin = dict(l = 45, r = 25, b = 0, t = 50), legend=dict(y = -0.02, x = 0.175, orientation='h'))\n",
    "inframe_mut_figS3a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620be20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inframe_mut_figS3a.write_image('./plots/revision_internal_indel_fig_S3a.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cb3af3",
   "metadata": {},
   "source": [
    "#### Plots for Fig. S5a, S5b - G4s  <a name=\"mutation_internal_indels_plots_figS5\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2432fe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "G4_QCeffect_indel = G4_norm_summary_indel_tri[-1.0607] - G4_norm_summary_indel_tri[-np.inf]\n",
    "\n",
    "G4_newlistofpositions = [\"run 5'\", \"run_positions_middle\", \"run 3'\", \"loop 5'\", \"loop_positions_middle\",  \"loop 3'\", \"loop 1nt\"]\n",
    "G4_newlistofnames = [\"5'\", 'mid',\"3'\", \"5'\", 'mid', \"3'\", '1nt']\n",
    "\n",
    "G4_QCeffect_indel_up = dict()\n",
    "G4_QCeffect_indel_down = dict()\n",
    "\n",
    "count = -0.35\n",
    "for position in G4_newlistofpositions:\n",
    "    G4_QCeffect_indel_up[position] = pd.DataFrame(G4_QCeffect_indel[position].loc[G4_QCeffect_indel[position] >0].copy())\n",
    "    G4_QCeffect_indel_down[position] = pd.DataFrame(G4_QCeffect_indel[position].loc[G4_QCeffect_indel[position] <0].copy())\n",
    "\n",
    "    G4_QCeffect_indel_up[position][-np.inf] = G4_norm_summary_indel_tri[-np.inf][position].reindex(G4_QCeffect_indel_up[position].index).copy()\n",
    "    G4_QCeffect_indel_down[position][-np.inf] = G4_norm_summary_indel_tri[-np.inf][position].reindex(G4_QCeffect_indel_down[position].index).copy()\n",
    "    G4_QCeffect_indel_up[position][-1.0607] = G4_norm_summary_indel_tri[-1.0607][position].reindex(G4_QCeffect_indel_up[position].index).copy()\n",
    "    G4_QCeffect_indel_down[position][-1.0607] = G4_norm_summary_indel_tri[-1.0607][position].reindex(G4_QCeffect_indel_down[position].index).copy()\n",
    "\n",
    "    G4_QCeffect_indel_up[position]['random'] = count + (0.75* np.random.random(len(G4_QCeffect_indel_up[position])))\n",
    "    G4_QCeffect_indel_down[position]['random'] = count + (0.75* np.random.random(len(G4_QCeffect_indel_down[position])))\n",
    "\n",
    "    G4_QCeffect_indel_up[position]['name'] = [str(name).replace('_', '>') if G4_QCeffect_indel_up[position][position][name] >1.5 else '' for name in G4_QCeffect_indel_up[position].index]\n",
    "    G4_QCeffect_indel_down[position]['name'] = [str(name).replace('_', '>') if G4_QCeffect_indel_down[position][position][name] <-1.5 else '' for name in G4_QCeffect_indel_down[position].index]\n",
    "\n",
    "    count +=1\n",
    "\n",
    "# Set y-axis location for particular trinucleotides\n",
    "G4_QCeffect_indel_down[\"loop 5'\"].loc['GTC_G', 'random'] = 2.65\n",
    "G4_QCeffect_indel_down[\"loop 5'\"].loc['GTA_G', 'random'] = 3\n",
    "G4_QCeffect_indel_down[\"loop 5'\"].loc['GTT_G', 'random'] = 3.35\n",
    "\n",
    "G4_QCeffect_indel_down[\"loop 3'\"].loc['TTG_G', 'random'] = 4.65\n",
    "G4_QCeffect_indel_down[\"loop 3'\"].loc['TAG_T', 'random'] = 5\n",
    "G4_QCeffect_indel_down[\"loop 3'\"].loc['CAG_T', 'random'] = 5.35\n",
    "\n",
    "G4_QCeffect_indel_down['loop 1nt'].loc['GTG_G', 'random'] = 5.8\n",
    "G4_QCeffect_indel_down['loop 1nt'].loc['GAG_T', 'random'] = 6.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c43cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "G4_QCeffect_ins = G4_norm_summary_ins_tri[-1.0607] - G4_norm_summary_ins_tri[-np.inf]\n",
    "\n",
    "G4_newlistofpositions = [\"run 5'\", \"run_positions_middle\", \"run 3'\", \"loop 5'\", \"loop_positions_middle\",  \"loop 3'\", \"loop 1nt\"]\n",
    "G4_newlistofnames = [\"5'\", 'mid',\"3'\", \"5'\", 'mid', \"3'\", '1nt']\n",
    "\n",
    "G4_QCeffect_ins_up = dict()\n",
    "G4_QCeffect_ins_down = dict()\n",
    "\n",
    "count = -0.35\n",
    "for position in G4_newlistofpositions:\n",
    "    G4_QCeffect_ins_up[position] = pd.DataFrame(G4_QCeffect_ins[position].loc[G4_QCeffect_ins[position] >0].copy())\n",
    "    G4_QCeffect_ins_down[position] = pd.DataFrame(G4_QCeffect_ins[position].loc[G4_QCeffect_ins[position] <0].copy())\n",
    "\n",
    "    G4_QCeffect_ins_up[position][-np.inf] = G4_norm_summary_ins_tri[-np.inf][position].reindex(G4_QCeffect_ins_up[position].index).copy()\n",
    "    G4_QCeffect_ins_down[position][-np.inf] = G4_norm_summary_ins_tri[-np.inf][position].reindex(G4_QCeffect_ins_down[position].index).copy()\n",
    "    G4_QCeffect_ins_up[position][-1.0607] = G4_norm_summary_ins_tri[-1.0607][position].reindex(G4_QCeffect_ins_up[position].index).copy()\n",
    "    G4_QCeffect_ins_down[position][-1.0607] = G4_norm_summary_ins_tri[-1.0607][position].reindex(G4_QCeffect_ins_down[position].index).copy()\n",
    "\n",
    "    G4_QCeffect_ins_up[position]['random'] = count + (0.75* np.random.random(len(G4_QCeffect_ins_up[position])))\n",
    "    G4_QCeffect_ins_down[position]['random'] = count + (0.75* np.random.random(len(G4_QCeffect_ins_down[position])))\n",
    "\n",
    "    G4_QCeffect_ins_up[position]['name'] = [str(name).replace('_', '>') if G4_QCeffect_ins_up[position][position][name] >10 else '' for name in G4_QCeffect_ins_up[position].index]\n",
    "    G4_QCeffect_ins_down[position]['name'] = [str(name).replace('_', '>') if G4_QCeffect_ins_down[position][position][name] <-10 else '' for name in G4_QCeffect_ins_down[position].index]\n",
    "\n",
    "    count +=1\n",
    "\n",
    "# Set y-axis location for particular trinucleotides\n",
    "G4_QCeffect_ins_down[\"loop 5'\"].loc['GTA_ins', 'random'] = 2.775\n",
    "G4_QCeffect_ins_down[\"loop 5'\"].loc['GCA_ins', 'random'] = 3.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b5a5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "G4_QCeffect_del = G4_norm_summary_del_tri[-1.0607] - G4_norm_summary_del_tri[-np.inf]\n",
    "\n",
    "G4_newlistofpositions = [\"run 5'\", \"run_positions_middle\", \"run 3'\", \"loop 5'\", \"loop_positions_middle\",  \"loop 3'\", \"loop 1nt\"]\n",
    "G4_newlistofnames = [\"5'\", 'mid',\"3'\", \"5'\", 'mid', \"3'\", '1nt']\n",
    "\n",
    "G4_QCeffect_del_up = dict()\n",
    "G4_QCeffect_del_down = dict()\n",
    "\n",
    "count = -0.35\n",
    "for position in G4_newlistofpositions:\n",
    "    G4_QCeffect_del_up[position] = pd.DataFrame(G4_QCeffect_del[position].loc[G4_QCeffect_del[position] >0].copy())\n",
    "    G4_QCeffect_del_down[position] = pd.DataFrame(G4_QCeffect_del[position].loc[G4_QCeffect_del[position] <0].copy())\n",
    "\n",
    "    G4_QCeffect_del_up[position][-np.inf] = G4_norm_summary_del_tri[-np.inf][position].reindex(G4_QCeffect_del_up[position].index).copy()\n",
    "    G4_QCeffect_del_down[position][-np.inf] = G4_norm_summary_del_tri[-np.inf][position].reindex(G4_QCeffect_del_down[position].index).copy()\n",
    "    G4_QCeffect_del_up[position][-1.0607] = G4_norm_summary_del_tri[-1.0607][position].reindex(G4_QCeffect_del_up[position].index).copy()\n",
    "    G4_QCeffect_del_down[position][-1.0607] = G4_norm_summary_del_tri[-1.0607][position].reindex(G4_QCeffect_del_down[position].index).copy()\n",
    "\n",
    "    G4_QCeffect_del_up[position]['random'] = count + (0.75* np.random.random(len(G4_QCeffect_del_up[position])))\n",
    "    G4_QCeffect_del_down[position]['random'] = count + (0.75* np.random.random(len(G4_QCeffect_del_down[position])))\n",
    "\n",
    "    G4_QCeffect_del_up[position]['name'] = [str(name).replace('_', '>') if G4_QCeffect_del_up[position][position][name] >1.5 else '' for name in G4_QCeffect_del_up[position].index]\n",
    "    G4_QCeffect_del_down[position]['name'] = [str(name).replace('_', '>') if G4_QCeffect_del_down[position][position][name] <-1.5 else '' for name in G4_QCeffect_del_down[position].index]\n",
    "\n",
    "    count +=1\n",
    "\n",
    "# Set y-axis location for particular trinucleotides\n",
    "#G4_QCeffect_del_down[\"loop 5'\"].loc['GTC_G', 'random'] = 2.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c6057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "G4_ins_arrow_fig = go.Figure()\n",
    "\n",
    "for QC_filter in vqslod_list_indel:\n",
    "    G4_ins_arrow_fig.add_trace(go.Bar(x = list(range(7)), y = G4_norm_summary_ins[0][QC_filter] -1, base = 1, marker = dict(color = QC_colors_internal_indel[0][QC_filter]), showlegend = True, name = QC_colors_internal_indel['name'][QC_filter], error_y=dict(type='data', symmetric=False, array = pd.Series(G4_norm_summary_ins[2][QC_filter] - G4_norm_summary_ins[0][QC_filter]), arrayminus = pd.Series(G4_norm_summary_ins[0][QC_filter] - G4_norm_summary_ins[1][QC_filter]), color=QC_colors_internal_indel[1][QC_filter], thickness=1.5, width=3)))\n",
    "\n",
    "list_of_annotations = []\n",
    "for pos in G4_QCeffect_ins_down:\n",
    "    current_group = G4_QCeffect_ins_down[pos]\n",
    "    if len(current_group) > 0:\n",
    "        current_lines = [dict(x=current_group['random'][mut], ax=current_group['random'][mut], y=current_group[-1.0607][mut], ay=current_group[-np.inf][mut], xref='x1', yref='y1', axref='x1', ayref='y1', text = current_group['name'][mut], showarrow=True, arrowhead=2, arrowsize=1, arrowwidth=1.5, arrowcolor='rgba(255,0,0,0.5)', font = dict(color = 'rgb(0,0,0)')) for mut in current_group.index]\n",
    "        list_of_annotations = list_of_annotations + current_lines\n",
    "    current_group = G4_QCeffect_ins_up[pos]\n",
    "    if len(current_group) > 0:\n",
    "        current_lines = [dict(x=current_group['random'][mut], ax=current_group['random'][mut], y=current_group[-1.0607][mut], ay=current_group[-np.inf][mut], xref='x1', yref='y1', axref='x1', ayref='y1', text = current_group['name'][mut], showarrow=True, arrowhead=2, arrowsize=1, arrowwidth=1.5, arrowcolor='rgba(0,0,0,0.5)', font = dict(color = 'rgb(0,0,0)')) for mut in current_group.index]\n",
    "        list_of_annotations = list_of_annotations + current_lines\n",
    "\n",
    "list_of_annotations = list_of_annotations + [dict(text = 'G4 stem                                     spacer', font = dict(size = 18), x = 0.16, y = 0, showarrow = False, xref = 'paper', yref = 'paper')]\n",
    "G4_ins_arrow_fig.add_shape(type='line', x0=0.4275, x1=0.4275, y0=-0.1, y1=1, xref='paper', yref='paper', line=dict(color='rgb(150,150,150)', width = 3))\n",
    "\n",
    "G4_ins_arrow_fig.update_xaxes(tickmode = 'array', tickvals = list(range(7)), ticktext = G4_newlistofnames)\n",
    "G4_ins_arrow_fig.update_yaxes(zeroline = False, range = [-5, 70], tickvals = [1,10,20,30,40,50,60], title = dict(text = 'Relative insertion frequency', standoff = 0, font = dict(size = 18)))\n",
    "G4_ins_arrow_fig.update_layout(annotations= list_of_annotations)\n",
    "\n",
    "G4_ins_arrow_fig.update_layout(height = 520, width = 700, margin = dict(l = 40, r = 10, b = 10, t = 10), legend=dict(y = -0.04, x = 0.2, orientation='h'))\n",
    "G4_ins_arrow_fig.update_layout(barmode = 'overlay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cd4023",
   "metadata": {},
   "outputs": [],
   "source": [
    "G4_ins_arrow_fig.write_image('./plots/revision_internal_mutation_G4_ins_fig_S5a.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4470a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "G4_del_arrow_fig = go.Figure()\n",
    "\n",
    "for QC_filter in vqslod_list_indel:\n",
    "    G4_del_arrow_fig.add_trace(go.Bar(x = list(range(7)), y = G4_norm_summary_del[0][QC_filter] -1, base = 1, marker = dict(color = QC_colors_internal_indel[0][QC_filter]), showlegend = True, name = QC_colors_internal_indel['name'][QC_filter], error_y=dict(type='data', symmetric=False, array = pd.Series(G4_norm_summary_del[2][QC_filter] - G4_norm_summary_del[0][QC_filter]), arrayminus = pd.Series(G4_norm_summary_del[0][QC_filter] - G4_norm_summary_del[1][QC_filter]), color=QC_colors_internal_indel[1][QC_filter], thickness=1.5, width=3)))\n",
    "\n",
    "list_of_annotations = []\n",
    "for pos in G4_QCeffect_del_down:\n",
    "    current_group = G4_QCeffect_del_down[pos]\n",
    "    if len(current_group) > 0:\n",
    "        current_lines = [dict(x=current_group['random'][mut], ax=current_group['random'][mut], y=current_group[-1.0607][mut], ay=current_group[-np.inf][mut], xref='x1', yref='y1', axref='x1', ayref='y1', text = current_group['name'][mut], showarrow=True, arrowhead=2, arrowsize=1, arrowwidth=1.5, arrowcolor='rgba(255,0,0,0.5)', font = dict(color = 'rgb(0,0,0)')) for mut in current_group.index]\n",
    "        list_of_annotations = list_of_annotations + current_lines\n",
    "    current_group = G4_QCeffect_del_up[pos]\n",
    "    if len(current_group) > 0:\n",
    "        current_lines = [dict(x=current_group['random'][mut], ax=current_group['random'][mut], y=current_group[-1.0607][mut], ay=current_group[-np.inf][mut], xref='x1', yref='y1', axref='x1', ayref='y1', text = current_group['name'][mut], showarrow=True, arrowhead=2, arrowsize=1, arrowwidth=1.5, arrowcolor='rgba(0,0,0,0.5)', font = dict(color = 'rgb(0,0,0)')) for mut in current_group.index]\n",
    "        list_of_annotations = list_of_annotations + current_lines\n",
    "\n",
    "list_of_annotations = list_of_annotations + [dict(text = 'G4 stem                                     spacer', font = dict(size = 18), x = 0.16, y = 0, showarrow = False, xref = 'paper', yref = 'paper')]\n",
    "G4_del_arrow_fig.add_shape(type='line', x0=0.4275, x1=0.4275, y0=-0.1, y1=1, xref='paper', yref='paper', line=dict(color='rgb(150,150,150)', width = 3))\n",
    "\n",
    "G4_del_arrow_fig.update_xaxes(tickmode = 'array', tickvals = list(range(7)), ticktext = G4_newlistofnames)\n",
    "G4_del_arrow_fig.update_yaxes(range = [0.05, 10.75], dtick = 1, title = dict(text = 'Relative deletion frequency', standoff = 0, font = dict(size = 18)))\n",
    "G4_del_arrow_fig.update_layout(annotations= list_of_annotations)\n",
    "\n",
    "G4_del_arrow_fig.update_layout(height = 520, width = 700, margin = dict(l = 40, r = 10, b = 10, t = 10), legend=dict(y = -0.04, x = 0.2, orientation='h'))\n",
    "G4_del_arrow_fig.update_layout(barmode = 'overlay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2c4894",
   "metadata": {},
   "outputs": [],
   "source": [
    "G4_del_arrow_fig.write_image('./plots/revision_internal_mutation_G4_del_fig_S5b.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0bcae1",
   "metadata": {},
   "source": [
    "### Combined indel/SNV plots\n",
    "\n",
    "####  Plot for Fig. 3a - STRs <a name=\"mutation_internal_combined_plots_fig3A\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b66b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeats_figlist = ['A', 'AT', 'AC', 'AG']\n",
    "counter = 0\n",
    "inframe_mut_fig3a = make_subplots(rows=len(repeats_figlist), cols=6, shared_yaxes=False, shared_xaxes = True, vertical_spacing = 0.0375, horizontal_spacing = 0.025,  column_widths=[0.188, 0.188, 0.01, 0.23, 0.188, 0.188], subplot_titles = ['Insertions', 'Deletions', '', 'SNVs in motif', 'Perfecting SNVs', 'Non-perfecting'])\n",
    "for repeat in repeats_figlist:\n",
    "    counter +=1\n",
    "    plot_internal_add('STR', [6,25], [repeat, 'motif_pos_genome_middle', 'perfect'], counter, 1, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_fig3a, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "    plot_internal_add('STR', [6,25], [repeat, 'motif_pos_genome_middle', 'perfect'], counter, 2, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_fig3a, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "\n",
    "    plot_internal_add('STR', [6,30], ['non_pred', repeat, 'motif_pos_genome_middle', 'perfect'], counter, 4, norm_internal_all, showleg = False, plot_name = inframe_mut_fig3a, pred_factor = 1)\n",
    "    plot_internal_add('STR', [10,30], ['pred', repeat, 'MM_pos_genome', 'inframe'], counter, 5, norm_internal_all, showleg = True if counter == 1 else False, plot_name = inframe_mut_fig3a, pred_factor = 3)\n",
    "    plot_internal_add('STR', [10,30], ['against_pred', repeat, 'MM_pos_genome', 'inframe'], counter, 6, norm_internal_all, showleg = False, plot_name = inframe_mut_fig3a, pred_factor = 1.5)\n",
    "    \n",
    "    inframe_mut_fig3a.update_yaxes(title = dict(text = repeat, font = dict(size = 18), standoff = 0), row = counter, col = 1)\n",
    "\n",
    "inframe_mut_fig3a.add_shape(type='line', x0=0.38, x1=0.38, y0=-0.05, y1=1.05, xref='paper', yref='paper', line=dict(color='rgb(150,150,150)', width = 3))\n",
    "\n",
    "inframe_mut_fig3a.update_yaxes(zeroline = False, range = [-1.1,3.1], type = 'log', dtick = 1, col = 1)\n",
    "inframe_mut_fig3a.update_yaxes(zeroline = False, showticklabels = False, range = [-1.1,3.1], type = 'log', dtick = 1, col = 2)\n",
    "inframe_mut_fig3a.update_yaxes(zeroline = False, range = [-0.5,14.99], dtick = 4, col = 4)\n",
    "inframe_mut_fig3a.update_yaxes(zeroline = False, showticklabels = False, range = [-0.5,14.99], dtick = 4, col = 5)\n",
    "inframe_mut_fig3a.update_yaxes(zeroline = False, showticklabels = False, range = [-0.5,14.99], dtick = 4, col = 6)\n",
    "\n",
    "inframe_mut_fig3a.update_xaxes(dtick = 5)\n",
    "inframe_mut_fig3a.update_xaxes(title = dict(text = 'motif length', font = dict(size = 14), standoff = 0), row = counter, col = 1)\n",
    "inframe_mut_fig3a.update_layout(width = 800, height = 120*len(repeats_figlist), margin = dict(l = 45, r = 25, b = 35, t = 50), legend=dict(y = -0.04, x = 0.175, orientation='h'))\n",
    "inframe_mut_fig3a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c49729",
   "metadata": {},
   "outputs": [],
   "source": [
    "inframe_mut_fig3a.write_image('./plots/revision_ACcor_internal_STR_indel_snv_combined_fig_3a.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fe947f",
   "metadata": {},
   "source": [
    "####  Plot for Fig. S6c - ZDNA <a name=\"mutation_internal_combined_plots_figS6C\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfcec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZDNA_mut_fig = make_subplots(rows=1, cols=6, shared_yaxes=True, shared_xaxes = True, vertical_spacing = 0.020, horizontal_spacing = 0.02, subplot_titles = ['Flank', 'Within Motif', 'Flank', 'Within Motif', 'Flank', 'Within Motif'])\n",
    "plot_internal_add('ZDNA', [10,18], ['non_pred', 'flank_pos'], 1, 1, norm_internal_all, showleg = False, plot_name = ZDNA_mut_fig, pred_factor = 1)\n",
    "plot_internal_add('ZDNA', [10,20], ['non_pred', 'motif_pos_genome_middle'], 1, 2, norm_internal_all, showleg = True, plot_name = ZDNA_mut_fig, pred_factor = 1)\n",
    "\n",
    "plot_internal_add('ZDNA', [10,20], ['flank_pos'], 1, 3, norm_internal_indel_ins, showleg = False, plot_name = ZDNA_mut_fig, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('ZDNA', [10,20], ['motif_pos_genome_middle'], 1, 4, norm_internal_indel_ins, showleg = False, plot_name = ZDNA_mut_fig, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('ZDNA', [10,20], ['flank_pos'], 1, 5, norm_internal_indel_del, showleg = False, plot_name = ZDNA_mut_fig, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "plot_internal_add('ZDNA', [10,20], ['motif_pos_genome_middle'], 1, 6, norm_internal_indel_del, showleg = False, plot_name = ZDNA_mut_fig, pred_factor = 1, QC_colors_current=QC_colors_internal_indel)\n",
    "\n",
    "ZDNA_mut_fig.add_shape(type='line', x0=0.33, x1=0.33, y0=-0.25, y1=1.25, xref='paper', yref='paper', line=dict(color='rgb(150,150,150)', width = 3))\n",
    "ZDNA_mut_fig.add_shape(type='line', x0=0.67, x1=0.67, y0=-0.25, y1=1.25, xref='paper', yref='paper', line=dict(color='rgb(150,150,150)', width = 3))\n",
    "ZDNA_mut_fig.update_layout(title = dict(text = 'SNVs                            Insertions                          Deletions', x = 0.175, font = dict(size = 18)))\n",
    "ZDNA_mut_fig.update_yaxes(title = dict(text = 'Z-DNA'), row = 1, col = 1)\n",
    "ZDNA_mut_fig.update_yaxes(zeroline = False, range = [-1.1,1.7], type = 'log', dtick = 1)\n",
    "ZDNA_mut_fig.update_xaxes(title = dict(text = 'motif length', font = dict(size = 14), standoff = 0), row = 1, col = 1)\n",
    "\n",
    "ZDNA_mut_fig.update_layout(width = 800, height = 150, margin = dict(l = 45, r = 5, b = 0, t = 50), legend=dict(y = -0.4, x = 0.2, orientation='h'))\n",
    "ZDNA_mut_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5491358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZDNA_mut_fig.write_image('./plots/revision_ACcor_ZDNA_mutfreq_figS6c.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17778424",
   "metadata": {},
   "source": [
    "## STR insertion fidelity <a name=\"mutation_internal_STR_insertion_fidelity\"></a>\n",
    "\n",
    "#### Calculation of error frequency <a name=\"mutation_internal_STR_insertion_fidelity_calculation\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c536865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all indels within STRs\n",
    "STRs_indel = dict()\n",
    "for chrom in range(chr_range,23):\n",
    "    indel_in_STR = variants_indel_all[chrom].loc[variants_indel_all[chrom]['POS'].isin(pos_expand_all['STR'].loc[pos_expand_all['STR']['chrom'] == chrom]['pos'])].copy()\n",
    "    STRs_current = all_STRs_unique.loc[all_STRs_unique['chrom'] == chrom][['start', 'end', 'chrom', 'length', 'repeat', 'repeat_frame_L', 'Strand', 'status', 'Sequence', 'MM_pos']]\n",
    "    STRs_indel[chrom] = STRs_current.iloc[np.searchsorted(STRs_current['end'], indel_in_STR['POS'])].copy()\n",
    "    STRs_indel[chrom][['POS', 'REF', 'ALT', 'AS_VQSLOD', 'indel']] = indel_in_STR[['POS', 'REF', 'ALT', 'AS_VQSLOD', 'indel']].values\n",
    "STRs_indel = pd.concat(STRs_indel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9f411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate insertions and deletions\n",
    "STRs_ins = STRs_indel.loc[STRs_indel['ALT'].str.len() > 1].copy()\n",
    "STRs_del = STRs_indel.loc[STRs_indel['REF'].str.len() > 1].copy()\n",
    "# Adjust for included reference base\n",
    "STRs_del['del_len'] = STRs_del['REF'].str.len() -1\n",
    "STRs_ins['ins_len'] = STRs_ins['ALT'].str.len() -1\n",
    "STRs_ins['ins_seq'] = STRs_ins['ALT'].str[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592791ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude insertions at flank\n",
    "STRs_ins = STRs_ins.loc[(STRs_ins['POS'] >= STRs_ins['start']) & (STRs_ins['POS'] <= STRs_ins['end'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2c6759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find motif frame for the inserted sequence\n",
    "STRs_ins['repeat_frame_ins'] = [seq[pos-start:pos-start+rep_len] if (pos - start) < (total_len/2) else seq[pos-start-rep_len:pos-start] for seq, pos, start, rep_len, total_len in zip(STRs_ins['Sequence'], STRs_ins['POS'], STRs_ins['start'], STRs_ins['repeat'].str.len(), STRs_ins['length'])]\n",
    "# Perfect insertion template (repeat unit multipled by integer of insertion length/unit length)\n",
    "STRs_ins['repeat_unit_altlen'] = STRs_ins['repeat_frame_ins'] * ((STRs_ins['ins_len']) / STRs_ins['repeat'].str.len()).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7c2d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insertion template allowing partial repeat units\n",
    "STRs_ins['ins_template'] = [template + frame[:ins_len-len(template)] for template, frame, ins_len in zip(STRs_ins['repeat_unit_altlen'], STRs_ins['repeat_frame_ins'], STRs_ins['ins_len'])]\n",
    "# Template with +/- 1nt from reference sequence\n",
    "STRs_ins['ins_template+'] = [reference_genome[chrom][pos-1] + template + reference_genome[chrom][pos] for chrom, pos, template in zip(STRs_ins['chrom'], STRs_ins['POS'], STRs_ins['ins_template'])]\n",
    "STRs_ins['ALT+'] = [alt + reference_genome[chrom][pos] for chrom, pos, alt in zip(STRs_ins['chrom'], STRs_ins['POS'], STRs_ins['ALT'])]\n",
    "# Positions where insertion differs from template\n",
    "STRs_ins['dup_mut_pos'] = [np.where([a!=b for a,b in zip(seq1, seq2)]) for seq1, seq2 in zip(STRs_ins['ins_template+'], STRs_ins['ALT+'])]\n",
    "STRs_ins['dup_mut_pos'] = [pos[0] for pos in STRs_ins['dup_mut_pos']]\n",
    "\n",
    "STRs_ins['#_errors'] = STRs_ins['dup_mut_pos'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c0322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find perfect expansions (insertion sequence is a multiple of repeat unit)\n",
    "STRs_ins['perfect_expansion'] = STRs_ins['repeat_unit_altlen'] == STRs_ins['ins_seq']\n",
    "STRs_ins_perfect = STRs_ins.loc[(STRs_ins['status'] == 'perfect') & (STRs_ins['perfect_expansion'] == True) & (STRs_ins['repeat_frame_ins'].str.len() > 0)].copy()\n",
    "# Find out of register expansions (insertion length is not a multiple of repeat unit length)\n",
    "STRs_ins_oor = STRs_ins.loc[(STRs_ins['status'] == 'perfect') & (STRs_ins['perfect_expansion'] == False) & STRs_ins['#_errors'] == 0].copy()\n",
    "# Insertions have errors compared to repeat motif of same length\n",
    "STRs_ins_imperfect = STRs_ins.loc[(STRs_ins['status'] == 'perfect') & (STRs_ins['perfect_expansion'] == False) & (STRs_ins['#_errors'] > 0)].copy()\n",
    "# Insertions have fewer than 3 errors, and length of insertion is longer than length or errors\n",
    "STRs_ins_imperfect_related = STRs_ins_imperfect.loc[(STRs_ins_imperfect['#_errors'] < 3) & (STRs_ins_imperfect['ins_len'] > STRs_ins_imperfect['#_errors'] +1)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ecdbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insertions with up to 2 SNV errors\n",
    "STRs_ins_imperfect_related['dup_mut_pos_0'] = [pos[0] for pos in STRs_ins_imperfect_related['dup_mut_pos']]\n",
    "STRs_ins_imperfect_related['dup_mut_pos_1'] = [pos[1] if len(pos) == 2 else np.nan for pos in STRs_ins_imperfect_related['dup_mut_pos']]\n",
    "\n",
    "STRs_ins_imperfect_related['error1_tri'] = [seq[pos-1:pos+2] for seq, pos in zip(STRs_ins_imperfect_related['ins_template+'], STRs_ins_imperfect_related['dup_mut_pos_0'])]\n",
    "STRs_ins_imperfect_related['error1_mut'] = [seq[pos] for seq, pos in zip(STRs_ins_imperfect_related['ALT+'], STRs_ins_imperfect_related['dup_mut_pos_0'])]\n",
    "\n",
    "STRs_ins_imperfect_related['error2_tri'] = [np.nan if np.isnan(pos) == True else seq[int(pos)-1:int(pos)+2] for seq, pos in zip(STRs_ins_imperfect_related['ins_template+'], STRs_ins_imperfect_related['dup_mut_pos_1'])]\n",
    "STRs_ins_imperfect_related['error2_mut'] = [np.nan if np.isnan(pos) == True else seq[int(pos)] for seq, pos in zip(STRs_ins_imperfect_related['ALT+'], STRs_ins_imperfect_related['dup_mut_pos_1'])]\n",
    "\n",
    "STR_ins_muterrors_1 = STRs_ins_imperfect_related.groupby(['repeat', 'length', 'error1_tri', 'error1_mut']).count()['ALT'].unstack().fillna(0).astype(int)\n",
    "STR_ins_muterrors_2 = STRs_ins_imperfect_related.groupby(['repeat', 'length', 'error2_tri', 'error2_mut']).count()['ALT'].unstack().fillna(0).astype(int)\n",
    "STR_ins_muterrors_1.index.names = ['repeat', 'length', 'tri']; STR_ins_muterrors_2.index.names = ['repeat', 'length', 'tri']\n",
    "STR_ins_muterrors_all = STR_ins_muterrors_1.add(STR_ins_muterrors_2, fill_value = 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade04c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganize data\n",
    "STR_ins_muterrors_repeat = dict()\n",
    "repeats_figlist = ['A', 'C', 'AT', 'AC', 'AG', 'ACC', 'AGG', 'ATC', 'AGC', 'AAG', 'AAC', 'AAT', 'AAAT']\n",
    "for repeat in repeats_figlist:\n",
    "    STR_ins_muterrors_repeat[repeat] = dict()\n",
    "    current_repeat = STR_ins_muterrors_all.loc[repeat]\n",
    "    for length in set(current_repeat.index.get_level_values(0)):\n",
    "        current_length = current_repeat.loc[length].stack()\n",
    "        current_length.index = [tri+'_'+alt for tri, alt in zip(current_length.index.get_level_values(0), current_length.index.get_level_values(1))]\n",
    "        STR_ins_muterrors_repeat[repeat][length] = triplet_combine_RC(current_length, mut_input=True)\n",
    "    STR_ins_muterrors_repeat[repeat] = pd.concat(STR_ins_muterrors_repeat[repeat])\n",
    "STR_ins_muterrors_repeat = pd.concat(STR_ins_muterrors_repeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11533e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count all trinucleotides in insertions\n",
    "def count_tri_from_groupby(df):\n",
    "    return triplet_combine_RC(pd.Series(flatten([re.findall('...', seq) + re.findall('...', seq[1:]) + re.findall('...', seq[2:]) for seq in df['ins_template+']])).value_counts(), mut_output=True)\n",
    "\n",
    "STRs_ins_tri_total_repeat = STRs_ins.groupby(['repeat', 'length']).apply(count_tri_from_groupby)\n",
    "STRs_ins_tri_total_repeat = STRs_ins_tri_total_repeat.transpose().unstack().fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45ebe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate error frequency, weighted to trinucleotide count\n",
    "STRs_ins_muterrors_freq = STR_ins_muterrors_repeat.div(STRs_ins_tri_total_repeat.reindex(STR_ins_muterrors_repeat.index))\n",
    "STRs_ins_muterrors_freq_weight = dict()\n",
    "for repeat in repeats_figlist:\n",
    "    STRs_ins_muterrors_freq_weight[repeat] = pd.Series(np.nan)\n",
    "    for length in set(STRs_ins_muterrors_freq.loc[repeat].index.get_level_values(0)):\n",
    "        STRs_ins_muterrors_freq_weight[repeat][length] = np.ma.average(np.ma.MaskedArray(STRs_ins_muterrors_freq.loc[repeat].loc[length], mask=np.isnan(STRs_ins_muterrors_freq.loc[repeat].loc[length])), weights=STRs_ins_tri_total_repeat.loc[repeat].loc[length])\n",
    "STRs_ins_muterrors_freq_weight = pd.concat(STRs_ins_muterrors_freq_weight).dropna()\n",
    "STRs_ins_muterrors_freq_weight = STRs_ins_muterrors_freq_weight.unstack().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af31e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate error frequency, normalized to denovo mutation frequency, weighted to trinucleotide count\n",
    "STRs_ins_muterrors_norm = STRs_ins_muterrors_freq / (denovo_freq_RC.reindex(STRs_ins_muterrors_freq.index.get_level_values(2)) / denovo_n_genomes).values\n",
    "STRs_ins_muterrors_norm_weight = dict()\n",
    "for repeat in repeats_figlist:\n",
    "    STRs_ins_muterrors_norm_weight[repeat] = pd.Series(np.nan)\n",
    "    for length in set(STRs_ins_muterrors_norm.loc[repeat].index.get_level_values(0)):\n",
    "        STRs_ins_muterrors_norm_weight[repeat][length] = np.ma.average(np.ma.MaskedArray(STRs_ins_muterrors_norm.loc[repeat].loc[length], mask=np.isnan(STRs_ins_muterrors_norm.loc[repeat].loc[length])), weights=STRs_ins_tri_total_repeat.loc[repeat].loc[length])\n",
    "STRs_ins_muterrors_norm_weight = pd.concat(STRs_ins_muterrors_norm_weight).dropna()\n",
    "STRs_ins_muterrors_norm_weight = STRs_ins_muterrors_norm_weight.unstack().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bdb066",
   "metadata": {},
   "source": [
    "####  Plot for Fig. S3d - STR insertion fidelity <a name=\"mutation_internal_STR_insertion_fidelity_plots_figS3D\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df8c944",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeats_figlist = ['A', 'C', 'AT', 'AC', 'AG', 'ACC', 'AGG', 'ATC', 'AGC', 'AAG', 'AAC', 'AAT', 'AAAT']\n",
    "STR_fidelity_fig = make_subplots(rows = 1, cols = len(repeats_figlist), shared_yaxes = True, subplot_titles = repeats_figlist)\n",
    "counter = 0\n",
    "for repeat in repeats_figlist:\n",
    "    counter +=1\n",
    "    STR_fidelity_fig.add_trace(go.Bar(x = STRs_ins_muterrors_freq_weight[repeat].dropna().index, y = STRs_ins_muterrors_freq_weight[repeat].dropna()[:-1], name = repeat, showlegend = False), row = 1, col = counter)\n",
    "STR_fidelity_fig.update_yaxes(type = 'log', range = [-3,-1])#, dtick = np.log10(2))\n",
    "STR_fidelity_fig.add_shape(type='line', x0=0, x1=1, y0=1, y1=1, line=dict(color='Black', width = .5), xref = 'paper')\n",
    "STR_fidelity_fig.update_xaxes(title = dict(text = 'motif length', font = dict(size = 14)), row = 1, col = 1)\n",
    "STR_fidelity_fig.update_yaxes(title = dict(text = 'per base error density in expansions', font = dict(size = 14)), row = 1, col = 1)\n",
    "\n",
    "STR_fidelity_fig.update_layout(width = 800, height = 350, margin = dict(l = 65, r = 5, b = 40, t = 20))\n",
    "\n",
    "STR_fidelity_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d84fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "STR_fidelity_fig.write_image('./plots/revision_STR_fidelity_fig_S3d.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ee2473",
   "metadata": {},
   "source": [
    "### Ratio of insertions to deletions <a name=\"mutation_internal_STR_insertion_deletion_ratio\"></a>\n",
    "\n",
    "- (insertion frequency * insertion length * percent of insertions that are expansions) / (deletion frequency * deletion length)\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116a49dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate deletions within repeat tract\n",
    "STRs_del['seq+'] = [reference_genome[chrom][start-1: end+1] for chrom, start, end in zip(STRs_del['chrom'], STRs_del['start'], STRs_del['end'])]\n",
    "STRs_del['deletion_pos'] = [[match.start(0) for match in re.finditer(deletion, seq, overlapped = True)] for deletion, seq in zip(STRs_del['REF'], STRs_del['seq+'])]\n",
    "STRs_del['n_deletion_found'] = [len(location) for location in STRs_del['deletion_pos']]\n",
    "\n",
    "# Count perfect and non-perfect expansions\n",
    "STRs_ins['expansion'] = ((STRs_ins['perfect_expansion'] == True) | ((STRs_ins['#_errors'] < 3) & (STRs_ins['ins_len'] > STRs_ins['#_errors'] +1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c32175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate indel length and expansion percent\n",
    "del_length = STRs_del.groupby(['repeat', 'status', 'length']).sum()['del_len']\n",
    "ins_length = STRs_ins.groupby(['repeat', 'status', 'expansion', 'length']).sum()['ins_len']\n",
    "\n",
    "# Calculate ratio\n",
    "repeats_figlist = ['A', 'C', 'AT', 'AC', 'AG', 'ACC', 'AGG', 'ATC', 'AGC', 'AAG', 'AAC', 'AAT', 'AAAT']\n",
    "ins_del_bias = pd.DataFrame()\n",
    "for repeat in repeats_figlist:\n",
    "    ins_del_bias[repeat] = ((((norm_internal_indel_ins['STR'][0][-1.0607][repeat]['motif_pos_genome_middle']['perfect'] * normtorandom_indel['ins'][-1.0607]) * ins_length[repeat]['perfect'][True])) / (((norm_internal_indel_del['STR'][0][-1.0607][repeat]['motif_pos_genome_middle']['perfect'] * normtorandom_indel['del'][-1.0607]) * del_length[repeat]['perfect'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e6c44c",
   "metadata": {},
   "source": [
    "####  Plot for Fig. S3c - STR ins/del ratio <a name=\"mutation_internal_STR_insertion_deletion_ratio_plots_figS3C\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5effbda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "indel_bias_fig = make_subplots(rows = 1, cols = len(repeats_figlist), shared_yaxes = True, subplot_titles = repeats_figlist)\n",
    "counter = 0\n",
    "for repeat in repeats_figlist:\n",
    "    counter +=1\n",
    "    indel_bias_fig.add_trace(go.Bar(x = ins_del_bias[repeat].dropna().index, y = ins_del_bias[repeat].dropna()[:-1], name = repeat, showlegend = False), row = 1, col = counter)\n",
    "indel_bias_fig.update_yaxes(type = 'log', dtick = np.log10(2), tickmode = 'array', tickvals = [1024, 256, 64, 16, 4, 1, 1/4, 1/16, 1/64, 1/256, 1/1024], ticktext = [1024, 256, 64, 16, 4, 1, '1/4', '1/16', '1/64', '1/256', '1/1024'])\n",
    "\n",
    "indel_bias_fig.add_shape(type='line', x0=0, x1=1, y0=1, y1=1, line=dict(color='Black', width = .5), xref = 'paper')\n",
    "indel_bias_fig.update_xaxes(title = dict(text = 'motif length', font = dict(size = 14)), row = 1, col = 1)\n",
    "indel_bias_fig.update_yaxes(title = dict(text = 'expansions:contractions', font = dict(size = 14)), row = 1, col = 1)\n",
    "\n",
    "indel_bias_fig.update_layout(width = 800, height = 350, margin = dict(l = 65, r = 5, b = 40, t = 20))\n",
    "\n",
    "indel_bias_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9130daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "indel_bias_fig.write_image('./plots/revision_STR_indel_bias_fig_S3c.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb78b2f",
   "metadata": {},
   "source": [
    "### Absolute frequency of indels and SNVs <a name=\"mutation_internal_STR_indel_SNV_rate\"></a>\n",
    "\n",
    "- multiply relative mutation frequencies by independently measured genomic mutation rates for SNVs and indels\n",
    "- testing hypothesis that SNVs could be explained by length-neutral combination of insertions and deletions\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69321874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolution of the Insertion-Deletion Mutation Rate Across the Tree of Life\n",
    "# Sung, et al, 2016\n",
    "\n",
    "ug_snv = 1.82 * (10**-9)        # ug for SNVs: 1.82 x 10^-9\n",
    "ug_indel = 1.3513 * (10**-8)    # ug for indels: 1.3513 x 10^-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3ac915",
   "metadata": {},
   "source": [
    "####  Plot for Fig. S3e <a name=\"mutation_internal_STR_indel_SNV_rate_plots_figS3E\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526591cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inframe_mut_figS3e = make_subplots(rows=4, cols=3, shared_xaxes = True, shared_yaxes=True, vertical_spacing = 0.05, horizontal_spacing = 0.025, subplot_titles = ['Mutation at imperfection', 'Insertion in tract', 'Deletion at imperfection'])\n",
    "\n",
    "counter = 0\n",
    "for repeat in ['A', 'AT', 'AG', 'AC']:\n",
    "    counter +=1\n",
    "    plot_internal_add('STR', [10,30], ['pred', repeat, 'MM_pos_genome', 'inframe'], counter, 1, norm_internal_all, showleg = True if counter ==1 else False, plot_name = inframe_mut_figS3e, pred_factor = ug_snv)\n",
    "    plot_internal_add('STR', [10,25], [repeat, 'motif_pos_genome_middle', 'inframe'], counter, 2, norm_internal_indel_ins, showleg = False, plot_name = inframe_mut_figS3e, pred_factor = ug_indel, QC_colors_current=QC_colors_internal_indel)\n",
    "    plot_internal_add('STR', [10,25], [repeat, 'MM_pos_genome', 'inframe'], counter, 3, norm_internal_indel_del, showleg = False, plot_name = inframe_mut_figS3e, pred_factor = ug_indel, QC_colors_current=QC_colors_internal_indel)\n",
    "    inframe_mut_figS3e.update_yaxes(zeroline = False, title = dict(text = repeat, font = dict(size = 18), standoff = 5), row = counter, col = 1)\n",
    "    \n",
    "inframe_mut_figS3e.update_xaxes(title = dict(text = 'motif length', font = dict(size = 14), standoff = 0), row = counter, col = 1)\n",
    "\n",
    "inframe_mut_figS3e.update_yaxes(type = 'log', range = [-10.1, -5.9], exponentformat = 'e', dtick = 1, domain=[0.72, 1], row = 1)\n",
    "inframe_mut_figS3e.update_yaxes(type = 'log', range = [-10.15, -6.9], exponentformat = 'e', dtick = 1, domain=[0.48, 0.67], row = 2)\n",
    "inframe_mut_figS3e.update_yaxes(type = 'log', range = [-10.1, -6.9], exponentformat = 'e', dtick = 1, domain=[0.24, 0.43], row = 3)\n",
    "inframe_mut_figS3e.update_yaxes(type = 'log', range = [-10.1, -6.9], exponentformat = 'e', dtick = 1, domain=[0, 0.19], row = 4)\n",
    "\n",
    "inframe_mut_figS3e.update_layout(width = 750, height = 500, margin = dict(l = 65, r = 25, b = 35, t = 20), legend=dict(y = -0.03, x = 0.35, orientation='h'))\n",
    "\n",
    "inframe_mut_figS3e.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e936135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inframe_mut_figS3e.write_image('./plots/revision_STR_absolutefreq_figS3e.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8526920",
   "metadata": {},
   "source": [
    "## Direct repeat duplications <a name=\"mutation_internal_indel_DR_duplications\"></a>\n",
    "\n",
    "#### Find duplications and count them positionally <a name=\"mutation_internal_indel_DR_duplications_count\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe669d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve info for insertions that overlap with direct repeats\n",
    "DRs_ins = dict()\n",
    "for chrom in range(chr_range,23):\n",
    "    long_ins_in_DR = variants_ins_long[chrom].loc[variants_ins_long[chrom]['POS'].isin(pos_expand_all['DR'].loc[pos_expand_all['DR']['chrom'] == chrom]['pos'])].copy()\n",
    "    DRs_current = all_DRs.loc[all_DRs['chrom'] == chrom][['start', 'end', 'chrom', 'length', 'Sequence', 'L_end', 'R_start', 'stem_len', 'spacer', 'seq_L', 'seq_R', '#MM', 'MM_pos', 'MM_pos_L', 'MM_pos_R', 'spacer_pos', \"spacer_5'_pos\", 'spacer_middle_pos', \"spacer_3'_pos\"]]\n",
    "    DRs_ins[chrom] = DRs_current.iloc[np.searchsorted(DRs_current['end'], long_ins_in_DR['POS'])].copy()\n",
    "    DRs_ins[chrom][['POS', 'REF', 'ALT', 'AS_VQSLOD']] = long_ins_in_DR[['POS', 'REF', 'ALT', 'AS_VQSLOD']].values\n",
    "DRs_ins = pd.concat(DRs_ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18d9017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sequence of direct repeat +/- 10nt, in order to locate template position of inserted sequences\n",
    "DRs_ins['seq+'] = [reference_genome[chrom][start-10: end+10] for chrom, start, end in zip(DRs_ins['chrom'], DRs_ins['start'], DRs_ins['end'])]\n",
    "DRs_ins['insert_pos'] = [[match.start(0) for match in re.finditer(insert, seq, overlapped = True)] for insert, seq in zip(DRs_ins['ALT'], DRs_ins['seq+'])]\n",
    "DRs_ins['n_insert_found'] = [len(location) for location in DRs_ins['insert_pos']]\n",
    "# Select DRs with one sequence match from insertion to template\n",
    "DRs_ins_match = DRs_ins.loc[DRs_ins['n_insert_found'] == 1].copy().reset_index()\n",
    "DRs_ins_match['insert_pos'] = [match[0] for match in DRs_ins_match['insert_pos']]\n",
    "DRs_ins_match['alt_len'] = DRs_ins_match['ALT'].str.len()\n",
    "# Location of insertion within template\n",
    "DRs_ins_match['L_end'] = DRs_ins_match['L_end'].astype(int)\n",
    "DRs_ins_match['R_start'] = DRs_ins_match['R_start'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd967a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print color-coded text diagrams showing position of templated insertions and position of repeats and mismatches\n",
    "def highlight_dr_ins(current_dr):\n",
    "    current_str_series = pd.DataFrame(enumerate(current_dr['seq+']))[1]\n",
    "\n",
    "    # label insertion template\n",
    "    current_str_series[current_dr['insert_pos']+1] = bg(255, 150, 50) + current_str_series[current_dr['insert_pos']+1]\n",
    "    if current_dr['insert_pos'] + current_dr['alt_len'] in current_str_series.index:\n",
    "        current_str_series[current_dr['insert_pos'] + current_dr['alt_len']] =  bg.rs + current_str_series[current_dr['insert_pos'] + current_dr['alt_len']]\n",
    "\n",
    "    # label MM positions, left and right repeats\n",
    "    current_str_series.index += -10 + current_dr['start']\n",
    "    for pos in current_dr['MM_pos_L']:\n",
    "        current_str_series[pos] = ef.inverse + current_str_series[pos] + ef.rs\n",
    "    for pos in current_dr['MM_pos_R']:\n",
    "        current_str_series[pos] = ef.inverse + current_str_series[pos] + ef.rs\n",
    "    current_str_series[current_dr['start']] = fg.blue + current_str_series[current_dr['start']]\n",
    "    if current_dr['L_end'] != current_dr['R_start']:\n",
    "        current_str_series[current_dr['L_end']] = fg.rs + current_str_series[current_dr['L_end']]\n",
    "    current_str_series[current_dr['R_start']] = fg.li_blue + current_str_series[current_dr['R_start']]\n",
    "    current_str_series[current_dr['end']] = fg.rs + current_str_series[current_dr['end']]\n",
    "    \n",
    "    return current_str_series.str.cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d863f742",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show first 50 text diagrams, used in Fig. S4c\n",
    "for dr in DRs_ins_match.index[:50]:\n",
    "    print(highlight_dr_ins(DRs_ins_match.loc[dr]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4d8365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count where insertions fall within the repeat structure\n",
    "def dr_ins_count(current_dr):\n",
    "    current_str_series = pd.DataFrame(enumerate(current_dr['seq+']))\n",
    "\n",
    "    current_str_series['ins_start'] = 0\n",
    "    current_str_series['ins_mid'] = 0\n",
    "    current_str_series['ins_flank'] = 0\n",
    "    current_str_series['pos_type'] = np.nan\n",
    "\n",
    "    # count insertion start/end points\n",
    "    current_str_series.loc[current_dr['insert_pos']+1:current_dr['insert_pos']+1, 'ins_start'] +=1\n",
    "    if current_dr['insert_pos'] + current_dr['alt_len']-1 in current_str_series.index:\n",
    "        current_str_series.loc[current_dr['insert_pos'] + current_dr['alt_len']-1 : current_dr['insert_pos'] + current_dr['alt_len']-1, 'ins_start'] +=1\n",
    "    # count insertion mid points\n",
    "    current_str_series.loc[current_dr['insert_pos']+2:current_dr['insert_pos']+current_dr['alt_len']-2, 'ins_mid'] +=1\n",
    "     # count insertion flank start/end points\n",
    "    current_str_series.loc[current_dr['insert_pos']:current_dr['insert_pos'], 'ins_flank'] +=1\n",
    "    if current_dr['insert_pos']+1 + current_dr['alt_len'] in current_str_series.index:\n",
    "        current_str_series.loc[current_dr['insert_pos'] + current_dr['alt_len'] : current_dr['insert_pos'] + current_dr['alt_len'], 'ins_flank'] +=1\n",
    "   \n",
    "    # count MM positions, left and right repeats\n",
    "    current_str_series.index += -10 + current_dr['start']\n",
    "    current_str_series.loc[current_dr['start']-2:current_dr['start']-1, 'pos_type'] = 'flank'\n",
    "    current_str_series.loc[current_dr['end']:current_dr['end']+1, 'pos_type'] = 'flank'\n",
    "    current_str_series.loc[current_dr['start']:current_dr['start'], 'pos_type'] = 'L_start'\n",
    "    current_str_series.loc[current_dr['start']+1:current_dr['L_end']-2, 'pos_type'] = 'repeat_L'\n",
    "    current_str_series.loc[current_dr['L_end']-1:current_dr['L_end']-1, 'pos_type'] = 'L_end'\n",
    "    current_str_series.loc[current_dr['L_end']:current_dr['L_end'], 'pos_type'] = 'spacer_start'\n",
    "    current_str_series.loc[current_dr['L_end']+1:current_dr['R_start']-1, 'pos_type'] = 'spacer'\n",
    "    current_str_series.loc[current_dr['R_start']-1:current_dr['R_start']-1, 'pos_type'] = 'spacer_end'\n",
    "    current_str_series.loc[current_dr['R_start']:current_dr['R_start'], 'pos_type'] = 'R_start'\n",
    "    current_str_series.loc[current_dr['R_start']+1:current_dr['end']-2, 'pos_type'] = 'repeat_R'\n",
    "    current_str_series.loc[current_dr['end']-1:current_dr['end']-1, 'pos_type'] = 'R_end'\n",
    "    for pos in current_dr['MM_pos_L']:\n",
    "        current_str_series.loc[pos:pos, 'pos_type'] = 'mismatch_L'\n",
    "    for pos in current_dr['MM_pos_R']:\n",
    "        current_str_series.loc[pos:pos, 'pos_type'] = 'mismatch_R'\n",
    "    current_str_series['total_count'] = 1\n",
    "\n",
    "    return current_str_series.groupby(['pos_type']).sum()[['ins_start', 'ins_mid', 'ins_flank', 'total_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de852cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count where insertions fall within the repeat structure\n",
    "dr_count_sum = pd.DataFrame()\n",
    "for dr in DRs_ins_match.index:\n",
    "    dr_count_sum = dr_count_sum.add(dr_ins_count(DRs_ins_match.loc[dr]), fill_value = 0)\n",
    "\n",
    "# Calculate frequency\n",
    "dr_count_freq = dr_count_sum.div(dr_count_sum['total_count'], axis=0)\n",
    "dr_count_freq['ins_start'] = dr_count_freq['ins_start'] / (dr_count_sum.sum()['ins_start'] / dr_count_sum.sum()['total_count'])\n",
    "dr_count_freq['ins_flank'] = dr_count_freq['ins_flank'] / (dr_count_sum.sum()['ins_flank'] / dr_count_sum.sum()['total_count'])\n",
    "dr_count_freq['ins_mid'] = dr_count_freq['ins_mid'] / (dr_count_sum.sum()['ins_mid'] / dr_count_sum.sum()['total_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8eeaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count separately for DRs with short spacers\n",
    "dr_count_sum_spacerb10 = pd.DataFrame()\n",
    "for dr in DRs_ins_match.loc[DRs_ins_match['spacer'] <10].index:\n",
    "    dr_count_sum_spacerb10 = dr_count_sum_spacerb10.add(dr_ins_count(DRs_ins_match.loc[dr]), fill_value = 0)\n",
    "\n",
    "dr_count_freq_spacerb10 = dr_count_sum_spacerb10.div(dr_count_sum_spacerb10['total_count'], axis=0)\n",
    "dr_count_freq_spacerb10['ins_start'] = dr_count_freq_spacerb10['ins_start'] / (dr_count_sum_spacerb10.sum()['ins_start'] / dr_count_sum_spacerb10.sum()['total_count'])\n",
    "dr_count_freq_spacerb10['ins_flank'] = dr_count_freq_spacerb10['ins_flank'] / (dr_count_sum_spacerb10.sum()['ins_flank'] / dr_count_sum_spacerb10.sum()['total_count'])\n",
    "dr_count_freq_spacerb10['ins_mid'] = dr_count_freq_spacerb10['ins_mid'] / (dr_count_sum_spacerb10.sum()['ins_mid'] / dr_count_sum_spacerb10.sum()['total_count'])\n",
    "\n",
    "dr_count_freq_spacerb10 = dr_count_freq_spacerb10.reindex(['L_start', 'mismatch_L','repeat_L', 'L_end', 'spacer_start', 'spacer', 'spacer_end', 'R_start', 'mismatch_R','repeat_R', 'R_end', 'flank'])\n",
    "dr_count_freq_spacerb10.index = ['Left start', 'MM left', 'DR left', 'Left end', 'Spacer start', 'Spacer', 'Spacer end', 'Right start', 'MM right', 'DR right', 'Right end', 'flank']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65789e3c",
   "metadata": {},
   "source": [
    "####  Plot for Fig. S4d <a name=\"mutation_internal_indel_DR_duplications_plot_figS4D\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932f4523",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_duplication_figS4d = go.Figure()\n",
    "dr_duplication_figS4d.add_trace(go.Bar(x = dr_count_freq_spacerb10.index, y = dr_count_freq_spacerb10['ins_start']-1, base = 1, name = 'duplication start/end'))\n",
    "#dr_duplication_figS4d.add_trace(go.Bar(x = dr_count_freq_spacerb10.index, y = dr_count_freq_spacerb10['ins_mid']-1, base = 1, name = 'duplication middle'))\n",
    "dr_duplication_figS4d.add_trace(go.Bar(x = dr_count_freq_spacerb10.index, y = dr_count_freq_spacerb10['ins_flank']-1, base = 1, name = 'duplication flank'))\n",
    "dr_duplication_figS4d.update_yaxes(zeroline = False, type = 'log', dtick = np.log10(2), range = [-0.725,0.95], tickmode = 'array', tickvals = [8,4,2,1,0.5,0.25], ticktext = [8,4,2,1,'1/2', '1/4'], title = dict(text = 'obs. / exp.', standoff = 0, font = dict(size = 14)))\n",
    "dr_duplication_figS4d.update_layout(width = 450, height = 250, margin = dict(l = 65, r = 25, b = 60, t = 20), legend=dict(y = 1.175, x = 0.05, orientation='h'))\n",
    "dr_duplication_figS4d.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894974c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_duplication_figS4d.write_image('./plots/revision_DR_ins_position_bias_fig_S4d.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f728476d",
   "metadata": {},
   "source": [
    "#### Errors within DR duplications <a name=\"mutation_internal_indel_DR_duplications_errors\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1359aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplications, allowing for a single error\n",
    "DRs_ins['insert_pos_1error'] = [[match.start(0) for match in re.finditer('(' + insert + '){e<=1}', seq, overlapped = True)] for insert, seq in zip(DRs_ins['ALT'], DRs_ins['seq+'])]\n",
    "DRs_ins['n_insert_found_1error'] = [len(location) for location in DRs_ins['insert_pos_1error']]\n",
    "\n",
    "# Find duplications, allowing for two errors\n",
    "DRs_ins['insert_pos_2error'] = [[match.start(0) for match in re.finditer('(' + insert + '){e<=2}', seq, overlapped = True)] for insert, seq in zip(DRs_ins['ALT'], DRs_ins['seq+'])]\n",
    "DRs_ins['n_insert_found_2error'] = [len(location) for location in DRs_ins['insert_pos_2error']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c77cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect duplications with 0, 1 and 2 errors\n",
    "DR_ins_0error = DRs_ins.loc[(DRs_ins['n_insert_found'] == 1) & (DRs_ins['ALT'].str.len() >= 10)].copy()\n",
    "DR_ins_1error = DRs_ins.loc[(DRs_ins['n_insert_found'] == 0) & (DRs_ins['n_insert_found_1error'] == 1) & (DRs_ins['ALT'].str.len() >= 10)].copy()\n",
    "DR_ins_2error = DRs_ins.loc[(DRs_ins['n_insert_found'] == 0) & (DRs_ins['n_insert_found_2error'] == 1)& (DRs_ins['ALT'].str.len() >= 10)].copy()\n",
    "\n",
    "DR_ins_1error['insert_pos_1error'] = [pos[0] for pos in DR_ins_1error['insert_pos_1error']]\n",
    "DR_ins_2error['insert_pos_2error'] = [pos[0] for pos in DR_ins_2error['insert_pos_2error']]\n",
    "DR_ins_0error['insert_pos'] = [pos[0] for pos in DR_ins_0error['insert_pos']]\n",
    "\n",
    "# Get motif sequence +/-1 nt for counting trinucleotides\n",
    "DR_ins_0error['dup_seq+'] = [seq[pos-1:pos+length+1] for seq, pos, length in zip(DR_ins_0error['seq+'], DR_ins_0error['insert_pos'], DR_ins_0error['ALT'].str.len())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1ab7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 1-error duplications, find location of interruptions within each DR\n",
    "DR_ins_1error['dup_seq'] = [seq[pos:pos+length] for seq, pos, length in zip(DR_ins_1error['seq+'], DR_ins_1error['insert_pos_1error'], DR_ins_1error['ALT'].str.len())]\n",
    "DR_ins_1error['dup_mut_pos'] = [np.where([a!=b for a,b in zip(seq1, seq2)]) for seq1, seq2 in zip(DR_ins_1error['dup_seq'], DR_ins_1error['ALT'])]\n",
    "DR_ins_1error['dup_mut_pos'] = [pos[0] for pos in DR_ins_1error['dup_mut_pos']]\n",
    "DR_ins_1error['dup_seq+'] = [seq[pos-1:pos+length+1] for seq, pos, length in zip(DR_ins_1error['seq+'], DR_ins_1error['insert_pos_1error'], DR_ins_1error['ALT'].str.len())]\n",
    "\n",
    "# Restrict to SNVs\n",
    "DR_ins_1error = DR_ins_1error.loc[DR_ins_1error['dup_mut_pos'].map(len) == 1]\n",
    "DR_ins_1error['dup_mut_pos'] = [pos[0] for pos in DR_ins_1error['dup_mut_pos']]\n",
    "\n",
    "# Count errors by trinucleotide context\n",
    "DR_ins_1error['error_tri'] = [seq[pos:pos+3] for seq, pos in zip(DR_ins_1error['dup_seq+'], DR_ins_1error['dup_mut_pos'])]\n",
    "DR_ins_1error['error_mut'] = [seq[pos] for seq, pos in zip(DR_ins_1error['ALT'], DR_ins_1error['dup_mut_pos'])]\n",
    "DR_ins_1error_muterrors = DR_ins_1error.groupby(['error_tri', 'error_mut']).count()['ALT'].unstack().reindex(all_triplets).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58e390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 1-error duplications, find location of interruptions within each DR\n",
    "DR_ins_2error['dup_seq'] = [seq[pos:pos+length] for seq, pos, length in zip(DR_ins_2error['seq+'], DR_ins_2error['insert_pos_2error'], DR_ins_2error['ALT'].str.len())]\n",
    "DR_ins_2error['dup_mut_pos'] = [np.where([a!=b for a,b in zip(seq1, seq2)]) for seq1, seq2 in zip(DR_ins_2error['dup_seq'], DR_ins_2error['ALT'])]\n",
    "DR_ins_2error['dup_mut_pos'] = [pos[0] for pos in DR_ins_2error['dup_mut_pos']]\n",
    "DR_ins_2error['dup_seq+'] = [seq[pos-1:pos+length+1] for seq, pos, length in zip(DR_ins_2error['seq+'], DR_ins_2error['insert_pos_2error'], DR_ins_2error['ALT'].str.len())]\n",
    "\n",
    "# Restrict to SNVs\n",
    "DR_ins_2error = DR_ins_2error.loc[DR_ins_2error['dup_mut_pos'].map(len) == 2].copy()\n",
    "\n",
    "# Position of first and second errors\n",
    "DR_ins_2error['dup_mut_pos_0'] = [pos[0] for pos in DR_ins_2error['dup_mut_pos']]\n",
    "DR_ins_2error['dup_mut_pos_1'] = [pos[1] for pos in DR_ins_2error['dup_mut_pos']]\n",
    "\n",
    "# Count errors by trinucleotide context\n",
    "DR_ins_2error['error_tri_1'] = [seq[pos:pos+3] for seq, pos in zip(DR_ins_2error['dup_seq+'], DR_ins_2error['dup_mut_pos_0'])]\n",
    "DR_ins_2error['error_mut_1'] = [seq[pos] for seq, pos in zip(DR_ins_2error['ALT'], DR_ins_2error['dup_mut_pos_0'])]\n",
    "DR_ins_2error['error_tri_2'] = [seq[pos:pos+3] for seq, pos in zip(DR_ins_2error['dup_seq+'], DR_ins_2error['dup_mut_pos_1'])]\n",
    "DR_ins_2error['error_mut_2'] = [seq[pos] for seq, pos in zip(DR_ins_2error['ALT'], DR_ins_2error['dup_mut_pos_1'])]\n",
    "\n",
    "# Distinguish between double nucleotide errors and two SNVs\n",
    "DR_ins_2error_doublemut = DR_ins_2error.loc[DR_ins_2error['dup_mut_pos_0'] +1 == DR_ins_2error['dup_mut_pos_1']].copy()\n",
    "DR_ins_2error = DR_ins_2error.loc[DR_ins_2error['dup_mut_pos_0'] +1 != DR_ins_2error['dup_mut_pos_1']].copy()\n",
    "\n",
    "# Count errors by trinucleotide context\n",
    "DR_ins_2error_muterrors_1 = DR_ins_2error.groupby(['error_tri_1', 'error_mut_1']).count()['ALT'].unstack().reindex(all_triplets).fillna(0).astype(int)\n",
    "DR_ins_2error_muterrors_2 = DR_ins_2error.groupby(['error_tri_2', 'error_mut_2']).count()['ALT'].unstack().reindex(all_triplets).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f468fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all counts and calculate normalized frequency\n",
    "DR_ins_muterrors_all = DR_ins_1error_muterrors + DR_ins_2error_muterrors_1 + DR_ins_2error_muterrors_2\n",
    "DR_ins_muterrors_all = DR_ins_muterrors_all.stack()\n",
    "DR_ins_muterrors_all.index = [tri+'_'+alt for tri, alt in zip(DR_ins_muterrors_all.index.get_level_values(0), DR_ins_muterrors_all.index.get_level_values(1))]\n",
    "DR_ins_muterrors_RC = triplet_combine_RC(DR_ins_muterrors_all, mut_input=True)\n",
    "\n",
    "DR_ins_muterrors_tri_0 = pd.Series(flatten([re.findall('...', seq) + re.findall('...', seq[1:]) + re.findall('...', seq[2:]) for seq in DR_ins_0error['dup_seq+']])).value_counts()\n",
    "DR_ins_muterrors_tri_1 = pd.Series(flatten([re.findall('...', seq) + re.findall('...', seq[1:]) + re.findall('...', seq[2:]) for seq in DR_ins_1error['dup_seq+']])).value_counts()\n",
    "DR_ins_muterrors_tri_2 = pd.Series(flatten([re.findall('...', seq) + re.findall('...', seq[1:]) + re.findall('...', seq[2:]) for seq in DR_ins_2error['dup_seq+']])).value_counts()\n",
    "\n",
    "DR_ins_muterrors_tri = triplet_combine_RC(DR_ins_muterrors_tri_0 + DR_ins_muterrors_tri_1 + DR_ins_muterrors_tri_2, mut_output=True)\n",
    "DR_ins_muterrors_freq = DR_ins_muterrors_RC / DR_ins_muterrors_tri\n",
    "DR_ins_muterrors_norm = DR_ins_muterrors_freq / (denovo_freq_RC / denovo_n_genomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d287387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of error frequencies, weighted by trinucleotide count\n",
    "np.average(DR_ins_muterrors_freq, weights = DR_ins_muterrors_tri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed704be2",
   "metadata": {},
   "source": [
    "####  Plot for Fig. S4e <a name=\"mutation_internal_indel_DR_duplications_plot_figS4E\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ea0efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "DR_spectrum_plot_figS4e = go.Figure()\n",
    "for group in colors.index:\n",
    "    DR_spectrum_plot_figS4e.add_trace(go.Bar(x = DR_ins_muterrors_norm.loc[colors['ind'][group]].index, y = DR_ins_muterrors_norm.loc[colors['ind'][group]], marker = dict(color = colors['color'][group]), name = group, showlegend = True))\n",
    "DR_spectrum_plot_figS4e.update_xaxes(dtick = dict(font = dict(size = 6)))\n",
    "DR_spectrum_plot_figS4e.update_yaxes(exponentformat = 'e', title = dict(text = 'Relative mutation frequency', standoff = 0, font = dict(size = 14)))\n",
    "DR_spectrum_plot_figS4e.update_layout(width = 1400, height = 250, margin = dict(l = 75, r = 25, b = 60, t = 20))\n",
    "\n",
    "DR_spectrum_plot_figS4e.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7d3757",
   "metadata": {},
   "outputs": [],
   "source": [
    "DR_spectrum_plot_figS4e.write_image('./plots/revision_DR_dup_error_spectrum_fig_S4e.png', format='png', scale = 10, engine = 'orca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7271211",
   "metadata": {},
   "source": [
    "####  Frequency of double-nucleotide variants, used in Fig. S4f <a name=\"mutation_internal_indel_DR_duplications_figS4F\"></a>\n",
    "\n",
    "[Return to Table of Contents](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4028502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to combine reverse complements for double-nucleotide variants\n",
    "def reverse_complement_dnv(mut):\n",
    "    complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A', 'N': 'N'}\n",
    "    return ''.join([complement[base] for base in mut.split('>')[0][::-1]])+'>'+''.join([complement[base] for base in mut.split('>')[1][::-1]])\n",
    "\n",
    "dinuc = [base1+base2 for base1 in ['A', 'T', 'G', 'C'] for base2 in ['A', 'T', 'G', 'C']]\n",
    "\n",
    "dinuc_F = ['AA', 'AG', 'AC', 'TG', 'TC', 'GG']\n",
    "dinuc_RC = ['TT', 'CT', 'GT', 'CA', 'GA', 'CC']\n",
    "dinuc_sym = ['AT', 'TA', 'GC', 'CG']\n",
    "\n",
    "dinuc_mut_F = [di1 + '>' + di2 for di1 in dinuc_F for di2 in dinuc if (di1[0] != di2[0]) & (di1[1] != di2[1])]\n",
    "dinuc_mut_RC = [reverse_complement_dnv(mut) for mut in dinuc_mut_F]\n",
    "dinuc_mut_sym = [di1 + '>' + di2 for di1 in dinuc_sym for di2 in dinuc if (di1[0] != di2[0]) & (di1[1] != di2[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac525a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DR_dnv_sum = pd.Series([pos1[1] + pos2[1] + '>' + mut1 + mut2 for pos1, pos2, mut1, mut2 in zip(DR_ins_2error_doublemut['error_tri_1'], DR_ins_2error_doublemut['error_tri_2'], DR_ins_2error_doublemut['error_mut_1'], DR_ins_2error_doublemut['error_mut_2'])]).value_counts()\n",
    "DR_dnv_sum_RC = pd.concat([(DR_dnv_sum.reindex(dinuc_mut_F) + DR_dnv_sum.reindex(dinuc_mut_RC).set_axis(dinuc_mut_F)), DR_dnv_sum.reindex(dinuc_mut_sym)])\n",
    "DR_dnv_freq = DR_dnv_sum_RC / DR_dnv_sum_RC.sum()\n",
    "\n",
    "DR_ins_muterrors_di_0 = pd.Series(flatten([re.findall('..', seq) + re.findall('..', seq[1:]) for seq in DR_ins_0error['dup_seq+']])).value_counts()\n",
    "DR_ins_muterrors_di_1 = pd.Series(flatten([re.findall('..', seq) + re.findall('..', seq[1:]) for seq in DR_ins_1error['dup_seq+']])).value_counts()\n",
    "DR_ins_muterrors_di_2 = pd.Series(flatten([re.findall('..', seq) + re.findall('..', seq[1:]) for seq in DR_ins_2error['dup_seq+']])).value_counts()\n",
    "\n",
    "DR_ins_muterrors_di = DR_ins_muterrors_di_0 + DR_ins_muterrors_di_1 + DR_ins_muterrors_di_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da1667b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of DNVs sorted by frequency, for Fig. S4f\n",
    "(DR_dnv_sum_RC / (DR_ins_muterrors_di.reindex([di[:2] for di in DR_dnv_sum_RC.index])).values).dropna().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d66bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DR_dnv_sum_RC.sum() / (DR_ins_0error['ALT'].str.len().sum() + DR_ins_1error['ALT'].str.len().sum() + DR_ins_2error['ALT'].str.len().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
